[
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://realpython.com/",
    "title": "Python Tutorials ‚Äì Real Python",
    "content": "Learn how Python's continue statement works, when to use it, common mistakes to avoid, and what happens under the hood in CPython byte code. Aug 04, 2025\n\nbasics\npython ‚Äî FREE Email Series ‚Äî üêç Python Tricks üíå üîí No spam. Unsubscribe any time. Jul 30, 2025\n\nadvanced\npython Jul 29, 2025\n\nintermediate\npython Jul 28, 2025\n\nintermediate\npython Jul 23, 2025\n\nintermediate\nweb-dev Jul 22, 2025\n\nintermediate\npython Jul 21, 2025\n\nintermediate\npython Jul 16, 2025\n\nintermediate\npython Jul 15, 2025\n\nintermediate\ndata-science\neditors\npython\ntools Jul 14, 2025\n\nbasics\npython Jul 09, 2025\n\nbasics\npython Jul 08, 2025\n\nintermediate\npython Jul 07, 2025\n\ncommunity Jul 02, 2025\n\nintermediate\npython Jul 01, 2025\n\nintermediate\nbest-practices Jun 30, 2025\n\nintermediate\nmachine-learning Jun 25, 2025\n\nbasics\npython Jun 24, 2025\n\nintermediate\ndatabases\ndata-science\npython Jun 23, 2025\n\nbasics\nbest-practices"
  },
  {
    "url": "https://developer.mozilla.org/en-US/docs/Web",
    "title": "Web technology for developers | MDN",
    "content": "Web technology reference for developers Structure of content on the web Code used to describe document style General-purpose scripting language Protocol for transmitting web resources Interfaces for building web applications Developing extensions for web browsers Build web projects usable for all Web technology reference for developers Learn web development Learn web development Learn to structure web content with HTML Learn to style content using CSS Learn to run scripts in the browser Learn to make the web accessible to all A customized MDN experience Get real-time assistance and support All browser compatibility updates at a glance Learn how to use MDN Plus Frequently asked questions about MDN Plus Write, test and share your code Scan a website for free Get real-time assistance and support The open Web presents incredible opportunities for developers. To take full advantage of these technologies, you need to know how to use them. Below you'll find links to our Web technology documentation. The Web Developer Guides provide practical, how-to content to help you use Web technologies for your goals or needs. Tutorials to take you step-by-step through learning HTML, CSS, JavaScript, and Web APIs. Enabling as many people as possible to use websites, even when those people's abilities are limited in some way. Making content as available and interactive as possible, as soon as possible. Protecting users' personal data. Protecting users from data leaks and data theft, side-channel attacks, and attacks such as cross-site scripting, content injection, and click-jacking. Definitions of Web-related terms. JavaScript programming APIs you can use to build apps on the Web. HTML provides the fundamental building blocks for structuring Web documents and apps. Cascading Style Sheets are used to describe the appearance of Web documents and apps. JavaScript is the Web's native programming language. WebAssembly allows programs written in C, C++, Rust, Swift, C#, Go, and more to run on the Web. HTTP is the fundamental Internet protocol for fetching documents, stylesheets, scripts, images, videos, fonts, and other resources over the Web √¢¬Ä¬î and for sending data back to Web servers. Formats, codecs, protocols, APIs, and techniques for embedding and streaming video, audio, and image content in Web documents and apps. Scalable Vector Graphics lets you create images that scale smoothly to any size. MathML lets you display complex mathematical notation on the Web. Uniform Resource Identifiers are used by various technologies, including the browser itself via the address bar, to identify resources in various ways. WebDriver is a browser-automation mechanism for remotely controlling a browser by emulating the actions of a real person using the browser. It's widely used for cross-browser testing of Web apps. Web Extensions are a way for you to give users enhanced capabilities in their browsers √¢¬Ä¬î for doing things such as blocking ads and other content, customizing the appearance of pages, and more. Web App Manifests let you enable users to install Web apps to their device home screens, with aspects such as portrait/landscape screen orientation and display mode (e.g., full screen) pre-set. Progressive Web Apps provide a user experience similar to native mobile apps. OpenSearch allows a website to describe a search engine for itself, so that a browser or other client application can use that search engine. The Extensible Markup Language is a strict serialization of the Document Object Model. Extensible Stylesheet Language Transformations is an XML-based language used, in conjunction with specialized processing software, for the transformation of XML documents. XPath uses a non-XML syntax to provide a flexible way of addressing (pointing to) different parts of an XML document. It can also be used to test addressed nodes within a document to determine whether they match a pattern or not. EXSLT a set of extensions to XSLT. Documentation for the set of web-developer tools built into Firefox. Documentation for the set of web-developer tools built into Chrome. Documentation for the set of web-developer tools built into Safari. Documentation for the set of web-developer tools built into Edge. This page was last modified on Jul 29, 2025 by MDN contributors. Your blueprint for a better internet. Visit Mozilla Corporation√¢¬Ä¬ôs not-for-profit parent, the Mozilla Foundation.Portions of this content are √Ç¬©1998√¢¬Ä¬ì2025 by individual mozilla.org contributors. Content available under a Creative Commons license."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#bodyContent",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Main_Page",
    "title": "Wikipedia, the free encyclopedia",
    "content": "2020 Missouri Amendment¬†2, also called the Medicaid Expansion Initiative, was a ballot measure to amend the Constitution of Missouri to expand Medicaid under the Affordable Care Act. The initiative was on the August¬†4, 2020, primary ballot and passed with 53.27% of the vote. Following Medicaid expansion initiatives in other states, Republican lawmakers in Nebraska and Utah added work requirements to their states' expansions; supporters aimed to prevent this by proposing state constitutional amendments for future Medicaid expansion initiatives. The measure was supported most in urban areas and opposed in rural areas. After a delay due to a lack of funding from the Missouri General Assembly and resulting litigation, the initiative was slowly implemented in October¬†2021. Republican lawmakers attempted to roll back the program and add a work requirement through a state constitutional amendment, which failed after the United States Supreme Court prevented its implementation. (Full¬†article...) August 4 The Swedish pop group Tages released six studio albums and 26 singles in their home country during their existence from 1963 to 1970. Their professional career began during the summer of 1964, when they won a contest awarding them a recording contract with Platina Records, an independent record label. Their debut single, \"Sleep Little Girl\", was released in October¬†1964 and became a large hit in Sweden. The band's debut album, Tages, was released in November¬†1965, reaching the top¬†10 of the Finnish Albums Charts. The band's fourth and fifth albums, Contrast and Studio (both 1967), were released by Parlophone, whereas their sixth and final album, The Lilac Years (1969), was released through Fontana Records. The Lilac Years and the band's final three singles were released under the name Blond, which was considered more internationally viable by their management. (Full¬†list...) The Cheat is a 1923 American silent drama film produced by Famous Players‚ÄìLasky and distributed by Paramount Pictures. It is a remake of Cecil B. DeMille's 1915 film The Cheat, using the same script by Hector Turnbull and Jeanie MacPherson. The remake stars Pola Negri and was directed by George Fitzmaurice,  and tells the story of Carmelita De Cordoba, a beautiful young South American woman who has been betrothed by her stern father to Don Pablo, whom she despises, and then meets and falls in love with Dudley Drake, a New York City broker. With no known prints of The Cheat remaining, it is considered a lost film, although there is an extant version in novel form, written in the same year as the film by Russell Holman, a Paramount Pictures employee. This color lithograph poster was produced in 1923 by Paramount to promote The Cheat, and depicts Negri as Carmelita with Charles de Rochefort as Claude Mace, an art swindler masquerading as the East Indian prince Rao-Singh. Poster credit: Paramount Pictures; restored by Ezarate Wikipedia is written by volunteer editors and hosted by the Wikimedia Foundation, a non-profit organization that also hosts a range of other volunteer projects: This Wikipedia is written in English. Many other Wikipedias are available; some of the largest are listed below."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Wikipedia:Contents",
    "title": "Wikipedia:Contents - Wikipedia",
    "content": "Easily explore Wikipedia using the topic links below. You can also search directly using the search bar. All section headers are clickable for quick navigation. Wikipedia's content is divided into broad subject areas: Topics Types Places, people and times Indices"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Portal:Current_events",
    "title": "Portal:Current events - Wikipedia",
    "content": "Armed conflicts and attacks Business and economy Disasters and accidents International relations Armed conflicts and attacks Disasters and accidents Law and crime Armed conflicts and attacks Disasters and accidents Law and crime Politics and elections Sports Armed conflicts and attacks Business and economy International relations Law and crime Armed conflicts and attacks Arts and culture Disasters and accidents Health and environment International relations Law and crime Politics and elections Science and technology Armed conflicts and attacks Disasters and accidents International relations Science and technology Armed conflicts and attacks Disasters and accidents International relations Law and crime Politics and elections"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Special:Random",
    "title": "Libbie Janse van Rensburg - Wikipedia",
    "content": "Elizabetha \"Libbie\" Magdalena Janse van Rensburg (born 28 September 1994)[1]  is a South African rugby union and sevens player.[2][3] Janse van Rensburg made her debut for the Springbok Women in 2021. In a test match against Namibia, she scored two tries and added 14 conversions for a personal contribution of 38 points ‚Äì a new Test record for the Springbok Women.[4] In 2022 she was selected for the 2021 World Cup squad. In South Africa's second game against Fiji, they were awarded a penalty in the 79th minute, Janse van Rensburg kicked and South Africa went ahead 17‚Äì14. Fiji, would retain the restart and score a try to win the game.[5] In 2023, Janse van Rensburg was named as a part of the first professional women's team in South Africa, the Bulls Daisies.[6] She was the vice-captain in their 2023 Women's Premier Division win.[7][8] In April 2023, it was announced that Janse van Rensburg would join the sevens team ahead of the 2023 World Rugby Sevens Challenger Series. South Africa won the series and earned promotion to the SVNS, Janse van Rensburg scoring the game-winning try in the final against Belgium.[9][10] Janse van Rensburg played in WXV 2 for the XV team, where she was the top try scorer and top point scorer, as South Africa finished third.[11] She joined the sevens team for the 2023 Dubai Sevens, where she sustained an injury.[12] In 2024, Janse van Rensburg was named as the 2023 SA Rugby Women's player of the year.[13] Following her recovery, Janse van Rensburg joined the team for the 2024 Spain Sevens.[14] She was a member of the South African side that competed at the 2024 Summer Olympics in Paris.[15][16]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Wikipedia:About",
    "title": "Wikipedia:About - Wikipedia",
    "content": "Wikipedia is a free online encyclopedia that anyone can edit, and millions already have. Wikipedia's purpose is to benefit readers by presenting information on all branches of knowledge. Hosted by the Wikimedia Foundation, Wikipedia consists of freely editable content, with articles that usually contain numerous links guiding readers to more information. Written collaboratively by volunteers known as Wikipedians, Wikipedia articles can be edited by anyone with Internet access, except in limited cases in which editing is restricted to prevent disruption or vandalism. Since its creation on January 15, 2001, it has grown into the world's largest reference website, attracting over a billion visitors each month. Wikipedia currently has more than sixty-five million articles in more than 300 languages, including 7,034,172 articles in English, with 107,267 active contributors in the past month. Wikipedia's fundamental principles are summarized in its five pillars. While the Wikipedia community has developed many policies and guidelines, new editors do not need to be familiar with them before they start contributing. Anyone can edit Wikipedia's text, data, references, and images. The quality of content is more important than the expertise of who contributes it. Wikipedia's content must conform with its policies, including being verifiable by published reliable sources. Contributions based on personal opinions, beliefs, or personal experiences, unreviewed research, libellous material, and copyright violations are not allowed, and will not remain. Wikipedia's software makes it easy to reverse errors, and experienced editors watch and patrol bad edits. Wikipedia differs from printed references in important ways. Anyone can instantly improve it, add quality information, remove misinformation, and fix errors and vandalism. Since Wikipedia is continually updated, encyclopedic articles on major news events appear within minutes. For over 24 years, editors have volunteered their time and talents to create history's most comprehensive encyclopedia while providing references and other resources to researchers worldwide (see Researching with Wikipedia). In summary, Wikipedia has tested the wisdom of the crowd since 2001 and has found that it succeeds. To start editing simply click the Edit or Edit¬†source¬†button, or the pencil icon¬†, at the top of any non-protected Wikipedia page or section."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Wikipedia:Contact_us",
    "title": "Wikipedia:Contact us - Wikipedia",
    "content": "Introduction Readers\nHow to report a problem with an article, or find out more information. Article subjects\nProblems with articles about you, your company, or somebody you represent. Licensing\nHow to copy Wikipedia's information, donate your own, or report unlicensed use of your information. Donors\nFind out about the process, how to donate, and information about how your money is spent. Press and partnerships\nIf you're a member of the press looking to contact Wikipedia, or have a business proposal for us. Back to main page Thank you for your interest in contacting Wikipedia. Before proceeding, some important disclaimers: The links on the left should direct you to how to contact us or resolve problems. If you cannot find your issue listed there, you can email helpful, experienced volunteers at info-enwikimedia.org. Please refrain from emailing about disagreements with content; they will not be resolved via email."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Help:Contents",
    "title": "Help:Contents - Wikipedia",
    "content": "This page provides help with the most common questions about Wikipedia. Use the search box below, or browse the Help menu or the Help directory to search Wikipedia's help pages. For interactive assistance related to using and editing Wikipedia, see the help desk and the Teahouse. The Readers' FAQ and our about page contain the most commonly sought information about Wikipedia. For simple searches, there is a search bar at the top of every page. Type what you are looking for in the box. Suggested matches will appear in a dropdown list. Select any page in the list to go to that page. Or, select the \"Search\" button, or press ‚Üµ Enter, to go to a full search result. For advanced searches, see Help:Searching. There are other ways to browse and explore Wikipedia articles; many can be found at Wikipedia:Contents. See our disclaimer for cautions about Wikipedia's limitations. For mobile access, press the mobile view link at the very bottom of every desktop view page. Contributing is easy: see how to edit a page. For a quick summary on participating, see contributing to Wikipedia, and for a friendly tutorial, see our introduction. For a listing of introductions and tutorials by topic, see getting started. The Simplified Manual of Style and Cheatsheet can remind you of basic wiki markup. Be¬†bold in improving articles! When adding facts, please provide references so others may verify them. If you are affiliated with the article subject, please see our conflict of interest guideline. The simple guide to vandalism cleanup can help you undo malicious edits. If you're looking for places you can help out, the Task Center is the place to go, or check out what else is happening at the community portal. You can practice editing and experiment in a sandboxyour sandbox. If there is a problem with an article about yourself, a family member, a friend or a colleague, please read Biographies of living persons/Help. If you spot a problem with an article, you can fix it directly, by clicking on the \"Edit\" link at the top of that page. See the \"edit an article\" section of this page for more information. If you don't feel ready to fix the article yourself, post a message on the article's talk page. This will bring the matter to the attention of others who work on that article. There is a \"Talk\" link at the beginning of every article page. You can contact us. If it's an article about you or your organization, see Contact us ‚Äì Subjects. Check Your first article to see if your topic is appropriate, then the Article wizard will walk you through creating the article. Once you have created an article, see Writing better articles for guidance on how to improve it and what to include (like reference citations). For contributing images, audio or video files, see the Introduction to uploading images. Then the Upload wizard will guide you through that process. Answers to common problems can be found at frequently asked questions. Or check out where to ask questions or make comments. New users should seek help at the Teahouse if they're having problems while editing Wikipedia. More complex questions can be posed at the Help desk. Volunteers will respond as soon as they're able. Or ask for help on your talk page and a volunteer will visit you there! You can get live help with editing in the help chatroom. For help with technical issues, ask at the Village pump. If searching Wikipedia has not answered your question (for example, questions like \"Which country has the world's largest fishing fleet?\"), try the Reference Desk. Volunteers there will attempt to answer your questions on any topic, or point you toward the information you need. Articles created without a category should be tagged with a maintenance tag. Use the {{Uncategorized}} tag to put articles in a maintenance category. Optionally add a date parameter like {{Uncategorized|date=August 2025}} to put articles in by-date maintenance categories. Such tagged articles are found at Uncategorized pages. You can try to categorize articles yourself. One useful technique is to follow links in the article to other similar articles and see how they are categorized, so you know what to copy. Search Frequently Asked Questions Search the help desk archives"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Help:Introduction",
    "title": "Help:Introduction - Wikipedia",
    "content": "Wikipedia is made by people like you. Get started\nPolicies and Guidelines Editing\nReferencing\nImages\nTables Editing\nReferencing\nImages\nTables Talk pages\nNavigating WikipediaManual of StyleConclusion View all as single page For more training information, see also:"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Wikipedia:Community_portal",
    "title": "Wikipedia:Community portal - Wikipedia",
    "content": "This page provides a listing of current collaborations, tasks, and news about English Wikipedia. New to Wikipedia? See the contributing to Wikipedia page or our tutorial for everything you need to know to get started. For a listing of internal project pages of interest, see the department directory. For a listing of ongoing discussions and current requests, see the Dashboard. Welcome to the community bulletin board, which is a page used for announcements from WikiProjects and other groups. Included here are coordinated efforts, events, projects, and other general announcements. Yearly or infrequent events Monthly or continuous events Also consider posting WikiProject, Task Force, and Collaboration news at The Signpost's WikiProject Report page.\nPlease include your signature when adding a listing here. Latest tech news from the Wikimedia technical community. Please tell other users about these changes. Not all changes will affect you. Translations are available. Weekly highlight Updates for editors Updates for technical contributors Meetings and events Tech news prepared by Tech News writers and posted by bot¬†‚Ä¢ Contribute¬†‚Ä¢ Translate¬†‚Ä¢ Get help¬†‚Ä¢ Give feedback¬†‚Ä¢ Subscribe or unsubscribe. Discussions in the following areas have requested wider attention via Requests for comment: You can help improve the articles listed below! This list updates frequently, so check back here for more tasks to try. (See Wikipedia:Maintenance or the  Task Center for further information.) Help counter systemic bias by creating new articles on important women. Help improve popular pages, especially those of low quality. This week's article for improvement is: Housing Previous selections:\nHistory of hide materials¬†¬∑\nHuman behavior¬†¬∑\nEternal Sunshine of the Spotless Mind This week's backlog of the week is: Category:Wikipedia pages about a contentious topic mislabelled as protected When you create an article through Wikipedia's Articles for Creation process, \nit creates a draft in the Drafts area. The purpose of AfC process is to help new editors learn how to write better articles. If accepted, your draft can be a valuable contribution to the encyclopedia. Wikipedia is over 17 years old and has well over five million articles. The vast majority of those articles never went through AfC which is only a few years old. AfC works as a peer review process in which registered editors can either help create an article submitted or decline the article because it is unsuitable for Wikipedia. To nominate an existing draft or user sandbox for review at Articles for Creation, add the code {{subst:submit}} to the top of the draft or sandbox page. The AfC process allows others to review the draft when you are ready, and also to create the article for you, if it is suitable."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Special:RecentChanges",
    "title": "Recent changes - Wikipedia",
    "content": "This is a list of recent changes to Wikipedia."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard",
    "title": "Wikipedia:File upload wizard - Wikipedia",
    "content": "Thank you for offering to contribute an image or other media file for use on Wikipedia. This wizard will guide you through a questionnaire prompting you for the appropriate copyright and sourcing information for each file. Please ensure you understand copyright and the image use policy before proceeding. Uploads to Wikimedia Commons Upload a non-free file Uploads locally to the English Wikipedia; must comply with the non-free content criteria You do not have JavaScript enabled Sorry, in order to use this uploading script, JavaScript must be enabled. You can still use the plain Special:Upload page to upload files to the English Wikipedia without JavaScript. You are not currently logged in. Sorry, in order to use this uploading script and to upload files, you need to be logged in with your named account. Please log in and then try again. Your account has not become confirmed yet. Sorry, in order to upload files on the English Wikipedia, you need to have a confirmed account. Normally, your account will become confirmed automatically once you have made 10 edits and four days have passed since you created it. You may already be able to upload files on the Wikimedia Commons, but you can't do it on the English Wikipedia just yet. If the file you want to upload has a free license, please go to Commons and upload it there. Important note: if you don't want to wait until you are autoconfirmed, you may ask somebody else to upload a file for you at Wikipedia:Files for upload. In very rare cases an administrator may make your account confirmed manually through a request at Wikipedia:Requests for permissions/Confirmed. Sorry, a few special characters and character combinations cannot be used in the filename for technical reasons. This goes especially for #¬†<¬†>¬†[¬†]¬†|¬†:¬†{¬†}¬†/¬† and ~~~. Your filename has been modified to avoid these. Please check if it is okay now. The filename you chose seems to be very short, or overly generic. Please don't use: A file of this name already exists on Commons! If you upload your file with this name, you will be masking the existing file and make it inaccessible. Your new file will be displayed everywhere the existing file was previously used. This should not be done, except in very rare exceptional cases. Please don't upload your file under this name, unless you seriously know what you are doing. Choose a different name for your new file instead. A file of this name already exists. If you upload your file with this name, you will be overwriting the existing file. Your new file will be displayed everywhere the existing file was previously used. Please don't do this, unless you have a good reason to: It is very important that you read through the following options and questions, and provide all required information truthfully and carefully. Thank you for offering to upload a free work. Wikipedia loves free files. However, we would love it even more if you uploaded them on our sister project, Wikimedia Commons.\nFiles uploaded on Commons can be used immediately here on Wikipedia as well as on all its sister projects. Uploading files on Commons works just the same as here. Your Wikipedia account will automatically work on Commons too. Please consider uploading your file on Commons. However, if you prefer to do it here instead, you may go ahead with this form. You can also first use this form to collect the information about your file and then send it to Commons from here. Please note that by \"entirely self-made\" we really mean just that. Do not use this section for any of the following: Editors who falsely declare such items as their \"own work\" will be blocked from editing. Use this only if there is an explicit licensing statement in the source. The website must explicitly say that the image is released under a license that allows free re-use for any purpose, e.g. the Creative Commons Attribution license. You must be able to point exactly to where it says this. If the source website doesn't say so explicitly, please do not upload the file. Public Domain means that nobody owns any copyrights on this work. It does not mean simply that it is freely viewable somewhere on the web or that it has been widely used by others. This is not for images you simply found somewhere on the web. Most images on the web are under copyright and belong to somebody, even if you believe the owner won't care about that copyright. If it is in the public domain, you must be able to point to an actual law that makes it so. If you can't point to such a law but merely found this image somewhere, then please do not upload it. Please remember that you will need to demonstrate that: This file will be used in the following article: Enter the name of exactly one Wikipedia article, without the [[...]] brackets and without the \"http://en.wikipedia.org/...\" URL code. It has to be an actual article, not a talkpage, template, user page, etc. If you plan to use the file in more than one article, please name only one of them here. Then, after uploading, open the image description page for editing and add your separate explanations for each additional article manually. Example ‚Äì article okay. This article doesn't exist! The article Example could not be found. Please check the spelling, and make sure you enter the name of an existing article in which you will include this file. If this is an article you are only planning to write, please write it first and upload the file afterwards. This is not an actual encyclopedia article! The page Example is not in the main article namespace. Non-free files can only be used in mainspace article pages, not on a user page, talk page, template, etc. Please upload this file only if it is going to be used in an actual article. If this page is an article draft in your user space, we're sorry, but we must ask you to wait until the page is ready and has been moved into mainspace, and only upload the file after that. This is a disambiguation page! The page Example is not a real article, but a disambiguation page pointing to a number of other pages. Please check and enter the exact title of the actual target article you meant. If neither of these two statements applies, then please do not upload this image. This section is not for images used merely to illustrate an article about a person or thing, showing what that person or thing look like. In view of this, please explain how the use of this file will be minimal. Well, we're very sorry, but if you're not sure about this file's copyright status, or if it doesn't fit into any of the groups above, then: Please don't upload it. Really, please don't. Even if you think it would make for a great addition to an article. We really take these copyright rules very seriously on Wikipedia. Note that media is assumed to be fully-copyrighted unless shown otherwise; the burden is on the uploader. In particular, please don't upload: If you are in any doubt, please ask some experienced editors for advice before uploading. People will be happy to assist you at Wikipedia:Media copyright questions. Thank you. This is the data that will be submitted to upload: Your file is being uploaded. This might take a minute or two, depending on the size of the file and the speed of your internet connection. Once uploading is completed, you will find your new file at this link: File:Example.jpg Your file has been uploaded successfully and can now be found here: File:Example.jpg Please follow the link and check that the image description page has all the information you meant to include. If you want to change the description, just go to the image page, click the \"edit\" tab at the top of the page and edit just as you would edit any other page. Do not go through this upload form again, unless you want to replace the actual file with a new version. To insert this file into an article, you may want to use code similar to the following: If you wish to make a link to the file in text, without actually showing the image, for instance when discussing the image on a talk page, you can use the following (mark the \":\" after the initial brackets!): See Wikipedia:Picture tutorial for more detailed help on how to insert and position images in pages. Thank you for using the File Upload Wizard.Please leave your feedback, comments, bug reports or suggestions on the talk page."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Special:SpecialPages",
    "title": "Special pages - Wikipedia",
    "content": "This page contains a list of special pages. Most of the content of these pages is automatically generated and cannot be edited. To suggest a change to the parts that can be edited, find the appropriate text on Special:AllMessages and then request your change on the talk page of the message (using {{editprotected}} to draw the attention of administrators). You can also see what message names are used on a page by adding ?uselang=qqx to the end of its URL, e.g. https://en.wikipedia.org/wiki/Special:SpecialPages?uselang=qqx will show (specialpages-summary) in place of this message, which allows you to find MediaWiki:Specialpages-summary. For an index of special pages, see Help:SpecialPages."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Special:Search",
    "title": "Search - Wikipedia",
    "content": ""
  },
  {
    "url": "https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en",
    "title": "Make your donation now - Wikimedia Foundation",
    "content": "Thank you for considering a donation to the Wikimedia Foundation. We invite you to reflect on the number of times you visited Wikipedia in the last year. If the knowledge you gained here was valuable, please join the 2% of readers who donate. Any amount helps: $5, $20, $50, or whatever feels right to you today. The internet we were promised‚Äîa place of free, collaborative, and accessible knowledge‚Äîis under constant threat. On Wikipedia, volunteers work together to create and verify the pages you rely on, supported by tools that undo vandalism within minutes, ensuring the information you seek is trustworthy. If Wikipedia has given you useful knowledge this year, please give back. There are no small contributions: every edit counts, every donation counts. Thank you. Technology: Servers, bandwidth, maintenance, development. Wikipedia is one of the top 10 websites in the world, and it runs on a fraction of what other top websites spend. People and Projects: The other top websites have thousands of employees. Wikimedia Foundation has about 700 staff and contractors to support a wide variety of projects, making your donation a great investment in a highly-efficient not-for-profit organization. The Wikimedia Foundation is an international non-profit organization that supports local and independent associations around the world. Our tax-exempt status varies according to the laws of each country. Donations to the Wikimedia Foundation are likely not tax-deductible outside the USA. If you have any questions about tax exemptions or reductions, we invite you to contact donate@wikimedia.org. We do not sell or trade your information to anyone. By donating, you agree to share your personal information with the Wikimedia Foundation, the nonprofit organization that hosts Wikipedia and other Wikimedia projects, and its service providers pursuant to our donor policy. Wikimedia Foundation and its service providers are located in the United States and in other countries whose privacy laws may not be equivalent to your own. For more information please read our donor policy. For recurring donors, fixed monthly payments will be debited by the Wikimedia Foundation on the monthly anniversary of the first donation, until such time as you notify us to discontinue them. Donations initiated on the 29, 30, or 31 of the month will recur on the last day of the month for shorter months, as close to the original date as possible. For questions, please contact donate@wikimedia.org."
  },
  {
    "url": "https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Search+engine",
    "title": "Create account - Wikipedia",
    "content": "edits articles recent contributors"
  },
  {
    "url": "https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Search+engine",
    "title": "Log in - Wikipedia",
    "content": "Login processing now uses our domain auth.wikimedia.org. If you are using blocking software, you will need to allow access to this domain to log in. (technical details)"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Special:MyContributions",
    "title": "User contributions for 37.61.116.214 - Wikipedia",
    "content": "This user or IP address is currently globally blocked.\nIf the block is marked as locally disabled, this means that it applies on other sites, but a local administrator has decided to disable it on this wiki.\nThe global block log entry is provided below for reference:"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Special:MyTalk",
    "title": "User talk:37.61.125.86 - Wikipedia",
    "content": "People on Wikipedia can use this talk page to post a public message about edits made from the IP address you are currently using. Many IP addresses change periodically, and are often shared by several people. You may create an account or log in to avoid future confusion with other logged out users. Creating an account also hides your IP address."
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#History",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Pre-1990s",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#1990s:_Birth_of_search_engines",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#2000s‚Äìpresent:_Post_dot-com_bubble",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Approach",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Local_search",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Market_share",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Russia_and_East_Asia",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Search_engine_bias",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Customized_results_and_filter_bubbles",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Religious_search_engines",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Search_engine_submission",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Comparison_to_social_bookmarking",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Technology",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Archie",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Veronica",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#The_Lone_Wanderer",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Excite",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Yahoo!",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Lycos",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Types_of_web_search_engines",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#See_also",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#References",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#Further_reading",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://en.wikipedia.org/wiki/Web_search_engine#External_links",
    "title": "Search engine - Wikipedia",
    "content": "A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89‚Äì90‚ÄØ% of the worldwide search share, with competitors trailing far behind: Bing (~4‚ÄØ%), Yandex (~2.5‚ÄØ%), Yahoo! (~1.3‚ÄØ%), DuckDuckGo (~0.8‚ÄØ%), and Baidu (~0.7‚ÄØ%).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90‚ÄØ% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[3] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[4] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[5] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper Search and PageRank.[6][7] The first internet search engines predate the debut of the Web in December 1990: WHOIS user search dates back to 1982,[8] and the Knowbot Information Service multi-network user search was first implemented in 1989.[9] The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.[10] Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains,[11] but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title \"What's New!\".[12] The first tool used for searching content (as opposed to users) on the Internet was Archie.[13] The name stands for \"archive\" without the \"v\".[14] It was created by Alan Emtage,[14][15][16][17] computer science student at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually. The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine \"Archie Search Engine\" was not a reference to the Archie comic book series, \"Veronica\" and \"Jughead\" are characters in the series, thus referencing their predecessor. In the summer of 1993, no search engine existed for the web, though numerous specialized catalogs were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.[18] In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called \"Wandex\". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format. JumpStation (created in December 1993[19] by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered. One of the first \"all text\" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any web page, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also, in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor. The first popular search engine on the Web was Yahoo! Search.[20] The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory.[21][22] It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages. Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search. In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking[23][24][25] and received a US patent for the technology.[26] It was the first search engine that used hyperlinks to measure the quality of websites it was indexing,[27] predating the very similar algorithm patent filed by Google two years later in 1998.[28] Larry Page referenced Li's work in some of his U.S. patents for PageRank.[29] Li later used his RankDex technology for the Baidu search engine, which was founded by him in China and launched in 2000. In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead, Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.[30][31] Google adopted the idea of selling search terms in 1998 from a small search engine company named goto.com. This move had a significant effect on the search engine business, which went from struggling to one of the most profitable businesses in the Internet.[32][33] Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.[34] Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in March 2000. Around 2000, Google's search engine rose to prominence.[35] The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google.[7] This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence.[29][25] Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, the Google search engine became so popular that spoof engines emerged such as Mystery Seeker. By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions. Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999, the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot). Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology. As of 2019,[update] active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex. A search engine maintains the following processes in near real time:[36] Web search engines get their information by web crawling from site to site. The \"spider\" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl and which pages not to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. \"[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially\".[38] Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are stored in a public database and accessible through web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible.[37] Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis. Between visits by the spider, the cached version of the page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case, the page may differ from the search terms indexed.[37] The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the website when the actual page has been lost, but this problem is also considered a mild form of linkrot. Typically, when a user enters a query into a search engine it is a few keywords.[39] The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes.[37] Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post-processing. Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results. For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking \"Show search tools\" in the leftmost column of the initial search results page, and then selecting the desired date range.[40] It is also possible to weight by date because each page has a modification time. Most search engines support the use of the Boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords.[37] There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases the user searches for. The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the \"best\" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.[37] The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an \"inverted index\" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work. Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.[41] Local search is the process that optimizes the efforts of local businesses. They focus on ensuring consistent search results. It is important because many people determine where they plan to go and what to buy based on their searches.[42] As of January¬†2022,[update] Google is by far the world's most used search engine, with a market share of 90%, and the world's other most used search engines were Bing at 4%, Yandex at 2%, Yahoo! at 1%. Other search engines not listed have less than a 3% market share.[43] In 2024, Google's dominance was ruled an illegal monopoly in a case brought by the US Department of Justice.[44] As of late 2023 and early 2024, search engine market shares in Russia and East Asia have remained relatively stable but with some notable shifts due to geopolitical and technological developments. In Russia, Yandex continues to dominate the search engine market with a share of approximately 70.7%, while Google holds around 23.3%.[45] Yandex also remains a key player in localized services including navigation, ride-hailing, and e-commerce, strengthening its ecosystem. In China, Baidu remains the leading search engine with a market share of about 59.3% as of early 2024. Other domestic engines such as Sogou and 360 Search hold smaller shares. Google remains inaccessible in mainland China due to long-standing censorship issues, having exited the Chinese market in 2010 following disputes over censorship and cybersecurity.[46][47] Bing, Microsoft's search engine, has maintained a niche presence in China with a market share around 13.6%, making it one of the few foreign search engines operating under local regulatory constraints.[48] In South Korea, Naver continues to lead the domestic market, with a market share of 59.8%, followed by Google at 35.4% as of Q4 2023.[49] Naver‚Äôs strength lies in its localized services and integration with Korean content platforms. In Japan, Google Japan currently holds the largest market share (around 76.2%), while Yahoo! Japan, operated by Z Holdings (a SoftBank and Naver joint venture), retains about 15.8% market share.[50] In Taiwan, Google is the predominant search engine, commanding over 93% of the market, with Yahoo! Taiwan and Bing trailing far behind.[51] Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide[52][53] and the underlying assumptions about the technology.[54] These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws).[55] For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal. Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more \"popular\" results.[56] Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.[53] Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons. Several scholars have studied the cultural changes triggered by search engines,[57] and the representation of certain controversial topics in their results, such as terrorism in Ireland,[58] climate change denial,[59] and conspiracy theories.[60] There has been concern raised that search engines such as Google and Bing provide customized results based on the user's activity history, leading to what has been termed echo chambers or filter bubbles by Eli Pariser in 2011.[61] The argument is that search engines and social media platforms use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behavior and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. According to Eli Pariser users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or \"bubbling\" users, such as DuckDuckGo. However many scholars have questioned Pariser's view, finding that there is little evidence for the filter bubble.[62][63][64] On the contrary, a number of studies trying to verify the existence of filter bubbles have found only minor levels of personalization in search,[64] that most people encounter a range of views when browsing online, and that Google news tends to promote mainstream established news outlets.[65][63] The global growth of the Internet and electronic media in the Arab and Muslim world during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either \"halal\" or \"haram\", based on interpretation of Sharia law. ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).[66] While lack of investment and slow pace in technologies in the Muslim world has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim (a Muslim lifestyle site) received millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google,[67] and Christian search engine SeekFind.org. SeekFind filters sites that attack or degrade their faith.[68] Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign. Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this \"can lead to a tremendous number of unnatural links for your site\" with a negative impact on site ranking.[69] In comparison to search engines, a social bookmarking system has several advantages over traditional automated resource location and classification software, such as search engine spiders. All tag-based classification of Internet resources (such as web sites) is done by human beings, who understand the content of the resource, as opposed to software, which algorithmically attempts to determine the meaning and quality of a resource. Also, people can find and bookmark web pages that have not yet been noticed or indexed by web spiders.[70] Additionally, a social bookmarking system can rank a resource based on how many times it has been bookmarked by users, which may be a more useful metric for end-users than systems that rank resources based on the number of external links pointing to it.  However, both types of ranking are vulnerable to fraud, (see Gaming the system), and both need technical countermeasures to try to deal with this. The first web search engine was Archie, created in 1990[71] by Alan Emtage, a student at McGill University in Montreal. The author originally wanted to call the program \"archives\", but had to shorten it to comply with the Unix world standard of assigning programs and files short, cryptic names such as grep, cat, troff, sed, awk, perl, and so on.[citation needed] The primary method of storing and retrieving files was via the File Transfer Protocol (FTP). This was (and still is) a system that specified a common way for computers to exchange files over the Internet. It works like this: An administrator decides that they want to make files available from their computer. They set up a program on their computer, called an FTP server. When someone on the Internet wants to retrieve a file from this computer, they connect to it via another program called an FTP client. Any FTP client program can connect with any FTP server program as long as the client and server programs both fully follow the specifications set forth in the FTP protocol. Initially, anyone who wanted to share a file had to set up an FTP server in order to make the file available to others. Later, \"anonymous\" FTP sites became repositories for files, allowing all users to post and retrieve them. Even with archive sites, many important files were still scattered on small FTP servers. These files could be located only by the Internet equivalent of word of mouth: Somebody would post an e-mail to a message list or a discussion forum announcing the availability of a file. Archie changed all that. It combined a script-based data gatherer, which fetched site listings of anonymous FTP files, with a regular expression matcher for retrieving file names matching a user query. (4) In other words, Archie's gatherer scoured FTP sites across the Internet and indexed all of the files it found. Its regular expression matcher provided users with access to its database.[72] In 1993, the University of Nevada System Computing Services group developed Veronica.[71] It was created as a type of searching device similar to Archie but for Gopher files. Another Gopher search service, called Jughead, appeared a little later, probably for the sole purpose of rounding out the comic-strip triumvirate. Jughead is an acronym for Jonzy's Universal Gopher Hierarchy Excavation and Display, although, like Veronica, it is probably safe to assume that the creator backed into the acronym. Jughead's functionality was pretty much identical to Veronica's, although it appears to be a little rougher around the edges.[72] The World Wide Web Wanderer, developed by Matthew Gray in 1993[73] was the first robot on the Web and was designed to track the Web's growth. Initially, the Wanderer counted only Web servers, but shortly after its introduction, it started to capture URLs as it went along. The database of captured URLs became the Wandex, the first web database. Matthew Gray's Wanderer created quite a controversy at the time, partially because early versions of the software ran rampant through the Net and caused a noticeable netwide performance degradation. This degradation occurred because the Wanderer would access the same page hundreds of times a day. The Wanderer soon amended its ways, but the controversy over whether robots were good or bad for the Internet remained. In response to the Wanderer, Martijn Koster created Archie-Like Indexing of the Web, or ALIWEB, in October 1993. As the name implies, ALIWEB was the HTTP equivalent of Archie, and because of this, it is still unique in many ways. ALIWEB does not have a web-searching robot. Instead, webmasters of participating sites post their own index information for each page they want listed. The advantage to this method is that users get to describe their own site, and a robot does not run about eating up Net bandwidth. The disadvantages of ALIWEB are more of a problem today. The primary disadvantage is that a special indexing file must be submitted. Most users do not understand how to create such a file, and therefore they do not submit their pages. This leads to a relatively small database, which meant that users are less likely to search ALIWEB than one of the large bot-based sites. This Catch-22 has been somewhat offset by incorporating other databases into the ALIWEB search, but it still does not have the mass appeal of search engines such as Yahoo! or Lycos.[72] Excite, initially called Architext, was started by six Stanford undergraduates in February 1993. Their idea was to use statistical analysis of word relationships in order to provide more efficient searches through the large amount of information on the Internet.\nTheir project was fully funded by mid-1993. Once funding was secured. they released a version of their search software for webmasters to use on their own web sites. At the time, the software was called Architext, but it now goes by the name of Excite for Web Servers.[72] Excite was the first serious commercial search engine which launched in 1995.[74] It was developed in Stanford and was purchased for $6.5 billion by @Home. In 2001 Excite and @Home went bankrupt and InfoSpace bought Excite for $10 million. Some of the first analysis of web searching was conducted on search logs from Excite[75][39] In April 1994, two Stanford University Ph.D. candidates, David Filo and Jerry Yang, created some pages that became rather popular. They called the collection of pages Yahoo! Their official explanation for the name choice was that they considered themselves to be a pair of yahoos. As the number of links grew and their pages began to receive thousands of hits a day, the team created ways to better organize the data. In order to aid in data retrieval, Yahoo! (www.yahoo.com) became a searchable directory. The search feature was a simple database search engine. Because Yahoo! entries were entered and categorized manually, Yahoo! was not really classified as a search engine. Instead, it was generally considered to be a searchable directory. Yahoo! has since automated some aspects of the gathering and classification process, blurring the distinction between engine and directory. The Wanderer captured only URLs, which made it difficult to find things that were not explicitly described by their URL. Because URLs are rather cryptic to begin with, this did not help the average user. Searching Yahoo! or the Galaxy was much more effective because they contained additional descriptive information about the indexed sites. At Carnegie Mellon University during July 1994, Michael Mauldin, on leave from CMU, developed the Lycos search engine. Search engines on the web are sites enriched with facility to search the content stored on other sites. There is difference in the way various search engines work, but they all perform three basic tasks.[76] The process begins when a user enters a query statement into the system through the interface provided. There are basically three types of search engines: Those that are powered by robots (called crawlers; ants or spiders) and those that are powered by human submissions; and those that are a hybrid of the two. Crawler-based search engines are those that use automated software agents (called crawlers) that visit a Web site, read the information on the actual site, read the site's meta tags and also follow the links that the site connects to performing indexing on all linked Web sites as well. The crawler returns all that information back to a central depository, where the data is indexed. The crawler will periodically return to the sites to check for any information that has changed. The frequency with which this happens is determined by the administrators of the search engine. Human-powered search engines rely on humans to submit information that is subsequently indexed and catalogued. Only information that is submitted is put into the index. In both cases, when a user queries a search engine to locate information, they're actually searching through the index that the search engine has created ‚Äîthey are not actually searching the Web. These indices are giant databases of information that is collected and stored and subsequently searched. This explains why sometimes a search on a commercial search engine, such as Yahoo! or Google, will return results that are, in fact, dead links. Since the search results are based on the index, if the index has not been updated since a Web page became invalid the search engine treats the page as still an active link even though it no longer is. It will remain that way until the index is updated. So why will the same search on different search engines produce different results? Part of the answer to that question is because not all indices are going to be exactly the same. It depends on what the spiders find or what the humans submitted. But more important, not every search engine uses the same algorithm to search through the indices. The algorithm is what the search engines use to determine the relevance of the information in the index to what the user is searching for. One of the elements that a search engine algorithm scans for is the frequency and location of keywords on a Web page. Those with higher frequency are typically considered more relevant. But search engine technology is becoming sophisticated in its attempt to discourage what is known as keyword stuffing, or spamdexing. Another common element that algorithms analyze is the way that pages link to other pages in the Web. By analyzing how pages link to each other, an engine can both determine what a page is about (if the keywords of the linked pages are similar to the keywords on the original page) and whether that page is considered \"important\" and deserving of a boost in ranking. Just as the technology is becoming increasingly sophisticated to ignore keyword stuffing, it is also becoming more savvy to Web masters who build artificial links into their sites in order to build an artificial ranking. Modern web search engines are highly intricate software systems that employ technology that has evolved over the years. There are a number of sub-categories of search engine software that are separately applicable to specific 'browsing' needs. These include web search engines (e.g. Google), database or structured data search engines (e.g. Dieselpoint), and mixed search engines or enterprise search. The more prevalent search engines, such as Google and Yahoo!, utilize hundreds of thousands computers to process trillions of web pages in order to return fairly well-aimed results. Due to this high volume of queries and text processing, the software is required to run in a highly dispersed environment with a high degree of superfluity. Another category of search engines is scientific search engines. These are search engines which search scientific literature. The best known example is Google Scholar. Researchers are working on improving search engine technology by making them understand the content element of the articles, such as extracting theoretical constructs or key research findings.[77]"
  },
  {
    "url": "https://ady.wikipedia.org/wiki/%D0%98%D0%BD%D1%82%D0%B5%D1%80%D0%BD%D0%B5%D1%82-%D0%BB%D1%8A%D1%8B%D1%85%D1%8A%D1%83%D0%BB%D1%8A%D1%8D",
    "title": "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–ª—ä—ã—Ö—ä—É–ª—ä—ç - –í–∏–∫–∏–ø–µ–¥–∏–µ",
    "content": "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–ª—ä—ã—Ö—ä—É–ª—ä—ç–º—ç –∞—â—ã—â—ã—Ö:"
  },
  {
    "url": "https://ar.wikipedia.org/wiki/%D9%85%D8%AD%D8%B1%D9%83_%D8%A8%D8%AD%D8%AB",
    "title": "ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ - ŸàŸäŸÉŸäÿ®ŸäÿØŸäÿß",
    "content": "ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: web search engine) ÿ£Ÿà ÿßŸÑÿ®ÿßÿ≠Ÿàÿ´ [1] ŸáŸà ÿ®ÿ±ŸÜÿßŸÖÿ¨ ÿ≠ÿßÿ≥Ÿàÿ®Ÿä ŸÖÿµŸÖŸÖ ŸÑŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ŸÖÿÆÿ≤ŸÜÿ© ÿπŸÑŸâ ÿ¥ÿ®ŸÉÿßÿ™ ŸÖÿπŸÑŸàŸÖÿßÿ™Ÿäÿ©ÿßŸÑÿ¥ÿ®ŸÉÿ© ÿßŸÑÿπŸÜŸÉÿ®Ÿàÿ™Ÿäÿ© ÿßŸÑÿπÿßŸÑŸÖŸäÿ© (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: World Wide Web)) ÿ£Ÿà ÿπŸÑŸâ ÿ≠ÿßÿ≥Ÿàÿ® ÿ¥ÿÆÿµŸäÿå Ÿàÿ™ŸÇÿØŸÖ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ®ÿ≠ÿ´ ÿπÿßÿØÿ©Ÿã ÿπŸÑŸâ ÿ¥ŸÉŸÑ ŸÇÿßÿ¶ŸÖÿ© ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ Ÿäÿ¥ÿßÿ± ÿ•ŸÑŸäŸáÿß ÿπÿßÿØÿ©Ÿã ÿ®ŸÄ ¬´ÿµŸÅÿ≠ÿßÿ™ ŸÜÿ™ÿßÿ¶ÿ¨ ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´¬ªÿå (ŸÖÿÆÿ™ÿµÿ± ÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿä: SERPs)ÿå ŸÇÿØ ÿ™ŸÉŸàŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖŸÇÿØŸÖÿ© ŸÖÿ≤Ÿäÿ¨Ÿãÿß ŸÖŸÜ ÿµŸÅÿ≠ÿßÿ™ ŸàŸäÿ® ŸàÿµŸàÿ± Ÿàÿ£Ÿä ŸÜŸàÿπ ÿ¢ÿÆÿ± ŸÖŸÜ ÿßŸÑŸÖŸÑŸÅÿßÿ™ÿå ÿ™ŸÜŸÇÿ® ÿ®ÿπÿ∂ ÿßŸÑŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿπŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÖÿ™ŸàŸÅÿ±ÿ© ŸÅŸä ŸÇŸàÿßÿπÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ£Ÿà ÿ£ÿØŸÑÿ© ŸÖŸàÿßŸÇÿπ ÿßŸÑŸàŸäÿ®ÿå ŸàÿπŸÑŸâ ÿπŸÉÿ≥ ÿ£ÿØŸÑÿ© ÿßŸÑŸÖŸàÿßŸÇÿπ ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿßŸÅÿ∏ ÿπŸÑŸäŸáÿß ŸÖŸÜ ÿÆŸÑÿßŸÑ ŸÖÿ≠ÿ±ÿ±ŸäŸÜ ÿ®ÿ¥ÿ±ŸäŸäŸÜ ŸÅŸÇÿ∑ÿå ŸÅÿ•ŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ™ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÅŸä ÿßŸÑÿ≤ŸÖŸÜ ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ™ÿ¥ÿ∫ŸäŸÑ ÿÆŸàÿßÿ±ÿ≤ŸÖŸäÿ© ÿπŸÑŸâ ÿ≤ÿßÿ≠ŸÅ ÿßŸÑÿ¥ÿ®ŸÉÿ©. ÿ®ŸÜŸäÿ™ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ£ŸàŸÑŸâ ÿßÿπÿ™ŸÖÿßÿØÿß ÿπŸÑŸâ ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿπŸÖŸÑÿ© ŸÅŸä ÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÖŸÉÿ™ÿ®ÿßÿ™ ÿßŸÑŸÉŸÑÿßÿ≥ŸäŸÉŸäÿ©. ÿ≠Ÿäÿ´ Ÿäÿ™ŸÖ ÿ®ŸÜÿßÿ° ŸÅŸáÿßÿ±ÿ≥ ŸÑŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿ™ÿ¥ŸÉŸÑ ŸÇÿßÿπÿØÿ© ŸÑŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ™ŸÅŸäÿØ ŸÅŸä ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿ£Ÿä ŸÖÿπŸÑŸàŸÖÿ©. Ÿäÿ≥ŸÖÿ≠ ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ£ŸÜ Ÿäÿ∑ŸÑÿ® ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿ∞Ÿä ŸäŸÇÿßÿ®ŸÑ ŸÖÿπÿßŸäŸäÿ± ŸÖÿ≠ÿØÿØÿ© (ŸàÿßŸÑŸÇÿßÿπÿØÿ© ŸÅŸäŸáÿß ÿ™ŸÑŸÉ ÿßŸÑÿ™Ÿä ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ŸÉŸÑŸÖÿ© ÿ£Ÿà ÿπÿ®ÿßÿ±ÿ© ŸÖÿß) ŸàŸäÿ≥ÿ™ÿØÿπŸä ŸÇÿßÿ¶ŸÖÿ©Ÿã ÿ®ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿ™ŸàÿßŸÅŸÇ ÿ™ŸÑŸÉ ÿßŸÑŸÖÿπÿßŸäŸäÿ±. ÿ™ÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸÖÿ§ÿ¥ÿ±ÿßÿ™/ŸÅŸáÿßÿ±ÿ≥/ŸÖÿ≥ÿßÿ±ÿØ ŸÖŸÜÿ™ÿ∏ŸÖÿ© ÿßŸÑÿ™ÿ≠ÿØŸäÿ´ ŸÑÿ™ÿ¥ÿ™ÿ∫ŸÑ ÿ®ÿ≥ÿ±ÿπÿ© ŸàŸÅÿπÿßŸÑŸäÿ©. ÿ™ÿπÿ±ÿ∂ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿπŸÑŸâ ÿ¥ŸÉŸÑ ŸÇÿßÿ¶ŸÖÿ© ÿ®ÿπŸÜÿßŸàŸäŸÜ ÿßŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸàÿßŸÅŸÇ ÿßŸÑÿ∑ŸÑÿ®. Ÿäÿ±ŸÅŸÇ ÿ®ÿßŸÑÿπŸÜÿßŸàŸäŸÜ ŸÅŸä ÿßŸÑÿ∫ÿßŸÑÿ® ŸÖÿÆÿ™ÿµÿ± ÿπŸÜ ÿßŸÑŸÖÿ≥ÿ™ŸÜÿØ ÿßŸÑŸÖÿ¥ÿßÿ± ÿ•ŸÑŸäŸá ÿ£Ÿà ŸÖŸÇÿ™ÿ∑ŸÅ ŸÖŸÜŸá ŸÑŸÑÿØŸÑÿßŸÑÿ© ÿπŸÑŸâ ŸÖŸàÿßŸÅŸÇÿ™Ÿá ŸÑŸÑÿ®ÿ≠ÿ´. Ÿàÿ™ÿ±ÿ™ÿ® ÿπŸÜÿßÿµÿ± ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑÿ®ÿ≠ÿ´ ŸàŸÅŸÇŸãÿß ŸÑŸÖÿπÿßŸäŸäÿ± ÿÆÿßÿµÿ© (ŸÇÿØ ÿ™ÿÆÿ™ŸÑŸÅ ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉ ŸÑÿ¢ÿÆÿ±)ÿå ŸÖŸÜ ÿ£ŸáŸÖŸáÿß ŸÖÿØŸâ ŸÖŸàÿßŸÅŸÇÿ© ŸÉŸÑ ÿπŸÜÿµÿ± ŸÑŸÑÿ∑ŸÑÿ®. ÿπŸÜÿØ ÿßŸÑÿ≠ÿØŸäÿ´ ÿπŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅÿ∫ÿßŸÑÿ®ÿß ŸÖÿß ŸäŸÇÿµÿØ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÑŸâ ÿ¥ÿ®ŸÉÿ© ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸàŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑŸàŸêŸäÿ® ÿ®ÿßŸÑÿÆÿµŸàÿµ. ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑŸàŸäÿ® ÿ™ÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÑŸâ ÿßŸÑÿ¥ÿ®ŸÉÿ© ÿßŸÑÿπŸÜŸÉÿ®Ÿàÿ™Ÿäÿ© ÿßŸÑÿπÿßŸÑŸÖŸäÿ©ÿå ŸàŸÖŸÜŸáÿß ŸÖÿß Ÿäÿ≥ÿ™ÿπŸÖŸÑ ÿπŸÑŸâ ŸÜÿ∑ÿßŸÇ ÿ∂ŸäŸÇ Ÿäÿ¥ŸÖŸÑ ÿßŸÑÿ®ÿ≠ÿ´ ÿØÿßÿÆŸÑ ÿßŸÑÿ¥ÿ®ŸÉÿßÿ™ ÿßŸÑŸÖÿ≠ŸÑŸäÿ© ŸÑŸÑŸÖÿ§ÿ≥ÿ≥ÿßÿ™ ÿ£Ÿä ÿ•ŸÜÿ™ÿ±ÿßŸÜÿ™ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Intranet). ÿ£ŸÖÿß ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ¥ÿÆÿµŸäÿ© ŸÅÿ™ÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑÿ≠Ÿàÿßÿ≥Ÿäÿ® ÿßŸÑÿ¥ÿÆÿµŸäÿ© ÿßŸÑŸÅÿ±ÿØŸäÿ©. ÿ™ŸÜŸÇÿ® ÿ®ÿπÿ∂ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ£Ÿäÿ∂ÿßŸã ŸÅŸä ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ÿπŸÑŸâ ÿßŸÑŸÖÿ¨ŸÖŸàÿπÿßÿ™ ÿßŸÑÿ•ÿÆÿ®ÿßÿ±Ÿäÿ©ÿå ŸàŸÇŸàÿßÿπÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ∂ÿÆŸÖÿ©ÿå ÿ£Ÿà ÿ£ÿØŸÑÿ© ŸÖŸàÿßŸÇÿπ ÿßŸÑŸàŸêÿ® ŸÖÿ´ŸÑ ÿØŸêŸÖŸàÿ≤ ÿØŸàÿ™ ÿ£Ÿàÿ±ÿ¨. ÿ•ŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿ®ÿ≠ÿ´ ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿ®ÿ≠ÿØ ÿ∞ÿßÿ™Ÿáÿß ÿ≥ÿßÿ®ŸÇÿ© ŸÑÿ∏ŸáŸàÿ± ÿßŸÑŸàŸäÿ® ŸÅŸä ŸÉÿßŸÜŸàŸÜ ÿßŸÑÿ£ŸàŸÑ ŸÖŸÜ ÿπÿßŸÖ 1991ÿå ÿ≠Ÿäÿ´ ŸäÿπŸàÿØ ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ®ÿ≠ÿ´ ÿ•ŸÑŸâ ÿπÿßŸÖ 1982 ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ∑ÿ±ŸäŸÇÿ© ¬´ŸáŸàÿ•ÿ≤¬ª[2]ÿå ŸÉŸÖÿß ŸÜŸÅÿ∞ÿ™ ÿÆÿØŸÖÿ© ÿ®ÿ≠ÿ´ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÜŸàÿ®Ÿàÿ™ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸÖÿ™ÿπÿØÿØŸä ÿßŸÑÿ¥ÿ®ŸÉÿßÿ™ ŸÑÿ£ŸàŸÑ ŸÖÿ±ÿ© ÿπÿßŸÖ 1989.[3] ŸàŸÇÿØ ŸÉÿßŸÜ ÿ£ŸàŸÑ ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ŸÖŸàÿ´ŸëŸÇ ŸäŸÇŸàŸÖ ÿ®ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÖÿ≠ÿ™ŸàŸäÿßÿ™ ÿßŸÑŸÖÿ≥ŸÖÿßÿ© ŸÖŸÑŸÅÿßÿ™ ÿ®ÿ±Ÿàÿ™ŸàŸÉŸàŸÑ ŸÜŸÇŸÑ ÿßŸÑŸÖŸÑŸÅÿßÿ™ÿå ŸáŸà ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿ£ÿ±ÿ¥Ÿäÿå ÿ≠Ÿäÿ´ ŸÇŸèÿØŸÖ ŸÑÿ£ŸàŸÑ ŸÖÿ±ÿ© ŸÅŸä 10 ÿ£ŸäŸÑŸàŸÑ ŸÖŸÜ ÿπÿßŸÖ 1990. ŸàŸÇÿØ ÿ£ŸÜÿ¥ÿ£Ÿá ÿ∑ÿßŸÑÿ® ŸÅŸä ÿ¨ÿßŸÖÿπÿ© ŸÖÿßŸÉÿ¨ŸäŸÑ ŸÅŸä ŸÖŸàŸÜÿ™ÿ±ŸäÿßŸÑ ÿπÿßŸÖ 1990ŸÖÿå ŸàŸÉÿßŸÜ Ÿäÿπÿ±ŸÅ ÿ®ÿßÿ≥ŸÖ ‚Äúÿ£ÿ±ÿ¥Ÿä‚Äù (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Archie) ‚Äì ŸÖÿ¥ÿ™ŸÇ ŸÖŸÜ ŸÉŸÑŸÖÿ© ‚ÄúÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ‚Äù ŸÖÿπ ÿ•ÿ≤ÿßŸÑÿ© ÿ≠ÿ±ŸÅ ‚ÄúŸÅ‚Äù- ŸàŸäÿ≠ŸÖŸÑ ÿ™ŸÑŸÇÿßÿ¶Ÿäÿß ŸÇÿßÿ¶ŸÖÿ© ÿ®ŸÉŸÑ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÖÿ™ŸàÿßŸÅÿ±ÿ© ÿπŸÑŸâ ŸÉŸÑ ŸÖŸàŸÇÿπ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸàŸÉÿßŸÜ ÿßŸÑÿ®ÿ≠ÿ´ Ÿäÿ™ŸÖ ŸÖŸÜ ÿÆŸÑÿßŸÑ Ÿáÿ∞Ÿá ÿßŸÑŸÇÿßÿ¶ŸÖÿ© ÿ®ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑŸÖŸÑŸÅÿßÿ™.[4][5]\nŸàÿ™ÿ∑Ÿàÿ±ÿ™ ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´ ŸÅÿ∏Ÿáÿ± ŸÖÿ≠ÿ±ŸÉ ÿ®ÿßÿ≥ŸÖ ŸàÿßŸÜÿØŸÉÿ≥ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Wandex)ÿå ŸàŸáŸà ŸÅŸáÿ±ÿ≥ ÿ¨ŸÖÿπŸá ŸÖÿ™ÿ¨ŸàŸÑ ŸàŸêÿ® ŸàŸáŸà ÿ≤ÿßÿ≠ŸÅ ÿπŸÜŸÉÿ®Ÿàÿ™Ÿä (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: web crawler) ÿ∑Ÿàÿ±Ÿá ŸÖÿßÿ´ŸäŸà ÿ¨ÿ±ÿßŸä ŸÅŸä ŸÖÿπŸáÿØ ŸÖÿßÿ≥ÿßÿ¥Ÿàÿ≥ÿ™ÿ≥ ŸÑŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß MIT ŸÅŸä 1993. ŸàŸäÿπÿØ ÿ¢ŸÑŸäŸàÿ® (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Aliweb) ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿ¢ÿÆÿ± ŸÖÿ®ŸÉÿ± ÿ¨ÿØŸãÿß ŸàŸÇÿØ ÿ∏Ÿáÿ± ŸÅŸä 1993 ŸàŸäÿπŸÖŸÑ ÿ≠ÿ™Ÿâ ÿßŸÑŸäŸàŸÖ. Ÿàÿ£ŸàŸÑ ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ŸÇÿßÿ¶ŸÖ ÿπŸÑŸâ ÿßŸÑÿ≤ÿßÿ≠ŸÅ ÿßŸÑÿπŸÜŸÉÿ®Ÿàÿ™Ÿä ŸÑŸÑŸÜÿµŸàÿµ ÿßŸÑŸÉÿßŸÖŸÑÿ© ŸÉÿßŸÜ Ÿàÿ®ŸÉÿ±ÿßŸàŸÑÿ± (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: WebCrawler)ÿå ŸàÿßŸÑÿ∞Ÿä ÿÆÿ±ÿ¨ ŸÑŸÑŸàÿ¨ŸàÿØ ŸÅŸä 1994. ŸàÿπŸÑŸâ ÿπŸÉÿ≥ ÿ≥ÿßÿ®ŸÇŸäŸáÿå ŸÅŸÇÿØ ÿ™ÿ±ŸÉ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ Ÿäÿ®ÿ≠ÿ´ŸàŸÜ ÿπŸÜ ÿ£Ÿä ŸÉŸÑŸÖÿ© ÿπŸÑŸâ ÿ£Ÿä ÿµŸÅÿ≠ÿ© ŸàŸäÿ®ÿå ŸàŸáŸà ŸÖÿß ÿµÿßÿ± ÿßŸÑŸÇÿßÿπÿØÿ© ŸÑŸÉŸÑ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÉÿ®ÿ±Ÿâ ŸÖŸÜÿ∞ ÿ∞ŸÑŸÉ ÿßŸÑŸàŸÇÿ™. ŸÉÿßŸÜ ŸáŸà ÿ£Ÿäÿ∂ÿß ÿßŸÑÿ£ŸàŸÑ ŸÅŸä ŸÖÿπÿ±ŸÅÿ© ÿßŸÑÿ¨ŸÖŸáŸàÿ± ÿ®Ÿá ÿπŸÑŸâ ŸÜÿ∑ÿßŸÇ Ÿàÿßÿ≥ÿπ. ŸÅŸä 1994 ŸÉÿ∞ŸÑŸÉ ÿ¨ÿßÿ° ŸÑÿßŸäŸÉŸàÿ≥ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Lycos) (ÿßŸÑÿ∞Ÿä ÿ®ÿØÿ£ ŸÅŸä ÿ¨ÿßŸÖÿπÿ© ŸÉÿßÿ±ŸÜŸäÿ∫Ÿä ŸÖŸäŸÑŸàŸÜ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Carnegie Mellon University)) Ÿàÿµÿßÿ± ŸÖÿ¥ÿ±ŸàÿπŸãÿß ÿ™ÿ¨ÿßÿ±ŸäŸãÿß ŸÉÿ®Ÿäÿ±Ÿãÿß. ÿ®ÿπÿØ ÿ∞ŸÑŸÉ ÿ®ŸÇŸÑŸäŸÑÿå ÿ∏Ÿáÿ± ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ Ÿàÿ™ÿ≤ÿßÿ≠ŸÖÿ™ ÿπŸÑŸâ ÿßŸÑÿ¥ÿπÿ®Ÿäÿ©. ŸàŸÉÿßŸÜ ŸÖŸÜ ÿ∂ŸÖŸÜŸáÿß ÿ•ŸÉÿ≥ÿßŸäÿ™ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Excite)ÿå ÿ•ŸÜŸÅŸàÿ≥ŸäŸÉ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Infoseek)ÿå Ÿàÿ•ŸÜŸÉÿ™ŸàŸÖŸä (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Inktomi)ÿå ŸàŸÜŸàÿ±ÿ´ÿ±ŸÜ ŸÑÿßŸäÿ™ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Northern Light)ÿå Ÿàÿ£ŸÑÿ™ÿßŸÅŸäÿ≥ÿ™ÿß (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Alta Vista). ŸàŸÅŸä ÿ®ÿπÿ∂ ÿßŸÑÿ≠ÿßŸÑÿßÿ™ ÿ™ŸÜÿßŸÅÿ≥ÿ™ ŸÖÿπ ÿßŸÑÿ£ÿØŸÑÿ© ÿ∞ÿßÿ™ ÿßŸÑÿ¥ÿπÿ®Ÿäÿ© ŸÖÿ´ŸÑ ŸäÿßŸáŸà! (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: !Yahoo). ŸÅŸäŸÖÿß ÿ®ÿπÿØÿå ÿ£ÿØŸÖÿ¨ÿ™ ÿßŸÑÿ£ÿØŸÑÿ© ÿ£Ÿà ÿ£ÿ∂ÿßŸÅÿ™ ÿ•ŸÑŸäŸáÿß ÿ™ŸÇŸÜŸäÿ© ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ŸÖŸÜ ÿ£ÿ¨ŸÑ ÿ£ÿØÿßÿ° ÿ£ŸÉÿ®ÿ± ŸÑŸÑŸàÿ∏ÿßÿ¶ŸÅ. ÿπÿ±ŸÅÿ™ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ£Ÿäÿ∂ÿß ÿ®ŸÉŸàŸÜŸáÿß ÿ®ÿπÿ∂ ÿ£ŸÑŸÖÿπ ÿßŸÑŸÜÿ¨ŸàŸÖ ŸÅŸä ŸÜŸàÿ®ÿ© ÿßŸÑÿßÿ≥ÿ™ÿ´ŸÖÿßÿ± ŸÅŸä ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿßŸÑÿ™Ÿä ŸàŸÇÿπÿ™ ŸÅŸä ÿ£ŸàÿßÿÆÿ± ÿßŸÑÿ™ÿ≥ÿπŸäŸÜÿßÿ™. ÿØÿÆŸÑÿ™ ÿπÿØÿ© ÿ¥ÿ±ŸÉÿßÿ™ ÿßŸÑÿ≥ŸàŸÇ ŸÅŸä ŸÖÿ¥ŸáÿØ ŸÉÿ®Ÿäÿ±ÿå ŸÖÿ≥ÿ¨ŸÑÿ© ŸÖŸÉÿßÿ≥ÿ® ŸÇŸäÿßÿ≥Ÿäÿ© ÿÆŸÑÿßŸÑ ÿ∑ÿ±ÿ≠ ÿ£ÿ≥ŸáŸÖŸáÿß ÿßŸÑÿπÿßŸÖ ÿßŸÑÿßŸÅÿ™ÿ™ÿßÿ≠Ÿä. ŸàŸÇÿØ ÿ≥ÿ≠ÿ® ÿßŸÑÿ®ÿπÿ∂ ŸÖÿ≠ÿ±ŸÉÿßÿ™ŸáŸÖ ÿßŸÑÿ®ÿ≠ÿ´Ÿäÿ© ÿßŸÑÿπÿßŸÖÿ©ÿå ŸàŸáŸÖ Ÿäÿ≥ŸàŸÇŸàŸÜ ŸÜÿ≥ÿÆÿß ŸÑŸÑÿ¥ÿ±ŸÉÿßÿ™ ŸÅŸÇÿ∑ÿå ŸÖÿ´ŸÑ ŸÜŸàÿ±ÿ´ÿ±ŸÜ ŸÑÿßŸäÿ™ ÿßŸÑÿ™Ÿä ŸÉÿßŸÜÿ™ ŸÖŸÜ ÿßŸÑ8 ÿ£Ÿà 9 ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿ®ÿ≠ÿ´ ÿßŸÑŸÖÿ®ŸÉÿ±ÿ© ÿ®ÿπÿØ ÿ£ŸÜ ÿ¨ÿßÿ° ŸÑÿßŸäŸÉŸàÿ≥ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Lycos). ŸÇÿ®ŸÑ ŸÖÿ¨Ÿäÿ° ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ÿå ŸÉÿßŸÜÿ™ ŸáŸÜÿßŸÉ ÿ®Ÿàÿßÿ≠Ÿäÿ´ ŸÑŸÖŸàÿßŸÅŸäŸÇ (ÿ®ÿ±Ÿàÿ™ŸàŸÉŸàŸÑÿßÿ™)ÿ£Ÿà ÿßÿ≥ÿ™ÿÆÿØÿßŸÖÿßÿ™ ÿ£ÿÆÿ±Ÿâÿå ŸÖÿ´ŸÑ ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿ¢ÿ±ŸÉŸä ŸÑŸÖŸàÿßŸÇÿπ ÿ•ŸÅ‚Äå.ÿ™Ÿä.‚Äåÿ®Ÿä ÿßŸÑŸÖÿ¨ŸáŸàŸÑÿ© (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: anonymous FTP) ŸàŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ⁄§Ÿäÿ±ŸàŸÜŸäŸÉÿß ŸÑÿ®ÿ±Ÿàÿ™ŸàŸÉŸàŸÑ ÿ¨ŸàŸÅÿ±. Ÿàÿ≥ÿ™ÿ£ÿ™Ÿä ÿ®ÿπÿ∂ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ£ÿÆÿ±Ÿâ ŸÖŸÜŸáÿß ÿ•ŸäŸá ŸÜÿßŸäŸÜ.ŸÉŸàŸÖ a9.com (ÿ£ŸÖÿßÿ≤ŸàŸÜ.ŸÉŸàŸÖ)ÿå ÿ¢ÿ≥ŸÉ ⁄ÜŸä⁄§Ÿäÿ≤/ÿ™ŸäŸàŸÖÿß (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Ask Jeeves/Teoma)ÿå ÿ¨Ÿäÿ¨ÿßÿ®ŸÑÿßÿ≥ÿ™ÿå ÿ≥ŸÜÿßŸæ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Snap)ÿå ŸàÿßŸÑŸáÿßŸÑŸÑŸà (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Walhello)ÿå ŸÉÿßÿ≤ÿßÿ≤ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: Kazazz)ÿå ŸàŸàÿßŸäÿ≥ŸÜŸéÿ™ (ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©: WiseNut). Ÿàÿ®ÿπÿ∂ ÿ¢ÿÆÿ± ÿ¢ÿÆÿ± ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ®ÿ≠ÿ´ ŸÅŸÇÿ∑ ÿ£ŸÜŸàÿßÿπÿß ŸÖÿ≠ÿØÿØÿ© ŸÖŸÜ ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ ŸáŸä ŸæŸÑÿßÿ≤Ÿà Plazoo (ŸÑŸÖÿ±ÿØŸàÿØ ÿßŸÑÿÆŸÑÿßÿµÿßÿ™ RSS feeds)ÿå Ÿàÿ¨ŸàŸáŸàŸÉ GoHook (ŸÑŸÖŸÑŸÅÿßÿ™ ŸæŸä ÿØŸä ÿ•ŸÅ PDF ÿ®ÿ¥ŸÉŸÑ ÿ±ÿ¶Ÿäÿ≥Ÿä). ŸàŸÖŸÜ ÿ£ÿ¥Ÿáÿ± ÿßŸÑŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿ£Ÿäÿ∂ÿß: Yooci Ÿà ThroughSearch ÿ™ÿπŸÖŸÑ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿ∑ÿ±ŸäŸÇ ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÜ ÿπÿØÿØ ŸÉÿ®Ÿäÿ± ŸÖŸÜ ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸêÿ®ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ≥ÿ™ÿπŸäÿØŸáÿß ŸÖŸÜ ÿßŸÑÿ¥ÿ®ŸÉÿ© ÿßŸÑÿπÿßŸÑŸÖŸäÿ© ŸàŸàÿ±ŸÑÿØ ŸàÿßŸäÿØ Ÿàÿ® ŸÜŸÅÿ≥Ÿáÿß. ÿ™ÿ≥ÿ™ÿπÿßÿØ Ÿáÿ∞Ÿá ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ÿ®Ÿàÿßÿ≥ÿ∑ÿ© ÿ≤ÿßÿ≠ŸÅ ŸàŸêÿ® (Ÿäÿπÿ±ŸÅ ÿ£ÿ≠ŸäÿßŸÜÿß ÿ£Ÿäÿ∂ÿß ÿ®ŸÄ ‚ÄôÿπŸÜŸÉÿ®Ÿàÿ™‚Äò) ‚Äì ŸàŸáŸà ŸÖÿ≥ÿ™ÿπÿ±ÿ∂ ŸàŸêÿ® ÿ¢ŸÑŸä Ÿäÿ™ÿ®ÿπ ŸÉŸÑ ÿ±ÿßÿ®ÿ∑ Ÿäÿ±ÿßŸá. ÿ®ÿπÿØ ÿ∞ŸÑŸÉ Ÿäÿ¨ÿ±Ÿä ÿ™ÿ≠ŸÑŸäŸÑ ŸÉŸÑ ÿµŸÅÿ≠ÿ© ŸÑÿ™ÿ≠ÿØŸäÿØ ŸÉŸäŸÅ ŸäŸÜÿ®ÿ∫Ÿä ŸÅŸáÿ±ÿ≥ÿ™Ÿáÿß (ÿπŸÑŸâ ÿ≥ÿ®ŸäŸÑ ÿßŸÑŸÖÿ´ÿßŸÑÿå ÿ™ÿ≥ÿ™ÿÆŸÑÿµ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ŸÖŸÜ ÿßŸÑÿπŸÜÿßŸàŸäŸÜÿå ÿ±ÿ§Ÿàÿ≥ ÿßŸÑŸÖŸàÿ∂Ÿàÿπÿßÿ™ÿå ÿ£Ÿà ÿ≠ŸÇŸàŸÑ ÿÆÿßÿµÿ© ÿ™ÿπÿ±ŸÅ ÿ® ŸÖŸäÿ™ÿß ÿ™ÿßÿ¨ÿ≤). ÿ™ÿÆÿ≤ŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿπŸÜ ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸêÿ® ŸÅŸä ŸÇÿßÿπÿØÿ© ÿ®ŸäÿßŸÜÿßÿ™ ŸÅŸáÿ±ÿ≥Ÿäÿ© ŸÑŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÅŸä ÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ∑ŸÑÿ®ÿß ŸÑŸÑŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÑÿßÿ≠ŸÇÿß. ÿ®ÿπÿ∂ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸÖÿ´ŸÑ ÿ¨Ÿàÿ¨ŸÑÿå ÿ™ÿÆÿ≤ŸÜ ŸÉŸÑ ÿ£Ÿà ÿ®ÿπÿ∂ ÿßŸÑÿµŸÅÿ≠ÿ© ÿßŸÑŸÖÿµÿØÿ± (Ÿàÿ™ÿ¥Ÿäÿ± ŸÑŸáÿß ÿ® ŸÖÿÆÿ®Ÿàÿ°ÿ©) Ÿàÿ®ÿßŸÑŸÖÿ´ŸÑ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÜ ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸêÿ®ÿå ÿ®ŸäŸÜŸÖÿß ÿ®ÿπÿ∂Ÿáÿß ÿ™ÿÆÿ≤ŸÜ ŸÉŸÑ ŸÉŸÑŸÖÿ© ŸÖŸÜ ŸÉŸÑ ÿµŸÅÿ≠ÿ© ÿ™ÿ¨ÿØŸáÿßÿå ŸÖÿ´ŸÑ ÿ£ŸÑÿ™ÿß⁄§Ÿäÿ≥ÿ™ÿß. Ÿáÿ∞Ÿá ÿßŸÑÿµŸÅÿ≠ÿ© ÿßŸÑŸÖÿÆÿ®Ÿàÿ°ÿ© ÿ™ŸÖÿ≥ŸÉ ÿ®ŸÜÿµ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÅÿπŸÑŸä ÿ®ŸÖÿß ÿ£ŸÜŸá ŸáŸà ÿßŸÑÿ∞Ÿä ÿ™ŸÖÿ™ ŸÅŸáÿ±ÿ≥ÿ™Ÿá ŸÅÿπŸÑŸäÿßÿå ŸÑÿ∞ÿß ŸÅŸÇÿØ ÿ™ŸÉŸàŸÜ ŸÖŸÅŸäÿØÿ© ÿ¨ÿØÿß ÿπŸÜÿØŸÖÿß ŸäŸÉŸàŸÜ ŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿµŸÅÿ≠ÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ© ŸÇÿØ ÿ¨ÿ±Ÿâ ÿ™ÿ≠ÿØŸäÿ´Ÿá ŸàŸÑŸÖ ÿ™ÿπÿØ ÿ£ŸÑŸÅÿßÿ∏ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸäŸá. ÿ±ÿ®ŸÖÿß ÿ™ÿπÿ™ÿ®ÿ± Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ¥ŸÉŸÑÿß ÿÆŸÅŸäŸÅÿß ŸÖŸÜ ÿ™ÿπŸÅŸÜ ÿßŸÑÿ±Ÿàÿßÿ®ÿ∑ÿå Ÿàÿ™ÿ≤ŸäÿØ ŸÖÿπÿßŸÑÿ¨ÿ© ÿ¨Ÿàÿ¨ŸÑ ŸÑŸáÿß ŸÖŸÜ ÿ•ŸÖŸÉÿßŸÜŸäÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ®ÿ•ÿ±ÿ∂ÿßÿ° ÿ™ŸàŸÇÿπÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ®ÿ£ŸÜ ÿ™ÿ±ÿØ ÿ£ŸÑŸÅÿßÿ∏ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸêÿ® ÿßŸÑÿπÿßÿ¶ÿØÿ© ŸÅŸä ÿßŸÑÿ±ÿØ. ŸàŸáŸà ŸÖÿß Ÿäÿ±ÿ∂Ÿä ‚ÄôŸÖÿ®ÿØÿ£ ŸÖŸÅÿßÿ¨ÿ£ÿ© ÿ£ÿÆŸÅ ŸÖŸÜ ŸÖŸÅÿßÿ¨ÿ£ÿ©‚Äò ÿ®ŸÖÿß ÿ£ŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ Ÿäÿ™ŸàŸÇÿπ ÿ®ÿ¥ŸÉŸÑ ÿ∑ÿ®ŸäÿπŸä ÿ£ŸÑŸÅÿßÿ∏ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ© ÿßŸÑÿπÿßÿ¶ÿØÿ© ŸÑŸá. ŸàŸáÿ∞Ÿá ÿßŸÑÿµŸÑÿ© ÿ®ÿßŸÑÿ®ÿ≠ÿ´ ÿ™ÿ¨ÿπŸÑ Ÿáÿ∞Ÿá ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸÖÿÆÿ®Ÿàÿ°ÿ© ŸÖŸÅŸäÿØÿ© ÿ¨ÿØÿßÿå ÿ≠ÿ™Ÿâ ÿ£ŸÉÿ´ÿ± ŸÖŸÜ ŸàÿßŸÇÿπ ÿ£ŸÜŸáÿß ŸÇÿØ ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ®ŸäÿßŸÜÿßÿ™ ÿ±ÿ®ŸÖÿß ŸÑŸÖ ÿ™ÿπÿØ ŸÖÿ™ÿßÿ≠ÿ© ŸÅŸä ŸÖŸàÿ∂ÿπ ÿ¢ÿÆÿ±. ÿπŸÜÿØŸÖÿß Ÿäÿ™Ÿàÿ¨Ÿá ŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÑŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ŸàŸäÿ¨ÿ±Ÿä ÿπŸÖŸÑŸäÿ© ÿ®ÿ≠ÿ´ ÿ∑ŸÑÿ®ÿß ŸÑŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ÿå ŸÉŸÖÿß ŸáŸà ÿ≥ÿßÿ¶ÿØ ÿ®ÿ•ÿπÿ∑ÿßÿ° ŸÉŸÑŸÖÿßÿ™ ŸÖŸÅÿ™ÿßÿ≠Ÿäÿ©ÿå ŸäŸÅÿ™ÿ¥ ÿßŸÑŸÖÿ≠ÿ±ŸÉ ŸÅŸä ÿßŸÑŸÅŸáÿ±ÿ≥ ŸàŸäŸÇÿØŸÖ ŸÇÿßÿ¶ŸÖÿ© ÿ®ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸêÿ® ÿßŸÑÿ£ŸÅÿ∂ŸÑ ÿ™ŸàÿßŸÅŸÇÿß ÿ™ÿ®ÿπÿß ŸÑŸÖÿπÿßŸäŸäÿ±Ÿáÿå ŸÅŸä ÿßŸÑŸÖÿπÿ™ÿßÿØ ŸÖÿπ ŸÖŸÑÿÆÿµ ŸÇÿµŸäÿ± Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿπŸÜŸàÿßŸÜ ÿßŸÑŸàÿ´ŸäŸÇÿ© Ÿàÿ£ÿ≠ŸäÿßŸÜÿß ÿ£ÿ¨ÿ≤ÿßÿ° ŸÖŸÜ ÿßŸÑŸÜÿµ. ŸÖÿπÿ∏ŸÖ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ™ÿØÿπŸÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿßÿµÿ∑ŸÑÿßÿ≠ÿßÿ™ ÿßŸÑÿ®ŸàŸÑŸäŸÜŸäÿ© (ŸÜÿ≥ÿ®ÿ© ŸÑŸÑÿ¨ÿ®ÿ± ÿßŸÑÿ®ŸàŸÑŸäŸÜŸä ŸàŸáŸà ŸÜŸàÿπ ŸÖŸÜ ÿßŸÑŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑŸÖŸÜÿ∑ŸÇŸäÿ©): AND ŸàOR ŸàNOT ŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿ™ÿ≠ÿØŸäÿØ ÿ∑ŸÑÿ® ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™. ŸàŸáŸÜÿßŸÉ ÿÆÿØŸÖÿ© Ÿàÿ∏ŸäŸÅŸäÿ© ŸÖÿ™ŸÇÿØŸÖÿ© ŸáŸä ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿßŸÑÿ™ŸÇÿßÿ±ÿ®ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖÿ≥ÿßŸÅÿ© ÿ®ŸäŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ©ÿå ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ£ŸÑŸÅÿßÿ∏ ŸÖÿ´ŸÑ NEARÿå NOT NEARÿå FOLLOWED BYÿå NOT FOLLOWED BYÿå SENTENCEÿå FAR. Ÿäÿπÿ™ŸÖÿØ ŸÖÿØŸâ ŸÅÿßÿ¶ÿØÿ© ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿπŸÑŸâ ŸÖÿØŸâ ÿµŸÑÿ© ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™Ÿä Ÿäÿ±ÿØ ÿ®Ÿáÿß. ŸÅÿ®ŸäŸÜŸÖÿß ŸÇÿØ ÿ™ŸÉŸàŸÜ ŸáŸÜÿßŸÉ ŸÖŸÑÿßŸäŸäŸÜ ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸêÿ® ÿßŸÑÿ™Ÿä ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ŸÉŸÑŸÖÿ© ÿ£Ÿà ÿπÿ®ÿßÿ±ÿ© ŸÖÿ≠ÿØÿØÿ©ÿå ŸÇÿØ ÿ™ŸÉŸàŸÜ ÿ®ÿπÿ∂ ÿ£Ÿàÿ´ŸÇ ÿµŸÑÿ©ÿå ÿ£Ÿà ÿ£ÿ±Ÿàÿ¨ÿå ÿ£Ÿà ŸÖÿπÿ™ŸÖÿØÿ© ÿ£ŸÉÿ´ÿ± ŸÖŸÜ ÿ∫Ÿäÿ±Ÿáÿß. ŸÖÿπÿ∏ŸÖ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ™Ÿàÿ∏ŸÅ ÿ£ÿ≥ÿßŸÑŸäÿ® ŸÑŸàÿ∂ÿπ ŸÖÿ±ÿßÿ™ÿ® ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ŸÑÿ™ŸÇÿØŸÖ ÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿ£ŸàŸÑÿß. ÿßŸÑŸÉŸäŸÅŸäÿ© ÿßŸÑÿ™Ÿä ŸäŸÇÿ±ÿ± ÿ®Ÿáÿß ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿ£Ÿä ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ŸáŸä ÿßŸÑÿ£ŸÅÿ∂ŸÑ ÿ™ŸàÿßŸÅŸÇÿßÿå ŸàŸÖÿß ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ∞Ÿä Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ÿ∏Ÿáÿ± ÿ®Ÿá ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ÿå ÿ™ÿÆÿ™ŸÑŸÅ ÿ®ÿ¥ŸÉŸÑ ÿ¥ÿßÿ≥ÿπ ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉ ŸÑÿ¢ÿÆÿ±. ÿßŸÑÿ£ÿ≥ÿßŸÑŸäÿ® ÿ£Ÿäÿ∂ÿß ÿ™ÿ™ÿ∫Ÿäÿ± ÿπÿ®ÿ± ÿßŸÑÿ≤ŸÖŸÜ ÿ®ÿ™ÿ∫Ÿäÿ± ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ Ÿàÿ™ŸÉŸÜŸäŸÉÿßÿ™ ÿ¨ÿØŸäÿØÿ© ÿ™ÿ™ÿ∑Ÿàÿ±. ŸÖÿπÿ∏ŸÖ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸáŸä ŸÖÿ∂ÿßÿ±ÿ®ÿßÿ™ ÿ™ÿ¨ÿßÿ±Ÿäÿ© ŸäÿØÿπŸÖŸáÿß ÿπÿßÿ¶ÿØ ÿ•ÿπŸÑÿßŸÜŸä Ÿàÿå ÿ®ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ©ÿå ŸäŸàÿ∏ŸÅ ÿßŸÑÿ®ÿπÿ∂ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿ© ÿßŸÑŸÖÿ´Ÿäÿ±ÿ© ŸÑŸÑÿ¨ÿØŸÑ ÿ®ÿßŸÑÿ≥ŸÖÿßÿ≠ ŸÑŸÑŸÖÿπŸÑŸÜŸäŸÜ ÿ®ÿØŸÅÿπ ÿßŸÑŸÜŸÇŸàÿØ ŸÑŸäÿ±ŸÅÿπŸàÿß ŸÑŸáŸÖ ŸÇŸàÿßÿ¶ŸáŸÖ ŸÅŸä ŸÖÿ±ÿßÿ™ÿ® ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ®ÿ≠ÿ´. ÿßŸÑÿ£ÿ∫ŸÑÿ®Ÿäÿ© ÿßŸÑŸÉÿßÿ≥ÿ≠ÿ© ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ™ÿØŸäÿ±Ÿáÿß ÿ¥ÿ±ŸÉÿßÿ™ ÿÆÿßÿµÿ© ÿ™ÿ≥ÿ™ÿÆÿØŸÖ ÿÆŸàÿßÿ±ÿ≤ŸÖŸäÿßÿ™ ŸÖŸÑŸÉŸáÿß ŸàŸÇŸàÿßÿπÿØ ÿ®ŸäÿßŸÜÿßÿ™ ŸÖÿ∫ŸÑŸÇÿ©ÿå Ÿàÿ£ŸÉÿ´ÿ±Ÿáÿß ÿ±Ÿàÿßÿ¨ÿß ÿ≠ÿßŸÑŸäÿß ŸáŸä ÿ¨Ÿàÿ¨ŸÑ Ÿàÿ®ÿßÿ≠ÿ´ ÿ•ŸÖ‚Å¨ÿ•ÿ≥‚Å¨ÿ•ŸÜ ŸàŸäÿßŸáŸà. ÿ™Ÿàÿ¨ÿØ ÿ™ŸÇŸÜŸäÿ© ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿ®ÿ≠ÿ´ ŸÖŸÅÿ™Ÿàÿ≠ÿ© ÿßŸÑŸÖÿµÿØÿ± ŸÖÿ´ŸÑ ÿ•ÿ™ÿ¥‚Å¨ÿ™Ÿä‚Å¨ÿØŸêÿ¨ÿå ŸÜÿ™ÿ¥ÿå ÿ≥ŸäŸÜÿßÿ≤ÿå ÿ•Ÿäÿ¨Ÿàÿ´Ÿàÿ± Ÿàÿ£Ÿàÿ®ŸÜ‚Å¨ÿ•ŸÅ‚Å¨ÿ™Ÿä‚Å¨ÿ•ÿ≥ÿå ŸàŸÑŸÉŸÜ ŸÑŸäÿ≥ ŸáŸÜÿßŸÉ ÿÆÿßÿØŸÖ ÿ®ÿ≠ÿ´ ŸàŸàÿ±ŸÑÿØ ŸàÿßŸäÿØ ŸàŸêÿ® ŸÖÿ¥ÿßÿπ Ÿäÿ≥ÿ™ÿÆÿØŸÖ Ÿáÿ∞Ÿá ÿßŸÑÿ™ŸÇŸÜŸäÿ©. ÿ¨ÿßÿ° ÿ™ÿ∑Ÿàÿ± ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿßŸÑŸàŸêÿ® ŸÖŸÜ ÿ™ÿ∑Ÿàÿ± ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÑŸâ ÿ¥ÿ®ŸÉÿßÿ™ ÿßŸÑÿ£ÿ¨Ÿáÿ≤ÿ© ŸàÿßŸÑÿ¥ÿ®ŸÉÿßÿ™ ÿßŸÑÿØÿßÿÆŸÑŸäÿ©. ŸÅŸä ÿ®ÿπÿ∂ ÿØŸàŸÑ ÿ¥ÿ±ŸÇ ÿ¢ÿ≥Ÿäÿß Ÿàÿ±Ÿàÿ≥Ÿäÿß ŸÑŸäÿ≥ ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿ¨Ÿàÿ¨ŸÑ ŸáŸà ÿßŸÑÿ£ÿ¥Ÿáÿ± ÿ≠Ÿäÿ´ ÿßŸÜ ÿ≠ÿ≥ÿßÿ®ÿßÿ™Ÿá ŸàŸÖÿπÿßÿØŸÑÿßÿ™ ÿßŸÑŸÖÿ≠ÿ±ŸÉ ŸÑŸÑÿ®ÿ≠ÿ´ (algorithm) Ÿäÿ™ŸÖ ÿπŸÖŸÑ ÿ™ÿµŸÅŸäÿ© ÿ•ŸÇŸÑŸäŸÖŸäÿ© (regional filtering) ŸÑŸáÿß Ÿàÿ®ÿßŸÑÿ™ÿßŸÑŸä ÿ™ÿÆÿ™ŸÅŸä ŸÖÿπÿ∏ŸÖ ÿßŸÑŸÜŸàÿßÿ™ÿ¨.[6]\n.[7] ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ±Ÿàÿ≥Ÿä ŸäÿßŸÜÿØŸÉÿ≥ ŸäŸÖÿ™ŸÑŸÉ 61.9 ŸÅŸä ÿßŸÑŸÖÿ¶ÿ© ŸÖŸÜ ÿ≠ÿµÿ© ÿßŸÑÿ≥ŸàŸÇ. ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ£ÿµŸÑŸä ŸäŸÖŸÉŸÜŸÜÿß ÿßŸÑŸÇŸàŸÑ ÿ®ÿ£ŸÜ ÿßŸÑÿ¥ÿ®ŸÉÿ© ŸàŸÖŸàÿßŸÇÿπŸáÿß ŸÑŸÜ ÿ™ŸÉŸàŸÜ ÿ∞ÿßÿ™ ŸÅÿßÿ¶ÿØÿ© ŸÉÿ®Ÿäÿ±ÿ© ÿ®ÿßŸÑŸÜÿ≥ÿ®ÿ© ŸÑŸÜÿß ŸÑŸà ŸÑŸÖ ÿ™ŸÉŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÑŸâ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸÖŸàÿ¨ŸàÿØÿ©. ŸÅŸä ÿßŸÑÿ®ÿØÿ° ŸÉÿßŸÜÿ™ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿπÿ®ÿßÿ±ÿ© ÿπŸÜ ÿ£ÿØŸÑÿßÿ° ÿ™ŸÇŸàŸÖ ÿ®ŸÅŸáÿ±ÿ≥ÿ© ŸÖŸàÿßŸÇÿπ ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ©. ŸàŸÇÿØ ŸÉÿßŸÜ ÿ∞ŸÑŸÉ ŸÅÿπÿßŸÑÿß ÿπŸÜÿØŸÖÿß ŸÉÿßŸÜ ÿ≠ÿ¨ŸÖ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸäŸÇÿØÿ± ÿ®ŸÖŸÑÿßŸäŸäŸÜ ÿßŸÑÿµŸÅÿ≠ÿßÿ™. ÿ´ŸÖ ÿ™ÿ∑Ÿàÿ±ÿ™ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ÿå ŸàÿßŸÜÿ∂ŸÖ ÿ•ŸÑŸäŸáÿß ÿßŸÑŸÖŸÑÿßŸäŸäŸÜ ŸÖŸÜ ŸÖÿ§ÿ≥ÿ≥ÿßÿ™ ÿßŸÑÿ£ÿπŸÖÿßŸÑÿå ŸàÿßŸÑŸÖÿ§ÿ≥ÿ≥ÿßÿ™ ÿßŸÑÿ≠ŸÉŸàŸÖŸäÿ©ÿå Ÿàÿ®ŸÑÿßŸäŸäŸÜ ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ŸÖŸÜ ÿ£ÿØŸÑÿ© ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ÿå ŸàÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿÆÿßÿµÿ© ÿ®ÿßŸÑŸÖÿ≥ÿ™ÿ´ŸÖÿ±ŸäŸÜÿå Ÿàÿ∫Ÿäÿ± ÿ∞ŸÑŸÉ ŸÖŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÇŸàŸÖ ÿ®ÿ™ÿ≥ŸäŸäÿ± ÿπÿ¨ŸÑÿ© ÿßŸÇÿ™ÿµÿßÿØ ÿ•ŸÜÿ™ÿ±ŸÜÿ™. ŸàŸÖÿπ Ÿáÿ∞ÿß ÿßŸÑŸÜŸÖŸà ÿ£ÿµÿ®ÿ≠ ŸÖŸÜ ÿßŸÑÿ∂ÿ±Ÿàÿ±Ÿäÿå ÿ®ŸÑ ŸàŸÖŸÜ ÿßŸÑÿ≠ÿ™ŸÖŸä ÿ•ÿ∂ÿßŸÅÿ© ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ŸÅÿπÿßŸÑ ÿ•ŸÑŸâ ŸÉÿßŸÅÿ© ŸÖŸàÿßŸÇÿπ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ÿå ŸäŸÇŸàŸÖ ÿ®ŸÅŸáÿ±ÿ≥ÿ© Ÿàÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ÿ∂ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑŸÖŸàÿßŸÇÿπ ŸÉŸä ÿ™ÿ™ŸÖŸÉŸÜ ŸÖŸÜ ÿÆÿØŸÖÿ© ÿ≤Ÿàÿßÿ±Ÿáÿß ÿ®ÿ¥ŸÉŸÑ ŸÅÿπÿßŸÑ.\nŸàÿßŸÑŸäŸàŸÖÿå Ÿàÿ®ÿπÿØ ÿ£ŸÜ ÿ£ÿµÿ®ÿ≠ÿ™ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ¨ÿ≤ÿ°ÿß ÿ£ÿ≥ÿßÿ≥Ÿäÿß ŸÅŸä ÿ≠ÿ∂ÿßÿ±ÿ™ŸÜÿß ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™Ÿäÿ©ÿå ŸÅÿ•ŸÜ ŸáŸÜÿßŸÉ ÿßŸÑÿπÿ¥ÿ±ÿßÿ™ ŸÖŸÜ ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ÿßŸÑÿπÿßŸÖŸÑÿ© ŸÅŸä ŸÖÿ¨ÿßŸÑ ÿ•ŸÜÿ™ÿßÿ¨ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ÿå Ÿàÿ™ŸÇŸÜŸäÿßÿ™ÿå Ÿàÿ£ÿ≥ÿßŸÑŸäÿ® ÿ®ÿ≠ÿ´ ÿ¨ÿØŸäÿØÿ© ŸÖŸàÿ¨Ÿáÿ© ŸÜÿ≠Ÿà ÿ•ŸÜÿ™ÿ±ŸÜÿ™ Ÿàÿ•ŸÜÿ™ÿ±ÿßŸÜÿ™. Ÿàÿ®ÿ≥ÿ®ÿ® ÿßŸÑÿØŸàÿ± ÿßŸÑŸÖÿ™ÿ≤ÿßŸäÿØ ÿßŸÑÿ∞Ÿä ÿ™ŸÑÿπÿ®Ÿá ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ© ŸàÿßŸÑÿ£ÿπŸÖÿßŸÑ ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿ© ŸÅŸä ÿßŸÇÿ™ÿµÿßÿØ ÿßŸÑŸäŸàŸÖÿå ŸÅÿ•ŸÜ ÿßŸÑÿ≠ÿßŸÅÿ≤ ÿßŸÑŸÖÿßÿØŸä ÿπŸÑŸâ ÿßŸÑÿ£ŸÇŸÑ ŸÖŸàÿ¨ŸàÿØ. ŸàŸÑŸÉŸÜ ÿ±ÿ∫ŸÖ ÿßŸÑŸÜÿ¨ÿßÿ≠ ÿßŸÑÿ∞Ÿä ÿ™ÿØŸëÿπŸä ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿ© ŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ™ÿ≠ŸÇŸäŸÇŸáÿå ŸÅÿ•ŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸÑÿß ÿ≤ÿßŸÑŸàÿß Ÿäÿ¥ŸÉŸàŸÜ ŸÖŸÜ ÿßŸÅÿ™ŸÇÿßÿ± ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ•ŸÑŸâ ÿßŸÑÿØŸÇÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©ÿå Ÿàÿ™ŸÑÿ®Ÿäÿ© ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™Ÿä Ÿäÿ™ŸÖ ÿ™ÿ≠ÿµŸäŸÑŸáÿß ŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿ•ŸÜ ŸÖŸÅÿ™ÿßÿ≠ ÿßŸÑŸÜÿ¨ÿßÿ≠ ŸÅŸä ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÜÿ™ÿßÿ¶ÿ¨ ÿ®ÿ≠ÿ´ ÿ¨ŸäÿØÿ©ÿå ÿ™ŸÉŸÖŸÜ ŸÅŸä ŸÜŸàÿπŸäÿ© ÿßŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿßÿ™ÿå ÿ£Ÿà ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©ÿå ÿ£Ÿà ÿßŸÑÿπÿ®ÿßÿ±ÿßÿ™ ÿ£Ÿà ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ÿßŸÑÿ™Ÿä ŸÜŸÇŸàŸÖ ÿ®ÿ•ÿØÿÆÿßŸÑŸáÿß ŸÅŸä ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´. ŸÑŸÉŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸáŸÜÿß ÿ™ŸÉŸÖŸÜ ŸÅŸä ÿ£ŸÜ ÿßŸÑÿ∫ÿßŸÑÿ®Ÿäÿ© ÿßŸÑÿπÿ∏ŸÖŸâ ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸÑÿß ŸäŸÇŸàŸÖŸàŸÜ ÿπÿßÿØÿ© ÿ®ÿ•ÿØÿÆÿßŸÑ ÿßŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿßÿ™ ÿ£Ÿà ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ÿßŸÑÿµÿ≠Ÿäÿ≠ÿ©ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ§ÿØŸä ÿ•ŸÑŸâ ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©ÿå Ÿàÿ≥ŸÜÿ≥ÿ™ÿπÿ±ÿ∂ ŸÅŸäŸÖÿß ŸäŸÑŸä ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ŸÅŸä ÿπÿßŸÑŸÖ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ÿå ŸàÿßŸÑÿ∑ÿ±ŸÇ ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿßŸàŸÑ ÿ®Ÿáÿß ÿßŸÑÿ®ÿßÿ≠ÿ´ŸàŸÜ ŸÖÿπÿßŸÑÿ¨ÿ© Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿßÿ™. ŸÖŸÜ ÿßŸÑÿ≠ŸÇÿßÿ¶ŸÇ ÿßŸÑÿ∫ÿ±Ÿäÿ®ÿ© ÿßŸÑÿ™Ÿä Ÿäÿ§ŸÉÿØŸáÿß ÿÆÿ®ÿ±ÿßÿ° ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸáŸä ÿ£ŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸÜÿßÿØÿ±ÿß ŸÖÿß ŸäŸÇŸàŸÖŸàŸÜ ÿ®ÿ∑ÿ±ÿ≠ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ™Ÿä ÿ™ÿπÿ®ÿ± ÿπŸÖÿß Ÿäÿ±ŸäÿØŸàŸÜŸá ŸÅÿπŸÑÿß. ŸàÿßŸÑÿ≥ÿ®ÿ® ÿßŸÑÿ±ÿ¶Ÿäÿ≥ ŸÅŸä ÿ∞ŸÑŸÉ ŸáŸà ÿßŸÑÿßŸÅÿ™ŸÇÿßÿ± ÿ•ŸÑŸâ ÿßŸÑŸÅŸáŸÖ ÿßŸÑÿµÿ≠Ÿäÿ≠ ŸÑŸÑŸÖŸàÿ∂Ÿàÿπ ŸÇŸäÿØ ÿßŸÑÿ®ÿ≠ÿ´ÿå Ÿàÿ®ÿßŸÑÿ™ÿßŸÑŸä ÿπÿØŸÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ÿßŸÑÿµÿ≠Ÿäÿ≠ÿ©ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ§ÿØŸä ÿ•ŸÑŸâ ÿ™ŸÉŸàŸäŸÜ ÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿßÿ™ Ÿàÿ£ÿ≥ÿ¶ŸÑÿ© ÿµÿ≠Ÿäÿ≠ÿ©. ŸÅÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸáŸÜÿß ÿ•ÿ∞ÿßÿå ŸáŸä ŸÖÿ≥ÿßÿπÿØÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿπŸÑŸâ ÿ∑ÿ±ÿ≠ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© Ÿàÿ™ŸÉŸàŸäŸÜ ÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿßÿ™ ÿßŸÑÿµÿ≠Ÿäÿ≠ÿ©.\nŸàŸÖŸÜ ŸÖÿ∏ÿßŸáÿ± Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ£Ÿäÿ∂ÿß ŸáŸä ÿµÿ∫ÿ± ÿ≠ÿ¨ŸÖ ÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿßÿ™ ÿßŸÑÿ™Ÿä ŸäŸÉŸàŸÜŸáÿß ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿπÿßÿØÿ© ŸÑŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ± ÿπŸÜ ŸÖŸàÿ∂Ÿàÿπ ŸÖÿπŸäŸÜ. ŸÅÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿß Ÿäÿ±ŸäÿØ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÜ ¬´ÿßŸÑÿ≥ŸÅÿ±¬ª ŸÖÿ´ŸÑÿßÿå ŸÅÿ•ŸÜŸá Ÿäÿ®ÿØÿ£ ÿ®ÿ•ÿØÿÆÿßŸÑ ŸÉŸÑŸÖÿ© ÿπÿßŸÖÿ© ŸÅŸä ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸàŸÖŸÜ ÿ´ŸÖÿå Ÿàÿßÿπÿ™ŸÖÿßÿØÿß ÿπŸÑŸâ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿµŸÑ ÿπŸÑŸäŸáÿßÿå ŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∂ŸäŸäŸÇ ŸÜÿ∑ÿßŸÇ ÿ®ÿ≠ÿ´Ÿá ÿ•ŸÑŸâ ÿ£ŸÜ ŸäÿµŸÑ ÿ•ŸÑŸâ ŸÖÿß Ÿäÿ±ŸäÿØŸá. ŸàÿßŸÑÿ≥ÿ®ÿ® ŸÅŸä ÿ£ŸÜ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ•ŸÜÿ™ÿ±ŸÜÿ™ Ÿäÿ≥ÿ™ÿπŸÖŸÑŸàŸÜ Ÿáÿ∞ÿß ÿßŸÑÿ£ÿ≥ŸÑŸàÿ® ŸäŸÉŸÖŸÜ ŸÅŸä ÿ£ŸÜŸáŸÖ ŸÑÿß Ÿäÿπÿ±ŸÅŸàŸÜ ÿ≠ŸÇÿß ÿßŸÑÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸáŸàŸÑ ŸÑŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ŸÇŸàÿßÿπÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿÆÿßÿµÿ© ÿ®ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ŸÅŸàŸÇ ÿπÿßÿØÿ© ŸÖÿß ŸäŸÖŸÉŸÜ ŸÑÿ£Ÿä ÿ•ŸÜÿ≥ÿßŸÜ ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπŸá. ÿ™ÿ™ŸÖŸäÿ≤ ŸÖÿπÿ∏ŸÖ ÿßŸÑŸÑÿ∫ÿßÿ™ ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ÿ®ÿ™ŸÜŸàÿπ ÿßŸÑŸÖŸÅÿ±ÿØÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ™ŸÜÿßŸàŸÑ ŸÜŸÅÿ≥ ÿßŸÑŸÖÿπŸÜŸâÿå ŸÅŸÖÿ´ŸÑÿßŸã (ÿßŸÑÿ≥ÿ≠ÿßÿ®ÿå ÿßŸÑÿ∫ŸÖÿßŸÖÿå ÿßŸÑŸÖÿ≤ŸÜÿå ÿßŸÑÿπÿßÿ±ÿ∂.. Ÿàÿ∫Ÿäÿ±Ÿáÿß) ÿ™ÿØŸàÿ± ÿ≠ŸàŸÑ ŸÜŸÅÿ≥ ÿßŸÑŸÖÿπŸÜŸâ ÿ≥ÿ≠ÿßÿ®ÿå Ÿàÿ®ŸäŸÜŸÖÿß ŸäÿØÿ±ŸÉ ÿßŸÑÿ•ŸÜÿ≥ÿßŸÜ ÿ™ÿ∑ÿßÿ®ŸÇ Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÅÿ±ÿØÿßÿ™ ŸÅŸä ÿßŸÑŸÖÿπŸÜŸâ ÿ™ÿπÿ¨ÿ≤ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™ŸÇŸÑŸäÿØŸäÿ© ÿπŸÜ ÿßÿ≥ÿ™Ÿäÿπÿßÿ® ŸÉŸÑ ÿßŸÑŸÖÿ±ÿßÿØŸÅÿßÿ™ ÿßŸÑŸÖŸÖŸÉŸÜÿ©ÿå ŸÅÿ™ŸÅÿ™ŸÇÿ± ŸÜÿ™ÿßÿ¶ÿ¨Ÿáÿß ÿ•ŸÑŸâ ŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿ∞ÿßÿ™ ÿßŸÑÿπŸÑÿßŸÇÿ© ÿ®ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ®ÿ≠ÿ´ ŸÑŸÉŸÜŸáÿß ŸÑŸÖ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ ŸÜŸÅÿ≥ ŸÖŸÅÿ±ÿØÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿå Ÿàÿ™ÿ≥ŸÖŸâ Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÅÿ¨Ÿàÿ© ÿßŸÑŸÖŸÅÿ±ÿØÿßÿ™. ÿπŸÜÿØ ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπ ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸÑÿß ÿ®ÿØ ŸÖŸÜ ÿßŸÑŸÖŸàÿßÿ≤ŸÜÿ© ÿ®ŸäŸÜ ÿßŸÑŸÉŸÖ ŸàÿßŸÑŸÜŸàÿπÿå ÿ£Ÿà ŸÖÿß ŸäÿØÿπŸàŸá ÿßŸÑÿÆÿ®ÿ±ÿßÿ° ÿ®ÿßŸÑÿØŸÇÿ© ŸàÿßŸÑŸÇÿØÿ±ÿ© ÿπŸÑŸâ ÿßŸÑÿßÿ≥ÿ™ÿ±ÿ¨ÿßÿπ. ŸàŸáŸä ÿπŸÑÿßŸÇÿ© ÿπŸÉÿ≥Ÿäÿ© ÿ™ŸÖÿßŸÖÿßÿå ŸÅŸÉŸÑŸÖÿß ÿ™ŸÖ ÿ™ÿ∂ŸäŸäŸÇ ŸÜÿ∑ÿßŸÇ ÿßŸÑÿ®ÿ≠ÿ´ ÿ≥ÿπŸäÿß ÿπŸÜ ŸÜÿ™ÿßÿ¶ÿ¨ ÿ£ŸÉÿ´ÿ± ÿØŸÇÿ©ÿå ŸÉŸÑŸÖÿß ŸÇŸÑ ŸÖŸÇÿØÿßÿ± ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ∞Ÿä ŸäŸÖŸÉŸÜ ÿßÿ≥ÿ™ÿ±ÿ¨ÿßÿπŸá. ŸàŸÑÿ∞ŸÑŸÉ ŸÅÿ•ŸÜ ŸáŸÜÿßŸÉ ÿ≠ÿßÿ¨ÿ© ŸÑŸàÿ¨ŸàÿØ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿ®ÿ≠ÿ´ ÿ™ŸÇÿØŸÖ ÿØŸÇÿ© ÿπÿßŸÑŸäÿ© ÿØŸàŸÜ ÿßŸÑÿ™ÿ∂ÿ≠Ÿäÿ© ÿ®ŸÖŸÇÿØÿßÿ± ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ¬´ÿßŸÑÿØŸÇŸäŸÇÿ©¬ª ÿßŸÑÿ™Ÿä ŸÜÿ≥ÿ™ÿ±ÿ¨ÿπŸáÿß. ŸÖÿπÿ∏ŸÖ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿ™ÿ≠ŸÖŸÑ ÿ£ŸÉÿ´ÿ± ŸÖŸÜ ŸÖÿπŸÜŸâÿå ŸàŸÖÿπÿ∏ŸÖ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ© ÿßŸÑŸäŸàŸÖ ÿ™ŸÇŸàŸÖ ÿ®ŸÖÿ∑ÿßÿ®ŸÇÿ© ÿßŸÑŸÉŸÑŸÖÿßÿ™ ŸàŸÑŸäÿ≥ ŸÖÿπÿßŸÜŸäŸáÿßÿå ŸàŸÑÿ∞ŸÑŸÉ ŸÅÿ•ŸÜ ŸÜÿ™ÿßÿ¶ÿ¨ ÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™Ÿä ŸÜÿ≠ÿµŸÑ ÿπŸÑŸäŸáÿßÿå ÿ™ÿ≠ÿ™ŸàŸä ÿ∫ÿßŸÑÿ®ÿß ÿπŸÑŸâ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ÿßŸÑÿµÿ≠Ÿäÿ≠ÿ©ÿå ŸàŸÑŸÉŸÜŸáÿß ÿ∞ÿßÿ™ ÿßŸÑŸÖÿπŸÜŸâ ÿßŸÑÿÆÿßÿ∑ÿ¶. ŸÅÿ•ÿ∞ÿß ÿ¨ÿ±ÿ®ÿ™ ŸÖÿ´ŸÑÿß ÿ£ŸÜ ÿ™ÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖÿπŸÜŸâ ŸÉŸÑŸÖÿ© ¬´ÿ¨ÿßŸÅÿß¬ª ŸÖÿ´ŸÑÿßÿå ŸàŸáŸä ÿ•ÿ≠ÿØŸâ ŸÑÿ∫ÿßÿ™ ÿßŸÑÿ®ÿ±ŸÖÿ¨ÿ© ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖÿå ŸÅÿ•ŸÜŸÉ ÿ≥ÿ™ÿ≠ÿµŸÑ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿßŸÑÿ¨ŸÅÿßŸÅÿå ÿ£Ÿà ÿ®ÿßÿ≥ŸÖ ÿ¨ÿ≤Ÿäÿ±ÿ© ÿ•ŸÜÿØŸàŸÜŸäÿ≥Ÿäÿ© ÿ™ÿ≠ŸÖŸÑ ÿßŸÑÿßÿ≥ŸÖ ŸÜŸÅÿ≥Ÿáÿå ÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÜ ŸÑÿ∫ÿ© ÿßŸÑÿ®ÿ±ŸÖÿ¨ÿ© ŸÑÿßŸÜŸá Ÿäÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑÿ®ŸÜŸäÿ© ÿßŸÑÿµÿ±ŸÅŸäÿ© ŸàÿßŸÑÿ¥ŸÉŸÑŸäŸá ŸÑŸÑŸÉŸÑŸÖÿ© ŸàŸÑŸäÿ≥ ŸÖÿπŸÜÿßŸáÿß. ŸàŸÖÿßÿ∞ÿß ÿπŸÜ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑÿ£ÿ≥ŸÖÿßÿ°ÿå ÿ£Ÿä ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÜ ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ŸàÿßŸÑÿ£ŸÖÿßŸÉŸÜÿå ŸàŸÖÿß ÿ•ŸÑŸâ ÿ∞ŸÑŸÉ. ÿÆÿµŸàÿµÿß Ÿàÿ£ŸÜ ÿßŸÑŸÉÿ™ÿßÿ® Ÿäÿ∫Ÿäÿ±ŸàŸÜ ÿπÿßÿØÿ© ÿßŸÑÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑÿ™Ÿä ŸäŸÇŸàŸÖŸàŸÜ ÿ®Ÿáÿß ÿ®ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑÿ£ÿ≥ŸÖÿßÿ°. Ÿàÿ•ÿ∞ÿß ŸÖÿß ÿ™ÿ≠ÿØÿ´ŸÜÿß ŸÖÿ´ŸÑÿß ÿπŸÜ ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ÿå ŸÅÿ•ŸÜŸáÿß ÿ™ÿ™ÿ∫Ÿäÿ± ÿ®ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ± ŸÜÿ™Ÿäÿ¨ÿ© ÿπŸÖŸÑŸäÿ© ÿßŸÑÿßŸÜÿØŸÖÿßÿ¨ ŸàÿßŸÑÿ∂ŸÖÿå ŸÖŸÖÿß Ÿäÿ¨ÿπŸÑ ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´ ÿµÿπÿ®ÿ©. ŸàŸÇÿØ ŸäŸÇŸàŸÑ ÿßŸÑÿ®ÿπÿ∂ ÿ£ŸÜŸá ŸäŸÖŸÉŸÜ ÿßŸÑÿ™ÿ∫ŸÑÿ® ÿπŸÑŸâ Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÜŸàÿπÿß ŸÖÿß ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑŸÅŸáÿ±ÿ≥ÿ©ÿå ŸàŸÑŸÉŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸáŸä ÿ£ŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÅŸä ÿπÿßŸÑŸÖŸÜÿß ÿ™ÿ™ÿ∫Ÿäÿ± ÿ®ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ± ŸÖŸÖÿß Ÿäÿ¨ÿπŸÑ ÿßŸÑŸÅŸáÿ±ÿ≥ÿ© ÿßŸÑŸäÿØŸàŸäÿ© ÿµÿπÿ®ÿ©. ŸàŸÖÿßÿ∞ÿß ÿπŸÜ ÿßŸÑŸÅŸáÿ±ÿ≥ÿ© ÿßŸÑÿ¢ŸÑŸäÿ©ÿü ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ŸáŸä ÿ£ŸÜŸá ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ®ÿπÿØ ÿßŸÑÿ™ŸÇŸÜŸäÿ© ÿßŸÑÿ™Ÿä ŸäŸÖŸÉŸÜŸáÿß ÿßŸÑŸÇŸäÿßŸÖ ÿ®ÿ∞ŸÑŸÉ ÿ®ÿØŸÇÿ©ÿå ÿ®ÿ≠Ÿäÿ´ ŸäŸÖŸÉŸÜ ÿßŸÑÿ™ŸÖŸäŸäÿ≤ ŸÖÿ´ŸÑÿß ÿ®ŸäŸÜ ŸÖŸÇÿßŸÑ ŸÉÿßŸÖŸÑ ÿπŸÜ ÿ¥ÿÆÿµ ŸÖÿπŸäŸÜÿå ŸàŸÖŸÇÿßŸÑ ÿ¢ÿÆÿ± Ÿäÿ∞ŸÉÿ± ÿßÿ≥ŸÖ ÿßŸÑÿ¥ÿÆÿµ ÿ®ÿ¥ŸÉŸÑ ÿπÿßÿ®ÿ±. Ÿäÿ¨ŸÖÿπ ÿßŸÑÿπÿßŸÖŸÑŸàŸÜ ŸÅŸä ŸÖÿ¨ÿßŸÑ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿ£ŸÜ ÿßŸÑÿ≠ŸÑ ŸÑŸÉÿßŸÅÿ© Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ŸäŸÉŸÖŸÜ ŸÅŸä ÿ™ÿµŸÖŸäŸÖ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå Ÿàÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÖŸàŸÖÿßÿå ÿ®ÿ≠Ÿäÿ´ ÿ™ÿ≥ÿ™ŸÅŸäÿØ ŸÖŸÜ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÑŸÑÿ∫ÿ© Natural Language ProcessingÿπŸÖŸàŸÖÿßÿå ŸàÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÑŸÑŸÖÿπŸÜŸâ Natural Meaning Processingÿå ŸàÿßŸÑÿßÿ≥ÿ™ŸÅÿßÿØÿ© ŸÖŸÜ ŸÇŸàÿßÿπÿØ ÿßŸÑŸÑÿ∫ÿ©.\nÿßŸÑŸÜŸÇÿ∑ÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸáŸÜÿß ŸáŸä ÿ£ŸÜ ÿßŸÑŸÑÿ∫ÿ© ÿπŸÖŸàŸÖÿß ŸÖÿ®ŸÜŸäÿ© ÿπŸÑŸâ ÿ£ÿ≥ÿßÿ≥ ŸÇŸàÿßÿπÿØ ÿ∞ÿßÿ™ ÿ£ÿ≥ÿßÿ≥ ÿ¥ÿ®ŸäŸá ÿ®ÿßŸÑŸÖÿπÿßÿØŸÑÿßÿ™ ÿßŸÑÿ±Ÿäÿßÿ∂Ÿäÿ©ÿå ŸÉŸÖÿß ÿ£ŸÜ ÿπÿ®ÿßÿ±ÿßÿ™ ÿßŸÑŸÑÿ∫ÿ© ŸàŸÉŸÑŸÖÿßÿ™Ÿáÿß ÿ™ŸÉŸàŸÜ ŸÖÿ®ŸÜŸäÿ© ÿ≠ÿ≥ÿ® ŸáŸäŸÉŸÑŸäÿ© ŸÖÿπŸäŸÜÿ©ÿå ŸÅŸÑŸÉŸÑ ÿ¨ŸÖŸÑÿ© ŸÖÿ®ÿ™ÿØÿ£ ŸàÿÆÿ®ÿ±ÿå ÿ£Ÿà ŸÅÿπŸÑ ŸàŸÅÿßÿπŸÑ ŸàŸÖŸÅÿπŸàŸÑ ÿ®Ÿáÿå ŸÉŸÖÿß ÿ£ŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿ™ÿ£ÿ™Ÿä ÿπÿßÿØÿ© ŸÖŸÜ ÿ¨ÿ∞Ÿàÿ± Ÿàÿ£ÿµŸàŸÑ. ŸàŸáÿ∞Ÿá ÿßŸÑŸáŸäŸÉŸÑŸäÿ© ÿßŸÑŸÖÿ®ŸÜŸäÿ© ÿ∂ŸÖŸÜ ÿßŸÑŸÑÿ∫ÿ© ÿ™ÿ™ŸÜÿßÿ≥ÿ® Ÿàÿ∑ÿ®Ÿäÿπÿ© ÿπŸÖŸÑ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ®ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ≠ÿ™ÿßÿ¨ ÿ•ŸÑŸâ ŸáŸäŸÉŸÑŸäÿ© ŸÖÿπŸäŸÜÿ© ÿ™ŸÜŸÅÿ∞ ÿπŸÑŸâ ÿ£ÿ≥ÿßÿ≥Ÿáÿß ÿπŸÖŸÑŸäÿßÿ™Ÿáÿß.\nÿ£ŸÖÿß ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÑŸÑŸÖÿπŸÜŸâ ŸÅŸáŸä ÿ£ŸÉÿ´ÿ± ÿµÿπŸàÿ®ÿ©ÿå ŸÅŸÉŸÑŸÖÿ© ŸÖÿ´ŸÑ ¬´ÿ±ÿßÿ≠ÿ©¬ª ŸäŸÖŸÉŸÜ ŸÑŸáÿß ÿ£ŸÜ ÿ™ÿπŸÜŸä ÿπÿØÿ© ÿ£ÿ¥Ÿäÿßÿ°ÿå ŸÉÿßŸÑÿßÿ±ÿ™Ÿäÿßÿ≠ ÿ®ÿπÿØ ÿßŸÑÿ™ÿπÿ®ÿå ÿ£Ÿà ÿßŸÑÿ±ÿßÿ≠ÿ© ÿßŸÑÿ£ÿ®ÿØŸäÿ© ŸàÿßŸÑÿ™Ÿä ÿ™ÿπŸÜŸä ÿßŸÑŸÖŸàÿ™ÿå ÿ£Ÿà ÿ±ÿßÿ≠ÿ© ÿßŸÑŸäÿØ. ŸàŸÑŸáÿ∞ÿß ŸÅÿ•ŸÜ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ÿ™ŸÖŸÉŸÜ ŸÖŸÜ ŸÅŸáŸÖ ÿßŸÑŸÉŸÑŸÖÿ© ÿ∂ŸÖŸÜ ÿ≥ŸäÿßŸÇ ÿßŸÑŸÜÿµÿå ŸàÿØŸàÿ± ÿßŸÑŸÉŸÑŸÖÿ© ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑÿ≥ŸäÿßŸÇ. ŸàŸÑŸÉŸÜ ÿ≠ÿ™Ÿâ Ÿáÿ∞ÿß ÿßŸÑÿ£ÿ≥ŸÑŸàÿ® ŸÑÿß ŸäŸÅŸÑÿ≠ ÿØŸàŸÖÿß ŸÅŸä ŸÅŸáŸÖ ÿßŸÑŸÖÿπŸÜŸâ. ÿ¨ÿ±ÿ® ÿ£ŸÜ ÿ™ŸÇÿ±ÿ£ ÿØŸäŸàÿßŸÜÿß ÿ¥ÿπÿ±Ÿäÿß ÿ¨ŸäÿØÿßÿå Ÿàÿ≥ÿ™ÿ¨ÿØ ÿ£ŸÜ ŸáŸÜÿßŸÑŸÉ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿµÿπÿ®ÿ©ÿå ŸàÿßŸÑÿ™Ÿä ŸÇÿØ Ÿäÿ≠ÿßŸàŸÑ ÿßŸÑÿ®ÿπÿ∂ ŸÅŸáŸÖŸáÿß ŸÖŸÜ ÿßŸÑÿ≥ŸäÿßŸÇÿå ŸàŸÑŸÉŸÜŸÜÿß ÿπŸÜÿØŸÖÿß ŸÜÿπÿ¨ÿ≤ ÿπŸÜ ÿ∞ŸÑŸÉ ŸÅÿ•ŸÜŸÜÿß ŸÜÿ™ÿ¨Ÿá ÿ•ŸÑŸâ ÿßŸÑŸÇÿßŸÖŸàÿ≥. ŸàŸáÿ∞ÿß ÿ£ÿ≥ŸÑŸàÿ® ŸäŸÖŸÉŸÜ ŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ® ÿßÿ™ÿ®ÿßÿπŸáÿå ÿ£Ÿä ÿßŸÑÿßÿπÿ™ŸÖÿßÿØ ÿπŸÑŸâ ŸÇÿßŸÖŸàÿ≥ ÿ£Ÿà ŸÅŸáÿ±ÿ≥ ÿ®ÿßŸÑŸÉŸÑŸÖÿßÿ™ ŸàÿßŸÑÿπÿ®ÿßÿ±ÿßÿ™ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖÿå ŸàÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑÿ≥ŸäÿßŸÇ.\nŸàŸÅŸäŸÖÿß ŸäŸÑŸä ÿ®ÿπÿ∂ ŸÖŸÅÿßŸáŸäŸÖ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™Ÿä ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÑŸÑÿ∫ÿ©ÿõ ÿ™ÿ™ŸÖŸäÿ≤ ÿßŸÑÿ¨ŸèŸÖŸÑ ÿ®ÿ£ŸÜŸáÿß ÿ∞ÿßÿ™ ŸáŸäŸÉŸÑŸäÿ© ŸÖÿ≠ÿØÿØÿ© ŸàŸàÿßÿ∂ÿ≠ÿ©ÿå ŸÖŸÖÿß Ÿäÿ≥ÿßÿπÿØ ŸÅŸä ŸÅŸáŸÖ ÿßŸÑŸÖÿπŸÜŸâ ÿ®ÿ¥ŸÉŸÑ ÿ≥ÿ±Ÿäÿπ. ŸàŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ™ÿ≠ÿØŸäÿØ ŸÜŸàÿπ ÿßŸÑÿ¨ŸÖŸÑÿ©ÿå ŸäŸÖŸÉŸÜ ŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ£ŸÜ ÿ™ŸÇŸàŸÖ ÿ®ÿπŸÖŸÑŸáÿß ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÉÿ´ÿ± ÿØŸÇÿ©.\nŸàŸÑÿπŸÖŸÑ ÿ∞ŸÑŸÉ ŸÅÿ•ŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ŸÉŸÖŸäÿßÿ™ ŸÉÿ®Ÿäÿ±ÿ© ŸÖŸÜ ÿßŸÑŸÖÿµÿßÿØÿ± ŸàÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑŸÑÿ∫ŸàŸäÿ©ÿå ŸÉÿßŸÑŸÖŸÉÿßŸÜÿ≤ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿπÿ®ÿßÿ±ÿßÿ™ Ÿàÿ¨ŸÖŸÑ ÿ∞ÿßÿ™ ÿπŸÑÿßŸÇÿßÿ™ ŸÖÿ≠ÿØÿØÿ© ŸÖÿ≥ÿ®ŸÇÿß. Ÿàÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÉÿßŸÜÿ≤ ŸäŸÖŸÉŸÜ ŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ£ŸÜ ÿ™ŸÅŸáŸÖ ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÅÿ∂ŸÑ ÿ∑ÿ®Ÿäÿπÿ© ÿßŸÑÿπŸÑÿßŸÇÿ© ÿ®ŸäŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ© ŸàŸÖŸàÿßŸÇÿπŸáÿß ÿßŸÑÿµÿ≠Ÿäÿ≠ÿ© ÿ∂ŸÖŸÜ ÿßŸÑÿ¨ŸÖŸÑ. Ÿàÿ±ÿ∫ŸÖ ÿßŸÑŸÅÿßÿ¶ÿØÿ© ÿßŸÑÿπÿ∏ŸäŸÖÿ© ŸÑŸÑŸÖŸÉÿßŸÜÿ≤ÿå ŸÅÿ•ŸÜ ŸÖÿØŸâ ŸÅÿπÿßŸÑŸäÿ™Ÿáÿß Ÿäÿπÿ™ŸÖÿØ ÿπŸÑŸâ ÿ™ÿ≠ÿØŸäÿ´Ÿáÿß ÿ®ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±ÿå Ÿàÿ•ŸÑÿß ŸÅÿ•ŸÜŸáÿß ÿ™ŸÅŸÇÿØ ŸÅÿßÿπŸÑŸäÿ™Ÿáÿß ÿ™ÿØÿ±Ÿäÿ¨Ÿäÿß. Ÿàÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖŸÉÿßŸÜÿ≤ÿå Ÿàÿ™ÿµÿ±ŸäŸÅ ÿßŸÑÿ¨ŸÖŸÑ Ÿàÿ•ÿπÿ±ÿßÿ®Ÿáÿß ŸäŸÖŸÉŸÜ ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÜÿ∏ŸÖ ÿ®ÿ≠ÿ´ ŸÇŸàŸäÿ© ŸäŸÖŸÉŸÜŸáÿß ŸÅŸáŸÖ ÿπÿ®ÿßÿ±ÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸàŸÖÿπÿßŸÜŸä ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿ∂ŸÖŸÜ ÿßŸÑÿ≥ŸäÿßŸÇ ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÅÿ∂ŸÑ. ÿ£Ÿàÿ∂ÿ≠ŸÜÿß ŸÅŸä ÿßŸÑŸÜŸÇÿ∑ÿ© ÿ£ÿπŸÑÿßŸá ŸÉŸäŸÅ ŸäŸÖŸÉŸÜ ŸÑŸÑŸÖŸÉÿßŸÜÿ≤ ŸàŸÜÿ∏ŸÖ ÿ™ÿµÿ±ŸäŸÅ Ÿàÿ•ÿπÿ±ÿßÿ® ÿßŸÑÿ¨ŸÖŸÑ ÿ£ŸÜ ÿ™ÿ≥ŸáŸÖ ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÅÿ∂ŸÑ ŸÅŸä ŸÅŸáŸÖ ÿßŸÑŸÖÿπŸÜŸâ ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿßŸÑÿ≥ŸäÿßŸÇ. ŸàŸáÿ∞Ÿá ÿßŸÑÿ™ŸÇŸÜŸäÿ© ŸÖŸÅŸäÿØÿ© ÿ•ÿ∞ÿß ŸÉŸÜÿß ŸÜÿ®ÿ≠ÿ´ ÿ∂ŸÖŸÜ ŸÜÿµ ŸÖÿπŸäŸÜÿå ŸàŸÑŸÉŸÜŸáÿß ŸÑŸäÿ≥ÿ™ ŸÖŸÅŸäÿØÿ© ÿπŸÜÿØ ÿ•ÿØÿÆÿßŸÑ ÿßŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿßÿ™ ŸàÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿßÿ™ ÿ∂ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå ÿ≠Ÿäÿ´ ÿ™ÿ™ŸÉŸàŸÜ Ÿáÿ∞Ÿá ÿπÿßÿØÿ© ŸÖŸÜ ÿπÿØÿØ ŸÖÿ≠ÿØŸàÿØ ŸÖŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ÿå Ÿàÿ®ÿßŸÑÿ™ÿßŸÑŸä ŸÅÿ•ŸÜ ÿ≠ÿ¨ŸÖ ÿßŸÑŸÜÿµ ÿ∫Ÿäÿ± ŸÉÿßŸÅ ŸÑÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿπŸÜŸâ ÿßŸÑŸÉŸÑŸÖÿßÿ™. ŸàÿßŸÑÿ≠ŸÑ ŸÑŸáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿßÿ∂ÿ≠ ÿ•ŸÑŸâ ÿØÿ±ÿ¨ÿ© ÿßŸÑÿ•ÿ≠ÿ±ÿßÿ¨ ŸàŸäÿ™ŸÖÿ´ŸÑ ŸÅŸä ÿ≥ÿ§ÿßŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿπŸÜ ÿßŸÑŸÖÿπŸÜŸâ ÿßŸÑÿ∞Ÿä ŸäŸÇÿµÿØŸáÿõ ŸÅÿπŸÜÿØŸÖÿß ŸäŸèÿØÿÆŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÉŸÑŸÖÿ© ¬´ÿ±ÿßÿ≠ÿ©¬ª ŸÖÿ´ŸÑÿß ÿ∂ŸÖŸÜ ŸÖÿ±ÿ®ÿπ ÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿå ŸÅÿ•ŸÜ ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ Ÿäÿ≥ÿ£ŸÑŸá ÿπŸÜ ÿßŸÑŸÖÿπŸÜŸâ ÿßŸÑŸÖŸÇÿµŸàÿØÿå ÿ£Ÿà ÿßŸÑŸÖÿπŸÜŸâ ÿßŸÑŸÖÿ±ÿßÿØ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜŸáÿå ŸÇÿ®ŸÑ ÿßŸÑÿ¥ÿ±Ÿàÿπ ÿ®ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´. Ÿàÿ™Ÿàÿ¨ÿØ ÿßŸÑŸäŸàŸÖ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ÿ™ÿÆÿØŸÖ ŸÇŸàÿßŸÖŸäÿ≥ ŸÖÿ∂ŸÖŸÜÿ© ÿ™ŸÇŸàŸÖ ÿ®ÿ™ŸÇÿØŸäŸÖ ŸÇŸàÿßÿ¶ŸÖ ÿ®ÿßŸÑŸÖÿπÿßŸÜŸä ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÖÿ´ŸÑŸáÿß ÿßŸÑŸÉŸÑŸÖÿ© ÿßŸÑŸàÿßÿ≠ÿØÿ© ŸÇÿ®ŸÑ ÿßŸÑÿ¥ÿ±Ÿàÿπ ŸÅŸä ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´. ŸàŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ≠ÿ±ŸÉÿßÿ™ ŸáŸÜÿßŸÉ LexiGuide ŸÖŸÜ ÿ¥ÿ±ŸÉÿ© LexiQuestÿå ŸàOingoÿå ŸàSimplifind ÿπŸÑŸâ ŸÖŸàŸÇÿπ Simpli.com. Ÿáÿ∞ÿß ÿßŸÑÿ£ÿ≥ŸÑŸàÿ® ŸáŸà ÿßŸÑÿ£ŸÇÿØŸÖÿå ÿ≠Ÿäÿ´ Ÿäÿ™ŸÖ ÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿ≠ÿ≥ÿ® ÿ™ÿµŸÜŸäŸÅÿßÿ™ ŸàŸÅÿ±Ÿàÿπ ŸÖÿπŸäŸÜÿ©ÿå ŸàŸÖŸÜ ÿ´ŸÖ ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿ¥ŸÉŸÑ ŸÖŸÜŸÅÿµŸÑ ÿ∂ŸÖŸÜ ŸÉŸÑ ÿ™ÿµŸÜŸäŸÅ ÿπŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©. ŸÅŸÖÿ´ŸÑÿßÿå ÿπŸÜÿØ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÉŸÑŸÖÿ© ¬´ŸÜŸàÿßÿ©¬ª ŸÅÿ•ŸÜ ÿ®ÿ≠ÿ´ŸÉ ŸÇÿØ ŸäŸÇŸàÿØŸÉ ÿ•ŸÑŸâ ÿ™ÿµŸÜŸäŸÅ Ÿäÿ™ÿπŸÑŸÇ ÿ®ÿπŸÑŸàŸÖ ÿßŸÑÿ≤ÿ±ÿßÿπÿ©ÿå Ÿàÿ£ŸÜŸàÿßÿπ ÿßŸÑÿ≠ÿ®Ÿàÿ®ÿå ŸàŸÖÿß ÿ•ŸÑŸâ ÿ∞ŸÑŸÉÿå ŸàŸÑŸÉŸÜŸá ŸÅŸä ÿßŸÑŸàŸÇÿ™ ŸÜŸÅÿ≥Ÿá ŸÇÿØ ŸäŸÇŸàÿØŸÉ ÿ•ŸÑŸâ ÿ™ÿµŸÜŸäŸÅ ŸäŸÇÿπ ÿ∂ŸÖŸÜ ÿπŸÑŸàŸÖ ÿßŸÑŸÅŸäÿ≤Ÿäÿßÿ° ÿßŸÑŸÜŸàŸàŸäÿ©. ŸàÿßŸÑÿ≠ŸÑ ŸáŸÜÿß ŸäŸÉŸÖŸÜ ŸÅŸä ÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿ£ŸÜŸàŸäÿ© ÿßŸÑÿ≠ÿ®Ÿàÿ® ŸàÿßŸÑŸÖÿ≤ÿ±Ÿàÿπÿßÿ™ ŸÅŸä ŸÇÿ≥ŸÖ ÿßŸÑÿ≤ÿ±ÿßÿπÿ© ŸÖÿ´ŸÑÿßÿå ŸàÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿ£ŸÜŸàŸäÿ© ÿßŸÑÿ∞ÿ±ÿßÿ™ ŸÅŸä ŸÇÿ≥ŸÖ ÿßŸÑŸÅŸäÿ≤Ÿäÿßÿ° ÿßŸÑÿ∞ÿ±Ÿäÿ©. ŸàŸÑŸÉŸÜ ŸÖÿßÿ∞ÿß ŸÑŸà ŸÉÿßŸÜÿ™ ŸÑÿØŸäŸÜÿß Ÿàÿ´ŸäŸÇÿ© ÿ™ÿ™ÿπŸÑŸÇ ÿ®ÿ™ÿ£ÿ´Ÿäÿ± ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ® ÿßŸÑŸÜŸàŸàŸäÿ© ÿπŸÑŸâ ÿ£ŸÜŸàŸäÿ© ÿßŸÑÿ≠ÿ®Ÿàÿ® ŸàÿßŸÑŸÖÿ≤ÿ±Ÿàÿπÿßÿ™ÿü ŸáŸÑ Ÿäÿ¨ÿ® ÿπŸÜÿØŸáÿß Ÿàÿ∂ÿπ ÿßŸÑŸàÿ´ŸäŸÇÿ© ŸÅŸä ÿßŸÑŸÇÿ≥ŸÖŸäŸÜÿå ÿ£ŸÖ ŸÖÿß ŸáŸà ÿßŸÑÿ≠ŸÑÿü ŸàŸáŸÜÿß ÿ™ŸÜÿ¥ÿ£ ŸÑÿØŸäŸÜÿß ŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑŸÖÿπŸÜŸâ ÿßŸÑŸÖÿ≤ÿØŸàÿ¨.\nŸàŸÖŸÜ ŸáŸÜÿß ÿ™ÿ£ÿ™Ÿä ÿ£ŸáŸÖŸäÿ© ÿßŸÑÿ™ÿµŸÜŸäŸÅ ÿßŸÑÿ™ŸÑŸÇÿßÿ¶Ÿäÿå ÿ≠Ÿäÿ´ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿπŸÑŸàŸÖ ÿßŸÑŸÜÿ≠Ÿà ŸÖŸÜ ÿ™ÿµÿ±ŸäŸÅ Ÿàÿ•ÿπÿ±ÿßÿ®ÿå Ÿàÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖŸÉÿßŸÜÿ≤ ŸàÿßŸÑŸÇŸàÿßŸÖŸäÿ≥ÿå ÿ®ÿ≠Ÿäÿ´ Ÿäÿ™ŸÖŸÉŸÜ ÿßŸÑŸÜÿ∏ÿßŸÖ ŸÖŸÜ ¬´ŸÅŸáŸÖ¬ª ÿßŸÑŸÖŸàÿßÿ∂Ÿäÿπ ÿßŸÑÿ±ÿ¶Ÿäÿ≥ÿ© ŸÅŸä Ÿàÿ´ŸäŸÇÿ© ŸÖÿß. ŸàŸäÿ™ŸÖ ÿ∞ŸÑŸÉ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ£ÿ≥ÿßŸÑŸäÿ® ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿ© ÿ™ŸÇŸàŸÖ ÿ®ÿØÿ±ÿßÿ≥ÿ© ÿ™ŸÉÿ±ÿßÿ± ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿ∂ŸÖŸÜ Ÿàÿ´ŸäŸÇÿ© ŸÖÿßÿå ŸàŸÖŸÜ ÿ´ŸÖ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ≥ŸäÿßŸÇÿå ŸàÿßŸÑÿ∞Ÿä Ÿäÿ≥ÿßÿπÿØ ŸÅŸä ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´. ŸàŸÉŸÖÿ´ÿßŸÑ ÿπŸÑŸâ ÿ∞ŸÑŸÉ ŸÑŸÜÿ£ÿÆÿ∞ ŸÉŸÑŸÖÿ©ÿå ÿ£Ÿà ÿßÿ≥ŸÖ ŸÖÿ´ŸÑ ¬´ŸÅŸáÿØ¬ª ÿ£Ÿà ¬´ŸÑŸäÿ´¬ª ŸàŸáŸä ÿ£ÿ≥ŸÖÿßÿ° ÿπÿ±ÿ®Ÿäÿ© ÿØÿßÿ±ÿ¨ÿ©. ŸàŸÑŸÜŸÅÿ™ÿ±ÿ∂ ÿ£ŸÜŸÜÿß ŸÉÿ™ÿ®ŸÜÿß ŸÖŸàÿ∂Ÿàÿπÿß ŸÅŸä ŸÖÿ¨ŸÑÿ™ŸÜÿß ÿπŸÜ ÿ¥ÿÆÿµ ÿßÿ≥ŸÖŸá ¬´ŸÅŸáÿØ¬ªÿå ŸàŸÑŸÜŸÅÿ™ÿ±ÿ∂ ÿ£ŸÜ ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ÿ£ÿ±ÿßÿØ ÿ™ÿµŸÜŸäŸÅ ŸÖŸÇÿßŸÑŸÜÿß Ÿáÿ∞ÿß. ŸÅŸä Ÿáÿ∞Ÿá ÿßŸÑÿ≠ÿßŸÑÿå Ÿàÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ Ÿäÿ≥ÿ™ÿÆÿØŸÖ ÿ£ÿ≥ŸÑŸàÿ® ÿßŸÑÿ™ÿµŸÜŸäŸÅ ÿßŸÑÿ™ŸÑŸÇÿßÿ¶Ÿäÿå ŸÅÿ•ŸÜŸá ÿ≥ŸäŸÇŸàŸÖ ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿØÿ±ÿßÿ≥ÿ© ÿßŸÑŸÜÿµ ŸàŸÜŸàÿπŸäÿ© ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸäŸá ŸàÿπŸÑÿßŸÇÿßÿ™Ÿáÿß Ÿàÿ™ŸÉÿ±ÿßÿ±Ÿáÿßÿå ÿ®ÿ™ÿ≠ÿØŸäÿØ ÿ£ŸÜ ÿßŸÑŸÖŸÇÿßŸÑ ŸäŸÜÿ™ŸÖŸä ÿ•ŸÑŸâ ÿ™ÿµŸÜŸäŸÅ ÿπŸÑŸàŸÖ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ® ŸàÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸàŸÑŸäÿ≥ ÿßŸÑÿ≠ŸäŸàÿßŸÜÿßÿ™ ŸàÿßŸÑŸàÿ≠Ÿàÿ¥ ÿßŸÑÿ®ÿ±Ÿäÿ©.\nŸàÿ™ÿ™ÿ®ÿπ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ™ÿµŸÜŸäŸÅ ÿßŸÑÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÇŸàÿßÿπÿØ ŸÖÿπŸäŸÜÿ© Ÿäÿ≠ÿØÿØŸáÿß ÿßŸÑŸÖÿ®ÿ±ŸÖÿ¨ŸàŸÜÿå ÿ£Ÿà ŸäŸÖŸÉŸÜ ŸÑŸÑÿ¢ŸÑÿ© ŸÜŸÅÿ≥Ÿáÿß ÿ£ŸÜ ÿ™ÿ™ÿπŸÑŸÖ ÿ∞ÿßÿ™Ÿäÿß ŸÉŸäŸÅ ÿ™ŸÇŸàŸÖ ÿ®ÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸÉŸÑŸÖÿßÿ™. ÿ£Ÿà ŸäŸÖŸÉŸÜ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ£ÿ≥ŸÑŸàÿ®ŸäŸÜÿå ÿ®ÿ≠Ÿäÿ´ Ÿäÿ™ŸÖ ÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑÿ™Ÿä ÿ™ÿ™ÿ®ÿπ ŸÜŸÖÿ∑ÿß ŸÖÿπŸäŸÜÿß ÿ®ÿ¥ŸÉŸÑ ÿ™ŸÑŸÇÿßÿ¶Ÿäÿå ŸÅŸä ÿ≠ŸäŸÜ Ÿäÿ™ŸÖ ÿ™ÿ≠ŸàŸäŸÑ ÿ™ŸÑŸÉ ÿßŸÑÿ™Ÿä Ÿäÿ≥ÿ™ÿ≠ŸäŸÑ ÿ™ÿµŸÜŸäŸÅŸáÿß ÿ•ŸÑŸâ ÿπÿßŸÖŸÑ ÿ®ÿ¥ÿ±Ÿä ŸÉŸä ŸäŸÇŸàŸÖ ÿ®ÿ∞ŸÑŸÉ. ŸÖŸÜ Ÿäÿ≥ÿ™ÿπŸÖŸÑ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ± ŸäÿπŸÑŸÖ ÿ£ŸÜŸá ŸÖŸÜ ÿßŸÑŸÖÿ≠ÿ™ŸàŸÖ ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ¶ÿßÿ™ ÿßŸÑÿ£ŸÑŸàŸÅ ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿπŸÑŸâ ÿßŸÑÿ£ŸÇŸÑ ÿπŸÜÿØ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖŸàÿ∂Ÿàÿπ ŸÖÿπŸäŸÜ ÿ®ÿ¥ŸÉŸÑ ÿπÿßŸÖ. ÿ£ŸÖÿß ÿπŸÜÿØ ÿ™ÿ∂ŸäŸäŸÇ ŸÜÿ∑ÿßŸÇ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸÅÿ•ŸÜŸÜÿß ŸÜÿ≠ÿµŸÑ ÿπŸÑŸâ ŸÖŸÇÿØÿßÿ± ÿ£ŸÇŸÑ ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ£ŸÉÿ´ÿ± ÿØŸÇÿ©.\nŸàŸÑÿ≤ŸäÿßÿØÿ© ÿØŸÇÿ© ÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿßÿ™ÿå ŸÅÿ•ŸÜ ÿ®ÿπÿ∂ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ŸäŸÇŸàŸÖ ÿ®ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿå Ÿàÿ∞ŸÑŸÉ ÿ®ÿ™ŸÇÿØŸäŸÖ ŸÖÿπÿßŸÜ ŸÖÿ±ÿßÿØŸÅÿ© ŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ•ŸÑŸâ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿå ŸÑŸÖÿ≥ÿßÿπÿØÿ™Ÿá ÿπŸÑŸâ ÿ™ÿ≠ÿØŸäÿØ ŸÖŸàÿ∂Ÿàÿπ ÿ®ÿ≠ÿ´Ÿá ÿ®ÿØŸÇÿ© ÿ£ŸÉÿ®ÿ±. ŸÅŸÅŸä ŸÖÿ´ŸÑ Ÿáÿ∞Ÿá ÿßŸÑŸÜÿ∏ŸÖÿå Ÿàÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖŸàÿ∂Ÿàÿπ ÿßÿ≥ÿ™ÿπŸÑÿßŸÖŸÉ ŸáŸà ¬´ÿßŸÑÿ±Ÿäÿßÿ∂ÿ©¬ª ŸÖÿ´ŸÑÿßÿå ŸÅÿ•ŸÜ ÿßŸÑŸÜÿ∏ÿßŸÖ ŸäŸÇÿØŸÖ ŸÑŸÉ ÿπÿØÿØÿß ŸÖŸÜ ÿßŸÑÿ®ÿØÿßÿ¶ŸÑ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ÿßÿπÿØ ŸÅŸä ÿ™ÿ≠ÿØŸäÿØ ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ®ÿ≠ÿ´ ŸÖÿ´ŸÑ ¬´ÿßŸÑÿ™ÿ±ÿ®Ÿäÿ© ÿßŸÑÿ®ÿØŸÜŸäÿ©¬ªÿå ¬´ÿßŸÑŸÑŸäÿßŸÇÿ© ÿßŸÑÿ®ÿØŸÜŸäÿ©¬ª ÿ£Ÿà ¬´ÿßŸÑŸÑŸäÿßŸÇÿ©¬ª Ÿàÿ∫Ÿäÿ± ÿ∞ŸÑŸÉ ŸÖŸÜ ÿßŸÑŸÖÿ±ÿßÿØŸÅÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ÿßÿπÿØ ÿπŸÑŸâ ÿ™Ÿàÿ¨ŸäŸá ÿßŸÑÿπŸÖŸÑŸäÿ© ÿ®ÿ≠Ÿäÿ´ Ÿäÿ≠ÿµŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿπŸÑŸâ ÿ£ŸÉÿ®ÿ± ŸÉŸÖ ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿØŸÇŸäŸÇÿ© ÿßŸÑÿ™Ÿä ÿ™ÿπÿ®Ÿëÿ± ÿπŸÜ ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ®ÿ≠ÿ´. ÿ•ÿ∞ÿß ÿ¨ÿ±ÿ®ÿ™ ÿßŸÑŸäŸàŸÖ ÿ£ŸÜ ÿ™ÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑÿπÿ®ÿßÿ±ÿ© ¬´ÿßÿ≥ÿ∑ŸàÿßŸÜÿßÿ™ ÿßŸÑŸÑŸäÿ≤ÿ±¬ª (ŸàŸáŸä ÿßŸÑÿπÿ®ÿßÿ±ÿ© ÿßŸÑÿπÿßŸÖŸäÿ© ŸàÿßŸÑŸÇÿØŸäŸÖÿ© ŸÑŸÑÿ£ŸÇÿ±ÿßÿµ ÿßŸÑŸÖÿØŸÖÿ¨ÿ©) ŸÅÿ•ŸÜŸÉ ŸÑŸÜ ÿ™ÿ≠ÿµŸÑ ÿπŸÑŸâ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖŸÅŸäÿØÿ© ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå ÿ≠Ÿäÿ´ ÿ£ŸÜ ÿπÿ®ÿßÿ±ÿ© ¬´ÿßŸÑÿ£ŸÇÿ±ÿßÿµ ÿßŸÑŸÖÿØŸÖÿ¨ÿ©¬ª ŸáŸä ÿßŸÑŸÉŸÑŸÖÿ© ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ŸàÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ© ŸÅŸä ÿßŸÑÿ∫ÿßŸÑÿ®Ÿäÿ© ÿßŸÑÿπÿ∏ŸÖŸâ ŸÖŸÜ ÿßŸÑŸÖÿ∑ÿ®Ÿàÿπÿßÿ™.\nŸàŸÑŸáÿ∞ÿß ŸÅÿ•ŸÜ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ Ÿáÿ∞Ÿá ÿßŸÑÿ£ŸäÿßŸÖ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ ÿ£ÿ≥ŸÑŸàÿ® ÿßŸÑÿ±ÿ®ÿ∑ ÿ®ŸäŸÜ ÿßŸÑŸÖŸÅÿßŸáŸäŸÖÿå ÿ®ÿ≠Ÿäÿ´ ÿ£ŸÜŸÉ ÿ•ÿ∞ÿß ŸÇŸÖÿ™ ÿ®ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑÿπÿ®ÿßÿ±ÿ© ¬´ÿ£ŸÇÿ±ÿßÿµ ÿßŸÑŸÑŸäÿ≤ÿ±¬ª ŸÅÿ•ŸÜŸÉ ÿ≥ÿ™ÿ≠ÿµŸÑ ÿπŸÑŸâ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿπŸÜ ¬´ÿßŸÑÿ£ŸÇÿ±ÿßÿµ ÿßŸÑŸÖÿØŸÖÿ¨ÿ©¬ª. ŸàŸäÿπÿ™ŸÖÿØ Ÿáÿ∞ÿß ÿßŸÑÿ£ÿ≥ŸÑŸàÿ® ÿπŸÑŸâ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿπŸÑÿßŸÇÿ© ÿ®ŸäŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ŸàÿßŸÑÿπÿ®ÿßÿ±ÿßÿ™ ŸÅŸä ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ≥ÿ®ŸÇÿå ŸÉŸÖÿß ÿ£ŸÜŸá ŸÖŸÅŸäÿØ ÿπŸÜÿØ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä Ÿàÿ´ÿßÿ¶ŸÇ ŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ÿå ŸÅÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÉŸÑŸÖÿ© ¬´ÿ£ŸÇÿ±ÿßÿµ ÿßŸÑŸÑŸäÿ≤ÿ±¬ª ŸäŸÖŸÉŸÜ ÿ£ŸÜ Ÿäÿπÿ∑Ÿä ŸÜÿ™ÿßÿ¶ÿ¨ ŸÑŸàÿ´ÿßÿ¶ŸÇ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ© ÿπŸÜ \"Compact Disks\" ÿ£Ÿà CDs ŸàŸÖÿß ÿ•ŸÑŸâ ÿ∞ŸÑŸÉÿå ŸàŸáÿ∞ÿß ÿ£ÿ≥ŸÑŸàÿ® ŸÖŸÅŸäÿØ ÿ¨ÿØÿß ŸÅŸä ÿπÿßŸÑŸÖ ÿ•ŸÜÿ™ÿ±ŸÜÿ™Ÿä ŸÑŸÖ ÿ™ÿπÿØ ŸÅŸäŸá ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ© ŸáŸä ÿßŸÑÿ≥ÿßÿ¶ÿØÿ©. ÿßŸÜÿ∏ÿ± ÿ•ŸÑŸâ ÿ£Ÿä ŸÖŸàŸÇÿπ ŸÑŸÑÿ™ÿ¨ÿßÿ±ÿ© ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿ©ÿå Ÿàÿ≥ÿ™ÿ¨ÿØ ÿ£ŸÜŸá ÿ∫Ÿäÿ± ÿ∞ÿß ŸÅÿßÿ¶ÿØÿ© ÿ™Ÿèÿ∞ŸÉÿ± ÿ•ÿ∞ÿß ŸÑŸÖ ŸäŸÉŸÜ ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ®Ÿá ŸÇÿßÿØÿ±ÿß ÿπŸÑŸâ ŸÜŸÇŸÑŸÉ ÿ•ŸÑŸâ ÿµŸÅÿ≠ÿ© ÿßŸÑŸÖŸÜÿ™ÿ¨ÿå ÿ£Ÿà ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ÿå ÿßŸÑÿ™Ÿä ÿ™ÿ±ŸäÿØŸáÿß ÿÆŸÑÿßŸÑ ÿ£ÿ≥ÿ±ÿπ ŸàŸÇÿ™ ŸÖŸÖŸÉŸÜ. ŸàŸÑÿ∞ŸÑŸÉ ŸÜÿ¨ÿØ ÿ£ŸÜ ÿ®Ÿàÿßÿ®ÿßÿ™ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ© ŸàÿßŸÑÿ£ÿπŸÖÿßŸÑ ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿ© ÿßŸÑÿπÿßŸÑŸÖŸäÿ© ŸÖÿ´ŸÑ Ebay Ÿàÿ£ŸÖÿßÿ≤ŸàŸÜ ÿ™ÿπÿ™ÿ®ÿ± ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ£ÿ≠ÿØ ÿ£ŸáŸÖ ŸÖŸàÿ¨ŸàÿØÿßÿ™Ÿáÿß Ÿàÿ™ÿ≥ÿπŸâ ÿ®ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ± ÿ•ŸÑŸâ ÿ™ÿ≠ÿØŸäÿ´Ÿáÿß. ŸàŸÇÿØ ŸÇÿßŸÖÿ™ ÿ¥ÿ±ŸÉÿ© Ebay ŸÇÿ®ŸÑ ÿ≥ŸÜŸàÿßÿ™ ÿ®ÿ¥ÿ±ÿßÿ° ŸÜÿ∏ÿßŸÖ ÿ®ÿ≠ÿ´ ŸÖÿ™ŸÇÿØŸÖ ŸÖŸÜ ÿ¥ÿ±ŸÉÿ© Fast Search & Transfer ÿßŸÑŸÜÿ±ŸàŸäÿ¨Ÿäÿ©ÿå ŸàÿßŸÑÿ™Ÿä ŸÉÿßŸÜÿ™ ÿ™ŸÜÿ™ÿ¨ ÿ™ŸÇŸÜŸäÿ© ÿ®ÿ≠ÿ´ ÿ¨ÿØŸäÿØÿ© ÿ™ŸÇŸàŸÖ ÿ®ÿ™ŸÇÿØŸäŸÖ ÿ£ÿ≠ÿØÿ´ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÑŸÑÿ®ÿßÿ≠ÿ´ŸäŸÜ ÿπŸÜ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿ≤ÿßÿØÿßÿ™ ŸàÿßŸÑÿ£ÿ≥ÿπÿßÿ± ÿßŸÑŸÖÿ™ÿØÿßŸàŸÑÿ©. ŸÉŸÖÿß ÿ£ŸÜ ÿ£ŸÖÿßÿ≤ŸàŸÜ ŸàŸÖŸàÿßŸÇÿπ ŸÖÿ´ŸÑ Marthastewar.com ÿ™ŸÇŸàŸÖ ÿ®ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπ ÿ¥ÿ±ŸÉÿ© Google ŸàAskJeeves ÿ®ÿ≠Ÿäÿ´ Ÿäÿ™ŸÖ ÿ±ÿ®ÿ∑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿ®ÿßŸÑÿ®ÿ∂ÿßÿ¶ÿπ ÿßŸÑÿ™Ÿä Ÿäÿ±ŸäÿØŸàŸÜ ÿ¥ÿ±ÿßÿ¶Ÿáÿß ŸÖŸÜ ÿÆŸÑÿßŸÑ ŸÉÿ™ÿßÿ®ÿ© ÿ≥ÿ§ÿßŸÑ ÿßÿπÿ™ŸäÿßÿØŸä ÿ∂ŸÖŸÜ ŸÖÿ±ÿ®ÿπ ÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖ. Ÿàÿ™ŸÇŸàŸÑ ÿßŸÑÿÆÿ®Ÿäÿ±ÿ© ŸÖÿßÿ±ÿ´ÿß ŸÅÿ±ÿßŸäÿå ŸàŸáŸä ÿ®ÿßÿ≠ÿ´ÿ© ŸÅŸä ÿ¥ÿ§ŸàŸÜ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ© ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿ© ŸÅŸä ŸÖÿ¨ŸÖŸàÿπÿ© ÿ®ÿßÿ™ÿ±Ÿäÿ¥Ÿäÿß ÿ≥Ÿäÿ®ŸàŸÑÿØÿå ¬´ŸäŸÖŸÉŸÜ ÿßŸÑŸÇŸàŸÑ ÿ®ÿ£ŸÜ ÿßŸÑÿ≥ÿ®ÿ® ÿßŸÑÿ±ÿ¶Ÿäÿ≥ ŸÅŸä ŸÅÿ¥ŸÑ ŸÖÿπÿ∏ŸÖ ŸÖŸàÿßŸÇÿπ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ© ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿ©ÿå ŸäÿπŸàÿØ ÿ•ŸÑŸâ ÿßÿπÿ™ŸÖÿßÿØŸáÿß ŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿ®ÿ≠ÿ´ ÿ∂ÿπŸäŸÅÿ©.¬ª ŸÉŸÖÿß ÿßŸÉÿ™ÿ¥ŸÅÿ™ ŸÖÿ§ÿ≥ÿ≥ÿ© ŸÖŸäÿØŸäÿß ŸÖŸäÿ™ÿ±ŸäŸÉÿ≥ ŸÑŸÑÿ£ÿ®ÿ≠ÿßÿ´ ÿ®ÿ£ŸÜ 80% ŸÖŸÜ ŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ•ŸÜÿ™ÿ±ŸÜÿ™ÿå Ÿäÿ™ŸàŸÇŸÅŸàŸÜ ÿπŸÜ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÖŸàŸÇÿπ ŸÖÿß ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ÿπŸÖŸÑ Ÿàÿ∏ŸäŸÅÿ© ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÖÿ∂ŸÖŸÜÿ© ŸÅŸäŸá ÿ®ÿßŸÑÿ¥ŸÉŸÑ ÿßŸÑÿµÿ≠Ÿäÿ≠.\nŸàŸÖŸÜ ŸáŸÜÿß ŸÉÿßŸÜ ÿßŸÑÿ≥ÿ®ÿßŸÇ ÿ®ŸäŸÜ ÿπÿØÿØ ŸÖŸÜ ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ŸÑÿ™ÿ∑ŸàŸäÿ± ÿ™ŸÇŸÜŸäÿßÿ™ ÿ®ÿ≠ÿ´ ŸÖÿ™ŸÇÿØŸÖÿ©ÿå ŸäŸÖŸÉŸÜ ŸÑŸÑÿ®ÿ¥ÿ± ÿßŸÑÿßÿπÿ™ŸäÿßÿØŸäŸäŸÜ ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπŸáÿßÿå ŸàÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ™Ÿä Ÿäÿ±ŸäÿØŸàŸÜŸáÿß ÿ™ŸÖÿßŸÖÿß. Ÿàÿ≥ŸÜÿ≥ÿ™ÿπÿ±ÿ∂ ŸÅŸäŸÖÿß ŸäŸÑŸä ÿπÿØÿØÿß ŸÖŸÜ ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ÿßŸÑÿπÿßŸÑŸÖŸäÿ© ÿßŸÑÿ™Ÿä ÿßÿ®ÿ™ŸÉÿ±ÿ™ ÿ™ŸÇŸÜŸäÿßÿ™ ŸäŸÖŸÉŸÜ ŸÑŸáÿß ÿ£ŸÜ ÿ™ÿ∫Ÿäÿ± Ÿàÿ¨Ÿá ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿ•ŸÑŸâ ÿßŸÑÿ£ÿ®ÿØ. ÿßŸäŸÉÿ≥ÿßŸÑŸäÿØ (Exalead) ŸÖÿ≠ÿ±ŸÉ ÿ®ÿ≠ÿ´ ŸÅÿ±ŸÜÿ≥Ÿä ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ≠ÿØŸäÿ´Ÿá ŸÑŸÑÿ®ÿ≠ÿ´¬†: ŸÜŸàÿπŸäÿ© ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ®ÿ≠ÿ´ÿå ÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ÿå ÿµŸàÿ± ÿ™ŸÖŸáŸäÿØŸäÿ© ŸÑŸÉŸÑ ÿµŸÅÿ≠ÿ©.(Exalead) ÿ®ÿØÿ£ ŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿ≠ÿ´ Ÿáÿ∞ÿß Google.com ŸÉŸÖÿ¥ÿ±Ÿàÿπ ŸÑÿ±ÿ≥ÿßŸÑÿ© ÿØŸÉÿ™Ÿàÿ±ÿßÿ© ÿ≠ŸàŸÑ ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸàÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÑŸÑÿ∫ÿ© ŸÅŸä ÿ¨ÿßŸÖÿπÿ© ÿ≥ÿ™ÿßŸÜŸÅŸàÿ±ÿØ ŸÅŸä ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑŸÖÿ™ÿ≠ÿØÿ©ÿå Ÿàÿ™ÿ≠ŸàŸÑ ÿßŸÑŸäŸàŸÖ ÿ•ŸÑŸâ ÿ®Ÿàÿßÿ®ÿ© ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿπÿßŸÑŸÖŸäÿ© ŸÉÿ®ÿ±Ÿâ ÿ™ÿÆÿØŸÖ ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ŸÄ 66 ŸÑÿ∫ÿ© (ŸÖŸÜŸáÿß ÿßŸÑÿπÿ±ÿ®Ÿäÿ©)ÿå ÿ™ŸÇŸàŸÖ ÿ®ŸÖÿπÿßŸÑÿ¨ÿ© 120 ŸÖŸÑŸäŸàŸÜ ÿ∑ŸÑÿ® ÿ®ÿ≠ÿ´ ŸäŸàŸÖŸäÿß (ÿ≠ÿ≥ÿ® ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ŸÖÿ§ÿ≥ÿ≥ÿ© ŸÖŸäÿØŸäÿß ŸÖŸäÿ™ÿ±ŸÉÿ≥ ŸÑŸÑÿ£ÿ®ÿ≠ÿßÿ´)ÿå ŸÉŸÖÿß ÿ£ŸÜ ÿßŸÑŸÖŸàŸÇÿπ ÿ£ÿµÿ®ÿ≠ ŸÖÿ§ÿÆÿ±ÿß ÿ∂ŸÖŸÜ ÿ£ŸÉÿ®ÿ± 15 ŸÖŸàŸÇÿπÿß ŸÅŸä ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑŸÖÿ™ÿ≠ÿØÿ©. ŸàŸÑÿß Ÿäÿ™ŸàŸÇŸÅ ÿßŸÑÿ£ŸÖÿ± ŸáŸÜÿßÿå ÿ≠Ÿäÿ´ ÿ£ŸÜ ÿπŸàÿßÿ¶ÿØŸá ÿ™ÿµŸÑ ÿ•ŸÑŸâ 50 ŸÖŸÑŸäŸàŸÜ ÿØŸàŸÑÿßÿ± ÿ≥ŸÜŸàŸäÿßÿå ŸàŸäÿ™ŸàŸÇÿπ ÿßŸÑÿ®ÿπÿ∂ ÿ£ŸÜ ŸäÿµŸÑ ÿ≠ÿ¨ŸÖ Ÿáÿ∞Ÿá ÿßŸÑÿπŸàÿßÿ¶ÿØ ŸÅŸä ÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿßŸÑŸÇÿ±Ÿäÿ® ÿ•ŸÑŸâ ŸÖŸÑŸäÿßÿ± ÿØŸàŸÑÿßÿ± ÿ£ŸÖÿ±ŸäŸÉŸä ÿ≠ÿ≥ÿ® ŸÖÿ¨ŸÑÿ© ÿ®Ÿäÿ≤ŸÜÿ≥ ŸàŸäŸÉ ÿßŸÑÿ£ŸÖÿ±ŸäŸÉŸäÿ©.\nŸàÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÑŸáÿ∞ÿß ÿßŸÑŸÖŸàŸÇÿπ Ÿäÿπÿ±ŸÅ ÿ™ŸÖÿßŸÖ ÿßŸÑŸÖÿπÿ±ŸÅÿ© ŸÖÿØŸâ ÿØŸÇÿ™Ÿá ŸÅŸä ÿ™ŸÇÿØŸäŸÖ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©ÿå ŸàŸÖŸÜ ÿßŸÑŸÖÿ±ÿ© ÿßŸÑÿ£ŸàŸÑŸâÿå ŸÉŸÖÿß ÿ£ŸÜŸá ŸÑÿß Ÿäÿ™ÿ∑ŸÑÿ® ÿÆÿ®ÿ±ÿ© ŸÉÿ®ÿ±Ÿâ ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸä ÿµŸäÿßÿ∫ÿ© ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ŸàÿßŸÑÿßÿ≥ÿ™ÿπŸÑÿßŸÖÿßÿ™. ŸàŸäÿπÿ™ŸÖÿØ Ÿáÿ∞ÿß ÿßŸÑŸÖŸàŸÇÿπ ÿ™ŸÇŸÜŸäÿßÿ™ ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿ© Ÿàÿ±Ÿäÿßÿ∂Ÿäÿ© ŸÖÿ™ŸÇÿØŸÖÿ© ÿ™ŸÇŸàŸÖ ÿ®ÿØÿ±ÿßÿ≥ÿ© ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖŸÅŸáÿ±ÿ≥ÿ©ÿå Ÿàÿ™ŸÉÿ±ÿßÿ± ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿ∂ŸÖŸÜ ŸÉŸÑ Ÿàÿ´ŸäŸÇÿ©ÿå Ÿàÿ®ÿßŸÑÿ™ÿßŸÑŸä ÿßŸÑÿ≠ŸÉŸÖ ÿπŸÑŸâ ŸÖŸàÿ∂ŸàÿπŸáÿß ŸàÿπŸÑÿßŸÇÿ™Ÿáÿß ÿ®ÿπÿ®ÿßÿ±ÿ© ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™Ÿä ŸäŸÇŸàŸÖ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ®ÿßÿ≥ÿ™ÿπŸÖÿßŸÑŸáÿß.\nŸàŸÖŸáŸÖÿß ŸÉÿßŸÜÿ™ ÿßŸÑŸàÿµŸÅÿ© ÿßŸÑÿ≥ÿ≠ÿ±Ÿäÿ© ÿßŸÑÿ™Ÿä Ÿäÿ≥ÿ™ÿÆÿØŸÖŸáÿß ŸÖŸàŸÇÿπ ÿ∫Ÿàÿ∫ŸÑ ŸÅÿ•ŸÜŸá Ÿäÿπÿ™ÿ®ÿ± ÿßŸÑÿ£ŸÅÿ∂ŸÑ ÿ®ŸäŸÜ ŸÉÿßŸÅÿ© ŸÖŸàÿßŸÇÿπ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ© ÿßŸÑŸäŸàŸÖ. ŸÖŸàŸÇÿπ Ask.com Ÿäÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÅŸä ÿßŸÑÿ®ÿ≠ÿ´ ŸàŸäÿπÿ™ŸÖÿØ ŸÇÿßÿπÿØÿ© ÿ®ŸäÿßŸÜÿßÿ™ Ÿàÿ™ŸÇŸÜŸäÿßÿ™ ÿ™ŸÖŸÉŸëŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖŸÜ ÿ™Ÿàÿ¨ŸäŸá ÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ®ÿ≠ÿ´ ¬´ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©¬ª ÿ®ŸÑÿ∫ÿ© ÿ≥ŸáŸÑÿ© (ŸàÿπÿßŸÖŸäÿ© ÿ£Ÿäÿ∂ÿßŸã) ŸÑÿ™ŸÇŸàŸÖ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿßŸÑŸÖÿ∑ÿßÿ®ŸÇÿ© ÿ®ŸäŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ŸÅŸä ÿßŸÑÿ≥ÿ§ÿßŸÑÿå Ÿàÿ®ŸäŸÜ ŸÖÿß ŸáŸà ŸÖŸàÿ¨ŸàÿØ ŸÅŸä ŸÇÿßÿπÿØÿ© ÿ®ŸäÿßŸÜÿßÿ™Ÿáÿß. Ÿàÿ±ÿ∫ŸÖ ÿ∞ŸÑŸÉ ŸÅÿ•ŸÜ ŸÖÿ≠ÿ±ŸÉ ¬´ÿ¢ÿ≥ŸÉ¬ª Ÿäÿπÿ™ŸÖÿØ ÿ¨ÿ≤ÿ¶Ÿäÿß ÿπŸÑŸâ ÿßŸÑÿ™ÿØÿÆŸÑ ÿßŸÑÿ®ÿ¥ÿ±Ÿä ŸÑÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸàŸÅŸáÿ±ÿ≥ÿ™Ÿáÿß ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™. ŸÅÿπŸÜÿØ ÿ≠ÿµŸàŸÑ ÿ≠ÿØÿ´ ÿ•ÿÆÿ®ÿßÿ±Ÿä ŸÖÿß ŸÖÿ´ŸÑÿßÿå ŸÅÿ•ŸÜ ¬´ÿ¢ÿ≥ŸÉ¬ª ŸÑŸÜ Ÿäÿ™ŸÖŸÉŸÜ ŸÖŸÜ ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπ ÿ£Ÿä ÿ≥ÿ§ÿßŸÑ Ÿäÿ™ÿπŸÑŸÇ ÿ®Ÿáÿ∞ÿß ÿßŸÑÿ≠ÿØÿ´ ÿ•ŸÑÿß ÿ•ÿ∞ÿß ŸÇÿßŸÖ ŸÖÿØÿ±ÿßÿ° ŸÇŸàÿßÿπÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑŸÜÿ∏ÿßŸÖ. ŸàŸÇÿØ ŸÇÿßŸÖÿ™ ÿßŸÑÿ¥ÿ±ŸÉÿ© ÿßŸÑŸÖÿ≥ÿ¶ŸàŸÑÿ© ÿπŸÜ ÿßŸÑŸÖŸàŸÇÿπ ÿ®ÿ∑ÿ±ÿ≠ ŸÜÿ∏ÿßŸÖ ŸÖÿ≥ÿ™ŸÇŸÑÿå ŸäŸÖŸÉŸÜ ŸÑŸÑŸÖÿ§ÿ≥ÿ≥ÿßÿ™ ÿßŸÑÿπÿßŸÖŸÑÿ© ŸÅŸä ŸÖÿ¨ÿßŸÑÿßÿ™ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ© ŸàÿßŸÑÿ£ÿπŸÖÿßŸÑ ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿ© ÿ™ÿ∂ŸÖŸäŸÜŸá ŸÅŸä ŸÖŸàÿßŸÇÿπŸáÿß ÿ®ÿ≠Ÿäÿ´ ŸäŸÖŸÉŸÜ ŸÑÿπŸÖŸÑÿßÿ¶Ÿáÿß ÿ™Ÿàÿ¨ŸäŸá ÿ£ÿ≥ÿ¶ŸÑÿ© Ÿàÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿßÿ™ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ©ÿå ŸàÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ£ÿ¨Ÿàÿ®ÿ© ŸÑŸáÿß ÿØŸàŸÜ ÿ£Ÿä ÿ™ÿØÿÆŸÑ ÿ®ÿ¥ÿ±Ÿä. ŸäŸàÿ¨ÿØ ÿπŸÑŸâ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿßŸÑŸäŸàŸÖ ÿ®ŸÑÿßŸäŸäŸÜ ÿßŸÑÿµŸÅÿ≠ÿßÿ™ÿå Ÿàÿ≠ÿ≥ÿ® ÿßŸÑŸÖÿµÿßÿØÿ± ÿßŸÑŸÖÿ™ŸàŸÅÿ±ÿ© ŸÅÿ•ŸÜŸá ŸÇÿØ ÿ™ŸÖ ÿ≠ÿ™Ÿâ ÿßŸÑŸäŸàŸÖ ŸÅŸáÿ±ÿ≥ÿ© ŸÖÿß Ÿäÿ≤ŸäÿØ ŸÇŸÑŸäŸÑÿß ÿπŸÑŸâ ÿßŸÑÿ®ŸÑŸäŸàŸÜ ÿµŸÅÿ≠ÿ©. Ÿàÿ™ÿ™ÿ≥ÿßÿ®ŸÇ ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÇŸàŸÖ ÿ®ŸÅŸáÿ±ÿ≥ÿ© Ÿáÿ∞Ÿá ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ŸÅŸä ÿ•ÿ™ÿßÿ≠ÿ™Ÿáÿß ŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ•ŸÜÿ™ÿ±ŸÜÿ™ÿå ŸàÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿ≥ÿ±ÿπÿ© ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿµŸÑ ÿπŸÑŸäŸáÿß ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ. Ÿàÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ ÿßŸÑÿ≥ÿ±ÿπÿ© ŸÅÿ•ŸÜ ÿπŸÑŸâ ŸÇŸàÿßÿπÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ Ÿáÿ∞Ÿá ÿ£ŸÜ ÿ™ÿ´ÿ®ÿ™ Ÿàÿ¨ŸàÿØŸáÿß ÿ®ÿ™ŸÇÿØŸäŸÖ ÿ£ÿ¨Ÿàÿ®ÿ© ¬´ÿ∑ÿßÿ≤ÿ¨ÿ©¬ªÿå ŸàŸÖÿ™ŸÜÿßÿ≥ŸÇÿ©ÿå Ÿàÿ∞ÿßÿ™ ÿπŸÑÿßŸÇÿ© ÿ®ŸÖÿß Ÿäÿ®ÿ≠ÿ´ ÿπŸÜŸá ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ.\nŸÉŸÖÿß ÿ£ŸÜ ÿπÿ¨ŸÑÿ© ÿßŸÑÿßÿ®ÿ™ŸÉÿßÿ± ŸÑÿß ÿ™ÿ™ŸàŸÇŸÅ ŸÅŸä ŸÖÿ¨ÿßŸÑ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸÅŸÖŸàŸÇÿπ www.hotlinks.com Ÿäÿ™Ÿäÿ≠ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿ•ŸÖŸÉÿßŸÜŸäÿ© ÿ≠ŸÅÿ∏ ŸÖŸÅÿ∂ŸÑÿßÿ™ŸáŸÖ Favorites ÿ∂ŸÖŸÜ ÿØŸÑŸäŸÑ ÿπŸÑŸâ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ÿå Ÿàÿ∞ŸÑŸÉ ŸÉŸä ÿ™ŸÉŸàŸÜ Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÅÿ∂ŸÑÿßÿ™ ŸÖÿ™ÿßÿ≠ÿ© ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ£ŸäŸÜŸÖÿß ŸÉÿßŸÜÿå ŸàŸäŸÖŸÉŸÜ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿ£ŸÜ ŸäÿÆÿ™ÿßÿ±Ÿàÿß ŸÖÿ¥ÿßÿ±ŸÉÿ© ŸÖŸÅÿ∂ŸÑÿßÿ™ŸáŸÖ ŸÖÿπ ŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿßŸÑÿ¢ÿÆÿ±ŸäŸÜÿå Ÿàÿ™ŸÖŸÉŸäŸÜ ÿ≤Ÿàÿßÿ± ÿßŸÑŸÖŸàŸÇÿπ ŸÖŸÜ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÑŸâ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ŸÖŸÅÿ∂ŸÑÿßÿ™ ÿßŸÑÿ¢ÿÆÿ±ŸäŸÜÿå Ÿàÿ®ÿßŸÑÿ™ÿßŸÑŸä ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ±ÿ£Ÿâ ŸÖÿ≥ÿ™ÿÆÿØŸÖŸàŸÜ ÿ¢ÿÆÿ±ŸàŸÜ ÿ£ŸÜŸáÿß ŸÖŸÅŸäÿØÿ© ŸÑÿØÿ±ÿ¨ÿ© Ÿàÿ∂ÿπ ÿßŸÑŸÖŸàÿßŸÇÿπ ÿßŸÑÿ™Ÿä ÿ™ÿ≠ÿ™ŸàŸäŸáÿß ÿ∂ŸÖŸÜ ŸÖŸÅÿ∂ŸÑÿßÿ™ŸáŸÖ.\nŸÉŸÖÿß ÿ£ŸÜ ŸáŸÜÿßŸÉ ŸÖŸàÿßŸÇÿπ ŸÑŸÑÿ®ÿ≠ÿ´ ŸÖÿ´ŸÑ www.expertcentral.com ŸàÿßŸÑÿ™Ÿä ÿ™ŸÇÿØŸÖ ŸÑŸÑÿ®ÿßÿ≠ÿ´ŸäŸÜ ÿ•ÿ¨ÿßÿ®ÿßÿ™ ŸÖÿ™ÿÆÿµÿµÿ©. Ÿàÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ ÿ∞ŸÑŸÉ ŸÅŸáŸÜÿßŸÉ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™Ÿä ÿ™ÿπÿ™ŸÖÿØ ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ¥ÿ®ŸÉÿßÿ™ ÿßŸÑÿπÿµÿ®Ÿäÿ© Neural Networksÿå ŸàŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™Ÿä ŸäŸÖŸÉŸÜ ÿ™ÿ´ÿ®Ÿäÿ™Ÿáÿß ÿπŸÑŸâ ÿ£ÿ¨Ÿáÿ≤ÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜÿå ŸàŸÅŸáÿ±ÿ≥ÿ© ŸÖÿ≠ÿ™ŸàŸäÿßÿ™ ÿ£ŸÇÿ±ÿßÿµŸáŸÖ ÿßŸÑÿµŸÑÿ®ÿ©.\nŸàŸÜÿ∏ÿ±ÿß ŸÑŸÑÿ£ŸáŸÖŸäÿ© ÿßŸÑŸÖÿ™ŸàÿßÿµŸÑÿ© ŸÑŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ÿå ŸÅÿ•ŸÜ ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ© ÿ≥ÿ™ŸàÿßÿµŸÑ ÿ∏ŸáŸàÿ±Ÿáÿßÿå Ÿàÿ≥ÿ™ŸàÿßÿµŸÑ ÿßŸÑÿ™ŸÇŸÜŸäÿ© ÿ™ÿ∑Ÿàÿ±Ÿáÿß ŸÑÿ™ŸÇÿØŸäŸÖ ŸÜÿ™ÿßÿ¶ÿ¨ ÿ£ŸÅÿ∂ŸÑ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ. Ÿàÿ®ÿ∏ŸáŸàÿ± Ÿáÿ∞Ÿá ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ŸÅÿ•ŸÜ ÿ®ÿπÿ∂Ÿáÿß ÿ≥ŸäŸÅÿ¥ŸÑ Ÿàÿ®ÿπÿ∂Ÿáÿß ÿ≥ŸäŸÜÿ¨ÿ≠ÿå Ÿàÿ≥ÿ™ÿµÿ®ÿ≠ ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑŸÜÿßÿ¨ÿ≠ÿ© ÿ¨ÿ≤ÿ°ÿß ŸÖŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ© ÿßŸÑŸäŸàŸÖ. ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ÿ™ÿ±ŸäÿØ ÿ•ŸÜŸÅÿßŸÇ ÿßŸÑŸÖŸÑÿßŸäŸäŸÜ ŸÅŸä ÿßÿ®ÿ™ŸÉÿßÿ± ÿ™ŸÇŸÜŸäÿßÿ™ ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸàÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸÑŸÑÿ∫ÿ©ÿå ŸÅÿ•ŸÜ ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ£ÿ≥ŸáŸÑ ŸáŸà ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÇÿØŸÖŸáÿß ŸÑÿ∫ÿ© ŸÑÿ∫ÿ© ÿßŸÑÿ™ÿ±ŸÖŸäÿ≤ ÿßŸÑŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿßŸÖÿ™ÿØÿßÿØ ŸÑÿ¨ÿπŸÑ ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´ ÿ£ŸÉÿ´ÿ± ÿØŸÇÿ©. ŸÅŸáÿ∞Ÿá ÿßŸÑŸÑÿ∫ÿ© ŸÉŸÖÿß ŸáŸà ŸÖÿπÿ±ŸàŸÅ ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ÿ™ŸàÿµŸäŸÅ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ŸàÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿπŸÜÿØ ŸÜÿ¥ÿ±Ÿáÿß ÿπŸÑŸâ ÿßŸÑÿ¥ÿ®ŸÉÿ©. ŸÅÿßŸÑŸÖÿßÿØÿ© ÿßŸÑŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿßŸÑÿ£ÿ≥ÿπÿßÿ± ŸÖÿ´ŸÑÿß Ÿäÿ™ŸÖ ÿ™ŸàÿµŸäŸÅŸáÿß ÿ®ÿπŸÑÿßŸÖÿßÿ™ ÿ™ÿØŸÑ ÿπŸÑŸâ ÿ£ŸÜŸáÿß ÿ™ŸÖÿ´ŸÑ ÿßŸÑÿ≥ÿπÿ±ÿå ŸàÿßŸÑŸÖÿßÿØÿ© ÿßŸÑÿ™Ÿä ÿ™ÿµŸÅ ÿ£ÿ®ÿπÿßÿØ ÿ®ÿ∂ÿßÿπÿ© ŸÖÿπŸäŸÜÿ© Ÿäÿ™ŸÖ ÿ™ŸàÿµŸäŸÅŸáÿß ÿ®Ÿáÿ∞ÿß ÿßŸÑÿ¥ŸÉŸÑ.\nŸàÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ XML ŸäŸÖŸÉŸÜ ŸÑŸÑÿ±Ÿàÿ®Ÿàÿ™ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÇŸàŸÖ ÿ®ŸÅŸáÿ±ÿ≥ÿ© ŸÖŸàÿßŸÇÿπ ÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿ£ŸÜ ÿ™ŸÅŸáŸÖ ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑŸÖŸàÿ¨ŸàÿØ ÿ∂ŸÖŸÜ ÿßŸÑÿµŸÅÿ≠ÿßÿ™. Ÿàÿ®ÿßŸÑÿ™ÿßŸÑŸä ŸÅÿπŸÜÿØŸÖÿß ÿ™ÿ®ÿ≠ÿ´ ÿπŸÜ ÿ™ÿ∞ŸÉÿ±ÿ© ÿ≥ŸÅÿ± ÿ®ÿ≥ÿπÿ± ŸÖÿπŸäŸÜ ŸÖÿ´ŸÑÿßÿå ŸÅÿ•ŸÜ ÿßŸÑÿ±Ÿàÿ®Ÿàÿ™ÿßÿ™ ŸÑÿß ÿ™ŸÇŸàŸÖ ŸÅŸÇÿ∑ ÿ®ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ÿßŸÑÿ™ÿ∞ŸÉÿ±ÿ© ÿ®ÿ£ŸÅÿ∂ŸÑ ÿßŸÑÿ£ÿ≥ÿπÿßÿ±ÿå ŸàŸÑŸÉŸÜŸáÿß ÿ™ÿπÿ´ÿ± ÿ£Ÿäÿ∂ÿß ÿπŸÑŸâ ÿ£ŸÅÿ∂ŸÑ ÿ≥ÿπÿ± ŸÑÿ∫ÿ±ŸÅÿ© ŸÅŸÜÿØŸÇÿå ÿ£Ÿà ÿ≥Ÿäÿßÿ±ÿ© ŸÖÿ≥ÿ™ÿ£ÿ¨ÿ±ÿ©.\nŸàŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ£ÿÆÿ±Ÿâ ŸÖÿ´ŸÑÿß ŸáŸä ÿ£ŸÜŸÉ ÿ•ÿ∞ÿß ÿπÿ±ÿ∂ÿ™ ÿ≥Ÿäÿ±ÿ™ŸÉ ÿßŸÑÿ∞ÿßÿ™Ÿäÿ© ÿπŸÑŸâ ÿßŸÑÿ±Ÿàÿ®Ÿàÿ™ ŸÅÿ•ŸÜŸá ŸäŸÇÿ™ÿ±ÿ≠ ÿπŸÑŸäŸÉ ÿ£ŸÅÿ∂ŸÑ Ÿàÿ∏ŸäŸÅÿ© ÿ™ŸÜÿßÿ≥ÿ® ŸÖÿ§ŸáŸÑÿßÿ™ŸÉ. ÿ£Ÿà ÿ•ÿ∞ÿß ÿπÿ±ÿ∂ÿ™ ÿπŸÑŸâ ÿßŸÑÿ±Ÿàÿ®Ÿàÿ™ ŸÖŸÑŸÅŸÉ ÿßŸÑÿµÿ≠Ÿä ŸÅÿ•ŸÜŸá ŸäŸÇÿ™ÿ±ÿ≠ ÿπŸÑŸäŸÉ ÿßŸÑŸÅŸäÿ™ÿßŸÖŸäŸÜÿßÿ™ ÿßŸÑÿ™Ÿä Ÿäÿ¨ÿ® ÿπŸÑŸäŸÉ ÿ™ŸÜÿßŸàŸÑŸáÿßÿå ÿ£Ÿà ÿßŸÑŸÜŸàÿßÿØŸä ÿßŸÑÿµÿ≠Ÿäÿ© ÿßŸÑÿ™Ÿä ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿßŸÜÿ∂ŸÖÿßŸÖ ÿ•ŸÑŸäŸáÿß.\nŸàÿ®ÿßŸÑÿ∑ÿ®ÿπ ŸÅÿ•ŸÜŸÜÿß ŸÑÿß ŸÜÿπÿ™ŸÇÿØ ÿ£ŸÜ XML ŸáŸä ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ≥ÿ≠ÿ±Ÿäÿå ŸàŸÑŸÉŸÜŸáÿß ŸäŸÖŸÉŸÜ ÿ£ŸÜ ÿ™ÿ§ÿØŸä ÿ•ŸÑŸâ ÿ≤ŸäÿßÿØÿ© ŸÜÿ¨ÿßÿπÿ© ÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿ•ÿ∞ÿß ŸÖÿß ÿßŸÇÿ™ÿ±ŸÜÿ™ ÿ®ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ£ÿÆÿ±Ÿâ ÿßŸÑŸÖÿ∞ŸÉŸàÿ±ÿ© ŸÅŸä ŸÖŸàÿ∂ŸàÿπŸÜÿß Ÿáÿ∞ÿß."
  },
  {
    "url": "https://az.wikipedia.org/wiki/Axtar%C4%B1%C5%9F_sistemi",
    "title": "Axtarƒ±≈ü sistemi ‚Äî Vikipediya",
    "content": "Axtarƒ±≈ü sistemi (ing. search engine) ‚Äì Veb-d…ô informasiyanƒ± a√ßar s√∂zl…ôr…ô, m√∂vzulara v…ô s. g√∂r…ô axtarmaƒüa imkan ver…ôn proqram (m…ôs…ôl…ôn, Bing, DuckDuckGo, Google, Rambler, Yahoo!, Yandex). Axtarƒ±≈ü sisteml…ôri avtomatla≈üdƒ±rƒ±lmƒ±≈ü indeksl…ôrdir v…ô h…ôr axtarƒ±≈ü sisteminin √∂z veril…ônl…ôr bazasƒ± var. Buna g√∂r…ô d…ô eyni a√ßar s√∂zl…ôr…ô g√∂r…ô m√ºxt…ôlif axtarƒ±≈ü sisteml…ôrind…ô axtarƒ±≈ü etdikd…ô f…ôrqli n…ôtic…ôl…ôr alƒ±nƒ±r. B…ôz…ôn axtarƒ±≈ü n…ôtic…ôl…ôrind…ô m…ôtl…ôb…ô d…ôxli olmayan informasiyalar √ßƒ±xƒ±r, √ß√ºnki el…ô bir veb-al…ôt yoxdur ki, b√ºt√ºn Veb‚Äôi indeksl…ôsin (nizamlasƒ±n).\nAxtarƒ±≈ü sisteml…ôri √º√ß …ôsas hiss…ôd…ôn ibar…ôt olur:"
  },
  {
    "url": "https://bn.wikipedia.org/wiki/%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%AC_%E0%A6%85%E0%A6%A8%E0%A7%81%E0%A6%B8%E0%A6%A8%E0%A7%8D%E0%A6%A7%E0%A6%BE%E0%A6%A8_%E0%A6%87%E0%A6%9E%E0%A7%8D%E0%A6%9C%E0%A6%BF%E0%A6%A8",
    "title": "‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶®‡ßç‡¶ß‡¶æ‡¶® ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® - ‡¶â‡¶á‡¶ï‡¶ø‡¶™‡¶ø‡¶°‡¶ø‡¶Ø‡¶º‡¶æ",
    "content": "‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® ‡¶¨‡¶æ ‡¶Ü‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶ú‡¶æ‡¶≤ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶®‡ßç‡¶ß‡¶æ‡¶® ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ ‡¶π‡¶≤ ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶≤‡ßç‡¶° ‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶° ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶¨‡¶æ  ‡¶Ü‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶ú‡¶æ‡¶≤‡ßá‡¶∞ ‡¶¶‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶§‡ßá ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶§‡¶•‡ßç‡¶Ø ‡¶¨‡¶æ ‡¶õ‡¶¨‡¶ø ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡•§ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶®‡ßç‡¶ß‡¶æ‡¶® ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶¶‡¶∞‡ßç‡¶∂‡¶® ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá ‡¶•‡¶æ‡¶ï‡ßá‡•§\n‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® ‡¶ï‡ßç‡¶∞‡ßã‡¶≤‡¶æ‡¶∞ ‡¶¨‡¶ü ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá‡•§ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶®‡ßá‡¶ü ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶®‡ßç‡¶ß‡¶æ‡¶® ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶®‡ßá‡¶∞ ‡¶Ø‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶π‡¶Ø‡¶º ‡ßß‡ßØ‡ßØ‡ß¶ ‡¶∏‡¶æ‡¶≤‡ßá‡¶∞ ‡¶°‡¶ø‡¶∏‡ßá‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶Æ‡¶æ‡¶∏‡ßá‡•§ ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø ‡¶è‡¶∞ ‡¶Ü‡¶ó‡ßá ‡ßß‡ßØ‡ßÆ‡ß¨ ‡¶∏‡¶æ‡¶≤‡ßá ‡¶π‡¶ø‡¶â‡¶≤‡ßá‡¶ü ‡¶™‡ßç‡¶Ø‡¶æ‡¶ï‡¶æ‡¶∞‡ßç‡¶° ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∑‡ßç‡¶†‡¶æ‡¶® ‡¶ï‡¶∞‡ßç‡¶§‡ßÉ‡¶ï ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶®‡ßç‡¶ß‡¶æ‡¶® ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® ‡¶Ü‡¶¨‡¶ø‡¶∑‡ßç‡¶ï‡ßÉ‡¶§ ‡¶π‡¶Ø‡¶º‡•§ ‡ßß‡ßØ‡ßØ‡ß™ ‡¶∏‡¶æ‡¶≤‡ßá ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶π‡¶Ø‡¶º ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶®‡ßç‡¶ß‡¶æ‡¶® ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶ï‡ßç‡¶∞‡¶≤‡¶æ‡¶∞‡•§ ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® ‡¶Æ‡ßÇ‡¶≤‡¶§ ‡¶§‡¶ø‡¶®‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá: ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶®‡ßá‡¶∞ ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶ï‡ßç‡¶∞‡¶≤‡¶æ‡¶∞ (bots/spiders) ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶≤‡¶ø‡¶ô‡ßç‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá ‡¶®‡¶§‡ßÅ‡¶® ‡¶ï ‡¶ï‡ßç‡¶∞‡¶≤‡¶æ‡¶∞ ‡¶¶‡ßç‡¶¨‡¶æ‡¶∞‡¶æ ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶æ ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶™‡ßá‡¶ú‡ßá‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶®‡ßá‡¶∞ ‡¶°‡¶æ‡¶ü‡¶æ‡¶¨‡ßá‡¶∏‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ (indexing) ‡¶ï‡¶∞‡¶æ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶™‡ßá‡¶ú‡ßá‡¶∞ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü, ‡¶ï‡ßÄ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶°, ‡¶á‡¶Æ‡ßá‡¶ú, ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì, ‡¶Æ‡ßá‡¶ü‡¶æ‡¶°‡¶æ‡¶ü‡¶æ ‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡ßá ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßã‡¶® ‡¶ï‡ßã‡¶® ‡¶™‡ßÉ‡¶∑‡ßç‡¶†‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ï‡ßã‡¶® ‡¶ï‡ßÄ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶°‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∞‚Äç‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶§‡¶æ ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá‡•§ ‡¶Ø‡¶ñ‡¶® ‡¶ï‡ßá‡¶â ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶ï‡¶∞‡ßá, ‡¶§‡¶ñ‡¶® ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶® ‡¶§‡¶æ‡¶∞ ‡¶á‡¶®‡¶°‡ßá‡¶ï‡ßç‡¶∏ ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶ì ‡¶Æ‡¶æ‡¶®‡¶∏‡¶Æ‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶™‡ßÉ‡¶∑‡ßç‡¶†‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶∞‚Äç‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï ‡¶ï‡¶∞‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶™‡ßÉ‡¶∑‡ßç‡¶†‡¶æ‡¶Ø‡¶º (SERP) ‡¶¶‡ßá‡¶ñ‡¶æ‡¶Ø‡¶º‡•§ ‡¶∞‚Äç‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡¶ø‡¶Ç ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£‡ßá ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá, ‡¶Ø‡ßá‡¶Æ‡¶®:"
  },
  {
    "url": "https://bjn.wikipedia.org/wiki/Masin_panggagai_web",
    "title": "Masin panggagai web - Wikipidia Banjar, kindai pangatahuan",
    "content": "Masin panggagai web (basa Inggris: web search engine) adalah parugram kumputar nang dirancang gasan manggawi panggagaian atas barakas-barakas nang tasimpan dalam layanan www, ftp, publikasi milis, atawa jua news group dalam sabuting atawa jua sajumlah kumputar paladin dalam sabuting jaringan. Masin panggagai adalah pakakas panggagai maklumat matan dukumin-dukumin nang tasadia. Kulihan panggagaian rancaknya ditampaiakan dalam bantuk daptar nang rancak diurutakan maumpat hingkat akurasi atawa jua rasio pailang atas sabuting barakas nang disambat sawagai hits. Maklumat nang jadi sasahan panggagaian kawa tadapat dalam bamamacam janis barakas kaya tungkaran web, gambar, atawa jua janis-janis barakas lainnya. Sapalih masin panggagai dikatahui jua manggawi pangumpulan maklumat atas data nang tasimpan dalam sabuting basis data atawa jua direktori web. Sapalih ganal masin panggagai dijalanakan ulih pausahaan swasta nang mamakai algoritme kaanggitan wan basis data tatutup, di antaranya nang panyuhurnya adalah sapari Google (MSN Search, wan Yahoo!). Sudah ada sapalih upaya manciptaakan masin panggagai lawan sumbar tabuka (open source), umpamanya adalah Htdig, Nutch, Egothor, wan OpenFTS.[1]"
  },
  {
    "url": "https://zh-min-nan.wikipedia.org/wiki/Chhiau-chh%C5%8De_ia%CC%8Bn-j%C3%ADn",
    "title": "Chhiau-chh≈çe iaÃãn-j√≠n ‚Äì Wikipedia",
    "content": "Chhiau-chh≈çe iaÃãn-j√≠n (Eng-g√≠: search engine), soÕò-s√Æm iaÃãn-j√≠n (T√¢i-o√¢n Chi√†‚Åø-th√© Tiong-b√ªn: ÊêúÂ∞ãÂºïÊìé) iah-sƒ´ soÕò-sek √≠n-k√®ng (K√°n-h√≤a-jƒ´: ÊêúÁ¥¢ÂºïÊìé), sƒ´ th√™-ki≈çng i≈çng-chi√° chhiau tiƒÅn-n√°u hƒì-th√≥ng chu-liƒÅu--√™ chu-s√¨n chhiau-chh≈çe (information retrieval) hƒì-th√≥ng. Si≈çng chhut-mi√¢--√™ sƒ´ bƒÅng-l≈çÕò chhiau-chh≈çe iaÃãn-j√≠n. Chi√†u kong-l√™ng thang hun-ch√≤ t√¥Õò-ph√¨‚Åø chhiau-chh≈çe iaÃãn-j√≠n, i√°‚Åø-ph√¨‚Åø chhiau-chh≈çe iaÃãn-j√≠n. Chi√†u beh chh≈çe--√™ chu-liƒÅu l√¢i-go√¢n ≈´ toh-bƒ´n chhiau-chh≈çe iaÃãn-j√≠n t√©ng."
  },
  {
    "url": "https://be.wikipedia.org/wiki/%D0%9F%D0%BE%D1%88%D1%83%D0%BA%D0%B0%D0%B2%D0%B0%D1%8F_%D1%81%D1%96%D1%81%D1%82%D1%8D%D0%BC%D0%B0",
    "title": "–ü–æ—à—É–∫–∞–≤–∞—è —Å—ñ—Å—Ç—ç–º–∞ ‚Äî –í—ñ–∫—ñ–ø–µ–¥—ã—è",
    "content": "–ü–æ—à—É–∫–∞–≤–∞—è —Å—ñ—Å—Ç—ç–º–∞ ‚Äî –ø—Ä–∞–≥—Ä–∞–º–Ω–∞-–∞–ø–∞—Ä–∞—Ç–Ω—ã –∫–æ–º–ø–ª–µ–∫—Å –∑ –≤—ç–±-—ñ–Ω—Ç—ç—Ä—Ñ–µ–π—Å–∞–º, —è–∫—ñ –¥–∞–µ –º–∞–≥—á—ã–º–∞—Å—Ü—å –ø–æ—à—É–∫—É —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—ñ —û –Ü–Ω—Ç—ç—Ä–Ω—ç—Ü–µ. –ü–∞–¥ –ø–æ—à—É–∫–∞–≤–∞–π —Å—ñ—Å—Ç—ç–º–∞–π –∑–≤—ã—á–∞–π–Ω–∞ –º–∞–µ—Ü—Ü–∞ –Ω–∞ —û–≤–∞–∑–µ —Å–∞–π—Ç, –Ω–∞ —è–∫—ñ–º —Ä–∞–∑–º–µ—à—á–∞–Ω—ã —ñ–Ω—Ç—ç—Ä—Ñ–µ–π—Å (—Ñ—Ä–æ–Ω—Ç-—ç–Ω–¥) —Å—ñ—Å—Ç—ç–º—ã. –ü—Ä–∞–≥—Ä–∞–º–Ω–∞–π —á–∞—Å—Ç–∫–∞–π –ø–æ—à—É–∫–∞–≤–∞–π —Å—ñ—Å—Ç—ç–º—ã –∑‚Äô—è—û–ª—è–µ—Ü—Ü–∞ –ø–æ—à—É–∫–∞–≤–∞—è –º–∞—à—ã–Ω–∞ (–ø–æ—à—É–∫–∞–≤—ã —Ä—É—Ö–∞–≤—ñ–∫) ‚Äî –∫–æ–º–ø–ª–µ–∫—Å –ø—Ä–∞–≥—Ä–∞–º, —è–∫—ñ –∑–∞–±—è—Å–ø–µ—á–≤–∞–µ —Ñ—É–Ω–∫—Ü—ã—è–Ω–∞–ª—å–Ω–∞—Å—Ü—å –ø–æ—à—É–∫–∞–≤–∞–π —Å—ñ—Å—Ç—ç–º—ã —ñ –∑–≤—ã—á–∞–π–Ω–∞ –∑‚Äô—è—û–ª—è–µ—Ü—Ü–∞ –∫–∞–º–µ—Ä—Ü—ã–π–Ω–∞–π —Ç–∞–π–Ω–∞–π –∫–∞–º–ø–∞–Ω—ñ—ñ-—Ä–∞—Å–ø—Ä–∞—Ü–æ—û—à—á—ã–∫–∞ –ø–æ—à—É–∫–∞–≤–∞–π —Å—ñ—Å—Ç—ç–º—ã. –ë–æ–ª—å—à–∞—Å—Ü—å –ø–æ—à—É–∫–∞–≤—ã—Ö —Å—ñ—Å—Ç—ç–º —à—É–∫–∞—é—Ü—å —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—é –Ω–∞ —Å–∞–π—Ç–∞—Ö –°—É—Å–≤–µ—Ç–Ω–∞–≥–∞ –ø–∞–≤—É—Ü—ñ–Ω–Ω—è, –∞–ª–µ —ñ—Å–Ω—É—é—Ü—å —Ç–∞–∫—Å–∞–º–∞ —Å—ñ—Å—Ç—ç–º—ã, –∑–¥–æ–ª—å–Ω—ã—è —à—É–∫–∞—Ü—å —Ñ–∞–π–ª—ã –Ω–∞ FTP-—Å–µ—Ä–≤–µ—Ä–∞—Ö, —Ç–∞–≤–∞—Ä—ã —û —ñ–Ω—Ç—ç—Ä–Ω—ç—Ç-–∫—Ä–∞–º–∞—Ö, –∞ —Ç–∞–∫—Å–∞–º–∞ —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—é —û –≥—Ä—É–ø–∞—Ö –Ω–∞–≤—ñ–Ω Usenet. –ü–∞–ª—è–ø—à—ç–Ω–Ω–µ –ø–æ—à—É–∫—É ‚Äî –≥—ç—Ç–∞ –∞–¥–Ω–∞ –∑ –ø—Ä—ã—è—Ä—ã—Ç—ç—Ç–Ω—ã—Ö –∑–∞–¥–∞—á —Å—É—á–∞—Å–Ω–∞–≥–∞ –Ü–Ω—Ç—ç—Ä–Ω—ç—Ç—É (–≥–ª. –ø—Ä–∞ –∞—Å–Ω–æ—û–Ω—ã—è –ø—Ä–∞–±–ª–µ–º—ã —û –ø—Ä–∞—Ü—ã –ø–æ—à—É–∫–∞–≤—ã—Ö —Å—ñ—Å—Ç—ç–º —É –∞—Ä—Ç—ã–∫—É–ª–µ –ì–ª—ã–±–æ–∫–∞–µ –ø–∞–≤—É—Ü—ñ–Ω–Ω–µ). –ü–∞ –¥–∞–Ω—ã—Ö –∫–∞–º–ø–∞–Ω—ñ—ñ Net Applications,[1] —É –ª—ñ—Å—Ç–∞–ø–∞–¥–∑–µ 2011 –≥–æ–¥–∞ –≤—ã–∫–∞—Ä—ã—Å—Ç–∞–Ω–Ω–µ –ø–æ—à—É–∫–∞–≤—ã—Ö —Å—ñ—Å—Ç—ç–º —Ä–∞–∑–º—è—Ä–∫–æ—û–≤–∞–ª–∞—Å—è –Ω–∞—Å—Ç—É–ø–Ω—ã–º —á—ã–Ω–∞–º:"
  },
  {
    "url": "https://be-tarask.wikipedia.org/wiki/%D0%9F%D0%BE%D1%88%D1%83%D0%BA%D0%B0%D0%B2%D0%B0%D1%8F_%D1%81%D1%8B%D1%81%D1%82%D1%8D%D0%BC%D0%B0",
    "title": "–ü–æ—à—É–∫–∞–≤–∞—è —Å—ã—Å—Ç—ç–º–∞ ‚Äî –í—ñ–∫—ñ–ø—ç–¥—ã—è",
    "content": "–ü–æ—à—É–∫–∞–≤–∞—è —Å—ã—Å—Ç—ç–º–∞¬†‚Äî —Å—É–∫—É–ø–Ω–∞—Å—å—Ü—å –∑–∞–ø—ñ—Å–∞—û —ñ—Å–∫—Ä—ã (—É—Å—Ç–∞–≤–∞ –∞–±–æ –ø—Ä–∞–≥—Ä–∞–º–∞), —è–∫—ñ –ø–∞–¥–∞–µ –º–∞–≥—á—ã–º–∞—Å—å—Ü—å –ø–æ—à—É–∫—É —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—ñ —û –°–µ—Ü—ñ–≤–µ. –ü–∞–¥ –ø–æ—à—É–∫–∞–≤–∞–π —Å—ã—Å—Ç—ç–º–∞–π –∑–≤—ã—á–∞–π–Ω–∞ –º–∞–µ—Ü—Ü–∞ –Ω–∞ —û–≤–∞–∑–µ —Å–∞–π—Ç, –Ω–∞ —è–∫—ñ–º —Ä–∞–∑—å–º–µ—à—á–∞–Ω—ã —ñ–Ω—Ç—ç—Ä—Ñ—ç–π—Å (—Ñ—Ä–æ–Ω—Ç-—ç–Ω–¥) —Å—ã—Å—Ç—ç–º—ã. –ü—Ä–∞–≥—Ä–∞–º–Ω–∞–π —á–∞—Å—Ç–∫–∞–π –ø–æ—à—É–∫–∞–≤–∞–π —Å—ã—Å—Ç—ç–º—ã –∑—å—è—û–ª—è–µ—Ü—Ü–∞ –ø–æ—à—É–∫–∞–≤–∞—è –º–∞—à—ã–Ω–∞ (–ø–æ—à—É–∫–∞–≤—ã —Ä—É—Ö–∞–≤—ñ—á–æ–∫)¬†‚Äî –∫–æ–º–ø–ª–µ–∫—Å –ø—Ä–∞–≥—Ä–∞–º, —è–∫—ñ –∑–∞–±—è—Å—å–ø–µ—á–≤–∞–µ –¥–∑–µ–π–Ω–∞—Å—å—Ü—å –ø–æ—à—É–∫–∞–≤–∞–π —Å—ã—Å—Ç—ç–º—ã —ñ –∑–≤—ã—á–∞–π–Ω–∞ –∑—å—è—û–ª—è–µ—Ü—Ü–∞ –∫–∞–º—ç—Ä—Ü—ã–π–Ω–∞–π —Ç–∞–π–Ω–∞–π –∫–∞–º–ø–∞–Ω—ñ—ñ-—Ä–∞—Å–ø—Ä–∞—Ü–æ—û—à—á—ã–∫–∞ –ø–æ—à—É–∫–∞–≤–∞–π —Å—ã—Å—Ç—ç–º—ã. –ë–æ–ª—å—à–∞—Å—å—Ü—å –ø–æ—à—É–∫–∞–≤—ã—Ö —Å—ã—Å—Ç—ç–º —à—É–∫–∞—é—Ü—å —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—é –Ω–∞ —Å–∞–π—Ç–∞—Ö –°—É—Å—å–≤–µ—Ç–Ω–∞–≥–∞ –ø–∞–≤—É—Ü—ñ–Ω—å–Ω—è, –∞–ª–µ —ñ—Å–Ω—É—é—Ü—å —Ç–∞–∫—Å–∞–º–∞ —Å—ã—Å—Ç—ç–º—ã, –∑–¥–æ–ª—å–Ω—ã—è —à—É–∫–∞—Ü—å —Ñ–∞–π–ª—ã –Ω–∞ FTP-—Å—ç—Ä–≤—ç—Ä–∞—Ö, —Ç–∞–≤–∞—Ä—ã —û —ñ–Ω—Ç—ç—Ä–Ω—ç—Ç-–∫—Ä–∞–º–∞—Ö, –∞ —Ç–∞–∫—Å–∞–º–∞ —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—é —û –≥—Ä—É–ø–∞—Ö –Ω–∞–≤—ñ–Ω Usenet. –ü–∞–ª—è–ø—à—ç–Ω—å–Ω–µ –ø–æ—à—É–∫—É¬†‚Äî –≥—ç—Ç–∞ –∞–¥–Ω–∞ –∑ –ø—Ä—ã—è—Ä—ã—Ç—ç—Ç–Ω—ã—Ö –∑–∞–¥–∞—á —Å—É—á–∞—Å–Ω–∞–≥–∞ –°–µ—Ü—ñ–≤–∞ (–≥–ª. –ø—Ä–∞ –∞—Å–Ω–æ—û–Ω—ã—è –ø—Ä–∞–±–ª–µ–º—ã —û –ø—Ä–∞—Ü—ã –ø–æ—à—É–∫–∞–≤—ã—Ö —Å—ñ—Å—Ç—ç–º —É –∞—Ä—Ç—ã–∫—É–ª–µ –ì–ª—ã–±–æ–∫–∞–µ –ø–∞–≤—É—Ü—ñ–Ω—å–Ω–µ). –ü–∞ –¥–∞–Ω—ã—Ö –∫–∞–º–ø–∞–Ω—ñ—ñ Net Applications,[1] —É –ª—ñ—Å—Ç–∞–ø–∞–¥–∑–µ 2011 –≥–æ–¥–∞ –≤—ã–∫–∞—Ä—ã—Å—Ç–∞–Ω—å–Ω–µ –ø–æ—à—É–∫–∞–≤—ã—Ö —Å—ã—Å—Ç—ç–º —Ä–∞–∑–º—è—Ä–∫–æ—û–≤–∞–ª–∞—Å—è –Ω–∞—Å—Ç—É–ø–Ω—ã–º —á—ã–Ω–∞–º:"
  },
  {
    "url": "https://bh.wikipedia.org/wiki/%E0%A4%B5%E0%A5%87%E0%A4%AC_%E0%A4%B8%E0%A4%B0%E0%A5%8D%E0%A4%9A_%E0%A4%87%E0%A4%82%E0%A4%9C%E0%A4%A8",
    "title": "‡§µ‡•á‡§¨ ‡§∏‡§∞‡•ç‡§ö ‡§á‡§Ç‡§ú‡§® - ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ",
    "content": "‡§µ‡•á‡§¨ ‡§ú‡•ã‡§π ‡§á‡§Ç‡§ú‡§® ‡§Ü ‡§∏‡§∞‡§ö ‡§á‡§Ç‡§ú‡§® (search engine) ‡§è‡§ó‡•ã ‡§Ö‡§á‡§∏‡§® ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§π‡•ã‡§≤‡§æ ‡§ú‡•á ‡§ñ‡§æ‡§∏ ‡§è‡§π ‡§ñ‡§æ‡§§‡•Ä ‡§°‡§ø‡§ú‡§æ‡§á‡§® ‡§ï‡§á‡§≤ ‡§ó‡§á‡§≤ ‡§π‡•ã‡§≤‡§æ ‡§ï‡§ø ‡§µ‡§≤‡•ç‡§° ‡§µ‡§æ‡§á‡§° ‡§µ‡•á‡§¨ ‡§∏‡•á ‡§ú‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ñ‡•ã‡§ú‡§≤ ‡§ú‡§æ ‡§∏‡§ï‡•á‡•§ ‡§Ö‡§á‡§∏‡§® ‡§ñ‡•ã‡§ú ‡§ï‡•á ‡§â‡§∞ ‡§∏‡§≠ ‡§ï‡•á ‡§è‡§ï ‡§ï‡§§‡§æ‡§∞ ‡§Æ‡•á ‡§™‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á ‡§Ü‡§≤‡§æ ‡§ï‡•á ‡§∏‡•ã‡§ù‡§æ ‡§∞‡§ñ‡•á ‡§≤‡§æ ‡§Ü ‡§è‡§π ‡§™‡§∞‡§ø‡§®‡§æ‡§Æ ‡§∏‡§≠ ‡§Æ‡•á ‡§µ‡•á‡§¨ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä, ‡§á‡§Æ‡•á‡§ú, ‡§¨‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§µ‡§ó‡•à‡§∞‡§π ‡§®‡§ø‡§Ø‡§∞ ‡§ï‡§à ‡§ï‡§ø‡§∏‡§ø‡§Æ ‡§ï‡•á ‡§ö‡•Ä‡§ú ‡§ï‡•á ‡§π‡•ã ‡§∏‡§ï‡•á ‡§≤‡§æ‡•§ ‡§ú‡§π‡§µ‡§æ‡§Å ‡§µ‡•á‡§¨ ‡§°‡§æ‡§á‡§∞‡•á‡§ï‡•ç‡§ü‡§∞‡•Ä ‡§∏‡§≠ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•á ‡§π‡§æ‡§•‡•á ‡§ñ‡•Å‡§¶ ‡§¨‡§®‡§æ‡§µ‡§≤ ‡§Ü ‡§Æ‡•á‡§Ç‡§ü‡•á‡§® ‡§ï‡§á‡§≤ ‡§ú‡§æ‡§≤‡•Ä‡§Ç, ‡§∏‡§∞‡§ö ‡§á‡§Ç‡§ú‡§® ‡§∏‡§≠ ‡§è‡§≤‡•ç‡§ó‡•ã‡§∞‡§ø‡§¶‡§Æ ‡§ï‡•á ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§∏‡•á ‡§µ‡•á‡§¨ ‡§ï‡•ç‡§∞‡§æ‡§â‡§≤‡§∞ ‡§ï‡•á ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§∏‡•á ‡§ë‡§ü‡•ã‡§Æ‡•á‡§ü‡§ø‡§ï ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§∏‡•á ‡§∞‡§ø‡§Ø‡§≤-‡§ü‡§æ‡§á‡§Æ ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§á‡§ï‡§ü‡•ç‡§†‡§æ ‡§ï‡§Ω ‡§ï‡•á ‡§ì‡§ï‡§∞‡§æ ‡§≤‡§ø‡§∏‡•ç‡§ü ‡§¨‡§®‡§æ ‡§≤‡•Ä‡•§ ‡§Ö‡§á‡§∏‡§® ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§ú‡•á ‡§µ‡§≤‡•ç‡§° ‡§µ‡§æ‡§á‡§° ‡§µ‡•á‡§¨ ‡§™‡§∞ ‡§π‡•ã‡§ñ‡•á ‡§≤‡•á‡§ï‡§ø‡§® ‡§∏‡§∞‡§ö ‡§á‡§Ç‡§ú‡§® ‡§ï‡•á ‡§á‡§Ç‡§°‡•á‡§ï‡•ç‡§∏‡§ø‡§Ç‡§ó (‡§≤‡§ø‡§∏‡•ç‡§ü ‡§¨‡§®‡§æ‡§µ‡•á) ‡§ï‡•á ‡§™‡§π‡•Å‡§Å‡§ö ‡§∏‡•á ‡§¨‡§π‡§∞‡§æ ‡§π‡•ã‡§ñ‡•á ‡§ì‡§ï‡§∞‡§æ ‡§ï‡•á ‡§°‡•Ä‡§™ ‡§µ‡•á‡§¨ ‡§ï‡•á ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§ï‡§π‡§≤ ‡§ú‡§æ‡§≤‡§æ‡•§ ‡§µ‡•á‡§¨ ‡§∏‡§∞‡•ç‡§ö ‡§á‡§Ç‡§ú‡§® ‡§§‡§ø‡§® ‡§ó‡•ã ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡•á‡§≤‡§æ: ‡§∏‡§∞‡•ç‡§ö ‡§á‡§Ç‡§ú‡§® ‡§ï‡•á ‡§µ‡•á‡§¨ ‡§ï‡•ç‡§∞‡•â‡§≤‡§∞ (bots/spiders) ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§™‡§∞ ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§ï‡•á ‡§∏‡•ç‡§ï‡•à‡§® ‡§ï‡§∞‡§ï‡•á ‡§®‡§Ø‡§æ ‡§Ü ‡§Ö‡§™‡§°‡•á‡§ü ‡§≠‡§á‡§≤ ‡§™‡•á‡§ú‡§® ‡§ï‡•á ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ú‡§Æ‡§æ ‡§ï‡§∞‡•á‡§≤‡§æ‡•§ ‡§à ‡§è‡§ï ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§∏‡•á ‡§¶‡•ã‡§∏‡§∞‡§æ ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§ï‡•á ‡§≤‡§ø‡§Ç‡§ï ‡§ï‡•á ‡§™‡•Ä‡§õ‡§æ ‡§ï‡§∞‡§ï‡•á ‡§®‡§Ø‡§æ ‡§ï‡§Ç‡§ü‡•á‡§Ç‡§ü ‡§ñ‡•ã‡§ú‡•á‡§≤‡§æ‡•§ ‡§ï‡•ç‡§∞‡•â‡§≤‡§∞ ‡§∏‡•á ‡§ú‡•Å‡§ü‡§æ‡§µ‡§≤ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§∏‡§∞‡•ç‡§ö ‡§á‡§Ç‡§ú‡§® ‡§ï‡•á ‡§°‡§æ‡§ü‡§æ‡§¨‡•á‡§∏ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ (indexing) ‡§ï‡§á‡§≤ ‡§ú‡§æ‡§≤‡§æ‡•§ ‡§è‡§π ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡§∞‡•ç‡§ö ‡§á‡§Ç‡§ú‡§® ‡§µ‡•á‡§¨‡§™‡•á‡§ú ‡§ï‡•á ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü, ‡§ï‡•Ä‡§µ‡§∞‡•ç‡§°, ‡§á‡§Æ‡•á‡§ú, ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§Æ‡•á‡§ü‡§æ‡§°‡§æ‡§ü‡§æ ‡§µ‡§ó‡•à‡§∞‡§π ‡§ï‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡•á‡§≤‡§æ ‡§Ü ‡§§‡§Ø ‡§ï‡§∞‡•á‡§≤‡§æ ‡§ï‡§ø ‡§ï‡§µ‡§® ‡§™‡•á‡§ú ‡§ï‡§µ‡§® ‡§ï‡•Ä‡§µ‡§∞‡•ç‡§° ‡§ñ‡§æ‡§§‡§ø‡§∞ ‡§∞‡•à‡§Ç‡§ï ‡§π‡•ã‡§à‡•§ ‡§ú‡§¨ ‡§ï‡•á‡§π‡•Ç ‡§ï‡•Å‡§õ‡•Å ‡§∏‡§∞‡•ç‡§ö ‡§ï‡§∞‡•á‡§≤‡§æ, ‡§§ ‡§∏‡§∞‡•ç‡§ö ‡§á‡§Ç‡§ú‡§® ‡§Ü‡§™‡§® ‡§á‡§Ç‡§°‡•á‡§ï‡•ç‡§∏ ‡§∏‡•á ‡§∏‡§¨‡§∏‡•á ‡§¨‡§¢‡§º‡§ø‡§Ø‡§æ ‡§Ü ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§µ‡•á‡§¨‡§™‡•á‡§ú ‡§ï‡•á ‡§è‡§≤‡•ç‡§ó‡•ã‡§∞‡§ø‡§¶‡§Æ ‡§∏‡•á ‡§∞‡•à‡§Ç‡§ï ‡§ï‡§∞‡§ï‡•á ‡§∏‡§∞‡•ç‡§ö ‡§∞‡§ø‡§ú‡§≤‡•ç‡§ü ‡§™‡•á‡§ú (SERP) ‡§™‡§∞ ‡§¶‡•á‡§ñ‡§æ‡§µ‡•á ‡§≤‡§æ‡•§ ‡§∞‡•à‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§§‡§Ø ‡§ï‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ï‡§à ‡§ó‡•ã ‡§ö‡•Ä‡§ú ‡§ï‡•á ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§∞‡§æ‡§ñ‡§≤ ‡§ú‡§æ‡§≤‡§æ, ‡§ú‡§á‡§∏‡•á:"
  },
  {
    "url": "https://bs.wikipedia.org/wiki/Internetski_pretra%C5%BEiva%C4%8D",
    "title": "Internetski pretra≈æivaƒç - Wikipedia",
    "content": "Internetski pretra≈æivaƒç (engleski: web search engine) jest veb-sajt koji omoguƒáava pretragu informacija na internetu. Internetski pretra≈æivaƒçi mogu se podijeliti na dvije grupe: meta pretra≈æivaƒçi i \"pravi\" internetski pretra≈æivaƒçi. Meta pretra≈æivaƒçi su programi koji skupljaju informacije o veb-sajtovima koji se nalaze u META oznakama HTML dokumenata. Pravi internetski pretra≈æivaƒçi jesu programi koji skupljaju sve dostupne HTML dokumente veb-sajtova i sortiraju i obraƒëuju iste u svojim bazama podataka. Na veb-sajtovima ovih pretra≈æivaƒça mogu se pogledati skupljene informacije u bazi podataka. Najpoznatiji internetski pretra≈æivaƒçi su Google, Bing i Yahoo!.[1] Nedovr≈°eni ƒçlanak Internetski pretra≈æivaƒç koji govori o raƒçunarstvu treba dopuniti. Dopunite ga prema pravilima Wikipedije."
  },
  {
    "url": "https://ca.wikipedia.org/wiki/Motor_de_cerca_web",
    "title": "Motor de cerca - Viquip√®dia, l'enciclop√®dia lliure",
    "content": "Quota d'√∫s dels Motor de cerca m√©s coneguts, segons StatCounter al Desembre del 2021[1] Un motor de cerca o de recerca o b√© cercador[2][3] √©s un programa inform√†tic dissenyat per ajudar a trobar informaci√≥ emmagatzemada en un sistema inform√†tic com ara una xarxa, Internet, un servidor o un ordinador personal. L'objectiu principal √©s el de trobar altres programes inform√†tics, p√†gines web i documents, entre d'altres. A partir d'una determinada paraula o paraules o una determinada frase, l'usuari demana un contingut sota un criteri determinat, i llavors recupera una llista de refer√®ncies que compleixen aquest criteri. El proc√©s es realitza a trav√©s de les metadades,[4] elements que permeten recuperar informaci√≥ als motors de cerca. Els √≠ndexs que utilitzen els cercadors sempre estan actualitzats a trav√©s d'un robot web per generar rapidesa i efic√†cia en la recerca. Els directoris, en canvi, s√≥n gestionats per editors humans. La forma m√©s p√∫blica i visible d'un motor de cerca √©s un motor de cerca web que cerca informaci√≥ a la World Wide Web. Un rastrejador web, indexador web, o aranya web √©s una programa inform√†tic que inspecciona les p√†gines de World Wide Web de forma met√≤dica i automatizada.[7] Un dels usos m√©s freq√ºents que se'ls dona consisteix a crear una c√≤pia de totes les p√†gines web visitades per al seu processament posterior per un motor de cerca que indexa les p√†gines proporcionant un sistema de recerques r√†pid. Les aranyes web solen ser bots.[8] Les aranyes web comencen visitant una llista d'URL, identifica els hiperenlla√ßos en aquestes p√†gines i els afegeix a la llista d'URL a visitar de manera recurrent d'acord a determinat conjunt de regles. L'operaci√≥ normal √©s que se li dona a el programa un grup d'adreces inicials, l'aranya desc√†rrega aquestes adreces, analitza les p√†gines i busca enlla√ßos a p√†gines noves. Despr√©s desc√†rrega aquestes p√†gines noves, analitza els seus enlla√ßos, i aix√≠ successivament. Entre les tasques m√©s comunes de les aranyes del web tenim: Un directori web √©s un tipus de lloc web que cont√© un directori organitzat de dades, imatges o, m√©s generalment, enlla√ßos a altres llocs web. Els directoris web, contr√†riament als motors de cerca, es caracteritzen per estar estructurats en categories i subcategories. Habitualment, els directoris web permeten als administradors web o creadors de llocs web que informin del seu lloc perqu√® sigui incl√≤s, i despr√©s els editors autoritzats revisen aquestes sol¬∑licituds abans d'incloure les seves enlla√ßos per comprovar que s'adeq√ºen als requisits d'acceptaci√≥ determinats pel directori web.[9] Entre els directoris web generalistes m√©s coneguts es poden esmentar el Yahoo! Directory (inactiu des 2014) i DMOZ (inactiu des 2017). En l'actualitat els directoris web supervivents s√≥n petites bases de dades especialitzades en temes concrets i per aix√≤ ja no s√≥n tan populars. Els grans repertoris generalistes com van ser Yahoo! Directory o DMOZ ja han estat definitivament reempla√ßats pels motors de cerca, principalment el cercador de Google. Els directoris web regionals integren en un mateix lloc a comer√ßos, serveis, empreses o participants de determinat sector, enfocant-se en un territori comercial en espec√≠fic, creant d'aquesta manera una comunitat que facilita la navegaci√≥, localitzaci√≥ i mercadeig. Aquests directoris promouen el creixement econ√≤mic de el sector a qu√® estan enfocats ja que posen a l'abast de l'usuari la possibilitat de descobrir prove√Ødors que desconeixia que existissin i amb aix√≤ resoldre una necessitat de compra. Una tecnologia molt simple per gran quantitat de scripts disponibles, ja que no calen molts recursos. En canvi, cal m√©s suport hum√† i mantenimient.[10] Un metacercador √©s un sistema que localitza informaci√≥ en els motors de cerca m√©s usats, no t√© base de dades pr√≤pia pel que fa servir les d'altres cercadors i mostra una combinaci√≥ de les millors p√†gines que ha cada un.[11] Un cercador normal recopila la informaci√≥ de les p√†gines mitjan√ßant la seva indexaci√≥, com Google o b√© mant√© un ampli directori tem√†tic, com Yahoo. La definici√≥ simplista seria que un metacercador √©s un cercador en cercadors. ¬´En altres paraules per al¬∑ludir a el concepte m√©s gen√®ric d'un cercador, podem afirmar que un metacercador √©s el cercador que incorpora un conjunt de cercadors. Alguns exemples de metacercadors s√≥n: Dogpile, Aleyares [12] MetaCrawler, entre d'altres. Aquests metacercadors presenten avantatges, com ampliar l'espai de recerca i en alguns casos mostrar la posici√≥ del web¬†¬ª.[13] Els motors de cerca proporcionen una interf√≠cie a un grup d'elements que permet als usuaris especificar criteris sobre un article d'inter√®s i que el motor trobi els elements coincidents. Els criteris s'anomenen consulta de cerca. En el cas dels motors de cerca de text, la consulta de cerca normalment s'expressa com un conjunt de paraules que identifiquen el concepte desitjat que un o m√©s documents poden contenir.[14] Hi ha diversos estils de sintaxi de consulta de cerca que varien en rigor. Tamb√© pot canviar de nom als motors de cerca dels llocs anteriors. Mentre que alguns motors de cerca de text requereixen que els usuaris introdueixin dues o tres paraules separades per espai en blanc, altres motors de cerca poden permetre als usuaris especificar documents sencers, imatges, sons i diverses formes de llenguatge natural. Alguns motors de cerca apliquen millores a les consultes de cerca per augmentar la probabilitat de proporcionar un conjunt d'elements de qualitat mitjan√ßant un proc√©s conegut com a expansi√≥ de la consulta. Els m√®todes de comprensi√≥ de consultes es poden utilitzar com a llenguatge de consulta estandarditzat. La llista d'elements que compleixen els criteris especificats per la consulta normalment s'ordena o es classifica. La classificaci√≥ dels elements per rellev√†ncia (de major a menor) redueix el temps necessari per trobar la informaci√≥ desitjada. Els motors de cerca probabil√≠stics classifiquen els elements basant-se en mesures de similaritat (entre cada element i la consulta, normalment en una escala d'1 a 0, l'1 √©s el m√©s semblant) i de vegades la popularitat o autoritat (vegeu bibliometria) o utilitza la opini√≥ sobre la rellev√†ncia. Els motors de cerca booleans normalment nom√©s retornen elements que coincideixen exactament sense tenir en compte l'ordre, tot i que el terme motor de cerca boole√† pot referir-se simplement a l'√∫s de la sintaxi d'estil boole√† (l'√∫s d'operadors AND, OR, NOT i XOR) en un context probabil√≠stic. Per proporcionar un conjunt d'elements coincidents que s'ordenen d'acord amb alguns criteris r√†pidament, un motor de cerca normalment recopilar√† metadades sobre el grup d'elements que s'est√† considerant pr√®viament mitjan√ßant un proc√©s anomenat indexaci√≥. L'√≠ndex normalment requereix una quantitat m√©s petita d'emmagatzematge inform√†tic, per la qual cosa alguns motors de cerca nom√©s emmagatzemen la informaci√≥ indexada i no el contingut complet de cada element, i en canvi proporcionen un m√®tode per navegar als elements a la p√†gina de resultats del cercador. Alternativament, el motor de cerca pot emmagatzemar una c√≤pia de cada element en una cach√© perqu√® els usuaris puguin veure l'estat de l'element en el moment en qu√® es va indexar o amb finalitats d'arxiu o perqu√® funcionin processos repetitius. de manera m√©s eficient i r√†pida. Altres tipus de cercadors no emmagatzemen un √≠ndex. Els Crawler, o motors de cerca de tipus aranya (tamb√© coneguts com motors de cerca en temps real) poden recollir i avaluar elements en el moment de la consulta de cerca, considerant din√†micament elements addicionals basats en el contingut d'un element inicial (conegut com a una llavor, o URL de llavor en el cas d'un rastrejador d'Internet). Els motors de cerca meta no emmagatzemen ni un √≠ndex ni una mem√≤ria cau i, en canvi, simplement reutilitzen l'√≠ndex o els resultats d'un o m√©s motors de cerca per proporcionar un conjunt final agregat de resultats. El primer cercador va ser \"Wandex\", un √≠ndex realitzat pel World Wide Web Wanderer, un robot desenvolupat per Mattew Gray al MIT, el 1993. Un altre dels primers cercadors, Aliweb, tamb√© va apar√®ixer en 1993 i encara est√† en funcionament. El primer motor de cerca de text complet va ser WebCrawler, que va apar√®ixer el 1994. A difer√®ncia dels seus predecessors, aquest permetia als seus usuaris una recerca per paraules en qualsevol p√†gina web, el que va arribar a ser un est√†ndard per a la gran majoria dels cercadors . WebCrawler va ser aix√≠ mateix el primer a donar-se a con√®ixer √†mpliament entre el p√∫blic. Tamb√© va apar√®ixer en 1994 Lycos (que va comen√ßar a la Carnegie Mellon University). Molt aviat van apar√®ixer molts m√©s cercadors, com Excite, Infoseek, Inktomi, Northern Light i Altavista. D'alguna manera, competien amb directoris (o √≠ndexs tem√†tics) populars com Yahoo!. M√©s tard, els directoris es van integrar o es van afegir a la tecnologia dels cercadors per augmentar la seva funcionalitat. Abans de l'adveniment de la Web, hi havia motors de cerca per a altres protocols o usos, com el cercador Archie, per a llocs FTP an√≤nims i el motor de cerca Ver√≤nica, per al protocol Gopher. El 1996 Larry Page i Serguei Brin van comen√ßar un projecte que portaria a l'aparici√≥ del cercador m√©s utilitzat avui dia: Google. El projecte inicial es va cridar BackRub,[15] que era el nom de la tecnologia utilitzada per al seu desenvolupament. BackRub basava la import√†ncia dels llocs web en la quantitat d'enlla√ßos que rebia. Presentava una interf√≠cie molt senzilla i capa√ß de mostrar als l'usuari els resultats m√©s rellevants per a cadascuna de les recerques. Amb l'arribada de Google, la manera en qu√® els motors de cerca funcionaven va canviar de forma radical, democratitzant els resultats que s'ofereixen en el seu cercador. Google va basar el funcionament del seu motor de cerca a la rellev√†ncia dels continguts de cada lloc web per als propis usuaris, √©s a dir, prioritzant aquells resultats que els usuaris consideraven m√©s rellevants per a una tem√†tica concreta. Per a aix√≤ va patentar el seu fam√≥s PageRank, un conjunt d'algoritmes que valoraven la rellev√†ncia d'un lloc web assignant-li un valor num√®ric de el 0 a el 10. En la majoria de pa√Øsos Google.com o la versi√≥ de Google per al pa√≠s concret, √©s el cercador m√©s utilitzat, per√≤, aix√≤ no passa en alguns pa√Øsos. Per exemple, a R√∫ssia el cercador m√©s utilitzat √©s Yandex[16][17] i a la Xina √©s Baidu.[18] La Uni√≥ Europea en 2018 li va imposar una multa de 5.000¬†milions d'euros per pr√†ctiques monopol√≠stiques, al considerar que for√ßa injustament als fabricants per a que la seva aplicaci√≥ de recerca estigui a tots els tel√®fons que executin Android.[19] Viccionari"
  },
  {
    "url": "https://cs.wikipedia.org/wiki/Webov%C3%BD_vyhled%C3%A1va%C4%8D",
    "title": "Webov√Ω vyhled√°vaƒç ‚Äì Wikipedie",
    "content": "Webov√Ω vyhled√°vaƒç je slu≈æba, kter√° umo≈æ≈àuje na Internetu naj√≠t webov√© str√°nky, kter√© obsahuj√≠ po≈æadovan√© informace. U≈æivatel zad√°v√° do rozhran√≠ vyhled√°vaƒçe kl√≠ƒçov√° slova, kter√° charakterizuj√≠ hledanou informaci, a vyhled√°vaƒç obratem na z√°kladƒõ sv√© datab√°ze vypisuje seznam odkaz≈Ø na str√°nky, kter√© hledan√© informace obsahuj√≠ (text, obr√°zky nebo jin√© typy multimedi√°ln√≠ch informac√≠). Datab√°ze je udr≈æov√°na p≈ôev√°≈ænƒõ automaticky na rozd√≠l od internetov√Ωch katalog≈Ø, kter√© jsou udr≈æov√°ny p≈ôev√°≈ænƒõ ruƒçnƒõ. C√≠lem vyhled√°vaƒç≈Ø je poskytnout u≈æivateli p≈ôi odpovƒõdi na dotaz co nejrelevantnƒõj≈°√≠ informace, a proto r≈Øzn√Ωmi zp≈Øsoby hodnot√≠ d≈Øle≈æitost obsa≈æen√Ωch informac√≠ na webov√Ωch str√°nk√°ch (nap≈ô. pomoc√≠ PageRank) a str√°nky s vy≈°≈°√≠m hodnocen√≠m zobrazuje u≈æivateli jako prvn√≠. Vyhled√°vaƒç pracuje z vƒõt≈°√≠ ƒç√°sti automaticky, k ƒçemu≈æ vyu≈æ√≠v√° des√≠tky a≈æ statis√≠ce poƒç√≠taƒç≈Ø. Kvalita vyhled√°vaƒçe je z√°visl√° na tom, jak kvalitn√≠ d√°v√° odpovƒõdi, tj. jestli u≈æivatel najde hledanou informaci na prvn√≠ch m√≠stech odpovƒõdi vyhled√°vaƒçe. Z tohoto d≈Øvodu je nutn√© mƒõ≈ôit kvalitu str√°nek, kter√© vyhled√°vaƒç m√° ve sv√© datab√°zi (nap≈ô. PageRank u Google, S-rank u Seznamu) a naopak majitel√© str√°nek se sna≈æ√≠ modifikac√≠ sv√Ωch str√°nek dos√°hnout na co nejvy≈°≈°√≠ pozice ve v√Ωstupu vyhled√°vaƒçe (SEO). V√Ωsledkem je, ≈æe vyhled√°vaƒç mus√≠ sv√© metody neust√°le vylep≈°ovat, aby vyhovƒõl ƒç√≠m d√°l vy≈°≈°√≠m po≈æadavk≈Øm sv√Ωch n√°v≈°tƒõvn√≠k≈Ø. Obecnƒõ vƒõt≈°ina internetov√Ωch vyhled√°vaƒç≈Ø pracuje ve ƒçty≈ôech kroc√≠ch: Pro proch√°zen√≠ webov√Ωch str√°nek m√° internetov√Ω vyhled√°vaƒç automatick√Ω program, tzv. vyhled√°vac√≠ robot (bot nebo t√©≈æ spider ‚Äì ‚Äûpavouk‚Äú), kter√Ω se pomoc√≠ hypertextov√Ωch odkaz≈Ø sna≈æ√≠ nav≈°t√≠vit v≈°echny webov√© str√°nky na Internetu (cel√Ω World Wide Web, tj. WWW). Robot pracuje tak, ≈æe dostane na zaƒç√°tku seznam atraktivn√≠ch str√°nek (tj. vstupn√≠ch m√≠st, resp. seznam URL odkaz≈Ø). Nejl√©pe je to seznam rozcestn√≠k≈Ø, jako je nap≈ô√≠klad katalog Seznamu[1], Yahoo! Directory[2] a podobnƒõ. Robot ka≈ædou str√°nku st√°hne na sv≈Øj pevn√Ω disk a poznamen√° si jej√≠ URL adresu, aby ji nenav≈°tƒõvoval opakovanƒõ. V ulo≈æen√© str√°nce p≈ôeƒçte v≈°echny hypertextov√© odkazy na dal≈°√≠ webov√© str√°nky, ƒç√≠m≈æ z√≠sk√° dal≈°√≠ m√≠sta, kter√° stejn√Ωm zp≈Øsobem nav≈°t√≠v√≠. Robot pracuje cyklicky, tak≈æe se po urƒçit√©m ƒçase na str√°nky vrac√≠, aby zjistil jejich p≈ô√≠padn√© zmƒõny. Str√°nky, kter√© robot ulo≈æil na pevn√Ω disk, je nutn√© zpracovat a vytvo≈ôit z nich datab√°zi. V datab√°zi jsou uvedena v≈°echna nalezen√° slova a k nim adresy, na kter√Ωch se tato slova vyskytuj√≠. Datab√°ze je tedy schopna poskytnout informaci, na kter√Ωch str√°nk√°ch se hledan√© slovo nach√°z√≠. Probl√©mem je velikost datab√°ze, proto≈æe jej√≠ sekvenƒçn√≠ prohled√°n√≠ by trvalo ne√∫mƒõrnƒõ dlouho. Proto n√°sleduje dal≈°√≠ krok, tzv. indexace. Indexov√°n√≠ datab√°ze urychluje vyhled√°n√≠ po≈æadovan√© informace. Z√°rove≈à je index vytvo≈ôen tak, aby poskytoval na prvn√≠ch m√≠stech str√°nky s nejvy≈°≈°√≠ u≈æitnou hodnotou (tzv. relevanc√≠, maj√≠c√≠ nejvy≈°≈°√≠ hodnocen√≠ kvality, nejvy≈°≈°√≠ v√°hu). Pro v√Ωpoƒçet relevance se pou≈æ√≠vaj√≠ nejr≈Øznƒõj≈°√≠ algoritmy, kter√© jsou zalo≈æeny na nejr≈Øznƒõj≈°√≠ch znac√≠ch str√°nek a r≈Øzn√Ωch √∫hlech anal√Ωzy jejich obsahu, nap≈ô√≠klad: Vyhled√°vaƒç poskytuje sv√Ωm u≈æivatel≈Øm vstupn√≠ formul√°≈ô, do kter√©ho jsou zad√°v√°na hledan√° slova (fr√°ze atp.). Po odesl√°n√≠ dotazu jsou pomoc√≠ indexu z√≠sk√°ny z datab√°ze odkazy na str√°nky, kter√© hledan√© slovo obsahuj√≠. Podle kvality indexu jsou na prvn√≠ch m√≠stech vƒõt≈°inou odkazy na str√°nky, kter√© jsou pro u≈æivatele dostaƒçuj√≠c√≠. Pro vy≈°≈°√≠ p≈ôehlednost se zobrazuje kromƒõ odkazu je≈°tƒõ titulek str√°nky, okol√≠ nalezen√Ωch slov a p≈ô√≠padnƒõ i dal≈°√≠ informace (st√°≈ô√≠ informace, kvalita odkazu, ‚Ä¶). Z principu pr√°ce vyhled√°vaƒçe vypl√Ωv√°, ≈æe nikdy nem√° √∫plnƒõ aktu√°ln√≠ informace, ale prezentuje je se zpo≈ædƒõn√≠m. Robot nav≈°tƒõvuje zaj√≠mav√© adresy co nejƒçastƒõji (nap≈ô. zpravodajsk√© servery) nebo se dokonce uzav√≠r√° smlouva o snadnƒõj≈°√≠m zp≈ô√≠stupnƒõn√≠ obsahu pro robota (m√≠sto pasivn√≠ho ƒçek√°n√≠ na n√°v≈°tƒõvu robota jsou nov√© informace robotovi p≈ô√≠mo zasl√°ny). Pro vy≈°≈°√≠ efektivitu se datab√°ze aktualizuje po ƒç√°stech nebo pr≈Øbƒõ≈ænƒõ nebo se co nejƒçastƒõji aktualizuj√≠ alespo≈à nejzaj√≠mavƒõj≈°√≠ a nejƒçastƒõji hledan√© informace. Nƒõkdy je ne≈æ√°douc√≠, aby robot indexoval nƒõkter√© str√°nky. Proto existuje mo≈ænost, jak roboty omezit pomoc√≠ souboru robots.txt, kter√Ω se umis≈•uje do ko≈ôene webov√©ho serveru. Technika, kter√° dok√°≈æe str√°nky upravit tak, aby se co nejl√©pe um√≠stily ve v√Ωsledc√≠ch vyhled√°v√°n√≠, se naz√Ωv√° SEO (anglicky Search Engine Optimization) a v posledn√≠ dobƒõ je velmi ≈æ√°danou slu≈æbou. SEO techniky se rozli≈°uj√≠ na ‚Äûpovolen√©‚Äú a ‚Äûzak√°zan√©‚Äú (tzv. Black Hat SEO, kter√© vyhled√°vaƒçe tvrdƒõ postihuj√≠ nap≈ô√≠klad vy≈ôazen√≠m ze sv√©ho indexu), av≈°ak z hlediska vyhled√°vaƒç≈Ø je jak√©koliv umƒõl√© zlep≈°ov√°n√≠ um√≠stƒõn√≠ ve v√Ωsledc√≠ch vyhled√°v√°n√≠ ne≈æ√°douc√≠ (snad kromƒõ p≈ô√≠pad≈Ø, kdy robot str√°nce z nƒõjak√©ho d≈Øvodu nerozum√≠). Na podobn√©m principu funguje i tzv. Google bomba, kter√° umo≈æ≈àuje do v√Ωsledk≈Ø vyhled√°v√°n√≠ zahrnout i str√°nky, kter√© hledan√© slovo neobsahuj√≠. Historie internetov√Ωch vyhled√°vaƒç≈Ø se zaƒçala ps√°t v roce 1990, kdy byl pro prohled√°v√°n√≠ FTP archiv≈Ø vytvo≈ôen vyhled√°vaƒç Archie. V roce 1998 byl p≈ôedstaven vyhled√°vaƒç Google, kter√Ω pomoc√≠ unik√°tn√≠ho ≈ôad√≠c√≠ho algoritmu v√Ωraznƒõ zmƒõnil pohled na vyhled√°v√°n√≠ v internetov√©m obsahu."
  },
  {
    "url": "https://ary.wikipedia.org/wiki/%D9%85%D9%88%D8%B7%D9%88%D8%B1_%D8%AF_%D8%A7%D9%84%D8%AA%D9%82%D9%84%D8%A7%D8%A8",
    "title": "ŸÖŸàÿ∑Ÿàÿ± ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® - ŸàŸäŸÉŸäŸæŸäÿØŸäÿß",
    "content": "ŸÑŸÖŸàÿ∑Ÿàÿ± ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® (ÿ® ŸÜŸë›£ŸÑŸäÿ≤Ÿäÿ© Search engine) ŸáŸàŸëÿß ÿµŸàŸÅÿ™ŸàŸäÿ± ŸÖÿØŸäŸàÿ± ÿ®ÿßÿ¥ ŸäŸÇŸÑÿ® ŸÅ ŸÑŸàŸäÿ®ÿå ÿ®ÿ¥ŸÉŸÑ ÿ≥Ÿäÿ≥ÿ™ŸäŸÖÿßÿ™ŸäŸÉŸäÿå ÿπŸÑŸâ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÖÿ≠ÿØÿØÿ© ÿ® ŸÉŸàŸäÿ±Ÿä ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® ŸÅ ŸÑŸàŸäÿ® ŸÑŸä ŸÉÿßÿ™ŸÉŸàŸÜ ÿπŸÑŸâ ÿ¥ŸÉŸÑ ŸÉŸÑŸÖÿ© ÿ§ŸÑÿß ŸÜÿµ.[1] ŸáÿßÿØ ŸÑŸÉŸÑŸÖÿ© ÿ§ŸÑÿß ŸÜŸëÿµ ŸÅ ŸÑÿπÿßÿØÿ© ŸÉŸäÿØÿÆŸÑŸáŸàŸÖ ÿÆÿØÿßŸäŸÖŸä ŸÅ ÿµŸÜÿØŸàŸÇÿ© ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ®ÿå ŸäŸÑÿß ŸÉÿßŸÜ ŸÑŸÖŸàÿ∑Ÿàÿ± ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® ÿπŸÜÿØŸà ÿ£ŸÜÿ∑Ÿäÿ±ŸÅÿßÿµ. ŸÜŸëÿ™Ÿäÿ¨ÿ© ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ®ÿå ŸäŸÑÿß ŸÑŸÖŸàÿ∑Ÿàÿ± ÿØ ŸÑÿ®ÿ≠ÿ™ ŸÑŸÇÿß ÿ¥Ÿä ÿ≠ÿßÿ¨ÿ©ÿå ŸÉÿßÿ™ŸÉŸàŸÜ ÿπÿßÿØÿ©Ÿã ÿπŸÑŸâ ÿ¥ŸÉŸÑ ŸÑŸäÿ≥ÿ™ÿ© ÿØ ŸÑÿπŸÜÿßÿµÿ±ÿå ÿ®ÿ≠ÿßŸÑ ÿ£ÿØÿ±Ÿäÿ≥ÿßÿ™ ÿØ ŸÑŸàŸäÿ®ÿå ÿ™ÿµÿßŸàÿ± ÿ§ŸÑÿß ⁄§ŸäÿØŸäŸàÿßÿ™. ÿπŸÉÿ≥ ŸÑŸÉÿßÿ∑ÿßŸÑŸà›£ÿßÿ™ ÿØ ŸÑŸàŸäÿ®ÿå ŸÑŸä ŸÅ ŸÑÿπÿßÿØÿ© ŸÉŸäŸÉŸàŸÜŸà ŸÖÿµÿßŸàÿ®ŸäŸÜ ŸÖŸÜ ÿ∑ÿßÿ±ÿßŸÅ ÿ®ŸÜÿßÿØŸÖÿå ŸÑŸÖŸàÿ∑Ÿàÿ± ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® ŸÉŸäÿ¨ÿ®ÿØ ŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ®ÿ¥ŸÉŸÑ ÿØŸäŸÜÿßŸÖŸäŸÉŸäÿå ÿ≠Ÿäÿ™ ŸÉŸäÿ™ÿ®ÿØŸëŸÑŸà ÿ®ÿ¥ŸÉŸÑ ŸÖÿ≥ÿ™ÿßŸÖÿ±ÿå ÿ®ÿ≥ÿ™ŸäÿπŸÖÿßŸÑ ÿ£ŸÑ›£Ÿàÿ±Ÿäÿ™ŸÖ ŸÑŸä ŸÉŸäÿÆÿØŸëŸÖ ÿ±ÿ™ŸäŸÑÿßÿ™ ÿØ ŸÑŸàŸäÿ®. ÿ£Ÿä ŸÖÿ≠ÿ™ŸàŸâ ÿØ ŸÑŸàŸäÿ® ŸÑŸä ŸÑŸÖŸàÿ∑Ÿàÿ± ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® ŸÖÿßŸäŸÇÿØÿ±ÿ¥ Ÿäÿ£ŸÜÿØŸäŸÉÿ≥ŸäŸá ŸÉŸäÿ™Ÿëÿπÿ™ÿßÿ®ÿ± ÿ¨ÿ≤ÿ° ŸÖŸÜ ÿØŸëŸäŸæ ŸàŸäÿ® ÿ§ŸÑÿß ŸÑŸàŸäÿ® ŸÑÿπŸÖŸäŸÇ. ÿ£ÿ¥Ÿáÿ± ŸÖŸàÿ∑Ÿàÿ± ÿØ ÿßŸÑÿ™ŸÇŸÑÿßÿ® ŸÅ ŸÑŸàŸäÿ® ŸáŸàŸëÿß ›£ŸàŸà›£ŸÑÿå ŸàŸÑÿßŸÉŸäŸÜ ŸÉÿßŸäŸÜŸäŸÜ ŸÖŸàÿ∑Ÿàÿ±ÿßÿ™ ÿÆÿ±ŸäŸÜ ÿ®ÿ≠ÿßŸÑ ÿ®ŸäŸÜ›£ÿå ŸäÿßŸÜÿØŸäŸÉÿ≥ÿå ÿ®ÿßŸäÿØŸà ÿ§ ŸäÿßŸáŸà!."
  },
  {
    "url": "https://et.wikipedia.org/wiki/Otsingumootor",
    "title": "Otsingumootor ‚Äì Vikipeedia",
    "content": "Otsingumootor ehk otsimootor on arvutiprogramm (tavaliselt otsinguprogrammide-andmebaaside s√ºsteem), mille v√§ljundi abil saab veebis infot kiiremini leida. Otsimootor otsib kindlate tunnustega andmeid veebist ja FTP-serveritest.[1] P√§ringu vastused esitatakse nimekirjana, mis v√µib koosneda viidetest veebilehtedele, piltidele, dokumentidele, videotele jt objektidele v√µrgus. M√µned otsingumootorid kaevandavad andmeid v√µrku √ºhendatud andmebaasidest v√µi avatud loenditest. Erinevalt veebiregistritest-portaalidest, mida hooldavad toimetajad, uuendavad otsingumootorid infot reaalajas, k√§itades veebi√§mblike abil algoritme.[2] Veebi algusaegadel kasutati veebiserverite loetelu, mida toimetas Tim Berners-Lee ja majutas CERN-i serveris. 1992. aastast on alles ka √ºks ajalooline pilt[3] Kuna internetti tekkis j√§rjest kiiremini uusi veebiservereid, ei suutnud see loetelu enam kasvuga sammu pidada. NCSA lehel teatati uutest serveritest jaotises \"What's New!\" ('mida uut!').[4] Esimene t√∂√∂riist, mida kasutati internetis otsimiseks, oli Archie. Nimi t√§hendas \"archive\" ('arhiiv') ilma \"v\"-ta. Selle l√µid 1990. aastal Alan Emtage, Bill Heelan ja J. Peter Deutsch, arvutitehnika √µpilased McGilli √ºlikoolist Montr√©alis. Programm laadis alla registri nimekirjad k√µikidest failidest, mis asusid avalikes FTP v√µrgukohtades, luues failinimedega otsitava andmebaasi. Archie ei indekseerinud lehtede sisu, sest andmemahud olid piiratud, samas v√µis andmeid lihtsalt leida. Gopheri loomine 1991. aastal Mark McCahilli poolt avas tee kahele uuele otsinguprogrammile: Veronica ja Jughead. Sarnaselt Archiega otsisid nad failinimesid ja pealkirju, mis olid salvestatud Gopheri indeksis√ºsteemidesse. Veronica v√µimaldas m√§rks√µnaotsingut enamikule Gopheri men√º√º pealkirjadele terves Gopheri nimekirjas. Jughead oli t√∂√∂riist, mille abil v√µis leida men√º√º infot kindlatest Gopheri serveritest. Kuigi otsingumootori Archie nimi polnud viide Archie koomiksisarjale, said Veronica ja Jughead nime selle sarja tegelaste j√§rgi ja viitasid niimoodi oma eelk√§ijale. 1993. aasta suvel ei olnud veebi jaoks √ºhtegi otsingumootorit, mitmeid spetsiaalseid katalooge hallati k√§sitsi. Oscar Nierstrasz Geneva √úlikoolist kirjutas seeria Perli skripte, mis perioodiliselt peegeldasid neid lehti ja nad kirjutasid need √ºmber standardvormingusse, mis moodustas W3Catalogi aluse. See oli esimene primitiivne veebis kasutatav otsingumootor ning anti v√§lja 2. septembril 1993.[5] 1993. aasta juunis l√µi Matthew Gray arvatavasti esimese veebiroboti, Perli baasil loodud World Wide Web Wandereri ja kasutas seda Wandexi-nimelise indeksi loomiseks. Wandereri eesm√§rgiks oli m√µ√µta veebi suurust, mida see tegi kuni 1995. aastate l√µpuni. Veebi teine otsingumootor ALiweb ilmus novembris 1993. Aliweb ei kasutanud veebirobotit, vaid s√µltus veebilehtede adminide teavitustest iga lehe olemasolu kohta. JumpStation ('h√ºppejaam') kasutas veebirobotit veebilehtede leidmiseks ja neist registri ehitamiseks ning kasutas veebiankeeti kasutajaliidesena oma p√§ringu programmina. See oli seega esimene WWW ressursi avastamise vahend, milles olid liidetud kolm p√µhilist otsingumootori omadust (roomamine, indekseerimine ja otsimine). Kuna platvormil, millel see jooksis, olid piiratud ressursid, piirdus selle indekseerimine ja seega ka otsimine pealkirjadega lehtedega, mida √§mblik oli k√ºlastanud. √úks esimesi t√§isteksti√§mbliku baasil toimivaid otsingumootoreid oli WebCrawler ('veebi√§mblik'), mis tuli v√§lja 1994. aastal. Erinevalt eelk√§ijatest lasi see oma kasutajatel otsida iga s√µna igal veebilehel, mis on sellest ajast saadik muutunud standardiks k√µigile otsingumootoritele. See oli ka √ºks esimesi otsingumootoreid, mis sai tuntuks laiema avalikkuse ees. Peagi loodi veel mitu otsingumootorit, mis konkureerisid omavahel populaarsuse p√§rast. Nende seas olid Magellan, Excite, Infoseek, Inktomi, Northern Light ja AltaVista. Yahoo! oli √ºks populaarsemaid viise inimesi huvitavate veebilehtede leidmiseks, kuid selle otsingufunktsioon toimis enda veebiregistril t√§istekstlehtede koopiate asemel. Info otsijad said vaadata ka registrit otsingus√µnal p√µhineva otsingu asemel. 1996. aastal tahtis Netscape anda √ºhele otsingumootorile eksklusiivse lepingu, millega see muutuks Netscape'i brauseriga kaasasolevaks otsingumootoriks. Huvi selle vastu oli nii suur, et Netscape tegi tehingu viie suurema otsingumootoriga. 5 miljoni dollari eest aastas olid Netscape'i otsingulehel ringluses viis otsimootorit: Yahoo!, Magellan, Lycos, Infoseek ja Excite.[6] Otsingumootoreid peeti ka eredamateks t√§htedeks 1990. aastate l√µpu internetti investeerimise hulluses.[7] Mitmel firmal l√§ks turule sisenemine suurep√§raselt, nad said avalikel pakkumistel rekordilisi tulusid. M√µned v√µtsid maha oma avalikud otsingumootorid ja turustasid ainult ettev√µtetele m√µeldud versioone nagu Northern Light. 2000. aasta paiku t√µusis tippu Google'i otsingumootor. Firma saavutas paremaid tulemusi innovatsiooniga PageRank. See korduv algoritm hindab veebilehti PageRank-numbri alusel. Eeldatakse, et headele ja n√µutud lehtedele lingitakse teistelt veebisaitidelt rohkem kui teistele. Google s√§ilitas oma otsingumootoris ka minimalistliku kasutajaliidese, vastandina mitmetele konkurentidele, kelle otsingumootor oli veebiportaali sisse ehitatud.[viide?] 2000. aastal hakkas Yahoo! kasutama otsingutulemuste saamiseks Google'it. Yahoo! hankis endale Inktomi 2002. ja Overture'i 2003. aastal. 2004 tuli ta v√§lja oma otsingumootoriga, milles olid √ºhendatud Yahoo!-le kuuluvate rakenduste tehnoloogiad.[viide?] Microsoft lasi MSN Searchi v√§lja 1998. aasta s√ºgisel, kasutades Inktomi otsingutulemusi. 1999. aasta alguses hakkas leht n√§itama loetelusid Looksmartist, mis olid kokku segatud tulemustega Inktomist.[viide?] 2004 hakkas Microsoft oma otsingutehnoloogiale √ºle minema.[viide?] Microsofti taasm√§rgistatud otsingumootor Bing avati kasutajatele 1. juunil 2009.[viide?]\n29. juulil l√µpetasid Yahoo! ja Microsoft lepingu, mille kohaselt hakkab Yahoo! Search toimima Microsoft Bingi tehnoloogia baasil.[viide?] Otsingumootor toimib sellises j√§rjekorras: Otsingumootorid toimivad salvestades infot mitmete veebilehtede kohta, mille nad otsivad v√§lja HTML-ist endast. Need lehed leitakse veebi√§mbliku abil ‚Äì see on automatiseeritud veebibrauser, mis j√§rgib igat linki lehel. Erandeid saab teha robots.txt abil. Seej√§rel anal√º√ºsitakse iga lehe sisu, misj√§rel otsustatakse, kuidas seda indekseerida. Andmeid veebilehtede kohta hoitakse indeksi andmebaasides, et kasutada hilisemates p√§ringutes, mis v√µib olla ka √ºhe s√µna pikkune. Indeksi eesm√§rk on lubada info v√µimalikult kiiret leidmist. M√µned otsingumootorid, n√§iteks Google, salvestavad kas k√µik v√µi osa allika lehest ja ka infot veebilehtede kohta. Teised, nagu AltaVista, salvestavad iga s√µna igalt lehelt, mis nad leiavad. Nii salvestatud leht omab tegelikku otsingumootori teksti, sest see oli see, mis tegelikult indekseeriti. Sellest on kasu, kui lehte on uuendatud ja otsingus√µnu pole seal enam n√§ha. Lehtede salvestamine v√µimaldab otsingu suurt t√§psust, sest need v√µivad sisaldada andmeid, mida enam kusagil mujal ei leidu. Kui kasutaja sisestab otsingumootorisse p√§ringu, siis uurib mootor oma indekseid ja tagastab nimekirja parima sobivusega veebilehtedest vastavalt oma sisule, tavaliselt l√ºhikese kokkuv√µttega dokumendi pealkirjast ja m√µnikord l√µiguga tekstist. Indeks ehitatakse √ºles informatsioonist, mis salvestatakse koos andmetega vastavalt info indekseerimismeetodile. Seni pole aga √ºhtegi avalikku otsingumootorit, mis lubaks faile otsida kuup√§eva alusel. Enamik otsingumootoreid toetab konnektorite JAH, V√ïI ja EI kasutamist, et v√µimaldada t√§psema p√§ringu esitamist. Konnektorid lubavad kasutajal muuta ja laiendada otsingutingimusi. Mootorid otsivad s√µnu v√µi fraase t√§pselt nii, nagu need sisestati. M√µned otsingumootorid pakuvad arenenud v√µimalust, mis lubab kasutajal m√§√§rata v√µtmes√µnade vahelist kaugust. On ka ideelisi otsinguid, kus uurimine sisaldab statistilise anal√º√ºsi kasutamist lehtedel, mis sisaldavad s√µnu v√µi fraase, mida otsitakse. Loomuliku keele p√§ringud lubavad kasutajal sisestada k√ºsimuse n√µnda, nagu seda k√ºsitaks teiselt inimeselt, √ºks selline sait on n√§iteks ask.com. Otsingumootori t√µhusus s√µltub otsingutulemuste asjakohasusest. Kuigi teatud s√µna v√µi fraasi sisaldavaid lehek√ºlgi on miljoneid, on m√µned neist asjakohasemad, populaarsemad v√µi usaldusv√§√§rsemad kui teised. Enamik otsingumootoreid kasutab meetmeid tulemuste j√§rjestamiseks, et tuua \"parimad\" tulemused ettepoole. See, kuidas mootorid otsustavad, millised vasted on parimad ja millises j√§rjekorras neid n√§idata, s√µltub mootorist endast. Meetodid muutuvad aja jooksul samamoodi, nagu muutub interneti kasutamine ja tekivad uued tehnikad. P√µhiliselt on olemas kahte t√º√ºpi otsingumootoreid: √ºks on s√ºsteem kindlaksm√§√§ratud ja hierarhiliselt j√§rjestatud otsingus√µnadega, mida on laialdaselt programmeeritud. Teine s√ºsteem loob tagurpidi indeksi, anal√º√ºsides leitavat teksti ning toetub tugevamalt arvutile, mis teeb √§ra suurema osa t√∂√∂st. Enamik otsingumootoreid on √§riprojektid, mis teenivad tulu reklaami m√º√ºgiga. Reklaamiandjad maksavad, et enda lehek√ºlge otsingutulemuste seas k√µrgemale t√µsta. Otsingumootorid, mis tulemusi raha eest ei j√§rjesta, teenivad, n√§idates oma tavatulemuste k√µrval otsingutulemustega seotud reklaame. Otsingumootor teenib raha iga kord, kui keegi avab √ºhe sellise reklaami. Google'i otsingumootori √ºlemaailmne populaarsus j√µudis tippu aprillis 2010, kui saadi k√§tte 86,3% turuosa.[8] Otsingumootorid nagu Yahoo! ja Bing olid populaarsemad Ameerikas kui Euroopas. Hiina Rahvavabariigis oli 2009. aasta juulis 61,6% turust Baidu k√§es.[9] NET MARKETSHARE kohaselt olid veebruaris 2021 otsimootorite turuosad maailmas j√§rgmised: Google 72,68%, Bing 11,94%, Baido 11,72%, Yahoo! 1,81% ja √ºlej√§√§nud j√§id 2% sisse.[10] Kuigi otsingumootorid on programmeeritud reastama veebilehti populaarsuse ja asjakohasuse j√§rgi, on kogemustel p√µhinevast uurimist√∂√∂st n√§ha, et neis leidub poliitilisi, majanduslikke ja sotsiaalseid eelarvamusi[11].[12] Nende eelarvamuste p√µhjuseks v√µivad olla majanduslikud, √§rilised (nt firmad, mis reklaamivad end otsingumootorite abil v√µivad muutuda populaarsemaks loomulikes otsingutulemustes) ja poliitilised (nt otsingu tulemuste kustutamine, et olla vastavuses kohalike seadustega) protsessid.[13] √úheks n√§iteks, kus otsingutulemusi √ºritatakse m√µjutada poliitilistel, sotsiaalsetel v√µi √§rilistel p√µhjustel, on \"Google Bombing\". Veebi√§mblik on robotprogramm, mis otsib veebis kindla ja korrap√§rase meetodiga uusi veebidokumente ja lisab leitud tulemused andmebaasidesse. Nimetuse on programm saanud selle j√§rgi, et see ronib veebis ringi, nii nagu √§mblik oma v√µrgul. Paljud otsingumootorite saidid kasutavad veebi√§mblikke, et tagada uusima info n√§itamine otsingutulemustes.\nKiirete otsingutulemuste saamiseks kasutatakse veebi√§mblikke, mis teevad k√ºlastatud lehtedest koopia, mida saab hiljem t√∂√∂delda.\n√Ñmblikke v√µib kasutada veebilehtedel automaatseteks hooldust√∂√∂deks nagu linkide kontrollimine v√µi HTML-koodi kinnitamine.\nLisaks v√µib neid kasutada ka veebilehtedelt kindla info leidmiseks, n√§iteks kogutakse e-posti aadresse r√§mpsposti saatmise eesm√§rgil. Veebi√§mblikel on alguses nimekiri URL-idest, mida nad peavad k√ºlastama. Iga kord, kui ta k√ºlastab √ºhte URL-i, tuvastab see k√µik lehel olevad h√ºperlingid ja lisab need oma URL-ide nimekirja. K√µiki linke k√ºlastatakse kindlate reeglite j√§rgi ja veebi√§mbliku k√§itumine oleneb nende reeglite koosk√µlast:[14]"
  },
  {
    "url": "https://es.wikipedia.org/wiki/Motor_de_b%C3%BAsqueda",
    "title": "Motor de b√∫squeda - Wikipedia, la enciclopedia libre",
    "content": "Un motor de b√∫squeda o buscador es un sistema inform√°tico que busca archivos almacenados en servidores web gracias a su ara√±a web.[1]‚Äã Un ejemplo son los buscadores de Internet (algunos buscan √∫nicamente en la web, pero otros lo hacen adem√°s en noticias, servicios como Gopher, FTP, etc.) cuando se pide informaci√≥n sobre alg√∫n tema. Las b√∫squedas se hacen con palabras clave o con √°rboles jer√°rquicos por temas; el resultado de la b√∫squeda ¬´P√°gina de resultados del buscador¬ª es un listado de direcciones web en los que se mencionan temas relacionados con las palabras clave buscadas. Como operan de forma autom√°tica, los motores de b√∫squeda contienen generalmente m√°s informaci√≥n que los directorios web. Sin embargo, estos √∫ltimos tambi√©n han de construirse a partir de b√∫squedas (no automatizadas) o bien a partir de avisos dados por los creadores de p√°ginas. Se pueden clasificar en tres tipos: Un rastreador web, indexador web, indizador web o ara√±a web es un programa inform√°tico que inspecciona las p√°ginas del World Wide Web de forma met√≥dica y automatizada.[2]‚Äã Uno de los usos m√°s frecuentes que se les da consiste en crear una copia de todas las p√°ginas web visitadas para su procesado posterior por un motor de b√∫squeda que indexa las p√°ginas proporcionando un sistema de b√∫squedas r√°pido. Las ara√±as web suelen ser bots.[3]‚Äã Las ara√±as web comienzan visitando una lista de URL, identifica los hiperenlaces en dichas p√°ginas y los a√±ade a la lista de URL a visitar de manera recurrente de acuerdo a determinado conjunto de reglas. La operaci√≥n normal es que se le da al programa un grupo de direcciones iniciales, la ara√±a descarga estas direcciones, analiza las p√°ginas y busca enlaces a p√°ginas nuevas. Luego descarga estas p√°ginas nuevas, analiza sus enlaces, y as√≠ sucesivamente. Entre las tareas m√°s comunes de las ara√±as de la web tenemos: Una tecnolog√≠a muy simple por gran cantidad de scripts disponibles, ya que no se requieren muchos recursos. En cambio, se requiere m√°s soporte humano y mantenimiento.[5]‚Äã Un metabuscador es un sistema que localiza informaci√≥n en los motores de b√∫squeda m√°s usados, carece de base de datos propia, por lo que usa las de otros buscadores y muestra una combinaci√≥n de las mejores p√°ginas que ha devuelto cada uno,[6]‚Äã de una sola vez y desde un solo punto.[7]‚Äã ¬´En otras palabras para aludir al concepto m√°s gen√©rico de un buscador, podemos afirmar que un metabuscador es el buscador que incorpora un conjunto de buscadores. Algunos ejemplos de metabuscadores son: Dogpile, Aleyares[9]‚Äã[10]‚Äã MetaCrawler, entre otros. Estos metabuscadores presentan ventajas, como ampliar el espacio de b√∫squeda y en algunos casos mostrar la posici√≥n de la web¬ª.[11]‚Äã En 1945, Vannevar Bush , quien escribi√≥ un art√≠culo en  The Atlantic Monthly titulado As We May Think[13]‚Äã en el que imagin√≥ bibliotecas de investigaci√≥n con anotaciones conectadas no muy diferentes a los hiperenlaces modernos.[14]‚Äã El an√°lisis de enlaces finalmente se convertir√≠a en un componente crucial de los motores de b√∫squeda a trav√©s de algoritmos como Hyper Search y PageRank.[15]‚Äã[16]‚Äã Los primeros motores de b√∫squeda de Internet son anteriores al debut de la Web en diciembre de 1990: la b√∫squeda de usuarios de WHOIS se remonta a 1982,[17]‚Äã y la b√∫squeda de usuarios de redes m√∫ltiples del Knowbot Information Service se implement√≥ por primera vez en 1989.[18]‚Äã La primera b√∫squeda bien documentada El motor que buscaba archivos de contenido, a saber, archivos FTP, era Archie, que debut√≥ el 10 de septiembre de 1990.[19]‚Äã Antes de septiembre de 1993, la World Wide Web se indexaba completamente a mano. Hab√≠a una lista de servidores web editada por Tim Berners-Lee y alojada en el servidor web del CERN. Queda una instant√°nea de la lista en 1992,[20]‚Äã pero a medida que m√°s y m√°s servidores web se pusieron en l√≠nea, la lista central ya no pudo mantenerse al d√≠a. En el sitio de la NCSA, se anunciaron nuevos servidores bajo el t√≠tulo What's New!.[21]‚Äã La primera herramienta utilizada para buscar contenido (a diferencia de usuarios) en Internet fue Archie.[22]‚Äã El nombre significa \"archivo\" sin la \"v\",[23]‚Äã Fue creado por Alan Emtage[23]‚Äã[24]‚Äã[25]‚Äã[26]‚Äã estudiante de inform√°tica en la Universidad McGill en Montreal, Quebec, Canad√° . El programa descarg√≥ las listas de directorios de todos los archivos ubicados en sitios p√∫blicos an√≥nimos de FTP (Protocolo de transferencia de archivos), creando una base de datos de b√∫squeda de nombres de archivos; sin embargo, Archie Search Engineno index√≥ el contenido de estos sitios ya que la cantidad de datos era tan limitada que se pod√≠a buscar f√°cilmente de forma manual. El auge de Gopher (creado en 1991 por Mark McCahill en la Universidad de Minnesota) dio lugar a dos nuevos programas de b√∫squeda, Veronica y Jughead. Al igual que Archie, buscaron los nombres y t√≠tulos de los archivos almacenados en los sistemas de √≠ndice Gopher. Veronica (Very Easy Rodent - Oriented Net-wide Index to Computerized Archives) proporcion√≥ una b√∫squeda de palabras clave de la mayor√≠a de los t√≠tulos de men√∫ de Gopher en todos los listados de Gopher. Jughead (Jonzy 's Universal Gopher Hierarchy Excavation And Display) era una herramienta para obtener informaci√≥n de men√∫ de servidores Gopher espec√≠ficos. Si bien el nombre del motor de b√∫squeda \"Archie Search Engine\" no era una referencia a la serie de c√≥mics de Archie, Veronica y Jughead son personajes de la serie, haciendo as√≠ referencia a su predecesor. En el verano de 1993 no exist√≠a ning√∫n motor de b√∫squeda para la web, aunque se manten√≠an a mano numerosos cat√°logos especializados. Oscar Nierstrasz de la Universidad de Ginebra escribi√≥ una serie de secuencias de comandos de Perl que reflejaban peri√≥dicamente estas p√°ginas y las reescrib√≠an en un formato est√°ndar. Esto form√≥ la base de W3Catalog , el primer motor de b√∫squeda primitivo de la web, lanzado el 2 de septiembre de 1993.[27]‚Äã En junio de 1993, Matthew Gray,[28]‚Äã entonces en el MIT, produjo lo que probablemente fue el primer robot web, el World Wide Web Wanderer basado en Perl , y lo us√≥ para generar un √≠ndice llamado Wandex. El prop√≥sito de Wanderer era medir el tama√±o de la World Wide Web, lo que hizo hasta fines de 1995. El segundo motor de b√∫squeda de la web, Aliweb, apareci√≥ en noviembre de 1993. Aliweb no usaba un robot web sino que depend√≠a de ser notificado por administradores del sitio web de la existencia en cada sitio de un archivo √≠ndice en un formato particular. JumpStation (creada en diciembre de 1993[29]‚Äã por Jonathon Fletcher) us√≥ un robot web para encontrar p√°ginas web y construir su √≠ndice, y us√≥ un formulario web como interfaz para su programa de consulta. Por lo tanto, fue la primera herramienta de descubrimiento de recursos WWW que combin√≥ las tres caracter√≠sticas esenciales de un motor de b√∫squeda web (rastreo, indexaci√≥n y b√∫squeda) como se describe a continuaci√≥n. Debido a los recursos limitados disponibles en la plataforma en la que se ejecutaba, su indexaci√≥n y, por lo tanto, las b√∫squedas se limitaban a los t√≠tulos y encabezados que se encontraban en las p√°ginas web que encontraba el rastreador. El primer buscador fue Wandex, un √≠ndice realizado por el World Wide Web Wanderer, un robot desarrollado por Mattew Gray en el MIT, en 1993. Otro de los primeros buscadores, Aliweb, tambi√©n apareci√≥ en 1993 y todav√≠a est√° en funcionamiento. El primer motor de b√∫squeda de texto completo fue WebCrawler, que apareci√≥ en 1994. A diferencia de sus predecesores, este permit√≠a a sus usuarios una b√∫squeda por palabras en cualquier p√°gina web, lo que lleg√≥ a ser un est√°ndar para la gran mayor√≠a de los buscadores. WebCrawler fue asimismo el primero en darse a conocer ampliamente entre el p√∫blico. Tambi√©n apareci√≥ en 1994 Lycos (que comenz√≥ en la Carnegie Mellon University). Muy pronto aparecieron muchos m√°s buscadores, como Excite, Infoseek, Inktomi, Northern Light y Altavista. De alg√∫n modo, compet√≠an con directorios (o √≠ndices tem√°ticos) populares tales como Yahoo!. M√°s tarde, los directorios se integraron o se a√±adieron a la tecnolog√≠a de los buscadores para aumentar su funcionalidad. Antes del advenimiento de la Web, hab√≠a motores de b√∫squeda para otros protocolos o usos, como el buscador Archie, para sitios FTP an√≥nimos y el motor de b√∫squeda Ver√≥nica, para el protocolo Gopher. En 1996 Larry Page y Sergey Brin comenzaron un proyecto que llevar√≠a a la aparici√≥n del buscador m√°s utilizado hoy en d√≠a: Google. El proyecto inicial se llam√≥ BackRub,[30]‚Äã que era el nombre de la tecnolog√≠a utilizada para su desarrollo. BackRub basaba la importancia de los sitios web en la cantidad de enlaces que recib√≠a. Presentaba una interfaz muy sencilla y capaz de mostrar al usuario los resultados m√°s relevantes para cada una de las b√∫squedas. Con la llegada de Google, el modo en que los motores de b√∫squeda funcionaban cambi√≥ de forma radical, democratizando los resultados que se ofrecen en su buscador. Google bas√≥ el funcionamiento de su motor de b√∫squeda en la relevancia de los contenidos de cada sitio web para los propios usuarios, es decir, priorizando aquellos resultados que los usuarios consideraban m√°s relevantes para una tem√°tica concreta. Para ello patent√≥ su famoso PageRank, un conjunto de algoritmos que valoraban la relevancia de un sitio web asign√°ndole un valor num√©rico del 0 al 10. En la mayor√≠a de pa√≠ses Google.com o la versi√≥n de Google para el pa√≠s concreto, es el buscador m√°s utilizado, sin embargo, esto no ocurre en algunos pa√≠ses. Por ejemplo, en Rusia el buscador m√°s utilizado es Yandex.ru[31]‚Äã[32]‚Äã y en China es Baidu.[33]‚Äã Conforme ha ido pasando el tiempo, miles de buscadores han ido naciendo y muriendo, entre los que podemos mencionar: Ver m√°s informaci√≥n sobre esto en el Anexo:Motores de b√∫squeda Alrededor de 2000, el motor de b√∫squeda de  Google salt√≥ a la fama.[34]‚Äã La empresa logr√≥ mejores resultados para muchas b√∫squedas con un algoritmo llamado PageRank, como se explic√≥ en el art√≠culo Anatom√≠a de un motor de b√∫squeda escrito por Sergey Brin y Larry Page , los fundadores posteriores de Google.[16]‚Äã Este algoritmo iterativo clasifica las p√°ginas web seg√∫n el n√∫mero y el PageRank de otros sitios web y p√°ginas que enlazan all√≠, con la premisa de que las p√°ginas buenas o deseables est√°n enlazadas a m√°s que otras. La patente de Larry Page para PageRank cita la patente anterior de RankDex de Robin Li como una influencia. Google tambi√©n mantuvo una interfaz minimalista para su motor de b√∫squeda. En cambio, muchos de sus competidores incrustaron un motor de b√∫squeda en un portal web. De hecho, el motor de b√∫squeda de Google se hizo tan popular que surgieron motores falsos como Mystery Seeker. Para el a√±o 2000, Yahoo! proporcionaba servicios de b√∫squeda basados en el motor de b√∫squeda de Inktomi. Yahoo! adquiri√≥ Inktomi en 2002 y Overture (propietaria de AlltheWeb y AltaVista) en 2003. Yahoo! cambi√≥ al motor de b√∫squeda de Google hasta 2004, cuando lanz√≥ su propio motor de b√∫squeda basado en las tecnolog√≠as combinadas de sus adquisiciones. Microsoft lanz√≥ por primera vez MSN Search en el oto√±o de 1998 utilizando los resultados de b√∫squeda de Inktomi. A principios de 1999, el sitio comenz√≥ a mostrar listados de Looksmart, combinados con los resultados de Inktomi. Durante un breve per√≠odo de tiempo en 1999, MSN Search utiliz√≥ en su lugar los resultados de AltaVista. En 2004, Microsoft inici√≥ una transici√≥n hacia su propia tecnolog√≠a de b√∫squeda, impulsada por su propio rastreador web (llamado msnbot). El motor de b√∫squeda renombrado de Microsoft, Bing, se lanz√≥ el 1 de junio de 2009. El 29 de julio de 2009, Yahoo! y Microsoft cerraron un trato en el que Yahoo! la b√∫squeda estar√≠a impulsada por la tecnolog√≠a Microsoft Bing. A partir de 2019, los rastreadores de motores de b√∫squeda activos incluyen los de Google, Petal, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo y Yandex. Aunque los motores de b√∫squeda est√°n programados para clasificar sitios web en funci√≥n de una combinaci√≥n de su popularidad y relevancia, los estudios emp√≠ricos indican varios sesgos pol√≠ticos, econ√≥micos y sociales en la informaci√≥n que proporcionan[35]‚Äã[36]‚Äã y las suposiciones subyacentes sobre la tecnolog√≠a.[37]‚Äã Estos sesgos pueden ser el resultado directo de procesos econ√≥micos y comerciales (p. ej., las empresas que anuncian con un motor de b√∫squeda tambi√©n pueden volverse m√°s populares en sus resultados de b√∫squeda org√°nicos) y procesos pol√≠ticos (p. ej., la eliminaci√≥n de resultados de b√∫squeda para cumplir con las leyes locales).[38]‚Äã Por ejemplo, Google no mostrar√° ciertos sitios web neonazis en Francia y Alemania, donde la negaci√≥n del Holocausto es ilegal. Los sesgos tambi√©n pueden ser el resultado de procesos sociales, ya que los algoritmos de los motores de b√∫squeda suelen estar dise√±ados para excluir puntos de vista no normativos en favor de resultados m√°s populares.[39]‚Äã Los algoritmos de indexaci√≥n de los principales motores de b√∫squeda se inclinan hacia la cobertura de sitios basados en los EE. UU., en lugar de sitios web de pa√≠ses fuera de los EE. UU.[36]‚Äã Google Bombing es un ejemplo de un intento de manipular los resultados de b√∫squeda por motivos pol√≠ticos, sociales o comerciales. Varios acad√©micos han estudiado los cambios culturales desencadenados por los motores de b√∫squeda,[40]‚Äã y la representaci√≥n de ciertos temas controvertidos en sus resultados, como el terrorismo en Irlanda,[41]‚Äã la negaci√≥n del cambio clim√°tico,[42]‚Äã y las  teor√≠as de la conspiraci√≥n.[43]‚Äã Muchos motores de b√∫squeda como Google y Bing brindan resultados personalizados basados en el historial de actividad del usuario. Esto conduce a un efecto que se ha denominado filtro burbuja. El t√©rmino describe un fen√≥meno en el que los sitios web usan algoritmos para adivinar selectivamente qu√© informaci√≥n le gustar√≠a ver a un usuario, en funci√≥n de la informaci√≥n sobre el usuario (como la ubicaci√≥n, el comportamiento de clics anterior y el historial de b√∫squeda). Como resultado, los sitios web tienden a mostrar solo informaci√≥n que concuerda con el punto de vista anterior del usuario. Esto pone al usuario en un estado de aislamiento intelectual sin informaci√≥n contraria. Los principales ejemplos son los resultados de b√∫squeda personalizados de Google y el flujo de noticias personalizado de Facebook. Seg√∫n Eli Pariser, quien acu√±√≥ el t√©rmino, los usuarios est√°n menos expuestos a puntos de vista conflictivos y est√°n aislados intelectualmente en su propia burbuja informativa. Pariser relat√≥ un ejemplo en el que un usuario busc√≥ en Google \"BP\" y obtuvo noticias de inversi√≥n sobre British Petroleum , mientras que otro buscador obtuvo informaci√≥n sobre el derrame de petr√≥leo de Deepwater Horizon y que las dos p√°ginas de resultados de b√∫squeda eran \"sorprendentemente diferentes\".[44]‚Äã[45]‚Äã[46]‚Äã El efecto burbuja puede tener implicaciones negativas para el discurso c√≠vico, seg√∫n Pariser.[47]‚Äã Desde que se identific√≥ este problema, han surgido motores de b√∫squeda de la competencia que buscan evitar este problema al no rastrear o \"burbujear\" a los usuarios, como DuckDuckGo. Otros acad√©micos no comparten el punto de vista de Pariser y consideran que la evidencia en apoyo de su tesis no es convincente.[48]‚Äã El env√≠o de un motor de b√∫squeda web es un proceso en el que un webmaster env√≠a un sitio web directamente a un motor de b√∫squeda. Si bien el env√≠o a los motores de b√∫squeda a veces se presenta como una forma de promocionar un sitio web, generalmente no es necesario porque los principales motores de b√∫squeda utilizan rastreadores web que finalmente encontrar√°n la mayor√≠a de los sitios web en Internet sin ayuda. Pueden enviar una p√°gina web a la vez o pueden enviar todo el sitio usando un mapa del sitio , pero normalmente solo es necesario enviar la p√°gina de inicio.de un sitio web ya que los motores de b√∫squeda pueden rastrear un sitio web bien dise√±ado. Quedan dos razones para enviar un sitio web o una p√°gina web a un motor de b√∫squeda: agregar un sitio web completamente nuevo sin esperar a que un motor de b√∫squeda lo descubra y actualizar el registro de un sitio web despu√©s de un redise√±o sustancial. Algunos programas de env√≠o de motores de b√∫squeda no solo env√≠an sitios web a m√∫ltiples motores de b√∫squeda, sino que tambi√©n agregan enlaces a sitios web desde sus propias p√°ginas. Esto podr√≠a parecer √∫til para aumentar la clasificaci√≥n de un sitio web,[49]‚Äã ya que los enlaces externos son uno de los factores m√°s importantes que determinan la clasificaci√≥n de un sitio web. Sin embargo, John Mueller de Google ha declarado que esto \"puede dar lugar a una gran cantidad de enlaces no naturales para su sitio\" con un impacto negativo en la clasificaci√≥n del sitio.[50]‚Äã"
  },
  {
    "url": "https://eo.wikipedia.org/wiki/Interreta_ser%C4%89ilo",
    "title": "Serƒâilo - Vikipedio",
    "content": "Serƒâilo estas programo, kiun oni uzas por serƒâi informojn en komputila sistemo kiel la Interreto. Kun serƒâilo, oni povas trovi informon pri la≈≠vola temo. Oni tajpas la temon en formo de vortoj a≈≠ frazeto. La serƒâilo respondos kun listo de dokumentoj, kiuj (normale) koncernas la temon. La plej ofta serƒâo per serƒâilo estas por TTT-paƒùoj. Tamen, serƒâoj en serƒâilo ne estas limigita al nuraj TTT-paƒùoj. Oni povas serƒâi bildojn, novaƒµgrupajn artikolojn, telefonnumerojn, mapojn, kaj aliajn dokumentojn. Serƒâilo malsimilas al interreta katalogo per tio, ke katalogo estas ƒùisdatigata per homaj redaktistoj, sed serƒâilo estas ƒùisdatigata per komputila algoritmo. Sten Johansson en sia eseo Uzi interreton kiel tekstaron por lingvaj esploroj [2005][1] klarigas kiel li uzis interretajn rimedojn, precipe serƒâilojn kaj la disponeblon de la Tekstaro de Esperanto (versioj kaj de anta≈≠ kaj de post 1940) por studi kiuj vortoj, kombinoj kaj gramatikaj formoj estas uzataj, kaj la≈≠ kiu ofteco. La eseisto komparas la rezultojn de serƒâiloj en 2002 kaj 2004. Anta≈≠ ƒâio la a≈≠toro avertas pri dek limigoj kiuj relativigas la trovitajn rezultojn, inter kiuj: Krom precizaj ekzemploj, li dediƒâas partan atenton al klasikaj diskutoj. Ekzemple pri la nomitaj mal-vortoj, li konkludas ke inter \"venkintaj\" kazoj estus humida kontra≈≠ malseketa, stulta kontra≈≠ malsaƒùa kaj ƒâefe malsprita, kvereli kontra≈≠ malpaci, strikta kontra≈≠ malvasta, dum inter nesukcesintaj estus povra super kiu ankora≈≠ hegemonias malriƒâa a≈≠ eƒâ kompatinda, leƒùera super kiu ankora≈≠ hegemonias malpeza, frida super kiu ankora≈≠ hegemonias malvarma, a≈≠ olda super kiu ankora≈≠ hegemonias maljuna kaj malnova. Pri la polemiko inter landnomoj, la komparo inter diversaj epokoj konfirmas la venkon de landonomoj kun finaƒµo -io super finaƒµo -ujo (ƒâiam en la interreta etoso kaj ne nepre en aliaj), la partikularan venkon de Barato super Hindio, kaj la retenon de la finaƒµo -ujo ƒâe Esperantujo kaj ƒâe antikvaj landoj kiaj Egiptujo anta≈≠ Egipto por la nuna ≈ùtato, a≈≠ ƒàinujo anta≈≠ ƒàinio. Pri la litero ƒ• la komparoj faritaj en 2004 konstatas, ke ƒùi pluhegemonias nur en kelkaj vortoj kiaj ƒ§arkovo, monaƒ•ejo, ƒ•imero a≈≠ jaƒ•to kontra≈≠ la respektivaj korespondoj kun litero k, dum tiuj klare venkas en kirurgo, kameleono, mekanika, kemio, arkaika, anarkio, tekniko kaj ƒâefe arkitekturo kun 90¬†%; same anka≈≠ en la Tekstaro   hegemoniis monaƒ•ejo kaj ƒ•aoso, dum anka≈≠ tekniko. Pri la elekto inter kiel kaj kiom por indiki gradon, oni konstatas ke ƒâe \"adjektivoj kaj adverboj mezureblaj oni pli ofte uzas tiom. ƒàe la vortoj multe kaj malmulte oni eƒâ preferas tiom. ƒàe nemezureblaj ecoj kiel bela, bona kaj feliƒâa oni plej ofte preferas esprimi gradon per tiel.\"[2] El la falsaj korelativoj formitaj el radiko ali- oni konstatas ke nur estas iomete uzata alies, kiu relative malkreskas. Oni konstatas malgrandan uzon de vorto gepatro en singularo, de finaƒµo -ika anstata≈≠ -a precipe ƒâe ekzotika a≈≠ erotika kaj nedisputeble ƒâe mekanika, de finaƒµo -acio anstata≈≠ -o ƒâefe en civilizacio a≈≠ konversacio, sed ne en ina≈≠guro. Oni konfirmas anka≈≠ la finan venkon de modernaj vortoj kiaj komputilo, aidoso, retpo≈ùto, po≈ùtelefono, hamburgero, fritoj, kolao kaj ƒùinzo."
  },
  {
    "url": "https://eu.wikipedia.org/wiki/Web_bilaketa_motore",
    "title": "Web bilaketa motore - Wikipedia, entziklopedia askea.",
    "content": "Bilaketa-tresna edo bilatzailea bere web armiarmari esker web zerbitzarietan gordetako fitxategiak bilatzen dituen sistema informatikoa da.  Adibide bat Interneteko bilatzaileak dira (batzuek sarean bakarrik bilatzen dute, baina beste batzuek albisteak, Gopher bezalako zerbitzuak, FTP, etab.) gai bati buruzko informazioa eskatzen dugunean. Bilaketak gako-hitzekin edo zuhaitz hierarkikoekin egiten dira gaika; bilaketaren emaitza ¬´Bilaketa-emaitzen orria¬ª web-helbideen zerrenda bat da, non bilatutako gako-hitzekin lotutako gaiak aipatzen diren. Automatikoki funtzionatzen dutenez, bilatzaileek, oro har, web direktorioek baino informazio gehiago dute. Hala ere, azken horiek bilaketetatik (ez automatizatuak) edo orrialde sortzaileek emandako oharretatik ere eraiki behar dira."
  },
  {
    "url": "https://fa.wikipedia.org/wiki/%D9%85%D9%88%D8%AA%D9%88%D8%B1_%D8%AC%D8%B3%D8%AA%D8%AC%D9%88%DB%8C_%D9%88%D8%A8",
    "title": "ŸÖŸàÿ™Ÿàÿ± ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å Ÿàÿ® - Ÿà€å⁄©€å‚ÄåŸæÿØ€åÿßÿå ÿØÿßŸÜÿ¥ŸÜÿßŸÖŸáŸî ÿ¢ÿ≤ÿßÿØ",
    "content": "ŸÖŸàÿ™Ÿàÿ± ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å Ÿàÿ® €åÿß ÿ¨Ÿà€åÿ¥⁄Øÿ± (ÿ®Ÿá ÿßŸÜ⁄ØŸÑ€åÿ≥€å: Web search engine) ŸÖŸàÿ™Ÿàÿ± ÿ¨ÿ≥ÿ™ÿ¨Ÿà Ÿà ÿßÿ®ÿ≤ÿßÿ±€å ÿßÿ≥ÿ™ ⁄©Ÿá ÿ®Ÿá ŸÖŸÜÿ∏Ÿàÿ± ÿ¨Ÿèÿ≥ÿ™ÿ¨Ÿà ÿØÿ± Ÿàÿ® ÿ®ÿ±ÿß€å ÿ®Ÿá‚ÄåÿØÿ≥ÿ™ ÿ¢Ÿàÿ±ÿØŸÜ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿØÿ±ÿÆŸàÿßÿ≥ÿ™ ÿ¥ÿØŸáÿå ÿ®Ÿá ⁄©ÿßÿ± ŸÖ€å‚Äåÿ±ŸàÿØ. ŸÜÿ™ÿß€åÿ¨ €åÿßŸÅÿ™Ÿá ÿ¥ÿØŸá ÿ®Ÿá‚Äåÿ∑Ÿàÿ± ŸÖÿπŸÖŸàŸÑ ÿØÿ± ÿµŸÅÿ≠Ÿá‚Äåÿß€å ÿ®ÿß ÿπŸÜŸàÿßŸÜ ÿµŸÅÿ≠ŸáŸî ŸÜÿ™ÿß€åÿ¨ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÅŸáÿ±ÿ≥ÿ™ ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ.[€≥] ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ⁄©ŸÑŸÖŸáŸî ⁄©ŸÑ€åÿØ€å (⁄©ŸÑ€åÿØŸàÿß⁄òŸá) ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ ÿ™Ÿàÿ∂€åÿ≠€å ÿßÿ≥ÿ™ ⁄©Ÿàÿ™ÿßŸá ÿØÿ±ÿ®ÿßÿ±ŸáŸî ÿ¢ŸÜ⁄ÜŸá ŸÑÿßÿ≤ŸÖ ÿßÿ≥ÿ™ ÿØÿ± ÿß€åŸÜÿ™ÿ±ŸÜÿ™ Ÿæ€åÿØÿß ÿ¥ŸàÿØÿå ⁄©ŸÑŸÖŸá ⁄©ŸÑ€åÿØ€å ÿ®ÿß€åÿØ ÿ™ÿß ÿ¢ŸÜÿ¨ÿß ⁄©Ÿá ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ⁄©Ÿàÿ™ÿßŸáÿå ÿ¨ÿ≤ÿ¶€åÿå ŸÇÿßÿ®ŸÑ ŸÅŸáŸÖ Ÿà ÿØŸÇ€åŸÇ ÿ®ÿßÿ¥ÿØ. ÿ®Ÿá ÿ∫€åÿ± ÿßÿ≤ Ÿàÿßÿ±ÿØ ⁄©ÿ±ÿØŸÜ ⁄©ŸÑŸÖŸáŸî ŸÖÿ≥ÿ™ŸÇ€åŸÖÿå ŸÖ€å‚Äåÿ™ŸàÿßŸÜ ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿπŸÖŸÑ⁄Øÿ±Ÿáÿß€å€å ÿπŸÖŸÑ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ±ÿß ÿØŸÇ€åŸÇ‚Äåÿ™ÿ± Ÿà ŸÖŸÜÿ∏ŸÖ‚Äåÿ™ÿ± ÿßŸÜÿ¨ÿßŸÖ ÿØÿßÿØ.[€¥][€µ][€∂] ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å Ÿàÿ® ÿ®ÿ±ÿß€å ÿ¢ŸÜ⁄©Ÿá ÿ®ÿ™ŸàÿßŸÜŸÜÿØ ÿ®Ÿá ÿØÿ±ÿÆŸàÿßÿ≥ÿ™‚ÄåŸáÿß Ÿà ÿ¨ÿ≥ÿ™ÿ¨ŸàŸáÿß€å ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ Ÿæÿßÿ≥ÿÆ ŸÖŸÜÿßÿ≥ÿ®€å ÿ®ÿØŸáŸÜÿØ ÿ®ÿß€åÿØ ÿÆÿ≤€åÿØŸÜ ÿØÿ± Ÿàÿ®‚Äåÿ≥ÿß€åÿ™‚ÄåŸáÿß Ÿà ÿß€åŸÜÿØ⁄©ÿ≥ ⁄©ÿ±ÿØŸÜ ÿµŸÅÿ≠ÿßÿ™ ÿ±ÿß ÿßŸÜÿ¨ÿßŸÖ ÿØŸáŸÜÿØ.[€∑]\nŸàÿ∏€åŸÅŸá ÿßÿµŸÑ€å ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿß€åŸÜ ÿßÿ≥ÿ™ ⁄©Ÿá ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÜÿ™€åÿ¨Ÿá ÿ±ÿß ÿ®Ÿá ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ⁄©ÿßÿ±ÿ®ÿ± ÿßÿ±ÿßÿ¶Ÿá ÿØŸáŸÜÿØ. ŸáŸÜ⁄ØÿßŸÖ€å ⁄©Ÿá ⁄©ÿßÿ±ÿ®ÿ± €å⁄© Ÿæÿ±ÿ≥ Ÿà ÿ¨Ÿà ÿ±ÿß ÿØÿ± ŸÖŸàÿ™Ÿàÿ± ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿßŸÜÿ¨ÿßŸÖ ŸÖ€å‚ÄåÿØŸáÿØÿå ÿµŸÅÿ≠Ÿá ŸÜÿ™ÿß€åÿ¨ ŸÖŸàÿ™Ÿàÿ± ÿ¨ÿ≥ÿ™ÿ¨Ÿà (SERP) ⁄©Ÿá ÿ≠ÿßŸà€å ŸÜÿ™ÿß€åÿ¨ ÿßÿ≥ÿ™ ÿ®Ÿá ⁄©ÿßÿ±ÿ®ÿ± ŸÜŸÖÿß€åÿ¥ ÿØÿßÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØ. ŸÜÿ™ÿß€åÿ¨ €åÿßŸÅÿ™ ÿ¥ÿØŸá ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿ®ÿß Ÿæÿ±ÿ≥ Ÿà ÿ¨Ÿà€å ⁄©ÿßÿ±ÿ®ÿ± ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ. ŸÜÿ≠ŸàŸá ÿßŸÜÿ¨ÿßŸÖ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ÿØÿ± ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖÿ™ŸÅÿßŸàÿ™ ÿßÿ≥ÿ™. ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖÿ´ŸÑ ⁄ØŸà⁄ØŸÑÿå ŸÖÿØÿßŸÖ ÿßŸÑ⁄ØŸàÿ±€åÿ™ŸÖ‚ÄåŸáÿß€å ÿÆŸàÿØ ÿ±ÿß ÿ™ÿ∫€å€åÿ± ŸÖ€å‚ÄåÿØŸáŸÜÿØ Ÿà ÿ®ÿ±Ÿàÿ≤ ŸÖ€å‚Äå⁄©ŸÜŸÜÿØ ÿ™ÿß ÿ™ÿ¨ÿ±ÿ®Ÿá ⁄©ÿßÿ±ÿ®ÿ± ÿßÿ≤ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ±ÿß ÿ®Ÿáÿ®ŸàÿØ ÿ®ÿÆÿ¥ŸÜÿØ. ŸáÿØŸÅ ÿ¢ŸÜŸáÿß ÿß€åŸÜ ÿßÿ≥ÿ™ ⁄©Ÿá ÿßÿ®ÿ™ÿØÿß ÿØÿ±⁄© ⁄©ŸÜŸÜÿØ ⁄Ü⁄ØŸàŸÜŸá ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖ€å‚Äå⁄©ŸÜŸÜÿØ Ÿà ⁄ÜŸá ⁄Ü€åÿ≤€å ÿ±ÿß ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖ€å‚Äå⁄©ŸÜŸÜÿØ Ÿà ÿ≥Ÿæÿ≥ ÿ®Ÿá ÿ¢ŸÜŸáÿß ÿ®Ÿáÿ™ÿ±€åŸÜ Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß ÿ±ÿß ŸÜŸÖÿß€åÿ¥ ÿØŸáŸÜÿØ. [€∏] ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿÆÿ≤ŸÜÿØŸá‚ÄåŸáÿß€å ÿÆŸàÿØ ŸÖ€å‚Äåÿ™ŸàÿßŸÜŸÜÿØ ÿ™ŸÖÿßŸÖ€å ÿµŸÅÿ≠ÿßÿ™ Ÿà ŸÅÿß€åŸÑ‚ÄåŸáÿß€å ŸÖŸàÿ¨ŸàÿØ ÿØÿ± Ÿàÿ® ÿ±ÿß ÿß€åŸÜÿØ⁄©ÿ≥ ⁄©ŸÜŸÜÿØ. ÿß€åŸÜ ÿÆÿ≤ŸÜÿØŸá‚ÄåŸáÿß ÿ®ÿß Ÿàÿ±ŸàÿØ ÿ®Ÿá Ÿáÿ± ÿµŸÅÿ≠Ÿá ÿ®Ÿá ÿØŸÜÿ®ÿßŸÑ ŸÑ€åŸÜ⁄©‚ÄåŸáÿß Ÿáÿ≥ÿ™ŸÜÿØ ÿ™ÿß ÿ®ÿß ÿØŸÜÿ®ÿßŸÑ ⁄©ÿ±ÿØŸÜ ÿ¢ŸÜ‚ÄåŸáÿß Ÿàÿßÿ±ÿØ ÿµŸÅÿ≠ÿßÿ™ ÿ¨ÿØ€åÿØ ÿ¥ŸàŸÜÿØ. ÿ®ÿß ÿß€åŸÜ ÿ±Ÿàÿ¥ÿå ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖ€å‚Äåÿ™ŸàÿßŸÜŸÜÿØ ÿ™ŸÖÿßŸÖ€å ÿµŸÅÿ≠ÿßÿ™ ŸÖŸàÿ¨ŸàÿØ ÿØÿ± Ÿàÿ® ÿ±ÿß ÿß€åŸÜÿØ⁄©ÿ≥ ⁄©ŸÜŸÜÿØ.[€π][€±€∞] ÿßÿµŸÑ€å‚Äåÿ™ÿ±€åŸÜ Ÿàÿ∏€åŸÅŸá ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å Ÿàÿ®ÿå ÿßÿ±ÿßÿ¶Ÿá ÿ®Ÿáÿ™ÿ±€åŸÜ Ÿà ŸÖÿ±ÿ™ÿ®ÿ∑‚Äåÿ™ÿ±€åŸÜ ŸÜÿ™ÿß€åÿ¨ ÿ®Ÿá ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿßÿ≥ÿ™. ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ®ÿ±ÿß€å ÿ¢ŸÜ⁄©Ÿá ÿ®ÿ™ŸàÿßŸÜŸÜÿØ ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÜÿ™ÿß€åÿ¨ ÿ±ÿß ŸáŸÜ⁄ØÿßŸÖ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å €å⁄© ÿπÿ®ÿßÿ±ÿ™ ÿÆÿßÿµ ÿ®Ÿá ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ŸÜŸÖÿß€åÿ¥ ÿØŸáŸÜÿØÿå ŸÇŸàÿßŸÜ€åŸÜ Ÿà ÿßÿ≥ÿ™ÿßŸÜÿØÿßÿ±ÿØŸáÿß€å€å ÿ®ÿ±ÿß€å Ÿàÿ® ÿ≥ÿß€åÿ™‚ÄåŸáÿß ÿ™ÿπÿ±€åŸÅ ⁄©ÿ±ÿØŸá‚ÄåÿßŸÜÿØ ÿ™ÿß ÿ®ÿ™ŸàÿßŸÜŸÜÿØ ÿπŸÑÿßŸàŸá ÿ®ÿ± ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ≥ÿßÿØŸá‚Äåÿ™ÿ± ÿ®Ÿá ÿµŸÅÿ≠ÿßÿ™ Ÿàÿ® ÿ≥ÿß€åÿ™‚ÄåŸáÿßÿå ŸÖÿ≠ÿ™Ÿàÿß€å ŸÖŸàÿ¨ŸàÿØ ÿØÿ± ÿµŸÅÿ≠ÿßÿ™ ÿ±ÿß ÿ®Ÿáÿ™ÿ± ÿØÿ±⁄© ⁄©ŸÜŸÜÿØ. ÿ®ÿß ÿß€åŸÜ ⁄©ÿßÿ±ÿå ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖ€å‚Äåÿ™ŸàÿßŸÜŸÜÿØ Ÿàÿ® ÿ≥ÿß€åÿ™‚ÄåŸáÿß€å ⁄©Ÿá ÿØÿßÿ±ÿß€å ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ÿßÿ±ÿ™ÿ®ÿßÿ∑ ŸÖÿπŸÜÿß€å€å ÿ®ÿß ÿπÿ®ÿßÿ±ÿ™ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ¥ÿØŸá ÿ™Ÿàÿ≥ÿ∑ ⁄©ÿßÿ±ÿ®ÿ± Ÿáÿ≥ÿ™ŸÜÿØ ÿØÿ± ÿ±ÿ™ÿ®Ÿá‚ÄåŸáÿß€å ÿ®ÿßŸÑÿßÿ™ÿ±€å ÿØÿ± ŸÜÿ™ÿß€åÿ¨ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÇÿ±ÿßÿ± ÿØŸáŸÜÿØ.[€±€±][€±€≤][€±€≥] ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ®ÿ±ÿß€å ÿß€åÿ¨ÿßÿØ ŸÜÿ™€åÿ¨Ÿá €å⁄© ÿ¨ÿ≥ÿ™ÿ¨Ÿàÿå ÿ™ÿπÿØÿßÿØ€å ŸÅÿπÿßŸÑ€åÿ™ ÿßŸÜÿ¨ÿßŸÖ ŸÖ€å‚ÄåÿØŸáŸÜÿØ: ÿ≥ÿ¶Ÿà ŸÖÿÆŸÅŸÅ ÿπÿ®ÿßÿ±ÿ™ Search Engine Optimization ÿ®Ÿá ŸÖÿπŸÜ€å ¬´ÿ®Ÿá€åŸÜŸá‚Äåÿ≥ÿßÿ≤€å ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà¬ª ÿßÿ≥ÿ™ Ÿà ÿ®Ÿá ŸÖÿ¨ŸÖŸàÿπŸá ÿßŸÇÿØÿßŸÖÿßÿ™ ÿ®ÿ±ŸÜÿßŸÖŸá‚Äåÿ±€åÿ≤€å ÿ¥ÿØŸá Ÿà ÿØŸÇ€åŸÇ€å ⁄ØŸÅÿ™Ÿá ŸÖ€å‚Äåÿ¥ŸàÿØ ⁄©Ÿá ÿ±ŸÜ⁄©€åŸÜ⁄Ø ÿ≥ÿß€åÿ™ ÿ¥ŸÖÿß ÿ±ÿß ÿØÿ± ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ®Ÿáÿ®ŸàÿØ ŸÖ€å‚Äåÿ®ÿÆÿ¥ÿØ. ÿ≥ÿ¶Ÿà ÿ≥ÿß€åÿ™ ÿ®ÿß€åÿØ ÿ™Ÿàÿ≥ÿ∑ ŸÖÿ™ÿÆÿµÿµÿßŸÜ ÿ≥ÿ¶Ÿà ÿµŸàÿ±ÿ™ ⁄Ø€åÿ±ÿØ. ÿ≥ÿ¶Ÿà ÿ±ÿß ÿ®ÿ±ÿÆ€å ÿßŸàŸÇÿßÿ™ ŸÜ€åÿ≤ SEO Copywriting ŸÜ€åÿ≤ ŸÖ€å‚Äå⁄ØŸà€åŸÜÿØ ÿ≤€åÿ±ÿß ÿ®€åÿ¥ÿ™ÿ± ÿ™⁄©ŸÜ€å⁄©‚ÄåŸáÿß€å€å ⁄©Ÿá ÿØÿ± ÿ¢ŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØ ÿ®Ÿá ŸÖÿ≠ÿ™Ÿàÿß ŸÖÿ±ÿ®Ÿàÿ∑ ŸÖ€å‚Äåÿ¥ŸàÿØ. ÿ™ŸÖÿßŸÖ ÿ≠ÿ±ŸÅ ÿ≥ÿ¶Ÿà ÿ®Ÿá€åŸÜŸá‚Äåÿ≥ÿßÿ≤€å ÿ≥ÿß€åÿ™ ÿ®ÿ±ÿß€å ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿßÿ≥ÿ™ Ÿà ÿ®Ÿá ÿµŸàÿ±ÿ™ ⁄©ŸÑ€å ŸÅÿ±ÿß€åŸÜÿØ€å ÿßÿ≥ÿ™ ⁄©Ÿá ÿ®ÿßÿπÿ´ ŸÖ€å‚Äåÿ¥ŸàÿØ €å⁄© Ÿàÿ® ÿ≥ÿß€åÿ™ ÿ±ÿ™ÿ®Ÿá ÿÆŸàÿ®€å ÿØÿ± ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ®Ÿá ÿØÿ≥ÿ™ ÿ¢Ÿàÿ±ÿØ. ÿ≥ÿ¶Ÿà ÿ≤€åÿ± ŸÖÿ¨ŸÖŸàÿπŸá ÿß€å ÿßÿ≤ ÿ®ÿßÿ≤ÿßÿ±€åÿßÿ®€å ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿßÿ≥ÿ™. ÿ®ÿßÿ≤ÿßÿ±€åÿßÿ®€å ÿ≥ÿ¶Ÿà €åÿπŸÜ€å ÿ¢⁄ØÿßŸá€å ÿßÿ≤ ŸÜÿ≠ŸàŸá ⁄©ÿßÿ± ÿßŸÑ⁄ØŸàÿ±€åÿ™ŸÖ‚ÄåŸáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà Ÿà ÿ¥ŸÜÿßÿÆÿ™ ÿß€åŸÜ⁄©Ÿá ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿß€åŸÜÿ™ÿ±ŸÜÿ™ ⁄ÜŸá ⁄Ü€åÿ≤Ÿáÿß€å€å ÿ±ÿß ÿ¨ÿ≥ÿ™ÿ¨Ÿà ŸÖ€å‚Äå⁄©ŸÜŸÜÿØ.[€±€¥][€±€µ][€±€∂] ÿßŸÖÿß ÿØÿ± ÿ≥ÿ¶Ÿà ÿÆÿßÿ±ÿ¨€å ŸÖŸàÿßÿ±ÿØ ŸÖŸàÿ±ÿØ ÿ®ÿ≠ÿ´ Ÿà ÿ®ÿ±ÿ±ÿ≥€å ŸÖÿ™ŸÅÿßŸàÿ™ ÿßÿ≥ÿ™ ⁄©Ÿá ŸÖŸáŸÖ‚Äåÿ™ÿ±€åŸÜ ÿ¢ŸÜŸáÿß ŸÑ€åŸÜ⁄© ÿ≥ÿßÿ≤€å ŸÖ€å‚Äåÿ®ÿßÿ¥ÿØÿõ ŸÑ€åŸÜ⁄© ÿ≥ÿßÿ≤€å ÿ±ÿß ŸÖ€å‚Äåÿ™ŸàÿßŸÜ ÿØÿ± ÿ¨ÿßŸáÿß€å ŸÖÿÆÿ™ŸÑŸÅ€å ÿßŸÜÿ¨ÿßŸÖ ÿØÿßÿØ ⁄©Ÿá ⁄ÜŸÜÿØ ÿπÿØÿØ ÿßÿ≤ ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÖÿ≠ŸÑ‚ÄåŸáÿß ÿ®ÿ±ÿß€å ŸÑ€åŸÜ⁄© ÿ≥ÿßÿ≤€å ÿ±ÿß ÿØÿ± ÿßÿØÿßŸÖŸá ŸÖÿπÿ±ŸÅ€å ŸÖ€å‚Äåÿ¥ŸàÿØ: ÿ™ÿß ÿ™ÿßÿ±€åÿÆ ⁄òŸàÿ¶ŸÜ €≤€∞€≤€±[ÿ®ÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å]ÿå[€≤€∑] ŸÖŸàÿ™Ÿàÿ±ÿ¨ÿ≥ÿ™ÿ¨Ÿà ⁄ØŸà⁄ØŸÑ ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ÿ≥ŸáŸÖ ÿ®ÿß €π€≤Ÿ´€¥€πŸ™ÿ¨ÿ≥ÿ™ÿ¨ŸàŸáÿß€å ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØŸá ÿØÿ± ÿØŸÜ€åÿß ÿ±ÿß ÿØÿßÿ±ÿØ. ÿ®ŸÇ€åŸáŸî ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å Ÿæÿ±ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿß€åŸÜ‚ÄåŸáÿß ÿ®ŸàÿØŸÜÿØ:"
  },
  {
    "url": "https://fr.wikipedia.org/wiki/Moteur_de_recherche_web",
    "title": "Moteur de recherche ‚Äî Wikip√©dia",
    "content": "Cet article ne cite pas suffisamment ses sources (septembre 2010). Si vous disposez d'ouvrages ou d'articles de r√©f√©rence ou si vous connaissez des sites web de qualit√© traitant du th√®me abord√© ici, merci de compl√©ter l'article en donnant les r√©f√©rences utiles √† sa v√©rifiabilit√© et en les liant √† la section ¬´¬†Notes et r√©f√©rences¬†¬ª. Cet article contient une ou plusieurs listes (d√©cembre 2024). modifier - modifier le code - modifier Wikidata Un moteur de recherche est une application permettant √† un utilisateur d'effectuer une recherche locale ou en ligne, c'est-√†-dire de trouver des ressources √† partir d'une requ√™te compos√©e de termes. Les ressources peuvent notamment √™tre des pages web, des articles de forums Usenet, des images, des vid√©os, des fichiers, des ouvrages, des sites, p√©dagogiques, des applications, des logiciels open source. Des intelligences artificielles comme Perplexity commencent √† entrer en concurrence avec les moteurs de recherche ¬´¬†classiques¬†¬ª. Un moteur de recherche fonctionne g√©n√©ralement selon le principe suivant¬†: Il commence par indexer du contenu dans une ou plusieurs bases de donn√©es qui lui appartiennent. Cette indexation est effectu√©e au pr√©alable de toute recherche effectu√©e par un utilisateur. Lorsqu'une requ√™te est soumise, le moteur utilise ses param√®tres et algorithmes de classement pour g√©n√©rer une liste de r√©sultats. Certains sites web offrent un moteur de recherche comme principale fonctionnalit√©¬†; on appelle alors ¬´¬†moteur de recherche¬†¬ª le site lui-m√™me. Contrairement aux annuaires, les moteurs de recherche ne n√©cessitent pas d'intervention humaine. Ils sont bas√©s sur des ¬´¬†robots¬†¬ª, appel√©s ¬´¬†bots¬†¬ª, ¬´¬†spiders ¬´, ¬´¬†crawlers¬†¬ª ou ¬´¬†agents¬†¬ª, qui parcourent automatiquement les sites √† intervalles r√©guliers afin de d√©couvrir de nouvelles adresses (URL). Ils suivent les liens hypertexte qui relient les pages les unes aux autres, les uns apr√®s les autres. Chaque page identifi√©e est alors index√©e dans une base de donn√©es, accessible ensuite par les internautes √† partir de mots-cl√©s. C'est par abus de langage qu'on appelle √©galement ¬´¬†moteurs de recherche¬†¬ª des sites web proposant des annuaires de sites web¬†: dans ce cas, ce sont des instruments de recherche √©labor√©s par des personnes qui r√©pertorient et classifient des sites web jug√©s dignes d'int√©r√™t, et non des robots d'indexation. Les moteurs de recherche ne s'appliquent pas uniquement √† Internet¬†: certains moteurs sont des logiciels install√©s sur un ordinateur personnel. Ce sont des moteurs dits ¬´¬†de bureau¬†¬ª qui combinent la recherche parmi les fichiers stock√©s sur le PC et la recherche parmi les sites web. On peut citer par exemple Copernic Desktop Search, Windex Server,¬†etc. On trouve √©galement des m√©tamoteurs, c'est-√†-dire des sites web o√π une m√™me recherche est lanc√©e simultan√©ment sur plusieurs moteurs de recherche, les r√©sultats √©tant ensuite fusionn√©s pour √™tre pr√©sent√©s √† l'internaute. Les moteurs de recherche Internet pr√©c√®dent les d√©buts du Web √† la fin des ann√©es 1990¬†: Les moteurs de recherche sont inspir√©s des outils de recherche documentaire (√† base de fichiers invers√©s, alias fichiers d'index) utilis√©s sur les mainframes depuis les ann√©es 1970, comme le logiciel STAIRS sur IBM. Le mode de remplissage de leurs bases de donn√©es est cependant diff√©rent, car orient√© r√©seau. Par ailleurs la distinction entre donn√©es format√©es (¬´¬†Champs¬†¬ª) et texte libre n'y existe plus, bien que commen√ßant depuis 2010 √† se r√©introduire par le biais du web s√©mantique. Des moteurs historiques ont √©t√© Yahoo! (1994), Lycos (1994), AltaVista (1995, premier moteur 64 bits) et Backrub (1997), anc√™tre de Google (1998). Google apporte un changement important¬†: il stocke dans ses serveurs les pages qu'il indexe, ce que ne faisaient pas les autres moteurs. Et pour r√©pondre aux besoins des √©tudiants, des universitaires, chercheurs et ing√©nieurs, des moteurs sp√©cialis√©s destin√©s aux sujets scientifiques et techniques, comme Google Scholar sont apparus. Dans les ann√©es 2020, des syst√®mes d'intelligence artificielle √©mergent face aux moteurs de recherche classiques. Par exemple, Perplexity AI et son robot d'exploration web (PerplexityBot), pourrait √† moyen terme bouleverser la recherche en ligne, √† ce moment domin√© par des acteurs comme Google ou Bing[1]. Ces nouveaux agents conversationnels, au lieu de pr√©senter une longue liste de liens parmi lesquels l'internaute peut choisir, fournissent des r√©ponses synth√©tiques, contextualis√©es et sourc√©es[2],[3], √† partir de donn√©es qu'ils consultent en temps r√©el. Chaque r√©ponse est accompagn√©e de citations cliquables, renfor√ßant la transparence et la v√©rifiabilit√© des contenus. Une autre diff√©rence est que les IA comme Perplexity comprennent bien mieux le langage courant, m√©morisent le contexte des √©changes et proposent des suggestions pertinentes pour approfondir les recherches[4]. Les g√©ants du web r√©agissent √† cette mont√©e en puissance¬†: Apple a confirm√© en 2025 des discussions avec Perplexity, OpenAI et Anthropic pour int√©grer leurs moteurs IA dans Safari, en r√©ponse au proc√®s antitrust contre Google. Mozilla teste aussi l'int√©gration de Perplexity dans Firefox¬†; pendant que Perplexity a, de son c√¥t√©, lanc√© son propre navigateur, Comet, con√ßu autour de son moteur IA et d'un assistant embarqu√© capable de r√©sumer des pages web, interagir avec des contenus et automatiser des t√¢ches simples. Cette concurrence soul√®ve des enjeux majeurs¬†: Le fonctionnement d'un moteur de recherche comme tout instrument de recherche se d√©compose en trois processus principaux¬†: Des modules compl√©mentaires sont souvent utilis√©s en association avec les trois briques de bases du moteur de recherche. Les plus connus sont les suivants¬†: Afin d'optimiser les moteurs de recherche, les webmestres ins√®rent des m√©ta√©l√©ments (m√©tatags) dans les pages web, dans l'en-t√™te HTML (head). Ces informations permettent d'optimiser les recherches d'information sur les sites web. Les sites dont la recherche est le principal service se financent par la vente de technologie et de publicit√©. Le financement par la publicit√© consiste √† pr√©senter des publicit√©s correspondant aux mots recherch√©s par le visiteur. L'annonceur ach√®te des mots-cl√©s¬†: par exemple une agence de voyages peut acheter des mots-cl√©s comme ¬´¬†vacances¬†¬ª, ¬´¬†h√¥tel¬†¬ª et ¬´¬†plage¬†¬ª ou ¬´¬†Cannes¬†¬ª, ¬´¬†Antibes¬†¬ª et ¬´¬†Nice¬†¬ª si elle est sp√©cialis√©e dans cette r√©gion. Cet achat permet d'obtenir un r√©f√©rencement dit ¬´¬†r√©f√©rencement payant¬†¬ª √† distinguer du r√©f√©rencement dit ¬´¬†r√©f√©rencement naturel¬†¬ª. Le moteur de recherche peut afficher la publicit√© de deux mani√®res¬†: en encart s√©par√© ou en l'int√©grant aux r√©sultats de la recherche. Pour le visiteur, l'encart s√©par√© se pr√©sente comme une publicit√© classique. L'int√©gration aux r√©sultats se fait en revanche au d√©triment de la pertinence des r√©sultats et peut avoir des retomb√©es n√©gatives sur la qualit√© per√ßue du moteur. De ce fait, tous les moteurs ne vendent pas de placement dans les r√©sultats. Les moteurs de recherche constituent un enjeu √©conomique. La valeur boursi√®re du holding Alphabet propri√©taire de Google, principal moteur de recherche, √©tait de 831 milliards USD en avril 2020[5]. L'importance des enjeux √©conomiques a g√©n√©r√© des techniques de d√©tournement malhonn√™tes des moteurs de recherche pour obtenir des r√©f√©rencements ¬´¬†naturels¬†¬ª, le spamdexing (r√©f√©rencement abusif en fran√ßais). Les techniques les plus pratiqu√©es de spamdexing sont¬†: Les techniques de r√©f√©rencement abusif sont pourchass√©es par les √©diteurs de moteurs de recherches, qui constituent des listes noires, provisoires ou d√©finitives. On distingue le spamdexing, d√©tournement malhonn√™te, du ¬´¬†SEO¬†¬ª, Search Engine Optimization (optimisation pour les moteurs de recherche en fran√ßais). Les techniques de SEO sont commercialis√©es par des soci√©t√©s sp√©cialis√©es. Les grandes organisations (entreprises, administrations) disposent g√©n√©ralement de tr√®s nombreuses ressources informatiques dans un vaste intranet. Leurs ressources n'√©tant pas accessibles depuis Internet, elles ne sont pas couvertes par les moteurs de recherche du web. Elles doivent donc installer leur propre moteur si elles veulent mener des recherches dans leurs ressources. Elles constituent donc un march√© pour les d√©veloppeurs de moteurs de recherche. On parle alors de moteur de recherche pour entreprise (voir plus bas). Il arrive √©galement que des sites web publics utilisent les services d'un moteur de recherche pour √©toffer leur offre. On parle alors de ¬´¬†SiteSearch¬†¬ª. Ces logiciels permettent la recherche de contenus dans un ou plusieurs groupes de sites. Ces technologies sont particuli√®rement exploit√©es sur les sites de contenus et les sites de vente en ligne. La particularit√© de ces outils est souvent la complexit√© de mise en ≈ìuvre et les ressources techniques n√©cessaires disponibles. Il arrive aussi que de grands portails exploitent la technologie des moteurs de recherche. Ainsi Yahoo!, sp√©cialiste de l'annuaire web, a utilis√© pendant quelques ann√©es la technologie de Google pour la recherche jusqu'√† ce qu'elle lance son propre moteur de recherche Yahoo Search Technology en 2004 dont les fondations proviennent de Altavista, Inktomi et Overture, soci√©t√©s fondatrices des moteurs de recherche et rachet√©es par Yahoo!. De plus en plus de producteurs de contenu, √† la suite des recommandations du W3C sur le web s√©mantique, indexent leurs bases avec des m√©tadonn√©es ou des taxinomies (ontologies), en vue de permettre aux moteurs de recherche de s'adapter aux analyses s√©mantiques. Ces formes de recherches et d'analyses de corpus d'informations par voie informatique ne sont encore que des potentialit√©s. Par comparaison avec des recherches plein texte, des recherches r√©alis√©es sur le web s√©mantique doivent √™tre plus conviviales pour l'utilisateur¬†: Il n'existe pas encore √† proprement parler de moteur de recherche s√©mantique qui permette de comprendre une question en langue naturelle et d'adapter une r√©ponse en fonction des r√©sultats trouv√©s. Quelques tentatives existent n√©anmoins pour chercher √† r√©pondre par des formes interm√©diaires √† cette probl√©matique du sens dans la recherche d'information¬†: L'abandon progressif des annuaires imprim√©s conduit les usagers √† effectuer les m√™mes recherches sur l'internet ¬´¬†profession+localit√©¬†¬ª. Google a donc acquis en 2010 un fichier d'entreprises (pour la France et un certain nombre de pays), pour effectuer un mixage des donn√©es web et annuaire lorsque les requ√™tes correspondent a une activit√© localis√©e. Cette nouvelle tendance se v√©rifie chez les principaux moteurs de recherche et de nouveaux ¬´¬†outils mixte¬†¬ª voient le jour. Yandex et Baidu n'ont pas encore adopt√© ce mod√®le de mixage. Selon une √©tude r√©alis√©e par McKinsey&Co[6], seulement 65¬†% des PME fran√ßaises disposaient d'une pr√©sence sur Internet en 2013. Les moteurs de recherche qui par d√©finition collectent uniquement des donn√©es issues de l'internet, ont donc √©t√© oblig√©s d'acqu√©rir et de proposer ces adresses d'annuaire en compl√©ment pour satisfaire la recherche d'adresses des internautes. Google a baptis√© ces adresses ¬´¬†Google Adresses¬†¬ª, puis d'office bascul√©es vers ¬´¬†Google +¬†¬ª, actuellement ¬´¬†Google My Business¬†¬ª. Les moteurs de recherche Bing et Google ne communiquent pas l'origine de ces fichiers d'entreprises int√©gr√©s, hormis Yahoo! qui est en partenariat avec Pages Jaunes [7]. Les m√©tamoteurs sont des outils de recherche qui interrogent plusieurs moteurs de recherche simultan√©ment et affichent √† l'internaute une synth√®se pertinente. Exemples¬†: Startpage, Searx, Seeks, Lilo, Framabee, Kagi... On d√©signe par ¬´¬†multi-moteurs¬†(en)¬†¬ª (ou plus rarement, ¬´¬†super moteur¬†¬ª[9]) une page web proposant un ou plusieurs formulaires permettant d'interroger plusieurs moteurs. Il peut √©galement (mais plus rarement) s'agir d'un logiciel, d'une fonction ou d'une extension de navigateur web, ou d'une barre d'outils‚Ä¶ Le choix d'un des moteurs peut se faire par bouton, bouton radio, onglet, liste d√©roulante ou autre. Les premi√®res pages de ce type recopiaient le code des formulaires de plusieurs moteurs. Avec l'apparition du JavaScript il est devenu possible de n'avoir plus qu'un seul formulaire.\nOn peut citer par exemple Creative Commons Search[10], Ecosia, Disconnect, le moteur de recherche de Maxthon, HooSeek (ferm√© en 2012), searchall.net,¬†etc. Le moteur de recherche le plus connu et le plus utilis√© concernant la litt√©rature scientifique et technique est Google Scholar, dont l'algorithme indexe un grand nombre de bases de donn√©es et de m√©tadonn√©es structur√©es de litt√©rature scientifique et technique et de brevets, mais il existe d'autres moteurs, plus ou moins sp√©cialis√©s¬†: On d√©signe par ¬´¬†moteur de recherche solidaire¬†¬ª, un moteur qui reverse une partie de ses revenus √† des causes √©cologiques, sociales ou humanitaires. Ces moteurs sont n√©s du constat que les revenus annuels g√©n√©r√©s par la publicit√© sur les moteurs de recherche sont assez importants (environ 45¬†$ par an par utilisateur pour Google en 2014[12]). Les moteurs de recherches solidaires se distinguent notamment dans la fa√ßon de distribuer les revenus g√©n√©r√©s. Certains moteurs comme Ecosia reversent alors une partie des revenus √† une seule et unique cause, alors que des moteurs comme Lilo et YouCare permettent aux internautes de choisir les projets √† financer. Certains moteurs ont √©galement adopt√© une politique de neutralit√© carbone, tels que Google, DuckDuckGo et Ecosia. Google affirme qu'il sera neutre en carbone d'ici 2030, en partie en achetant des √©nergies renouvelables et d√®s 2017, l'entreprise en rach√®te autant qu'elle en consomme mais il ne faut pas oublier que l'utilisation des √©nergies renouvelables produit souvent des gaz √† effet de serre. Au d√©but des ann√©es 2020 Google est le plus gros acheteur priv√© au monde de ce type d'√©nergie. Les √©nergies renouvelables √©tant essentiellement intermittentes, Google ne peut les utiliser directement ou de fa√ßon permanente¬†: une entreprise qui se d√©clare neutre en carbone utilise dans les faits des ¬´¬†garanties d'origines renouvelables¬†¬ª(ce qui n'est pas forc√©ment vrai, car certaines entreprises ach√®tent des garanties d'origine renouvelables, mais fournissent en r√©alit√© l'√©lectricit√© du r√©seau) qui permettent de s'assurer que l'√©nergie carbon√©e qu'elles consomment sera compens√©e par une production √©quivalente d'√©nergie renouvelable. Or, selon l'association The Shift Project, le mod√®le √©conomique de Google n√©cessite toujours plus de puissance de calcul, de renouveler et d'augmenter son infrastructure, ses r√©seaux et ses √©quipements dont la production est une source importante de gaz √† effet de serre. Pour l'association n√©gaWatt, la communication de Google se focalise sur l'usage, mais √©clipse les probl√®mes environnementaux li√©s √† l'extraction des ressources, du transport et du recyclage[13],[14]. Le m√©tamoteur de recherche Ecosia utilise 80¬†% de ses revenus publicitaires pour des projets de reforestation aux quatre coins du monde[15]. On d√©signe par ¬´¬†moteurs verticaux¬†¬ª une page web ou un service multim√©dia qui propose une recherche sp√©cialis√©e dans un domaine professionnel ou qui est particuli√®rement cibl√©e. Cet outil de recherche est sp√©cialis√© dans un secteur particulier, tel que les t√©l√©communications, le droit, la biotechnologie, la finance (assurance) ou encore l'immobilier. Son fonctionnement g√©n√©ral est bas√© sur une base de donn√©es constitu√©e √† partir des bases de tous les sites sp√©cialis√©s de l'activit√© cibl√©e. Certains de ces moteurs sont utilis√© par des professionnels pour cibler des consommateurs, avec le plus souvent une finalit√© √©conomique qui d√©rive sur la g√©olocalisation. On retrouve ainsi pour le grand public des annuaires, des comparateurs. Il en existe maintenant pour toutes les activit√©s¬†: immobilier, tourisme, recherche d'emploi, recrutement, automobile, loisirs, jeux. L'explosion du nombre de contenus de formats divers (donn√©es, informations non structur√©es, images, vid√©os‚Ä¶) disponibles dans les entreprises les poussent √† s'√©quiper de moteurs de recherche en interne. Selon une √©tude men√©e par MARKESS International en f√©vrier 2008, 49¬†% des organisations ont d√©j√† recours √† un moteur de recherche d'entreprise, et 18¬†% envisagent son utilisation d'ici √† 2010. Ces moteurs de recherche sont en majeure partie int√©gr√©s aux postes de travail ou aux outils de gestion √©lectronique des documents, mais ils sont dans un nombre grandissant d'entreprises capables de couvrir √† la fois les contenus internes et externes de l'entreprise, ou encore int√©gr√©s aux outils de gestion de contenu ou aux solutions d√©cisionnelles. Parmi les acteurs proposant des moteurs de recherche d'entreprise figurent Google, Exalead, PolySpot ou OpenSearchServer. Les technologies d'analyse du langage, telles que la lemmatisation, l'extraction d'entit√©s nomm√©es, la classification et le clustering permettent d'am√©liorer grandement le fonctionnement des moteurs de recherche. Ces technologies permettent √† la fois d'am√©liorer la pertinence des r√©sultats et d'engager l'internaute dans un processus de recherche plus performant, comme c'est le cas avec la recherche √† facettes [pr√©cision¬†n√©cessaire]. Selon l'√©tude de l'ADEME ¬´¬†Internet, courriels, r√©duire les impacts¬†¬ª publi√©e en f√©vrier 2014, aller directement √† l'adresse d'un site, soit en tapant son adresse dans son navigateur, soit en l'ayant enregistr√© comme ¬´¬†favori¬†¬ª (plut√¥t que de rechercher ce site via un moteur de recherche) divise par 4 les √©missions de gaz √† effet de serre, ce qui d√©pend en r√©alit√© du type de moteur de recherche, les recherches dans les moteurs comme Ecosia ayant une empreinte moyenne n√©gative[16]. Sur les autres projets Wikimedia¬†:"
  },
  {
    "url": "https://ga.wikipedia.org/wiki/Inneall_cuardaigh",
    "title": "Inneall cuardaigh - Vicip√©id",
    "content": "Is e at√° i gceist le inneall cuardaigh n√° acmhainn ar an ngr√©as√°n domhanda at√° insroichte le brabhs√°la√≠ Gr√©as√°in, a chabhra√≠onn leis an √∫s√°ideoir ionaid is eolas a aimsi√∫. B√≠onn na hinnill chuardaigh (Yahoo, Lycos, Google, Ask Jeeves) ag cuardach tr√≠d an ngr√©as√°n an t-am ar fad, ag t√≥g√°il inn√©acsanna √°bhar √©ags√∫la ‚Äî mar shampla, ag aimsi√∫ teidil, fotheidil, eochairfhocail is c√©adl√≠nte c√°ip√©is√≠. Uaidh sin, is f√©idir cuid mhaith c√°ip√©is√≠ √©ags√∫la ar √°bhar ar leith a aisghabh√°il. D√©anann an cuardach lean√∫nach cinnte de go bhfuil na hinn√©acsanna suas chun d√°ta. Mar sin f√©in, aisghabhann na hinnill an-chuid ch√°ip√©is√≠ nach mbaineann le h√°bhar, agus t√° an-iarracht ar si√∫l an t-am ar fad iad a fheabhs√∫. Comhl√≠onann an t-inneall cuardaigh na riachtanais seo: √ì Fheabhra 2023, is √© Google an t-inneall cuardaigh is m√≥ a √∫s√°idtear ar domhan, le sciar den mhargadh de 93.37%. B‚Äôiad na hinnill chuardaigh ba mh√≥ eile n√° Bing, Yahoo!, Baidu, Yandex agus DuckDuckGo[1].[2]"
  },
  {
    "url": "https://ko.wikipedia.org/wiki/%EA%B2%80%EC%83%89_%EC%97%94%EC%A7%84",
    "title": "Í≤ÄÏÉâ ÏóîÏßÑ - ÏúÑÌÇ§Î∞±Í≥º, Ïö∞Î¶¨ Î™®ÎëêÏùò Î∞±Í≥ºÏÇ¨Ï†Ñ",
    "content": "Í≤ÄÏÉâ ÏóîÏßÑ(search engine)ÏùÄ ÏÇ¨Ïö©ÏûêÏùò ÏøºÎ¶¨Ïóê ÏùëÎãµÌïòÏó¨ ÏõπÏùò Ïõπ ÌéòÏù¥ÏßÄ Î∞è Í∏∞ÌÉÄ Í¥ÄÎ†® Ï†ïÎ≥¥Ïóê ÎåÄÌïú ÌïòÏù¥ÌçºÎßÅÌÅ¨Î•º Ï†úÍ≥µÌïòÎäî ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏãúÏä§ÌÖúÏù¥Îã§. ÏÇ¨Ïö©ÏûêÎäî Ïõπ Î∏åÎùºÏö∞Ï†Ä ÎòêÎäî Î™®Î∞îÏùº Ïï±Ïóê ÏøºÎ¶¨Î•º ÏûÖÎ†•ÌïòÎ©∞, Í≤ÄÏÉâ Í≤∞Í≥ºÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÌÖçÏä§Ìä∏ ÏöîÏïΩ Î∞è Ïù¥ÎØ∏ÏßÄÏôÄ Ìï®Íªò ÌïòÏù¥ÌçºÎßÅÌÅ¨ Î™©Î°ùÏúºÎ°ú ÌëúÏãúÎêúÎã§. ÏÇ¨Ïö©ÏûêÎäî Í≤ÄÏÉâÏùÑ Ïù¥ÎØ∏ÏßÄ, ÎπÑÎîîÏò§ ÎòêÎäî Îâ¥Ïä§ Îì± ÌäπÏ†ï Ïú†ÌòïÏùò Í≤∞Í≥ºÎ°ú Ï†úÌïúÌï† ÏàòÎèÑ ÏûàÎã§. Í≤ÄÏÉâ Ï†úÍ≥µÏûêÏóêÍ≤åÎäî ÏóîÏßÑÏù¥ Ï†Ñ ÏÑ∏Í≥ÑÏùò ÎßéÏùÄ Îç∞Ïù¥ÌÑ∞ ÏÑºÌÑ∞Î•º Ìè¨Ìï®Ìï† Ïàò ÏûàÎäî Î∂ÑÏÇ∞ Ïª¥Ìì®ÌåÖ ÏãúÏä§ÌÖúÏùò ÏùºÎ∂ÄÏù¥Îã§. ÏóîÏßÑÏùò ÏøºÎ¶¨Ïóê ÎåÄÌïú ÏùëÎãµ ÏÜçÎèÑÏôÄ Ï†ïÌôïÏÑ±ÏùÄ ÏûêÎèôÌôîÎêú Ïõπ ÌÅ¨Î°§Îü¨Ïóê ÏùòÌï¥ ÏßÄÏÜçÏ†ÅÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏ÎêòÎäî Î≥µÏû°Ìïú ÏÉâÏù∏ ÏãúÏä§ÌÖúÏóê Í∏∞Î∞òÌïúÎã§. Ïó¨Í∏∞ÏóêÎäî Ïõπ ÏÑúÎ≤ÑÏóê Ï†ÄÏû•Îêú Ïª¥Ìì®ÌÑ∞ ÌååÏùº Î∞è Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïùò Îç∞Ïù¥ÌÑ∞ ÎßàÏù¥ÎãùÏù¥ Ìè¨Ìï®Îê† Ïàò ÏûàÏßÄÎßå, ÏùºÎ∂Ä ÏΩòÌÖêÏ∏†Îäî ÌÅ¨Î°§Îü¨Í∞Ä Ï†ëÍ∑ºÌï† Ïàò ÏóÜÎäî Ïã¨Ï∏µ ÏõπÏóê ÏûàÎã§. 1990ÎÖÑÎåÄ ÏõπÏù¥ Îì±Ïû•Ìïú Ïù¥ÎûòÎ°ú ÎßéÏùÄ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏûàÏóàÏßÄÎßå, Íµ¨Í∏Ä Í≤ÄÏÉâÏùÄ 2000ÎÖÑÎåÄÏóê ÏßÄÎ∞∞Ï†ÅÏù∏ ÏúÑÏπòÎ•º Ï∞®ÏßÄÌñàÏúºÎ©∞ ÏßÄÍ∏àÍπåÏßÄ Ïú†ÏßÄÌïòÍ≥† ÏûàÎã§. 2025ÎÖÑ 5Ïõî ÌòÑÏû¨, StatCounterÏóê Îî∞Î•¥Î©¥ Íµ¨Í∏ÄÏùÄ Ï†Ñ ÏÑ∏Í≥Ñ Í≤ÄÏÉâ ÏãúÏû• Ï†êÏú†Ïú®Ïùò ÏïΩ 89‚Äì90%Î•º Ï∞®ÏßÄÌïòÎ©∞, Í≤ΩÏüÅÏóÖÏ≤¥Îì§ÏùÄ ÌïúÏ∞∏ Îí§Ï≤òÏ†∏ ÏûàÎã§: Îπô (~4%), ÏñÄÎç±Ïä§ (~2.5%), ÏïºÌõÑ! (~1.3%), ÎçïÎçïÍ≥† (~0.8%), Í∑∏Î¶¨Í≥† Î∞îÏù¥Îëê (~0.7%).[1] ÌäπÌûà, Ïù¥Îäî Íµ¨Í∏ÄÏùò Ï†êÏú†Ïú®Ïù¥ 90% ÏïÑÎûòÎ°ú Îñ®Ïñ¥ÏßÑ Í≤ÉÏù¥ 10Ïó¨ ÎÖÑ ÎßåÏóê Ï≤òÏùåÏù¥Îã§. Îî∞ÎùºÏÑú ÏõπÏÇ¨Ïù¥Ìä∏Í∞Ä ÎßàÏºÄÌåÖ Î∞è ÏµúÏ†ÅÌôîÎ°ú ÏïåÎ†§ÏßÑ Í≤ÄÏÉâ Í≤∞Í≥ºÏóêÏÑú Í∞ÄÏãúÏÑ±ÏùÑ Ìñ•ÏÉÅÏãúÌÇ§Îäî ÏÇ¨ÏóÖÏùÄ Ï£ºÎ°ú Íµ¨Í∏ÄÏóê ÏßëÏ§ëÎêòÏóàÎã§. 1945ÎÖÑ Î≤ÑÎãàÎ∞î Î∂ÄÏãúÎäî ÏÇ¨Ïö©ÏûêÍ∞Ä ÌïòÎÇòÏùò Ï±ÖÏÉÅÏóêÏÑú Î∞©ÎåÄÌïú Ï†ïÎ≥¥Ïóê Ï†ëÍ∑ºÌï† Ïàò ÏûàÍ≤å Ìï¥Ï£ºÎäî Ï†ïÎ≥¥ Í≤ÄÏÉâ ÏãúÏä§ÌÖúÏùÑ ÏÑ§Î™ÖÌñàÏúºÎ©∞, Ïù¥Î•º Î©îÎ©ïÏä§ÎùºÍ≥† Î∂àÎ†ÄÎã§.[2] Í∑∏Îäî Ïù¥ ÏãúÏä§ÌÖúÏùÑ „ÄäÎîî Ïï†ÌãÄÎûúÌã± Î®ºÏä¨Î¶¨„ÄãÏóê Ïã§Î¶∞ \"As We May Think\"ÎùºÎäî Ï†úÎ™©Ïùò Í∏∞ÏÇ¨ÏóêÏÑú ÏÑ§Î™ÖÌñàÎã§.[3] Î©îÎ©ïÏä§Îäî Í≥ÑÏÜçÌï¥ÏÑú ÏÑ±Ïû•ÌïòÎäî Í≥ºÌïô Ïó∞Íµ¨Ïùò Ï§ëÏïô ÏßëÏ§ëÏãù ÏÉâÏù∏ÏóêÏÑú Ï†ïÎ≥¥Î•º Ï∞æÎäî Í≤ÉÏù¥ Ï†êÏ†ê Îçî Ïñ¥Î†§ÏõåÏßÄÎäî Î¨∏Ï†úÎ•º ÏÇ¨Ïö©ÏûêÍ∞Ä Í∑πÎ≥µÌï† Ïàò ÏûàÎèÑÎ°ù Í≥†ÏïàÎêòÏóàÎã§. Î≤ÑÎãàÎ∞î Î∂ÄÏãúÎäî ÌòÑÎåÄÏùò ÌïòÏù¥ÌçºÎßÅÌÅ¨ÏôÄ Ïú†ÏÇ¨Ìïú Ïó∞Í≤∞Îêú Ï£ºÏÑùÏù¥ ÏûàÎäî Ïó∞Íµ¨ ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º Íµ¨ÏÉÅÌñàÎã§.[4] ÎßÅÌÅ¨ Î∂ÑÏÑùÏùÄ Í≤∞Íµ≠ ÌïòÏù¥Ìçº ÏÑúÏπòÏôÄ ÌéòÏù¥ÏßÄÎû≠ÌÅ¨ÏôÄ Í∞ôÏùÄ ÏïåÍ≥†Î¶¨Ï¶òÏùÑ ÌÜµÌï¥ Í≤ÄÏÉâ ÏóîÏßÑÏùò Ï§ëÏöîÌïú Íµ¨ÏÑ± ÏöîÏÜåÍ∞Ä ÎêòÏóàÎã§.[5][6] ÏµúÏ¥àÏùò Ïù∏ÌÑ∞ÎÑ∑ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ 1990ÎÖÑ 12Ïõî ÏõπÏù¥ Îì±Ïû•ÌïòÍ∏∞ Ï†ÑÎ∂ÄÌÑ∞ Ï°¥Ïû¨ÌñàÎã§. WHOIS ÏÇ¨Ïö©Ïûê Í≤ÄÏÉâÏùÄ 1982ÎÖÑÏúºÎ°ú Í±∞Ïä¨Îü¨ Ïò¨ÎùºÍ∞ÄÍ≥†,[7] Knowbot Ï†ïÎ≥¥ ÏÑúÎπÑÏä§ Îã§Ï§ë ÎÑ§Ìä∏ÏõåÌÅ¨ ÏÇ¨Ïö©Ïûê Í≤ÄÏÉâÏùÄ 1989ÎÖÑÏóê Ï≤òÏùå Íµ¨ÌòÑÎêòÏóàÎã§.[8] ÏΩòÌÖêÏ∏† ÌååÏùº, Ï¶â FTP ÌååÏùºÏùÑ Í≤ÄÏÉâÌïú ÏµúÏ¥àÏùò Ïûò Î¨∏ÏÑúÌôîÎêú Í≤ÄÏÉâ ÏóîÏßÑÏùÄ 1990ÎÖÑ 9Ïõî 10ÏùºÏóê Ï∂úÏãúÎêú ÏïÑÌÇ§ÏòÄÎã§.[9] 1993ÎÖÑ 9Ïõî Ïù¥Ï†ÑÏóêÎäî ÏõîÎìú ÏôÄÏù¥Îìú ÏõπÏù¥ Ï†ÑÏ†ÅÏúºÎ°ú ÏàòÎèôÏúºÎ°ú ÏÉâÏù∏ÌôîÎêòÏóàÎã§. ÌåÄ Î≤ÑÎÑàÏä§Î¶¨Í∞Ä Ìé∏ÏßëÌïòÍ≥† CERN Ïõπ ÏÑúÎ≤ÑÏóêÏÑú Ìò∏Ïä§ÌåÖÌïú Ïõπ ÏÑúÎ≤Ñ Î™©Î°ùÏù¥ ÏûàÏóàÎã§. 1992ÎÖÑÏùò Î™©Î°ù Ïä§ÎÉÖÏÉ∑Ïù¥ ÌïòÎÇò ÎÇ®ÏïÑ ÏûàÏßÄÎßå,[10] Ï†êÏ†ê Îçî ÎßéÏùÄ Ïõπ ÏÑúÎ≤ÑÍ∞Ä Ïò®ÎùºÏù∏ ÏÉÅÌÉúÍ∞Ä ÎêòÎ©¥ÏÑú Ï§ëÏïô Î™©Î°ùÏùÄ Îçî Ïù¥ÏÉÅ Îî∞ÎùºÍ∞à Ïàò ÏóÜÏóàÎã§. Íµ≠Î¶Ω ÏäàÌçºÏª¥Ìì®ÌåÖ ÏùëÏö© ÏÑºÌÑ∞ ÏÇ¨Ïù¥Ìä∏ÏóêÏÑúÎäî \"What's New!\"ÎùºÎäî Ï†úÎ™©ÏúºÎ°ú ÏÉàÎ°úÏö¥ ÏÑúÎ≤ÑÍ∞Ä Î∞úÌëúÎêòÏóàÎã§.[11] Ïù∏ÌÑ∞ÎÑ∑ÏóêÏÑú ÏΩòÌÖêÏ∏†(ÏÇ¨Ïö©ÏûêÏôÄÎäî Î∞òÎåÄÎ°ú)Î•º Í≤ÄÏÉâÌïòÎäî Îç∞ ÏÇ¨Ïö©Îêú ÏµúÏ¥àÏùò ÎèÑÍµ¨Îäî ÏïÑÌÇ§ÏòÄÎã§.[12] Ïù¥Î¶ÑÏùÄ \"v\"Í∞Ä ÏóÜÎäî \"ÏïÑÏπ¥Ïù¥Î∏å\"Î•º ÏùòÎØ∏ÌïúÎã§.[13] Ï∫êÎÇòÎã§ Î™¨Ìä∏Î¶¨Ïò¨Ïùò Îß•Í∏∏ ÎåÄÌïôÍµê Ïª¥Ìì®ÌÑ∞ Í≥ºÌïô ÌïôÏÉùÏù¥ÏóàÎçò Ïï®Îü∞ Ïó†Ìã∞ÏßÄÍ∞Ä ÎßåÎì§ÏóàÎã§.[13][14][15][16] Ïù¥ ÌîÑÎ°úÍ∑∏Îû®ÏùÄ Í≥µÏö© ÏùµÎ™Ö FTP(ÌååÏùº Ï†ÑÏÜ° ÌîÑÎ°úÌÜ†ÏΩú) ÏÇ¨Ïù¥Ìä∏Ïóê ÏûàÎäî Î™®Îì† ÌååÏùºÏùò ÎîîÎ†âÌÑ∞Î¶¨ Î™©Î°ùÏùÑ Îã§Ïö¥Î°úÎìúÌïòÏó¨ ÌååÏùº Ïù¥Î¶ÑÏùò Í≤ÄÏÉâ Í∞ÄÎä•Ìïú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÏÉùÏÑ±ÌñàÎã§. Í∑∏Îü¨ÎÇò ÏïÑÌÇ§ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ïù¥ ÏÇ¨Ïù¥Ìä∏Ïùò ÎÇ¥Ïö©ÏùÑ ÏÉâÏù∏ÌôîÌïòÏßÄ ÏïäÏïòÎã§. Îç∞Ïù¥ÌÑ∞ ÏñëÏù¥ ÎÑàÎ¨¥ Ï†úÌïúÏ†ÅÏù¥Ïñ¥ÏÑú ÏàòÎèôÏúºÎ°ú ÏâΩÍ≤å Í≤ÄÏÉâÌï† Ïàò ÏûàÏóàÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§. 1991ÎÖÑ ÎØ∏ÎÑ§ÏÜåÌÉÄ ÎåÄÌïôÍµêÏùò ÎßàÌÅ¨ Îß•Ï∫êÌûêÏù¥ ÎßåÎì† Í≥†ÌçºÏùò Îì±Ïû•ÏùÄ Îëê Í∞ÄÏßÄ ÏÉàÎ°úÏö¥ Í≤ÄÏÉâ ÌîÑÎ°úÍ∑∏Îû®Ïù∏ Î≤†Î°úÎãàÏπ¥ÏôÄ Ï†ÄÍ∑∏Ìó§ÎìúÎ°ú Ïù¥Ïñ¥Ï°åÎã§. ÏïÑÌÇ§ÏôÄ ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú Ïù¥Îì§ÏùÄ Í≥†Ìçº ÏÉâÏù∏ ÏãúÏä§ÌÖúÏóê Ï†ÄÏû•Îêú ÌååÏùº Ïù¥Î¶ÑÍ≥º Ï†úÎ™©ÏùÑ Í≤ÄÏÉâÌñàÎã§. Î≤†Î°úÎãàÏπ¥(Very Easy Rodent-Oriented Net-wide Index to Computerized Archives)Îäî Ï†ÑÏ≤¥ Í≥†Ìçº Î™©Î°ùÏóêÏÑú ÎåÄÎ∂ÄÎ∂ÑÏùò Í≥†Ìçº Î©îÎâ¥ Ï†úÎ™©Ïóê ÎåÄÌïú ÌÇ§ÏõåÎìú Í≤ÄÏÉâÏùÑ Ï†úÍ≥µÌñàÎã§. Ï†ÄÍ∑∏Ìó§Îìú(Jonzy's Universal Gopher Hierarchy Excavation And Display)Îäî ÌäπÏ†ï Í≥†Ìçº ÏÑúÎ≤ÑÏóêÏÑú Î©îÎâ¥ Ï†ïÎ≥¥Î•º ÏñªÍ∏∞ ÏúÑÌïú ÎèÑÍµ¨ÏòÄÎã§. Í≤ÄÏÉâ ÏóîÏßÑ \"ÏïÑÌÇ§ Í≤ÄÏÉâ ÏóîÏßÑ\"Ïùò Ïù¥Î¶ÑÏù¥ ÏïÑÏπò ÎßåÌôîÏ±Ö ÏãúÎ¶¨Ï¶àÎ•º Ï∞∏Ï°∞Ìïú Í≤ÉÏùÄ ÏïÑÎãàÏßÄÎßå, \"Î≤†Î°úÎãàÏπ¥\"ÏôÄ \"Ï†ÄÍ∑∏Ìó§Îìú\"Îäî Ïù¥ ÏãúÎ¶¨Ï¶àÏùò Îì±Ïû•Ïù∏Î¨ºÎ°ú, Ï†ÑÏûëÏùÑ Ï∞∏Ï°∞ÌïòÍ≥† ÏûàÎã§. 1993ÎÖÑ Ïó¨Î¶ÑÏóêÎäî ÏõπÏùÑ ÏúÑÌïú Í≤ÄÏÉâ ÏóîÏßÑÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏïòÏßÄÎßå, ÏàòÎßéÏùÄ Ï†ÑÎ¨∏ÌôîÎêú Ïπ¥ÌÉàÎ°úÍ∑∏Í∞Ä ÏàòÎèôÏúºÎ°ú Í¥ÄÎ¶¨ÎêòÍ≥† ÏûàÏóàÎã§. Ï†úÎÑ§Î∞î ÎåÄÌïôÍµêÏùò Ïò§Ïä§Ïπ¥ ÎãàÏñ¥Ïä§Ìä∏ÎùºÏ¶àÎäî Ïù¥Îü¨Ìïú ÌéòÏù¥ÏßÄÎ•º Ï£ºÍ∏∞Ï†ÅÏúºÎ°ú ÎØ∏Îü¨ÎßÅÌïòÍ≥† ÌëúÏ§Ä ÌòïÏãùÏúºÎ°ú Îã§Ïãú ÏûëÏÑ±ÌïòÎäî ÏùºÎ†®Ïùò ÌéÑ Ïä§ÌÅ¨Î¶ΩÌä∏Î•º ÏûëÏÑ±ÌñàÎã§. Ïù¥Í≤ÉÏùÄ ÏõπÏùò ÏµúÏ¥àÏùò ÏõêÏãúÏ†ÅÏù∏ Í≤ÄÏÉâ ÏóîÏßÑÏù∏ W3CatalogÏùò Í∏∞Î∞òÏù¥ ÎêòÏóàÍ≥†, 1993ÎÖÑ 9Ïõî 2ÏùºÏóê Ï∂úÏãúÎêòÏóàÎã§.[17] 1993ÎÖÑ 6Ïõî, ÎãπÏãú MITÏóê Ïû¨Ìïô Ï§ëÏù¥Îçò Îß§Ìäú Í∑∏Î†àÏù¥Îäî ÏïÑÎßàÎèÑ ÏµúÏ¥àÏùò Ïõπ Î°úÎ¥áÏù∏ ÌéÑ Í∏∞Î∞òÏùò ÏõîÎìú ÏôÄÏù¥Îìú Ïõπ ÏõêÎçîÎü¨Î•º ÎßåÎì§ÏóàÍ≥†, Ïù¥Î•º ÏÇ¨Ïö©ÌïòÏó¨ \"Wandex\"ÎùºÎäî ÏÉâÏù∏ÏùÑ ÏÉùÏÑ±ÌñàÎã§. ÏõêÎçîÎü¨Ïùò Î™©Ï†ÅÏùÄ ÏõîÎìú ÏôÄÏù¥Îìú ÏõπÏùò ÌÅ¨Í∏∞Î•º Ï∏°Ï†ïÌïòÎäî Í≤ÉÏù¥ÏóàÏúºÎ©∞, 1995ÎÖÑ ÎßêÍπåÏßÄ Ïù¥ ÏûëÏóÖÏùÑ ÏàòÌñâÌñàÎã§. ÏõπÏùò Îëê Î≤àÏß∏ Í≤ÄÏÉâ ÏóîÏßÑ AliwebÏùÄ 1993ÎÖÑ 11ÏõîÏóê Îì±Ïû•ÌñàÎã§. AliwebÏùÄ Ïõπ Î°úÎ¥áÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÍ≥†, ÏõπÏÇ¨Ïù¥Ìä∏ Í¥ÄÎ¶¨ÏûêÍ∞Ä ÌäπÏ†ï ÌòïÏãùÏùò ÏÉâÏù∏ ÌååÏùºÏù¥ Í∞Å ÏÇ¨Ïù¥Ìä∏Ïóê Ï°¥Ïû¨ÌïúÎã§Îäî Í≤ÉÏùÑ ÌÜµÎ≥¥Ìï¥ Ï£ºÎäî Î∞©ÏãùÏóê ÏùòÏ°¥ÌñàÎã§. JumpStation (1993ÎÖÑ 12Ïõî Ï°∞ÎÑàÏÑ† ÌîåÎ†àÏ≤òÍ∞Ä ÎßåÎì¶[18])ÏùÄ Ïõπ Î°úÎ¥áÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïõπ ÌéòÏù¥ÏßÄÎ•º Ï∞æÍ≥† ÏÉâÏù∏ÏùÑ Íµ¨Ï∂ïÌñàÏúºÎ©∞, Ïõπ ÌèºÏùÑ ÏøºÎ¶¨ ÌîÑÎ°úÍ∑∏Îû®Ïùò Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î°ú ÏÇ¨Ïö©ÌñàÎã§. Îî∞ÎùºÏÑú Ïù¥Îäî ÏïÑÎûòÏóê ÏÑ§Î™ÖÎêú Ïõπ Í≤ÄÏÉâ ÏóîÏßÑÏùò ÏÑ∏ Í∞ÄÏßÄ ÌïÑÏàò Í∏∞Îä•(ÌÅ¨Î°§ÎßÅ, ÏÉâÏù∏Ìôî, Í≤ÄÏÉâ)ÏùÑ Í≤∞Ìï©Ìïú ÏµúÏ¥àÏùò WWW Î¶¨ÏÜåÏä§ Í≤ÄÏÉâ ÎèÑÍµ¨ÏòÄÎã§. Ïã§ÌñâÎêòÎäî ÌîåÎû´ÌèºÏùò Ï†úÌïúÎêú Î¶¨ÏÜåÏä§ ÎïåÎ¨∏Ïóê ÏÉâÏù∏Ìôî Î∞è Í≤ÄÏÉâÏùÄ ÌÅ¨Î°§Îü¨Í∞Ä Î∞úÍ≤¨Ìïú Ïõπ ÌéòÏù¥ÏßÄÏùò Ï†úÎ™©Í≥º Ìó§Îî©ÏúºÎ°ú Ï†úÌïúÎêòÏóàÎã§. ÏµúÏ¥àÏùò \"Î™®Îì† ÌÖçÏä§Ìä∏\" ÌÅ¨Î°§Îü¨ Í∏∞Î∞ò Í≤ÄÏÉâ ÏóîÏßÑ Ï§ë ÌïòÎÇòÎäî 1994ÎÖÑÏóê Ï∂úÏãúÎêú ÏõπÌÅ¨Î°§Îü¨ÏòÄÎã§. Ïù¥Ï†Ñ ÏóîÏßÑÎì§Í≥º Îã¨Î¶¨, ÏõπÌÅ¨Î°§Îü¨Îäî ÏÇ¨Ïö©ÏûêÍ∞Ä Î™®Îì† Ïõπ ÌéòÏù¥ÏßÄÏóêÏÑú Ïñ¥Îñ§ Îã®Ïñ¥Îì† Í≤ÄÏÉâÌï† Ïàò ÏûàÎèÑÎ°ù ÌóàÏö©ÌñàÏúºÎ©∞, Ïù¥Îäî Ïù¥ÌõÑ Î™®Îì† Ï£ºÏöî Í≤ÄÏÉâ ÏóîÏßÑÏùò ÌëúÏ§ÄÏù¥ ÎêòÏóàÎã§. ÎòêÌïú ÏùºÎ∞ò ÎåÄÏ§ëÏóêÍ≤å ÎÑêÎ¶¨ ÏïåÎ†§ÏßÑ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ÏóàÎã§. ÎòêÌïú 1994ÎÖÑÏóêÎäî Ïπ¥ÎÑ§Í∏∞ Î©úÎü∞ ÎåÄÌïôÍµêÏóêÏÑú ÏãúÏûëÎêú ÎùºÏù¥ÏΩîÏä§Í∞Ä Ï∂úÏãúÎêòÏñ¥ Ï£ºÏöî ÏÉÅÏóÖÏ†Å ÏÇ¨ÏóÖÏù¥ ÎêòÏóàÎã§. ÏõπÏóêÏÑú ÏµúÏ¥àÎ°ú Ïù∏Í∏∞ ÏûàÎäî Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏïºÌõÑ! Í≤ÄÏÉâÏù¥ÏóàÎã§.[19] Ï†úÎ¶¨ ÏñëÍ≥º Îç∞Ïù¥ÎπÑÎìú ÌååÏùºÎ°úÍ∞Ä 1994ÎÖÑ 1ÏõîÏóê ÏÑ§Î¶ΩÌïú ÏïºÌõÑ!Ïùò Ï≤´ Î≤àÏß∏ Ï†úÌíàÏùÄ Ïõπ ÎîîÎ†âÌÑ∞Î¶¨Ïù∏ Yahoo! DirectoryÏòÄÎã§. 1995ÎÖÑÏóêÎäî Í≤ÄÏÉâ Í∏∞Îä•Ïù¥ Ï∂îÍ∞ÄÎêòÏñ¥ ÏÇ¨Ïö©ÏûêÍ∞Ä Yahoo! DirectoryÎ•º Í≤ÄÏÉâÌï† Ïàò ÏûàÍ≤å ÎêòÏóàÎã§.[20][21] Ïù¥Îäî ÏÇ¨ÎûåÎì§Ïù¥ Í¥ÄÏã¨ ÏûàÎäî Ïõπ ÌéòÏù¥ÏßÄÎ•º Ï∞æÎäî Í∞ÄÏû• Ïù∏Í∏∞ ÏûàÎäî Î∞©Î≤ï Ï§ë ÌïòÎÇòÍ∞Ä ÎêòÏóàÏßÄÎßå, Í∑∏ Í≤ÄÏÉâ Í∏∞Îä•ÏùÄ Ïõπ ÌéòÏù¥ÏßÄÏùò Ï†ÑÏ≤¥ ÌÖçÏä§Ìä∏ ÏÇ¨Î≥∏Ïù¥ ÏïÑÎãå Ïõπ ÎîîÎ†âÌÑ∞Î¶¨ÏóêÏÑú ÏûëÎèôÌñàÎã§. Í≥ßÏù¥Ïñ¥ ÎßéÏùÄ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ Îì±Ïû•ÌïòÏó¨ Ïù∏Í∏∞Î•º Îã§Ìà¨ÏóàÎã§. Ïó¨Í∏∞ÏóêÎäî Îß§Ï†§ÎûÄ, ÏùµÏÇ¨Ïù¥Ìä∏, Ïù∏Ìè¨ÏãúÌÅ¨, ÏûâÌÅ¨ÌÜ†ÎØ∏, ÎÖ∏Îçò ÎùºÏù¥Ìä∏, ÏïåÌÉÄÎπÑÏä§ÌÉÄ Îì±Ïù¥ Ìè¨Ìï®ÎêòÏóàÎã§. Ï†ïÎ≥¥ Í≤ÄÏÉâÏûêÎì§ÏùÄ ÌÇ§ÏõåÎìú Í∏∞Î∞ò Í≤ÄÏÉâ ÎåÄÏã† ÎîîÎ†âÌÑ∞Î¶¨Î•º ÌÉêÏÉâÌï† ÏàòÎèÑ ÏûàÏóàÎã§. 1996ÎÖÑ Î¶¨ÏòåÌõôÏùÄ Í≤ÄÏÉâ ÏóîÏßÑ Í≤∞Í≥º ÌéòÏù¥ÏßÄ ÏàúÏúÑ ÏßÄÏ†ïÏùÑ ÏúÑÌïú RankDex ÏÇ¨Ïù¥Ìä∏ Ïä§ÏΩîÏñ¥ÎßÅ ÏïåÍ≥†Î¶¨Ï¶òÏùÑ Í∞úÎ∞úÌñàÍ≥†,[22][23][24] Ïù¥ Í∏∞Ïà†Î°ú ÎØ∏Íµ≠ ÌäπÌóàÎ•º Î∞õÏïòÎã§.[25] Ïù¥Îäî ÌïòÏù¥ÌçºÎßÅÌÅ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏÉâÏù∏ÌôîÌïòÎäî ÏõπÏÇ¨Ïù¥Ìä∏Ïùò ÌíàÏßàÏùÑ Ï∏°Ï†ïÌïòÎäî ÏµúÏ¥àÏùò Í≤ÄÏÉâ ÏóîÏßÑÏù¥ÏóàÏúºÎ©∞,[26] 2ÎÖÑ ÌõÑÏù∏ 1998ÎÖÑÏóê Íµ¨Í∏ÄÏù¥ Ï∂úÏõêÌïú Îß§Ïö∞ Ïú†ÏÇ¨Ìïú ÏïåÍ≥†Î¶¨Ï¶ò ÌäπÌóàÎ≥¥Îã§ ÏïûÏÑ† Í≤ÉÏù¥ÏóàÎã§.[27] ÎûòÎ¶¨ ÌéòÏù¥ÏßÄÎäî ÏûêÏã†Ïùò ÌéòÏù¥ÏßÄÎû≠ÌÅ¨ ÎØ∏Íµ≠ ÌäπÌóà Ï§ë ÏùºÎ∂ÄÏóêÏÑú Î¶¨Ïùò ÏûëÏóÖÏùÑ Ïñ∏Í∏âÌñàÎã§.[28] Î¶¨Îäî ÎÇòÏ§ëÏóê ÏûêÏã†Ïùò RankDex Í∏∞Ïà†ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ 2000ÎÖÑÏóê Ï§ëÍµ≠ÏóêÏÑú ÏÑ§Î¶ΩÌïú Î∞îÏù¥Îëê Í≤ÄÏÉâ ÏóîÏßÑÏóê Ï†ÅÏö©ÌñàÎã§. 1996ÎÖÑ, ÎÑ∑Ïä§ÏºÄÏù¥ÌîÑÎäî ÎÑ∑Ïä§ÏºÄÏù¥ÌîÑÏùò Ïõπ Î∏åÎùºÏö∞Ï†ÄÏóêÏÑú Ï£ºÏöî Í≤ÄÏÉâ ÏóîÏßÑÏúºÎ°ú Îã®Ïùº Í≤ÄÏÉâ ÏóîÏßÑÏóêÍ≤å ÎèÖÏ†ê Í≥ÑÏïΩÏùÑ Ï†úÍ≥µÌïòÎ†§ ÌñàÎã§. Í¥ÄÏã¨Ïù¥ ÎÑàÎ¨¥ ÎßéÏïÑÏÑú ÎåÄÏã† ÎÑ∑Ïä§ÏºÄÏù¥ÌîÑÎäî Ï£ºÏöî Í≤ÄÏÉâ ÏóîÏßÑ 5Í≥≥Í≥º Í≥ÑÏïΩÏùÑ Îß∫ÏóàÎã§. Ïó∞Í∞Ñ 5Î∞±Îßå Îã¨Îü¨Î•º Î∞õÍ≥† Í∞Å Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÎÑ∑Ïä§ÏºÄÏù¥ÌîÑ Í≤ÄÏÉâ ÏóîÏßÑ ÌéòÏù¥ÏßÄÏóêÏÑú Î≤àÍ∞àÏïÑ Í∞ÄÎ©∞ ÎÇòÌÉÄÎÇòÍ≤å ÎêòÏóàÎã§. Ïù¥ 5Í∞ú ÏóîÏßÑÏùÄ ÏïºÌõÑ!, Îß§Ï†§ÎûÄ, ÎùºÏù¥ÏΩîÏä§, Ïù∏Ìè¨ÏãúÌÅ¨, ÏùµÏÇ¨Ïù¥Ìä∏ÏòÄÎã§.[29][30] Íµ¨Í∏ÄÏùÄ 1998ÎÖÑ goto.comÏù¥ÎùºÎäî ÏûëÏùÄ Í≤ÄÏÉâ ÏóîÏßÑ ÌöåÏÇ¨Î°úÎ∂ÄÌÑ∞ Í≤ÄÏÉâÏñ¥ ÌåêÎß§ ÏïÑÏù¥ÎîîÏñ¥Î•º Ï±ÑÌÉùÌñàÎã§. Ïù¥ ÏõÄÏßÅÏûÑÏùÄ Í≤ÄÏÉâ ÏóîÏßÑ ÏÇ¨ÏóÖÏóê ÏÉÅÎãπÌïú ÏòÅÌñ•ÏùÑ ÎØ∏Ï≥§ÎäîÎç∞, Í≥†Ï†ÑÌïòÎçò ÏÇ¨ÏóÖÏù¥ Ïù∏ÌÑ∞ÎÑ∑ÏóêÏÑú Í∞ÄÏû• ÏàòÏùµÏÑ± ÎÜíÏùÄ ÏÇ¨ÏóÖ Ï§ë ÌïòÎÇòÎ°ú Î≥ÄÎ™®ÌñàÎã§.[31][32] Í≤ÄÏÉâ ÏóîÏßÑÏùÄ 1990ÎÖÑÎåÄ ÌõÑÎ∞òÏóê Î∞úÏÉùÌïú Ïù∏ÌÑ∞ÎÑ∑ Ìà¨Ïûê Í¥ëÌíçÏóêÏÑú Í∞ÄÏû• ÎπõÎÇòÎäî Î≥Ñ Ï§ë ÏùºÎ∂ÄÎ°úÎèÑ ÏïåÎ†§Ï†∏ ÏûàÏóàÎã§.[33] Ïó¨Îü¨ ÌöåÏÇ¨Í∞Ä ÌôîÎ†§ÌïòÍ≤å ÏãúÏû•Ïóê ÏßÑÏûÖÌïòÏó¨ Í∏∞ÏóÖÍ≥µÍ∞ú Ïãú Í∏∞Î°ùÏ†ÅÏù∏ Ïù¥ÏùµÏùÑ ÏñªÏóàÎã§. ÏùºÎ∂ÄÎäî Í≥µÍ∞ú Í≤ÄÏÉâ ÏóîÏßÑÏùÑ ÌèêÏáÑÌïòÍ≥† ÎÖ∏Îçò ÎùºÏù¥Ìä∏Ï≤òÎüº Í∏∞ÏóÖ Ï†ÑÏö© Î≤ÑÏ†ÑÏùÑ ÌåêÎß§ÌïòÍ≥† ÏûàÎã§. ÎßéÏùÄ Í≤ÄÏÉâ ÏóîÏßÑ ÌöåÏÇ¨Îäî 2000ÎÖÑ 3ÏõîÏóê Ï†ïÏ†êÏùÑ Ï∞çÏùÄ Ìà¨Í∏∞ Ï£ºÎèÑ ÏãúÏû• Ìò∏Ìô©Ïù∏ Îã∑Ïª¥Î≤ÑÎ∏îÏóê Ìú©Ïì∏Î†∏Îã§. 2000ÎÖÑÍ≤Ω Íµ¨Í∏ÄÏùò Í≤ÄÏÉâ ÏóîÏßÑÏù¥ Ïú†Î™ÖÌï¥Ï°åÎã§.[34] Ïù¥ ÌöåÏÇ¨Îäî Íµ¨Í∏ÄÏùò Ï∞ΩÎ¶ΩÏûêÏù∏ ÏÑ∏Î•¥Í≤åÏù¥ Î∏åÎ¶∞Í≥º ÎûòÎ¶¨ ÌéòÏù¥ÏßÄÍ∞Ä ÏûëÏÑ±Ìïú \"Í≤ÄÏÉâ ÏóîÏßÑÏùò Ìï¥Î∂ÄÌïô\"Ïù¥ÎùºÎäî ÎÖºÎ¨∏Ïóê ÏÑ§Î™ÖÎêú ÌéòÏù¥ÏßÄÎû≠ÌÅ¨ÎùºÎäî ÏïåÍ≥†Î¶¨Ï¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÎßéÏùÄ Í≤ÄÏÉâÏóêÏÑú Îçî ÎÇòÏùÄ Í≤∞Í≥ºÎ•º ÏñªÏóàÎã§.[6] Ïù¥ Î∞òÎ≥µ ÏïåÍ≥†Î¶¨Ï¶òÏùÄ Ï¢ãÍ±∞ÎÇò Î∞îÎûåÏßÅÌïú ÌéòÏù¥ÏßÄÍ∞Ä Îã§Î•∏ ÌéòÏù¥ÏßÄÎ≥¥Îã§ Îçî ÎßéÏù¥ ÎßÅÌÅ¨ÎêúÎã§Îäî Ï†ÑÏ†úÌïòÏóê Îã§Î•∏ ÏõπÏÇ¨Ïù¥Ìä∏ÏôÄ ÌéòÏù¥ÏßÄÏùò ÎßÅÌÅ¨ ÏàòÏôÄ ÌéòÏù¥ÏßÄÎû≠ÌÅ¨Î•º Í∏∞Î∞òÏúºÎ°ú Ïõπ ÌéòÏù¥ÏßÄÏùò ÏàúÏúÑÎ•º Îß§Í∏¥Îã§. ÎûòÎ¶¨ ÌéòÏù¥ÏßÄÏùò ÌéòÏù¥ÏßÄÎû≠ÌÅ¨ ÌäπÌóàÎäî Î¶¨ÏòåÌõôÏùò Ïù¥Ï†Ñ RankDex ÌäπÌóàÎ•º ÏòÅÌñ•ÏùÑ Ï§Ä Í≤ÉÏúºÎ°ú Ïù∏Ïö©ÌïúÎã§.[28][24] Íµ¨Í∏ÄÏùÄ ÎòêÌïú Í≤ÄÏÉâ ÏóîÏßÑÏóê ÎåÄÌïú ÎØ∏ÎãàÎ©ÄÎ¶¨Ïä§Ìä∏ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î•º Ïú†ÏßÄÌñàÎã§. ÎåÄÏ°∞Ï†ÅÏúºÎ°ú, ÎßéÏùÄ Í≤ΩÏüÅÏóÖÏ≤¥Îäî Í≤ÄÏÉâ ÏóîÏßÑÏùÑ Ïõπ Ìè¨ÌÑ∏Ïóê ÎÇ¥Ïû•ÌñàÎã§. ÏÇ¨Ïã§, Íµ¨Í∏Ä Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÎÑàÎ¨¥ Ïù∏Í∏∞Í∞Ä ÎßéÏïÑ Mystery SeekerÏôÄ Í∞ôÏùÄ Ïä§Ìë∏ÌîÑ ÏóîÏßÑÏù¥ Îì±Ïû•ÌïòÍ∏∞ÎèÑ ÌñàÎã§. 2000ÎÖÑÍπåÏßÄ ÏïºÌõÑ!Îäî ÏûâÌÅ¨ÌÜ†ÎØ∏Ïùò Í≤ÄÏÉâ ÏóîÏßÑÏùÑ Í∏∞Î∞òÏúºÎ°ú Í≤ÄÏÉâ ÏÑúÎπÑÏä§Î•º Ï†úÍ≥µÌïòÍ≥† ÏûàÏóàÎã§. ÏïºÌõÑ!Îäî 2002ÎÖÑÏóê ÏûâÌÅ¨ÌÜ†ÎØ∏Î•º, 2003ÎÖÑÏóêÎäî Ïò§Î≤ÑÏ∂îÏñ¥(AlltheWebÍ≥º ÏïåÌÉÄÎπÑÏä§ÌÉÄÎ•º ÏÜåÏú†)Î•º Ïù∏ÏàòÌñàÎã§. ÏïºÌõÑ!Îäî 2004ÎÖÑÍπåÏßÄ Íµ¨Í∏ÄÏùò Í≤ÄÏÉâ ÏóîÏßÑÏúºÎ°ú Ï†ÑÌôòÌïòÎã§Í∞Ä Ïù∏ÏàòÌïú Í∏∞Ïà†Îì§ÏùÑ Í≤∞Ìï©ÌïòÏó¨ ÏûêÏ≤¥ Í≤ÄÏÉâ ÏóîÏßÑÏùÑ Ï∂úÏãúÌñàÎã§. ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏Îäî 1998ÎÖÑ Í∞ÄÏùÑ ÏûâÌÅ¨ÌÜ†ÎØ∏Ïùò Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º ÏÇ¨Ïö©ÌïòÏó¨ MSN Í≤ÄÏÉâÏùÑ Ï≤òÏùå Ï∂úÏãúÌñàÎã§. 1999ÎÖÑ Ï¥àÏóêÎäî Î£©Ïä§ÎßàÌä∏Ïùò Î™©Î°ùÏùÑ ÏûâÌÅ¨ÌÜ†ÎØ∏Ïùò Í≤∞Í≥ºÏôÄ ÌòºÌï©ÌïòÏó¨ ÌëúÏãúÌïòÍ∏∞ ÏãúÏûëÌñàÎã§. 1999ÎÖÑ Ïû†Ïãú ÎèôÏïà MSN Í≤ÄÏÉâÏùÄ ÎåÄÏã† ÏïåÌÉÄÎπÑÏä§ÌÉÄÏùò Í≤∞Í≥ºÎ•º ÏÇ¨Ïö©ÌñàÎã§. 2004ÎÖÑ, ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏Îäî ÏûêÏ≤¥ Ïõπ ÌÅ¨Î°§Îü¨(msnbotÏù¥ÎùºÍ≥† Ìï®)Î°ú Íµ¨ÎèôÎêòÎäî ÏûêÏ≤¥ Í≤ÄÏÉâ Í∏∞Ïà†Î°ú Ï†ÑÌôòÌïòÍ∏∞ ÏãúÏûëÌñàÎã§. ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏Ïùò ÏÉàÎ°úÏö¥ Í≤ÄÏÉâ ÏóîÏßÑÏù∏ ÎπôÏùÄ 2009ÎÖÑ 6Ïõî 1ÏùºÏóê Ï∂úÏãúÎêòÏóàÎã§. 2009ÎÖÑ 7Ïõî 29Ïùº, ÏïºÌõÑ!ÏôÄ ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏Îäî ÏïºÌõÑ! Í≤ÄÏÉâÏù¥ ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏ Îπô Í∏∞Ïà†Î°ú Íµ¨ÎèôÎê† Í≤ÉÏù¥ÎùºÎäî Í≥ÑÏïΩÏùÑ ÏµúÏ¢Ö ÌôïÏ†ïÌñàÎã§. 2019ÎÖÑ Í∏∞Ï§Ä[update] ÌòÑÏû¨ ÌôúÎèô Ï§ëÏù∏ Í≤ÄÏÉâ ÏóîÏßÑ ÌÅ¨Î°§Îü¨ÏóêÎäî Íµ¨Í∏Ä, Sogou, Î∞îÏù¥Îëê, Îπô, Gigablast, Mojeek, ÎçïÎçïÍ≥† Î∞è ÏñÄÎç±Ïä§Ïùò ÌÅ¨Î°§Îü¨Í∞Ä ÏûàÎã§. Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Îã§Ïùå ÌîÑÎ°úÏÑ∏Ïä§Î•º Í±∞Ïùò Ïã§ÏãúÍ∞ÑÏúºÎ°ú Ïú†ÏßÄÌïúÎã§.[35] Ïõπ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ïõπ ÌÅ¨Î°§ÎßÅÏùÑ ÌÜµÌï¥ ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú ÏÇ¨Ïù¥Ìä∏Î°ú Ï†ïÎ≥¥Î•º ÏñªÎäîÎã§. \"Ïä§ÌååÏù¥Îçî\"Îäî ÏûêÏã†ÏóêÍ≤å Ìï†ÎãπÎêú ÌëúÏ§Ä ÌååÏùº Ïù¥Î¶ÑÏù∏ robots.txtÎ•º ÌôïÏù∏ÌïúÎã§. robots.txt ÌååÏùºÏóêÎäî Í≤ÄÏÉâ Ïä§ÌååÏù¥ÎçîÏóê Ïñ¥Îñ§ ÌéòÏù¥ÏßÄÎ•º ÌÅ¨Î°§ÎßÅÌïòÍ≥† Ïñ¥Îñ§ ÌéòÏù¥ÏßÄÎ•º ÌÅ¨Î°§ÎßÅÌïòÏßÄ ÏïäÏùÑÏßÄ ÏßÄÏãúÌïòÎäî ÏßÄÏãúÎ¨∏Ïù¥ Ìè¨Ìï®ÎêòÏñ¥ ÏûàÎã§. robots.txtÎ•º ÌôïÏù∏ÌïòÍ≥† ÌååÏùºÏùÑ Ï∞æÍ±∞ÎÇò Ï∞æÏßÄ Î™ªÌïú ÌõÑ, Ïä§ÌååÏù¥ÎçîÎäî Ï†úÎ™©, ÌéòÏù¥ÏßÄ ÎÇ¥Ïö©, ÏûêÎ∞îÏä§ÌÅ¨Î¶ΩÌä∏, Ï∫êÏä§ÏºÄÏù¥Îî© Ïä§ÌÉÄÏùº ÏãúÌä∏(CSS), Ìó§Îî© ÎòêÎäî HTML Î©îÌÉÄ ÌÉúÍ∑∏Ïùò Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÏôÄ Í∞ôÏùÄ Ïó¨Îü¨ ÏöîÏù∏Ïóê Îî∞Îùº ÌäπÏ†ï Ï†ïÎ≥¥Î•º Îã§Ïãú ÏÉâÏù∏ÌïòÎèÑÎ°ù Î≥¥ÎÇ∏Îã§. ÌäπÏ†ï ÏàòÏùò ÌéòÏù¥ÏßÄÎ•º ÌÅ¨Î°§ÎßÅÌïòÍ±∞ÎÇò, ÏÉâÏù∏ÌôîÎêú Îç∞Ïù¥ÌÑ∞ ÏñëÏù¥ ÎßéÍ±∞ÎÇò, ÏõπÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Î≥¥ÎÇ∏ ÏãúÍ∞ÑÏù¥ ÏßÄÎÇòÎ©¥ Ïä§ÌååÏù¥ÎçîÎäî ÌÅ¨Î°§ÎßÅÏùÑ Ï§ëÎã®ÌïòÍ≥† Îã§ÏùåÏúºÎ°ú ÎÑòÏñ¥Í∞ÑÎã§. \"Ïñ¥Îñ§ Ïõπ ÌÅ¨Î°§Îü¨ÎèÑ Ïã§Ï†úÎ°ú Ï†ëÍ∑º Í∞ÄÎä•Ìïú Ïõπ Ï†ÑÏ≤¥Î•º ÌÅ¨Î°§ÎßÅÌï† ÏàòÎäî ÏóÜÎã§. Î¨¥ÌïúÌïú ÏõπÏÇ¨Ïù¥Ìä∏, Ïä§ÌååÏù¥Îçî Ìä∏Îû©, Ïä§Ìå∏ Î∞è Ïã§Ï†ú ÏõπÏùò Îã§Î•∏ ÎπÑÏÉÅÏÇ¨ÌÉúÎ°ú Ïù∏Ìï¥ ÌÅ¨Î°§Îü¨Îäî ÎåÄÏã† ÌÅ¨Î°§ÎßÅ Ï†ïÏ±ÖÏùÑ Ï†ÅÏö©ÌïòÏó¨ ÏÇ¨Ïù¥Ìä∏ ÌÅ¨Î°§ÎßÅÏù¥ Ï∂©Î∂ÑÌïòÎã§Í≥† ÌåêÎã®Îê† ÏãúÍ∏∞Î•º Í≤∞Ï†ïÌïúÎã§. ÏùºÎ∂Ä ÏõπÏÇ¨Ïù¥Ìä∏Îäî Ï≤†Ï†ÄÌûà ÌÅ¨Î°§ÎßÅÎêòÏßÄÎßå, Îã§Î•∏ ÏõπÏÇ¨Ïù¥Ìä∏Îäî Î∂ÄÎ∂ÑÏ†ÅÏúºÎ°úÎßå ÌÅ¨Î°§ÎßÅÎêúÎã§.\"[37] ÏÉâÏù∏ÌôîÎûÄ Ïõπ ÌéòÏù¥ÏßÄÏóêÏÑú Î∞úÍ≤¨Îêú Îã®Ïñ¥ÏôÄ Í∏∞ÌÉÄ Ï†ïÏùò Í∞ÄÎä•Ìïú ÌÜ†ÌÅ∞ÏùÑ Ìï¥Îãπ ÎèÑÎ©îÏù∏ Ïù¥Î¶Ñ Î∞è HTML Í∏∞Î∞ò ÌïÑÎìúÏôÄ Ïó∞Í≤∞ÌïòÎäî Í≤ÉÏùÑ ÏùòÎØ∏ÌïúÎã§. Ïù¥Îü¨Ìïú Ïó∞Í≤∞ÏùÄ Í≥µÍ∞ú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•ÎêòÎ©∞ Ïõπ Í≤ÄÏÉâ ÏøºÎ¶¨Î•º ÌÜµÌï¥ Ï†ëÍ∑ºÌï† Ïàò ÏûàÎã§. ÏÇ¨Ïö©ÏûêÎ°úÎ∂ÄÌÑ∞Ïùò ÏøºÎ¶¨Îäî Îã®Ïùº Îã®Ïñ¥, Ïó¨Îü¨ Îã®Ïñ¥ ÎòêÎäî Î¨∏Ïû•Ïùº Ïàò ÏûàÎã§. ÏÉâÏù∏ÏùÄ ÏøºÎ¶¨ÏôÄ Í¥ÄÎ†®Îêú Ï†ïÎ≥¥Î•º Í∞ÄÎä•Ìïú Ìïú Îπ®Î¶¨ Ï∞æÎäî Îç∞ ÎèÑÏõÄÏù¥ ÎêúÎã§.[36] ÏÉâÏù∏Ìôî Î∞è Ï∫êÏã± Í∏∞Ïà† Ï§ë ÏùºÎ∂ÄÎäî ÏòÅÏóÖ ÎπÑÎ∞ÄÏù∏ Î∞òÎ©¥, Ïõπ ÌÅ¨Î°§ÎßÅÏùÄ Î™®Îì† ÏÇ¨Ïù¥Ìä∏Î•º Ï≤¥Í≥ÑÏ†ÅÏúºÎ°ú Î∞©Î¨∏ÌïòÎäî Í∞ÑÎã®Ìïú Í≥ºÏ†ïÏù¥Îã§. Ïä§ÌååÏù¥ÎçîÍ∞Ä Î∞©Î¨∏ÌïòÎäî ÎèôÏïà, Í≤ÄÏÉâ ÏóîÏßÑ ÏûëÏóÖ Î©îÎ™®Î¶¨Ïóê Ï†ÄÏû•Îêú ÌéòÏù¥ÏßÄÏùò Ï∫êÏãúÎêú Î≤ÑÏ†Ñ(ÌéòÏù¥ÏßÄÎ•º Î†åÎçîÎßÅÌïòÎäî Îç∞ ÌïÑÏöîÌïú ÏΩòÌÖêÏ∏†Ïùò ÏùºÎ∂Ä ÎòêÎäî Ï†ÑÎ∂Ä)Ïù¥ ÏöîÏ≤≠ÏûêÏóêÍ≤å Îπ†Î•¥Í≤å Ï†ÑÏÜ°ÎêúÎã§. Î∞©Î¨∏ Í∏∞ÌïúÏù¥ ÏßÄÎÇú Í≤ΩÏö∞, Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÎåÄÏã† Ïõπ ÌîÑÎ°ùÏãú Ïó≠Ìï†ÏùÑ Ìï† Ïàò ÏûàÎã§. Ïù¥ Í≤ΩÏö∞ ÌéòÏù¥ÏßÄÎäî ÏÉâÏù∏ÌôîÎêú Í≤ÄÏÉâÏñ¥ÏôÄ Îã§Î•º Ïàò ÏûàÎã§.[36] Ï∫êÏãúÎêú ÌéòÏù¥ÏßÄÎäî Ïù¥Ï†ÑÏóê Îã®Ïñ¥Í∞Ä ÏÉâÏù∏ÌôîÎêòÏóàÎçò Î≤ÑÏ†ÑÏùò Î™®ÏñëÏùÑ Ïú†ÏßÄÌïòÎØÄÎ°ú Ïã§Ï†ú ÌéòÏù¥ÏßÄÍ∞Ä ÏÜêÏã§ÎêòÏóàÏùÑ Îïå ÏõπÏÇ¨Ïù¥Ìä∏Ïóê Ï∫êÏãúÎêú Î≤ÑÏ†ÑÏùò ÌéòÏù¥ÏßÄÍ∞Ä Ïú†Ïö©Ìï† Ïàò ÏûàÏßÄÎßå, Ïù¥ Î¨∏Ï†ú ÎòêÌïú Í∞ÄÎ≤ºÏö¥ ÌòïÌÉúÏùò ÎßÅÌÅ¨ Íπ®ÏßêÏúºÎ°ú Í∞ÑÏ£ºÎêúÎã§. ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏÇ¨Ïö©ÏûêÍ∞Ä Í≤ÄÏÉâ ÏóîÏßÑÏóê ÏøºÎ¶¨Î•º ÏûÖÎ†•Ìï† ÎïåÏóêÎäî Î™á Í∞ÄÏßÄ ÌÇ§ÏõåÎìúÎ•º ÏÇ¨Ïö©ÌïúÎã§.[38] Ïó≠ÏÉâÏù∏ÏóêÎäî Ïù¥ÎØ∏ ÌÇ§ÏõåÎìúÎ•º Ìè¨Ìï®ÌïòÎäî ÏÇ¨Ïù¥Ìä∏Ïùò Ïù¥Î¶ÑÏù¥ ÏûàÏúºÎ©∞, Ïù¥Îì§ÏùÄ ÏÉâÏù∏ÏóêÏÑú Ï¶âÏãú ÏñªÏñ¥ÏßÑÎã§. Ïã§Ï†ú Ï≤òÎ¶¨ Î∂ÄÌïòÎäî Í≤ÄÏÉâ Í≤∞Í≥º Î™©Î°ùÏù∏ Ïõπ ÌéòÏù¥ÏßÄÎ•º ÏÉùÏÑ±ÌïòÎäî Îç∞ ÏûàÎã§. Ï†ÑÏ≤¥ Î™©Î°ùÏùò Î™®Îì† ÌéòÏù¥ÏßÄÎäî ÏÉâÏù∏Ïùò Ï†ïÎ≥¥Ïóê Îî∞Îùº Í∞ÄÏ§ëÏπòÍ∞Ä Î∂ÄÏó¨ÎêòÏñ¥Ïïº ÌïúÎã§.[36] Í∑∏Îü∞ Îã§Ïùå ÏÉÅÏúÑ Í≤ÄÏÉâ Í≤∞Í≥º Ìï≠Î™©ÏùÄ ÏùºÏπòÌïòÎäî ÌÇ§ÏõåÎìúÏùò Ïª®ÌÖçÏä§Ìä∏Î•º Î≥¥Ïó¨Ï£ºÎäî Ïä§ÎãàÌé´ÏùÑ Ï°∞Ìöå, Ïû¨Íµ¨ÏÑ± Î∞è ÎßàÌÅ¨ÏóÖÌï¥Ïïº ÌïúÎã§. Ïù¥Í≤ÉÎì§ÏùÄ Í∞Å Í≤ÄÏÉâ Í≤∞Í≥º Ïõπ ÌéòÏù¥ÏßÄÍ∞Ä ÏöîÍµ¨ÌïòÎäî Ï≤òÎ¶¨Ïùò ÏùºÎ∂ÄÏóê Î∂àÍ≥ºÌïòÎ©∞, Ï∂îÍ∞Ä ÌéòÏù¥ÏßÄ(ÏÉÅÏúÑ Îã§Ïùå)Îäî Ïù¥Îü¨Ìïú ÌõÑÏ≤òÎ¶¨ ÏûëÏóÖÏùÑ Îçî ÎßéÏù¥ ÏöîÍµ¨ÌïúÎã§. Í∞ÑÎã®Ìïú ÌÇ§ÏõåÎìú Ï°∞Ìöå Ïô∏ÏóêÎèÑ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Íµ¨Ï≤¥ÌôîÌïòÍ∏∞ ÏúÑÌï¥ ÏûêÏ≤¥Ï†ÅÏù∏ GUI ÎòêÎäî Î™ÖÎ†π Í∏∞Î∞ò Ïó∞ÏÇ∞Ïûê Î∞è Í≤ÄÏÉâ Îß§Í∞úÎ≥ÄÏàòÎ•º Ï†úÍ≥µÌïúÎã§. Ïù¥Îü¨Ìïú Í∏∞Îä•ÏùÄ Ï≤´ Í≤ÄÏÉâ Í≤∞Í≥ºÏùò Ï¥àÍ∏∞ ÌéòÏù¥ÏßÄÎ•º Í∏∞Î∞òÏúºÎ°ú ÏÇ¨Ïö©ÏûêÍ∞Ä Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º ÌïÑÌÑ∞ÎßÅÌïòÍ≥† Í∞ÄÏ§ëÏπòÎ•º Î∂ÄÏó¨ÌïòÎ©¥ÏÑú ÏÉùÏÑ±ÌïòÎäî ÌîºÎìúÎ∞± Î£®ÌîÑÏóê Ï∞∏Ïó¨ÌïòÎäî Îç∞ ÌïÑÏöîÌïú Ï†úÏñ¥Î•º Ï†úÍ≥µÌïúÎã§. ÏòàÎ•º Îì§Ïñ¥, 2007ÎÖÑÎ∂ÄÌÑ∞ Google.com Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ï¥àÍ∏∞ Í≤ÄÏÉâ Í≤∞Í≥º ÌéòÏù¥ÏßÄÏùò Í∞ÄÏû• ÏôºÏ™Ω Ïó¥ÏóêÏÑú \"Í≤ÄÏÉâ ÎèÑÍµ¨ ÌëúÏãú\"Î•º ÌÅ¥Î¶≠Ìïú Îã§Ïùå ÏõêÌïòÎäî ÎÇ†Ïßú Î≤îÏúÑÎ•º ÏÑ†ÌÉùÌïòÏó¨ ÎÇ†ÏßúÎ≥ÑÎ°ú ÌïÑÌÑ∞ÎßÅÌï† Ïàò ÏûàÎèÑÎ°ù ÌóàÏö©ÌñàÎã§.[39] Í∞Å ÌéòÏù¥ÏßÄÏóêÎäî ÏàòÏ†ï ÏãúÍ∞ÑÏù¥ ÏûàÏúºÎØÄÎ°ú ÎÇ†ÏßúÎ≥ÑÎ°ú Í∞ÄÏ§ëÏπòÎ•º Î∂ÄÏó¨ÌïòÎäî Í≤ÉÎèÑ Í∞ÄÎä•ÌïòÎã§. ÎåÄÎ∂ÄÎ∂ÑÏùò Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏµúÏ¢Ö ÏÇ¨Ïö©ÏûêÍ∞Ä Í≤ÄÏÉâ ÏøºÎ¶¨Î•º Íµ¨Ï≤¥ÌôîÌïòÎäî Îç∞ ÎèÑÏõÄÏù¥ ÎêòÎèÑÎ°ù Boolean Ïó∞ÏÇ∞Ïûê AND, OR Î∞è NOTÏùò ÏÇ¨Ïö©ÏùÑ ÏßÄÏõêÌïúÎã§. Î∂àÎ¶¨Ïñ∏ Ïó∞ÏÇ∞ÏûêÎäî ÏÇ¨Ïö©ÏûêÍ∞Ä Í≤ÄÏÉâ Ïö©Ïñ¥Î•º Íµ¨Ï≤¥ÌôîÌïòÍ≥† ÌôïÏû•Ìï† Ïàò ÏûàÎèÑÎ°ù ÌïòÎäî Î¶¨ÌÑ∞Îü¥ Í≤ÄÏÉâÏóê ÏÇ¨Ïö©ÎêúÎã§. ÏóîÏßÑÏùÄ ÏûÖÎ†•Îêú Îã®Ïñ¥ ÎòêÎäî Íµ¨Î¨∏ÏùÑ Ï†ïÌôïÌûà Ï∞æÎäîÎã§. ÏùºÎ∂Ä Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä ÌÇ§ÏõåÎìú Í∞ÑÏùò Í±∞Î¶¨Î•º Ï†ïÏùòÌï† Ïàò ÏûàÎäî Í∑ºÏ†ë Í≤ÄÏÉâÏù¥ÎùºÎäî Í≥†Í∏â Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌïúÎã§.[36] ÎòêÌïú ÏÇ¨Ïö©ÏûêÍ∞Ä Í≤ÄÏÉâÌïòÎäî Îã®Ïñ¥ ÎòêÎäî Íµ¨Î¨∏ÏùÑ Ìè¨Ìï®ÌïòÎäî ÌéòÏù¥ÏßÄÏóê ÎåÄÌïú ÌÜµÍ≥Ñ Î∂ÑÏÑùÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í∞úÎÖê Í≤ÄÏÉâÎèÑ ÏûàÎã§. Í≤ÄÏÉâ ÏóîÏßÑÏùò Ïú†Ïö©ÏÑ±ÏùÄ Î∞òÌôòÌïòÎäî Í≤∞Í≥º ÏÑ∏Ìä∏Ïùò Ï†ÅÌï©ÏÑ±Ïóê Îã¨Î†§ ÏûàÎã§. ÌäπÏ†ï Îã®Ïñ¥ÎÇò Íµ¨Î¨∏ÏùÑ Ìè¨Ìï®ÌïòÎäî ÏàòÎ∞±Îßå Í∞úÏùò Ïõπ ÌéòÏù¥ÏßÄÍ∞Ä ÏûàÏùÑ Ïàò ÏûàÏßÄÎßå, ÏùºÎ∂Ä ÌéòÏù¥ÏßÄÎäî Îã§Î•∏ ÌéòÏù¥ÏßÄÎ≥¥Îã§ Îçî Í¥ÄÎ†®ÏÑ±Ïù¥ ÎÜíÍ±∞ÎÇò, Ïù∏Í∏∞Í∞Ä ÎßéÍ±∞ÎÇò, Í∂åÏúÑÍ∞Ä ÏûàÏùÑ Ïàò ÏûàÎã§. ÎåÄÎ∂ÄÎ∂ÑÏùò Í≤ÄÏÉâ ÏóîÏßÑÏùÄ \"ÏµúÍ≥†Ïùò\" Í≤∞Í≥ºÎ•º Î®ºÏ†Ä Ï†úÍ≥µÌïòÍ∏∞ ÏúÑÌï¥ Í≤∞Í≥ºÎ•º ÏàúÏúÑ Îß§Í∏∞Îäî Î∞©Î≤ïÏùÑ ÏÇ¨Ïö©ÌïúÎã§. Í≤ÄÏÉâ ÏóîÏßÑÏù¥ Ïñ¥Îñ§ ÌéòÏù¥ÏßÄÍ∞Ä Í∞ÄÏû• ÏùºÏπòÌïòÎäîÏßÄ, Í∑∏Î¶¨Í≥† Ïñ¥Îñ§ ÏàúÏÑúÎ°ú Í≤∞Í≥ºÎ•º ÌëúÏãúÌï¥Ïïº ÌïòÎäîÏßÄÎ•º Í≤∞Ï†ïÌïòÎäî Î∞©Î≤ïÏùÄ ÏóîÏßÑÎßàÎã§ ÌÅ¨Í≤å Îã§Î•¥Îã§.[36] Ïù¥Îü¨Ìïú Î∞©Î≤ïÏùÄ Ïù∏ÌÑ∞ÎÑ∑ ÏÇ¨Ïö©Ïù¥ Î≥ÄÌïòÍ≥† ÏÉàÎ°úÏö¥ Í∏∞Ïà†Ïù¥ Î∞úÏ†ÑÌï®Ïóê Îî∞Îùº ÏãúÍ∞ÑÍ≥º Ìï®Íªò Î≥ÄÌïúÎã§. ÏßÑÌôîÌïú Í≤ÄÏÉâ ÏóîÏßÑÏùò Ï£ºÏöî Ïú†ÌòïÏùÄ Îëê Í∞ÄÏßÄÎã§. ÌïòÎÇòÎäî Ïù∏Í∞ÑÏù¥ Í¥ëÎ≤îÏúÑÌïòÍ≤å ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÌïú ÎØ∏Î¶¨ Ï†ïÏùòÎêòÍ≥† Í≥ÑÏ∏µÏ†ÅÏúºÎ°ú Ï†ïÎ†¨Îêú ÌÇ§ÏõåÎìú ÏãúÏä§ÌÖúÏù¥Îã§. Îã§Î•∏ ÌïòÎÇòÎäî Ï∞æÏùÄ ÌÖçÏä§Ìä∏Î•º Î∂ÑÏÑùÌïòÏó¨ \"Ïó≠ÏÉâÏù∏\"ÏùÑ ÏÉùÏÑ±ÌïòÎäî ÏãúÏä§ÌÖúÏù¥Îã§. Ï≤´ Î≤àÏß∏ ÌòïÌÉúÎäî Ïª¥Ìì®ÌÑ∞ ÏûêÏ≤¥Ïóê Ìõ®Ïî¨ Îçî ÎßéÏù¥ ÏùòÏ°¥ÌïòÏó¨ ÎåÄÎ∂ÄÎ∂ÑÏùò ÏûëÏóÖÏùÑ ÏàòÌñâÌïúÎã§. ÎåÄÎ∂ÄÎ∂ÑÏùò Ïõπ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Í¥ëÍ≥† ÏàòÏùµÏúºÎ°ú Ïö¥ÏòÅÎêòÎäî ÏÉÅÏóÖÏ†Å ÏÇ¨ÏóÖÏù¥ÎØÄÎ°ú, ÏùºÎ∂ÄÎäî Í¥ëÍ≥†Ï£ºÍ∞Ä Ïú†Î£åÎ°ú Í≤ÄÏÉâ Í≤∞Í≥ºÏóêÏÑú ÏûêÏã†Ïùò Î™©Î°ù ÏàúÏúÑÎ•º ÎÜíÏùº Ïàò ÏûàÎèÑÎ°ù ÌóàÏö©ÌïúÎã§. Í≤ÄÏÉâ Í≤∞Í≥ºÏóê ÎåÄÌï¥ ÎèàÏùÑ Î∞õÏßÄ ÏïäÎäî Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏùºÎ∞ò Í≤ÄÏÉâ ÏóîÏßÑ Í≤∞Í≥ºÏôÄ Ìï®Íªò Í≤ÄÏÉâ Í¥ÄÎ†® Í¥ëÍ≥†Î•º Í≤åÏû¨ÌïòÏó¨ ÎèàÏùÑ Î≤àÎã§. Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÎàÑÍµ∞Í∞Ä Ïù¥Îü¨Ìïú Í¥ëÍ≥†Î•º ÌÅ¥Î¶≠Ìï† ÎïåÎßàÎã§ ÎèàÏùÑ Î≤àÎã§.[40] ÏßÄÏó≠ Í≤ÄÏÉâÏùÄ ÏßÄÏó≠ ÎπÑÏ¶àÎãàÏä§Ïùò ÎÖ∏Î†•ÏùÑ ÏµúÏ†ÅÌôîÌïòÎäî Í≥ºÏ†ïÏù¥Îã§. Ïù¥Îì§ÏùÄ ÏùºÍ¥ÄÎêú Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Î≥¥Ïû•ÌïòÎäî Îç∞ Ï§ëÏ†êÏùÑ ÎëîÎã§. ÎßéÏùÄ ÏÇ¨ÎûåÎì§Ïù¥ Í≤ÄÏÉâÏùÑ Í∏∞Î∞òÏúºÎ°ú Ïñ¥ÎîîÎ°ú Í∞àÏßÄ, Î¨¥ÏóáÏùÑ ÏÇ¥ÏßÄ Í≤∞Ï†ïÌïòÍ∏∞ ÎïåÎ¨∏Ïóê Ï§ëÏöîÌïòÎã§.[41] 2022ÎÖÑ 01Ïõî Í∏∞Ï§Ä[update] Íµ¨Í∏ÄÏùÄ Ï†Ñ ÏÑ∏Í≥ÑÏóêÏÑú Í∞ÄÏû• ÎßéÏù¥ ÏÇ¨Ïö©ÎêòÎäî Í≤ÄÏÉâ ÏóîÏßÑÏúºÎ°ú ÏãúÏû• Ï†êÏú†Ïú® 90%Î•º Ï∞®ÏßÄÌïòÍ≥† ÏûàÏúºÎ©∞, ÏÑ∏Í≥ÑÏóêÏÑú Îëê Î≤àÏß∏Î°ú ÎßéÏù¥ ÏÇ¨Ïö©ÎêòÎäî Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÎπôÏù¥ 4%, ÏñÄÎç±Ïä§Í∞Ä 2%, ÏïºÌõÑ!Í∞Ä 1%Î•º Ï∞®ÏßÄÌñàÎã§. Î™©Î°ùÏóê ÏóÜÎäî Îã§Î•∏ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏãúÏû• Ï†êÏú†Ïú®Ïù¥ 3% ÎØ∏ÎßåÏù¥Îã§.[42] 2024ÎÖÑ, Íµ¨Í∏ÄÏùò ÏßÄÎ∞∞Î†•ÏùÄ ÎØ∏Íµ≠ Î≤ïÎ¨¥Î∂ÄÍ∞Ä Ï†úÍ∏∞Ìïú ÏÜåÏÜ°ÏóêÏÑú Î∂àÎ≤ï ÎèÖÏ†êÏúºÎ°ú ÌåêÍ≤∞ÎêòÏóàÎã§.[43] Îü¨ÏãúÏïÑÏóêÏÑú ÏñÄÎç±Ïä§Îäî 62.6%Ïùò ÏãúÏû• Ï†êÏú†Ïú®ÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÏúºÎ©∞, Íµ¨Í∏ÄÏùÄ 28.3%Ïù¥Îã§. ÏñÄÎç±Ïä§Îäî ÏïÑÏãúÏïÑÏôÄ Ïú†ÎüΩÏóêÏÑú Ïä§ÎßàÌä∏Ìè∞ÏóêÏÑú Îëê Î≤àÏß∏Î°ú ÎßéÏù¥ ÏÇ¨Ïö©ÎêòÎäî Í≤ÄÏÉâ ÏóîÏßÑÏù¥Îã§.[44] Ï§ëÍµ≠ÏóêÏÑúÎäî Î∞îÏù¥ÎëêÍ∞Ä Í∞ÄÏû• Ïù∏Í∏∞ ÏûàÎäî Í≤ÄÏÉâ ÏóîÏßÑÏù¥Îã§.[45] ÌïúÍµ≠ Í∏∞Î∞ò Í≤ÄÏÉâ Ìè¨ÌÑ∏Ïù∏ ÎÑ§Ïù¥Î≤ÑÎäî Íµ≠ÎÇ¥ Ïò®ÎùºÏù∏ Í≤ÄÏÉâÏùò 62.8%Î•º Ï∞®ÏßÄÌïúÎã§.[46] Yahoo! JapanÍ≥º Yahoo! TaiwanÏùÄ Í∞ÅÍ∞Å ÏùºÎ≥∏Í≥º ÎåÄÎßåÏóêÏÑú Ïù∏ÌÑ∞ÎÑ∑ Í≤ÄÏÉâÏóê Í∞ÄÏû• Ïù∏Í∏∞ ÏûàÎäî ÏÑ†ÌÉùÏßÄÏù¥Îã§.[47] Ï§ëÍµ≠ÏùÄ Íµ¨Í∏ÄÏù¥ Ïõπ Í≤ÄÏÉâ ÏóîÏßÑ ÏãúÏû• Ï†êÏú†Ïú® ÏÉÅÏúÑ 3ÏúÑÏóê Îì§ÏßÄ Î™ªÌïòÎäî Î™á Ïïà ÎêòÎäî Íµ≠Í∞Ä Ï§ë ÌïòÎÇòÏù¥Îã§. Íµ¨Í∏ÄÏùÄ Ïù¥Ï†ÑÏóê Ï§ëÍµ≠ÏóêÏÑú Îçî Ïù∏Í∏∞Í∞Ä ÏûàÏóàÏßÄÎßå, Í≤ÄÏó¥Í≥º ÏÇ¨Ïù¥Î≤Ñ Í≥µÍ≤©Ïóê ÎåÄÌïú Ï†ïÎ∂ÄÏôÄÏùò Î∂àÌôîÎ°ú Ïù∏Ìï¥ ÌÅ¨Í≤å Ï≤†ÏàòÌñàÎã§. Í∑∏Îü¨ÎÇò ÎπôÏùÄ 14.95%Ïùò ÏãúÏû• Ï†êÏú†Ïú®Î°ú Ïõπ Í≤ÄÏÉâ ÏóîÏßÑ ÏÉÅÏúÑ 3ÏúÑÏóê ÏÜçÌïúÎã§. Î∞îÏù¥ÎëêÎäî 49.1%Ïùò ÏãúÏû• Ï†êÏú†Ïú®Î°ú ÏÑ†ÎëêÎ•º Îã¨Î¶¨Í≥† ÏûàÎã§.[48] Ïú†ÎüΩ Ïó∞Ìï© ÎåÄÎ∂ÄÎ∂ÑÏùò Íµ≠Í∞Ä ÏãúÏû•ÏùÄ Íµ¨Í∏ÄÏù¥ ÏßÄÎ∞∞ÌïòÍ≥† ÏûàÏúºÎ©∞, Ï≤¥ÏΩîÏóêÏÑúÎäî SeznamÏù¥ Í∞ïÎ†•Ìïú Í≤ΩÏüÅÏûêÏù¥Îã§.[49] Í≤ÄÏÉâ ÏóîÏßÑ QwantÎäî ÌîÑÎûëÏä§ ÌååÎ¶¨Ïóê Î≥∏ÏÇ¨Î•º ÎëêÍ≥† ÏûàÏúºÎ©∞, ÎåÄÎ∂ÄÎ∂ÑÏùò ÏõîÍ∞Ñ 5Ï≤úÎßå Î™ÖÏùò Îì±Î°ù ÏÇ¨Ïö©ÏûêÎ•º Ïù¥Í≥≥ÏóêÏÑú Ïú†ÏπòÌïúÎã§. Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ïù∏Í∏∞ÎèÑÏôÄ Í¥ÄÎ†®ÏÑ± Ï°∞Ìï©ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÏõπÏÇ¨Ïù¥Ìä∏ ÏàúÏúÑÎ•º Îß§Í∏∞ÎèÑÎ°ù ÌîÑÎ°úÍ∑∏Îû®ÎêòÏñ¥ ÏûàÏßÄÎßå, Ïã§Ï¶ù Ïó∞Íµ¨Ïóê Îî∞Î•¥Î©¥ Ï†úÍ≥µÌïòÎäî Ï†ïÎ≥¥ÏôÄ[50][51] Í∏∞Ïà†Ïùò Í∏∞Î≥∏ Í∞ÄÏ†ïÏóê[52] Îã§ÏñëÌïú Ï†ïÏπòÏ†Å, Í≤ΩÏ†úÏ†Å, ÏÇ¨ÌöåÏ†Å Ìé∏Ìñ•Ïù¥ Ï°¥Ïû¨Ìï®ÏùÑ ÎÇòÌÉÄÎÇ∏Îã§. Ïù¥Îü¨Ìïú Ìé∏Ìñ•ÏùÄ Í≤ΩÏ†úÏ†Å Î∞è ÏÉÅÏóÖÏ†Å Í≥ºÏ†ï(Ïòà: Í≤ÄÏÉâ ÏóîÏßÑÏóê Í¥ëÍ≥†ÌïòÎäî ÌöåÏÇ¨Í∞Ä ÏûêÏó∞ Í≤ÄÏÉâ Í≤∞Í≥ºÏóêÏÑú Îçî Ïù∏Í∏∞Î•º ÏñªÏùÑ Ïàò ÏûàÏùå)Í≥º Ï†ïÏπòÏ†Å Í≥ºÏ†ï(Ïòà: ÌòÑÏßÄ Î≤ïÎ•† Ï§ÄÏàòÎ•º ÏúÑÌïú Í≤ÄÏÉâ Í≤∞Í≥º ÏÇ≠Ï†ú)Ïùò ÏßÅÏ†ëÏ†ÅÏù∏ Í≤∞Í≥ºÏùº Ïàò ÏûàÎã§.[53] ÏòàÎ•º Îì§Ïñ¥, Íµ¨Í∏ÄÏùÄ ÌôÄÎ°úÏΩîÏä§Ìä∏ Î∂ÄÏ†ïÏù¥ Î∂àÎ≤ïÏù∏ ÌîÑÎûëÏä§ÏôÄ ÎèÖÏùºÏóêÏÑúÎäî ÌäπÏ†ï ÎÑ§Ïò§ÎÇòÏπò ÏõπÏÇ¨Ïù¥Ìä∏Î•º Í≤ÄÏÉâ Í≤∞Í≥ºÏóê ÌëúÏãúÌïòÏßÄ ÏïäÎäîÎã§. Ìé∏Ìñ•ÏùÄ ÎòêÌïú ÏÇ¨ÌöåÏ†Å Í≥ºÏ†ïÏùò Í≤∞Í≥ºÏùº ÏàòÎèÑ ÏûàÎäîÎç∞, Í≤ÄÏÉâ ÏóîÏßÑ ÏïåÍ≥†Î¶¨Ï¶òÏùÄ Ï¢ÖÏ¢Ö ÎπÑÏ†ïÍ∑úÏ†ÅÏù∏ Í¥ÄÏ†êÏùÑ Î∞∞Ï†úÌïòÍ≥† Îçî \"Ïù∏Í∏∞ ÏûàÎäî\" Í≤∞Í≥ºÎ•º ÏÑ†Ìò∏ÌïòÎèÑÎ°ù ÏÑ§Í≥ÑÎêòÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§.[54] Ï£ºÏöî Í≤ÄÏÉâ ÏóîÏßÑÏùò ÏÉâÏù∏Ìôî ÏïåÍ≥†Î¶¨Ï¶òÏùÄ ÎπÑÎØ∏Íµ≠ Íµ≠Í∞ÄÏùò ÏõπÏÇ¨Ïù¥Ìä∏Î≥¥Îã§ ÎØ∏Íµ≠ Í∏∞Î∞ò ÏÇ¨Ïù¥Ìä∏Ïùò Ï†ÅÏö© Î≤îÏúÑÏóê Ìé∏Ìñ•ÎêòÏñ¥ ÏûàÎã§.[51] Íµ¨Í∏Ä Ìè≠ÌÉÑÏùÄ Ï†ïÏπòÏ†Å, ÏÇ¨ÌöåÏ†Å ÎòêÎäî ÏÉÅÏóÖÏ†Å Î™©Ï†ÅÏúºÎ°ú Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Ï°∞ÏûëÌïòÎ†§Îäî ÏãúÎèÑÏùò Ìïú ÏòàÏù¥Îã§. Ïó¨Îü¨ ÌïôÏûêÎì§Ïù¥ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ Ï¥âÎ∞úÌïú Î¨∏ÌôîÏ†Å Î≥ÄÌôî,[55] Í∑∏Î¶¨Í≥† ÏïÑÏùºÎûúÎìúÏóêÏÑúÏùò ÌÖåÎü¨Î¶¨Ï¶ò,[56] Í∏∞ÌõÑ Î≥ÄÌôî Î∂ÄÏ†ï,[57] Î∞è ÏùåÎ™®Î°†Í≥º Í∞ôÏùÄ ÎÖºÎûÄÏù¥ ÎßéÏùÄ Ï£ºÏ†úÏùò Í≤ÄÏÉâ Í≤∞Í≥º ÌëúÌòÑÏùÑ Ïó∞Íµ¨ÌñàÎã§.[58] Íµ¨Í∏ÄÏù¥ÎÇò ÎπôÍ≥º Í∞ôÏùÄ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏÇ¨Ïö©ÏûêÏùò ÌôúÎèô Í∏∞Î°ùÏóê Í∏∞Î∞òÌïòÏó¨ ÎßûÏ∂§ Í≤∞Í≥ºÎ•º Ï†úÍ≥µÌïòÏó¨, ÏùºÎùºÏù¥ ÌååÎ¶¨Ï†ÄÍ∞Ä 2011ÎÖÑÏóê ÏóêÏΩî Ï±îÎ≤Ñ ÎòêÎäî ÌïÑÌÑ∞ Î≤ÑÎ∏îÏù¥ÎùºÍ≥† Î∂ÄÎ•∏ ÌòÑÏÉÅÏúºÎ°ú Ïù¥Ïñ¥ÏßÑÎã§Îäî Ïö∞Î†§Í∞Ä Ï†úÍ∏∞ÎêòÏóàÎã§.[59] Ï£ºÏû•ÏùÄ Í≤ÄÏÉâ ÏóîÏßÑÍ≥º ÏÜåÏÖú ÎØ∏ÎîîÏñ¥ ÌîåÎû´ÌèºÏù¥ ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥(ÏúÑÏπò, Í≥ºÍ±∞ ÌÅ¥Î¶≠ ÌñâÎèô Î∞è Í≤ÄÏÉâ Í∏∞Î°ù Îì±)Î•º Í∏∞Î∞òÏúºÎ°ú ÏÇ¨Ïö©ÏûêÍ∞Ä Î≥¥Í≥† Ïã∂Ïñ¥Ìï† Ï†ïÎ≥¥Î•º ÏÑ†ÌÉùÏ†ÅÏúºÎ°ú Ï∂îÏ∏°ÌïòÍ∏∞ ÏúÑÌï¥ ÏïåÍ≥†Î¶¨Ï¶òÏùÑ ÏÇ¨Ïö©ÌïúÎã§Îäî Í≤ÉÏù¥Îã§. Í≤∞Í≥ºÏ†ÅÏúºÎ°ú ÏõπÏÇ¨Ïù¥Ìä∏Îäî ÏÇ¨Ïö©ÏûêÏùò Í≥ºÍ±∞ Í¥ÄÏ†êÍ≥º ÏùºÏπòÌïòÎäî Ï†ïÎ≥¥ÎßåÏùÑ Î≥¥Ïó¨Ï£ºÎäî Í≤ΩÌñ•Ïù¥ ÏûàÎã§. ÏùºÎùºÏù¥ ÌååÎ¶¨Ï†ÄÏóê Îî∞Î•¥Î©¥, ÏÇ¨Ïö©ÏûêÎì§ÏùÄ ÏÉÅÏ∂©ÎêòÎäî Í¥ÄÏ†êÏóê Îçú ÎÖ∏Ï∂úÎêòÍ≥† ÏûêÏã†Ïùò Ï†ïÎ≥¥ Í±∞Ìíà ÏÜçÏóê ÏßÄÏ†ÅÏúºÎ°ú Í≥†Î¶ΩÎêúÎã§. Ïù¥ Î¨∏Ï†úÍ∞Ä ÌôïÏù∏Îêú Ïù¥ÌõÑ, ÎçïÎçïÍ≥†ÏôÄ Í∞ôÏù¥ ÏÇ¨Ïö©ÏûêÎ•º Ï∂îÏ†ÅÌïòÍ±∞ÎÇò \"Í±∞ÌíàÏùÑ ÎßåÎì§ÏßÄ\" ÏïäÏïÑ Ïù¥ Î¨∏Ï†úÎ•º ÌîºÌïòÎ†§Îäî Í≤ΩÏüÅ Í≤ÄÏÉâ ÏóîÏßÑÎì§Ïù¥ Îì±Ïû•ÌñàÎã§. Í∑∏Îü¨ÎÇò ÎßéÏùÄ ÌïôÏûêÎì§ÏùÄ ÌååÎ¶¨Ï†ÄÏùò Í≤¨Ìï¥Ïóê ÏùòÎ¨∏ÏùÑ Ï†úÍ∏∞ÌïòÎ©∞, ÌïÑÌÑ∞ Î≤ÑÎ∏îÏóê ÎåÄÌïú Ï¶ùÍ±∞Í∞Ä Í±∞Ïùò ÏóÜÏùåÏùÑ Î∞úÍ≤¨ÌñàÎã§.[60][61][62] Ïò§ÌûàÎ†§ ÌïÑÌÑ∞ Î≤ÑÎ∏îÏùò Ï°¥Ïû¨Î•º ÌôïÏù∏ÌïòÎ†§Îäî Ïó¨Îü¨ Ïó∞Íµ¨Îäî Í≤ÄÏÉâÏóêÏÑú ÏÇ¨ÏÜåÌïú ÏàòÏ§ÄÏùò Í∞úÏù∏ÌôîÎßåÏùÑ Î∞úÍ≤¨ÌñàÏúºÎ©∞,[62] ÎåÄÎ∂ÄÎ∂ÑÏùò ÏÇ¨ÎûåÎì§Ïù¥ Ïò®ÎùºÏù∏ÏóêÏÑú Îã§ÏñëÌïú Í¥ÄÏ†êÏùÑ Ï†ëÌïòÍ≥†, Íµ¨Í∏Ä Îâ¥Ïä§Îäî Ï£ºÎ•ò Ïñ∏Î°†ÏùÑ ÌôçÎ≥¥ÌïòÎäî Í≤ΩÌñ•Ïù¥ ÏûàÏùåÏùÑ Î∞úÍ≤¨ÌñàÎã§.[63][61] ÏßÄÎÇú 10ÎÖÑÍ∞Ñ ÏïÑÎûç Î∞è Ïù¥Ïä¨Îûå ÏÑ∏Í≥ÑÏóêÏÑú Ïù∏ÌÑ∞ÎÑ∑Í≥º Ï†ÑÏûê ÎØ∏ÎîîÏñ¥Ïùò Ï†Ñ ÏÑ∏Í≥ÑÏ†ÅÏù∏ ÏÑ±Ïû•ÏùÄ Ï§ëÎèô Î∞è ÏïÑÏãúÏïÑ ÏïÑÎåÄÎ•ôÏùò Ïù¥Ïä¨Îûå Ïã†ÎèÑÎì§ÏóêÍ≤å ÏûêÏ≤¥ Í≤ÄÏÉâ ÏóîÏßÑ, Ï¶â ÏÇ¨Ïö©ÏûêÍ∞Ä ÏïàÏ†Ñ Í≤ÄÏÉâÏùÑ ÏàòÌñâÌï† Ïàò ÏûàÎèÑÎ°ù ÌïòÎäî ÏûêÏ≤¥ ÌïÑÌÑ∞ÎßÅÎêú Í≤ÄÏÉâ Ìè¨ÌÑ∏ÏùÑ ÏãúÎèÑÌïòÎèÑÎ°ù Ïû•Î†§ÌñàÎã§. ÏùºÎ∞òÏ†ÅÏù∏ ÏïàÏ†Ñ Í≤ÄÏÉâ ÌïÑÌÑ∞Î≥¥Îã§ Îçî ÎßéÏùÄ Ïù¥Ïä¨Îûå Ïõπ Ìè¨ÌÑ∏ÏùÄ ÏÉ§Î¶¨ÏïÑ Î≤ï Ìï¥ÏÑùÏóê Îî∞Îùº ÏõπÏÇ¨Ïù¥Ìä∏Î•º \"Ìï†ÎûÑ\" ÎòêÎäî \"ÌïòÎûå\"ÏúºÎ°ú Î∂ÑÎ•òÌïúÎã§. ImHalalÏùÄ 2011ÎÖÑ 9ÏõîÏóê Ïò®ÎùºÏù∏ÏúºÎ°ú Ï∂úÏãúÎêòÏóàÎã§. HalalgooglingÏùÄ 2013ÎÖÑ 7ÏõîÏóê Ïò®ÎùºÏù∏ÏúºÎ°ú Ï∂úÏãúÎêòÏóàÎã§. Ïù¥Îì§ÏùÄ Íµ¨Í∏ÄÍ≥º Îπô(Î∞è Í∏∞ÌÉÄ)ÏóêÏÑú ÏàòÏßëÎêú ÎÇ¥Ïö©Ïóê ÌïòÎûå ÌïÑÌÑ∞Î•º ÏÇ¨Ïö©ÌïúÎã§.[64] Ìà¨Ïûê Î∂ÄÏ°±Í≥º Ïù¥Ïä¨Îûå ÏÑ∏Í≥Ñ Í∏∞Ïà† Î∞úÏ†ÑÏùò ÎçîÎîò ÏÜçÎèÑÍ∞Ä Ïù¥Ïä¨Îûå Í≤ÄÏÉâ ÏóîÏßÑÏùò Î∞úÏ†ÑÍ≥º ÏÑ±Í≥µÏùÑ Î∞©Ìï¥ÌñàÏßÄÎßå, Ï£ºÏöî ÏÜåÎπÑÏ∏µÏù∏ Ïù¥Ïä¨Îûå Ïã†ÎèÑÎ•º ÎåÄÏÉÅÏúºÎ°ú ÌïòÎäî Muxlim(Î¨¥Ïä¨Î¶º ÎùºÏù¥ÌîÑÏä§ÌÉÄÏùº ÏÇ¨Ïù¥Ìä∏)Í≥º Í∞ôÏùÄ ÌîÑÎ°úÏ†ùÌä∏Îäî Rite Internet VenturesÏôÄ Í∞ôÏùÄ Ìà¨ÏûêÏûêÎ°úÎ∂ÄÌÑ∞ ÏàòÎ∞±Îßå Îã¨Îü¨Î•º Î∞õÏïòÏßÄÎßå Ïó≠Ïãú Ïã§Ìå®ÌñàÎã§. Îã§Î•∏ Ï¢ÖÍµê ÏßÄÌñ• Í≤ÄÏÉâ ÏóîÏßÑÏúºÎ°úÎäî Íµ¨Í∏ÄÏùò Ïú†ÎåÄÏù∏ Î≤ÑÏ†ÑÏù∏ JewogleÍ≥º[65] Í∏∞ÎèÖÍµê Í≤ÄÏÉâ ÏóîÏßÑÏù∏ SeekFind.orgÍ∞Ä ÏûàÎã§. SeekFindÎäî Ïã†ÏïôÏùÑ Í≥µÍ≤©ÌïòÍ±∞ÎÇò ÌõºÏÜêÌïòÎäî ÏÇ¨Ïù¥Ìä∏Î•º ÌïÑÌÑ∞ÎßÅÌïúÎã§.[66] Ïõπ Í≤ÄÏÉâ ÏóîÏßÑ Ï†úÏ∂úÏùÄ ÏõπÎßàÏä§ÌÑ∞Í∞Ä ÏõπÏÇ¨Ïù¥Ìä∏Î•º Í≤ÄÏÉâ ÏóîÏßÑÏóê ÏßÅÏ†ë Ï†úÏ∂úÌïòÎäî Í≥ºÏ†ïÏù¥Îã§. Í≤ÄÏÉâ ÏóîÏßÑ Ï†úÏ∂úÏùÄ ÎïåÎïåÎ°ú ÏõπÏÇ¨Ïù¥Ìä∏Î•º ÌôçÎ≥¥ÌïòÎäî Î∞©Î≤ïÏúºÎ°ú Ï†úÏãúÎêòÏßÄÎßå, ÏùºÎ∞òÏ†ÅÏúºÎ°úÎäî ÌïÑÏöîÌïòÏßÄ ÏïäÎã§. Ï£ºÏöî Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ïõπ ÌÅ¨Î°§Îü¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ïù∏ÌÑ∞ÎÑ∑ÏÉÅÏùò ÎåÄÎ∂ÄÎ∂ÑÏùò ÏõπÏÇ¨Ïù¥Ìä∏Î•º ÎèÑÏõÄ ÏóÜÏù¥ÎèÑ Í≤∞Íµ≠ Ï∞æÏïÑÎÇ¥Í∏∞ ÎïåÎ¨∏Ïù¥Îã§. ÏõπÎßàÏä§ÌÑ∞Îäî Ìïú Î≤àÏóê Ìïú Ïõπ ÌéòÏù¥ÏßÄÎ•º Ï†úÏ∂úÌïòÍ±∞ÎÇò, ÏÇ¨Ïù¥Ìä∏ÎßµÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ï†ÑÏ≤¥ ÏÇ¨Ïù¥Ìä∏Î•º Ï†úÏ∂úÌï† Ïàò ÏûàÏßÄÎßå, Í≤ÄÏÉâ ÏóîÏßÑÏù¥ Ïûò ÏÑ§Í≥ÑÎêú ÏõπÏÇ¨Ïù¥Ìä∏Î•º ÌÅ¨Î°§ÎßÅÌï† Ïàò ÏûàÏúºÎØÄÎ°ú ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏõπÏÇ¨Ïù¥Ìä∏Ïùò ÌôàÌéòÏù¥ÏßÄÎßå Ï†úÏ∂úÌïòÎ©¥ ÎêúÎã§. ÏõπÏÇ¨Ïù¥Ìä∏ ÎòêÎäî Ïõπ ÌéòÏù¥ÏßÄÎ•º Í≤ÄÏÉâ ÏóîÏßÑÏóê Ï†úÏ∂úÌï¥Ïïº ÌïòÎäî Îëê Í∞ÄÏßÄ ÎÇ®ÏùÄ Ïù¥Ïú†Îäî Îã§ÏùåÍ≥º Í∞ôÎã§. Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏÉàÎ°úÏö¥ ÏõπÏÇ¨Ïù¥Ìä∏Î•º Î∞úÍ≤¨Ìï† ÎïåÍπåÏßÄ Í∏∞Îã§Î¶¨ÏßÄ ÏïäÍ≥† ÏôÑÏ†ÑÌûà ÏÉàÎ°úÏö¥ ÏõπÏÇ¨Ïù¥Ìä∏Î•º Ï∂îÍ∞ÄÌïòÎäî Í≤ΩÏö∞, Í∑∏Î¶¨Í≥† ÏõπÏÇ¨Ïù¥Ìä∏Í∞Ä ÌÅ¨Í≤å Ïû¨ÏÑ§Í≥ÑÎêú ÌõÑ ÏõπÏÇ¨Ïù¥Ìä∏ Í∏∞Î°ùÏùÑ ÏóÖÎç∞Ïù¥Ìä∏ÌïòÎäî Í≤ΩÏö∞Ïù¥Îã§. ÏùºÎ∂Ä Í≤ÄÏÉâ ÏóîÏßÑ Ï†úÏ∂ú ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Îäî Ïó¨Îü¨ Í≤ÄÏÉâ ÏóîÏßÑÏóê ÏõπÏÇ¨Ïù¥Ìä∏Î•º Ï†úÏ∂úÌï† ÎøêÎßå ÏïÑÎãàÎùº, ÏûêÏ≤¥ ÌéòÏù¥ÏßÄÏóêÏÑú ÏõπÏÇ¨Ïù¥Ìä∏Î°úÏùò ÎßÅÌÅ¨Î•º Ï∂îÍ∞ÄÌïúÎã§. Ïù¥Îäî ÏõπÏÇ¨Ïù¥Ìä∏Ïùò Îû≠ÌÇπÏùÑ ÎÜíÏù¥Îäî Îç∞ ÎèÑÏõÄÏù¥ Îê† Ïàò ÏûàÎäîÎç∞, Ïô∏Î∂Ä ÎßÅÌÅ¨Í∞Ä ÏõπÏÇ¨Ïù¥Ìä∏ Îû≠ÌÇπÏùÑ Í≤∞Ï†ïÌïòÎäî Í∞ÄÏû• Ï§ëÏöîÌïú ÏöîÏÜå Ï§ë ÌïòÎÇòÏù¥Í∏∞ ÎïåÎ¨∏Ïù¥Îã§. Í∑∏Îü¨ÎÇò Íµ¨Í∏ÄÏùò Ï°¥ ÎÆ¨Îü¨Îäî Ïù¥Í≤ÉÏù¥ \"ÏÇ¨Ïù¥Ìä∏Ïóê ÏóÑÏ≤≠ÎÇú ÏàòÏùò Î∂ÄÏûêÏó∞Ïä§Îü¨Ïö¥ ÎßÅÌÅ¨Î•º Ï¥àÎûòÌï† Ïàò ÏûàÏúºÎ©∞\" ÏÇ¨Ïù¥Ìä∏ Îû≠ÌÇπÏóê Î∂ÄÏ†ïÏ†ÅÏù∏ ÏòÅÌñ•ÏùÑ ÎØ∏Ïπ† Ïàò ÏûàÎã§Í≥† Î∞ùÌòîÎã§.[67] ÏµúÏ¥àÏùò Ïõπ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ 1990ÎÖÑ[68] Î™¨Ìä∏Î¶¨Ïò¨Ïùò Îß•Í∏∏ ÎåÄÌïôÍµê ÌïôÏÉùÏù¥ÏóàÎçò Ïï®Îü∞ Ïó†Ìã∞ÏßÄÍ∞Ä ÎßåÎì† ÏïÑÌÇ§ÏòÄÎã§. Ï†ÄÏûêÎäî ÏõêÎûò Ïù¥ ÌîÑÎ°úÍ∑∏Îû®ÏùÑ \"ÏïÑÏπ¥Ïù¥Î∏å\"ÎùºÍ≥† Î∂ÄÎ•¥Í≥† Ïã∂ÏóàÏßÄÎßå, grep, cat, troff, sed, awk, perl Îì±Í≥º Í∞ôÏù¥ ÌîÑÎ°úÍ∑∏Îû®Í≥º ÌååÏùºÏóê ÏßßÍ≥† ÏïåÍ∏∞ Ïñ¥Î†§Ïö¥ Ïù¥Î¶ÑÏùÑ Ìï†ÎãπÌïòÎäî Ïú†ÎãâÏä§ ÏÑ∏Í≥Ñ ÌëúÏ§ÄÏùÑ Ï§ÄÏàòÌïòÍ∏∞ ÏúÑÌï¥ Ï§ÑÏó¨Ïïº ÌñàÎã§. ÌååÏùºÏùÑ Ï†ÄÏû•ÌïòÍ≥† Í≤ÄÏÉâÌïòÎäî Ï£ºÎêú Î∞©Î≤ïÏùÄ ÌååÏùº Ï†ÑÏÜ° ÌîÑÎ°úÌÜ†ÏΩú(FTP)ÏùÑ ÌÜµÌïòÎäî Í≤ÉÏù¥ÏóàÎã§. Ïù¥Í≤ÉÏùÄ Ïª¥Ìì®ÌÑ∞Í∞Ä Ïù∏ÌÑ∞ÎÑ∑ÏùÑ ÌÜµÌï¥ ÌååÏùºÏùÑ ÍµêÌôòÌïòÎäî ÏùºÎ∞òÏ†ÅÏù∏ Î∞©Î≤ïÏùÑ ÏßÄÏ†ïÌïòÎäî ÏãúÏä§ÌÖúÏù¥ÏóàÎã§(Í∑∏Î¶¨Í≥† ÏßÄÍ∏àÎèÑ Í∑∏Î†áÎã§). ÏûëÎèô Î∞©ÏãùÏùÄ Îã§ÏùåÍ≥º Í∞ôÎã§. Ïñ¥Îñ§ Í¥ÄÎ¶¨ÏûêÍ∞Ä ÏûêÏã†Ïùò Ïª¥Ìì®ÌÑ∞ÏóêÏÑú ÌååÏùºÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù ÎßåÎì§Í∏∞Î°ú Í≤∞Ï†ïÌïúÎã§. Í∑∏Îäî ÏûêÏã†Ïùò Ïª¥Ìì®ÌÑ∞Ïóê FTP ÏÑúÎ≤ÑÎùºÎäî ÌîÑÎ°úÍ∑∏Îû®ÏùÑ ÏÑ§Ï†ïÌïúÎã§. Ïù∏ÌÑ∞ÎÑ∑Ïùò ÎàÑÍµ∞Í∞ÄÍ∞Ä Ïù¥ Ïª¥Ìì®ÌÑ∞ÏóêÏÑú ÌååÏùºÏùÑ Í≤ÄÏÉâÌïòÎ†§Î©¥ FTP ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÎùºÎäî Îã§Î•∏ ÌîÑÎ°úÍ∑∏Îû®ÏùÑ ÌÜµÌï¥ Ïª¥Ìì®ÌÑ∞Ïóê Ïó∞Í≤∞ÌïúÎã§. ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏôÄ ÏÑúÎ≤Ñ ÌîÑÎ°úÍ∑∏Îû®Ïù¥ Î™®Îëê FTP ÌîÑÎ°úÌÜ†ÏΩúÏóê Î™ÖÏãúÎêú ÏÇ¨ÏñëÏùÑ ÏôÑÏ†ÑÌûà Ï§ÄÏàòÌïòÎäî Ìïú, Ïñ¥Îñ§ FTP ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÌîÑÎ°úÍ∑∏Îû®Ïù¥Îì† Ïñ¥Îñ§ FTP ÏÑúÎ≤Ñ ÌîÑÎ°úÍ∑∏Îû®Í≥ºÎèÑ Ïó∞Í≤∞Ìï† Ïàò ÏûàÎã§. Ï≤òÏùåÏóêÎäî ÌååÏùºÏùÑ Í≥µÏú†ÌïòÍ≥† Ïã∂ÏùÄ ÏÇ¨ÎûåÏùÄ ÌååÏùºÏùÑ Îã§Î•∏ ÏÇ¨ÎûåÏù¥ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù FTP ÏÑúÎ≤ÑÎ•º ÏÑ§Ï†ïÌï¥Ïïº ÌñàÎã§. ÎÇòÏ§ëÏóêÎäî \"ÏùµÎ™Ö\" FTP ÏÇ¨Ïù¥Ìä∏Í∞Ä ÌååÏùº Ï†ÄÏû•ÏÜåÍ∞Ä ÎêòÏñ¥ Î™®Îì† ÏÇ¨Ïö©ÏûêÍ∞Ä ÌååÏùºÏùÑ Í≤åÏãúÌïòÍ≥† Í≤ÄÏÉâÌï† Ïàò ÏûàÍ≤å ÎêòÏóàÎã§. ÏïÑÏπ¥Ïù¥Î∏å ÏÇ¨Ïù¥Ìä∏Í∞Ä ÏûàÎçîÎùºÎèÑ ÎßéÏùÄ Ï§ëÏöîÌïú ÌååÏùºÏùÄ Ïó¨Ï†ÑÌûà ÏûëÏùÄ FTP ÏÑúÎ≤ÑÏóê Ìù©Ïñ¥Ï†∏ ÏûàÏóàÎã§. Ïù¥Îü¨Ìïú ÌååÏùºÏùÄ Ïù∏ÌÑ∞ÎÑ∑Ïùò ÏûÖÏÜåÎ¨∏Í≥º ÎèôÎì±Ìïú Î∞©ÏãùÏúºÎ°úÎßå Ï∞æÏùÑ Ïàò ÏûàÏóàÎã§. ÎàÑÍµ∞Í∞ÄÍ∞Ä Î©îÏãúÏßÄ Î™©Î°ùÏù¥ÎÇò ÌÜ†Î°† Ìè¨ÎüºÏóê Ïù¥Î©îÏùºÏùÑ Í≤åÏãúÌïòÏó¨ ÌååÏùºÏùò Í∞ÄÏö©ÏÑ±ÏùÑ ÏïåÎ¶¨Îäî ÏãùÏù¥ÏóàÎã§. ÏïÑÌÇ§Îäî Ïù¥ Î™®Îì† Í≤ÉÏùÑ Î∞îÍø®Îã§. ÏïÑÌÇ§Îäî ÏùµÎ™Ö FTP ÌååÏùºÏùò ÏÇ¨Ïù¥Ìä∏ Î™©Î°ùÏùÑ Í∞ÄÏ†∏Ïò§Îäî Ïä§ÌÅ¨Î¶ΩÌä∏ Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ ÏàòÏßëÍ∏∞ÏôÄ ÏÇ¨Ïö©Ïûê ÏøºÎ¶¨ÏôÄ ÏùºÏπòÌïòÎäî ÌååÏùº Ïù¥Î¶ÑÏùÑ Í≤ÄÏÉâÌïòÎäî Ï†ïÍ∑ú ÌëúÌòÑÏãù Îß§Ï≤òÎ•º Í≤∞Ìï©ÌñàÎã§. (4) Îã§Ïãú ÎßêÌï¥, ÏïÑÌÇ§Ïùò ÏàòÏßëÍ∏∞Îäî Ïù∏ÌÑ∞ÎÑ∑ÏùÑ ÌÜµÌï¥ FTP ÏÇ¨Ïù¥Ìä∏Î•º ÏÉÖÏÉÖÏù¥ Îí§Ï†∏ÏÑú Î∞úÍ≤¨Ìïú Î™®Îì† ÌååÏùºÏùÑ ÏÉâÏù∏ÌôîÌñàÎã§. Ï†ïÍ∑ú ÌëúÌòÑÏãù Îß§Ï≤òÎäî ÏÇ¨Ïö©ÏûêÏóêÍ≤å Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÎåÄÌïú Ï†ëÍ∑º Í∂åÌïúÏùÑ Ï†úÍ≥µÌñàÎã§.[69] 1993ÎÖÑÏóê ÎÑ§Î∞îÎã§ ÎåÄÌïôÍµê ÏãúÏä§ÌÖú Ïª¥Ìì®ÌåÖ ÏÑúÎπÑÏä§ Í∑∏Î£πÏùÄ Î≤†Î°úÎãàÏπ¥Î•º Í∞úÎ∞úÌñàÎã§.[68] Ïù¥Îäî ÏïÑÌÇ§ÏôÄ Ïú†ÏÇ¨ÌïòÏßÄÎßå Í≥†Ìçº ÌååÏùºÏö©ÏúºÎ°ú ÎßåÎì§Ïñ¥ÏßÑ Í≤ÄÏÉâ Ïû•ÏπòÏòÄÎã§. ÏñºÎßà ÌõÑ Ï†ÄÍ∑∏Ìó§ÎìúÎùºÎäî Îòê Îã§Î•∏ Í≥†Ìçº Í≤ÄÏÉâ ÏÑúÎπÑÏä§Í∞Ä Îì±Ïû•ÌñàÎäîÎç∞, ÏïÑÎßàÎèÑ ÎßåÌôî ÏÇºÏ¥ùÏÇ¨Î•º ÏôÑÏÑ±ÌïòÍ∏∞ ÏúÑÌïú Ïú†ÏùºÌïú Î™©Ï†ÅÏúºÎ°ú Î≥¥ÏòÄÎã§. Ï†ÄÍ∑∏Ìó§ÎìúÎäî Jonzy's Universal Gopher Hierarchy Excavation and DisplayÏùò ÏïΩÏûêÏù¥ÏßÄÎßå, Î≤†Î°úÎãàÏπ¥Ï≤òÎüº Ï∞ΩÏûëÏûêÍ∞Ä ÏïΩÏûêÎ•º ÎÇòÏ§ëÏóê ÎÅºÏõå ÎßûÏ∑ÑÏùÑ Í≤ÉÏúºÎ°ú Ï∂îÏ†ïÌïòÎäî Í≤ÉÏù¥ ÏïàÏ†ÑÌïòÎã§. Ï†ÄÍ∑∏Ìó§ÎìúÏùò Í∏∞Îä•ÏùÄ Î≤†Î°úÎãàÏπ¥ÏôÄ Í±∞Ïùò ÎèôÏùºÌñàÏßÄÎßå, Ï¢Ä Îçî Í±∞Ïπ†Í≥† ÎØ∏ÏôÑÏÑ±Îêú ÎäêÎÇåÏù¥ÏóàÎã§.[69] 1993ÎÖÑ Îß§Ìäú Í∑∏Î†àÏù¥Í∞Ä Í∞úÎ∞úÌïú ÏõîÎìú ÏôÄÏù¥Îìú Ïõπ ÏõêÎçîÎü¨Îäî Ïõπ ÏÑ±Ïû•ÏùÑ Ï∂îÏ†ÅÌïòÍ∏∞ ÏúÑÌï¥ ÏÑ§Í≥ÑÎêú Ïõπ ÏµúÏ¥àÏùò Î°úÎ¥áÏù¥ÏóàÎã§.[70] Ï¥àÍ∏∞ÏóêÎäî Ïõπ ÏÑúÎ≤ÑÎßå ÏÑ∏ÏóàÏßÄÎßå, Í≥ßÏù¥Ïñ¥ URLÎèÑ ÏàòÏßëÌïòÍ∏∞ ÏãúÏûëÌñàÎã§. ÏàòÏßëÎêú URL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Îäî ÏµúÏ¥àÏùò Ïõπ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïù∏ WandexÍ∞Ä ÎêòÏóàÎã§. Îß§Ìäú Í∑∏Î†àÏù¥Ïùò ÏõêÎçîÎü¨Îäî ÎãπÏãú ÏÉÅÎãπÌïú ÎÖºÎûÄÏùÑ ÏùºÏúºÏº∞ÎäîÎç∞, Î∂ÄÎ∂ÑÏ†ÅÏúºÎ°úÎäî Ï¥àÍ∏∞ Î≤ÑÏ†ÑÏùò ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Í∞Ä ÎÑ∑ Ï†ÑÏ≤¥Î•º ÎÇúÏû°ÌïòÍ≤å ÎèåÏïÑÎã§ÎãàÎ©∞ ÎààÏóê ÎùÑÎäî ÎÑ§Ìä∏ÏõåÌÅ¨ ÏÑ±Îä• Ï†ÄÌïòÎ•º Ï¥àÎûòÌñàÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§. Ïù¥ Ï†ÄÌïòÎäî ÏõêÎçîÎü¨Í∞Ä ÌïòÎ£®Ïóê Í∞ôÏùÄ ÌéòÏù¥ÏßÄÏóê ÏàòÎ∞± Î≤à Ï†ëÍ∑ºÌñàÍ∏∞ ÎïåÎ¨∏Ïóê Î∞úÏÉùÌñàÎã§. ÏõêÎçîÎü¨Îäî Í≥ß Í∞úÏÑ†ÎêòÏóàÏßÄÎßå, Î°úÎ¥áÏù¥ Ïù∏ÌÑ∞ÎÑ∑Ïóê Ï¢ãÏùÄÏßÄ ÎÇòÏÅúÏßÄÏóê ÎåÄÌïú ÎÖºÎûÄÏùÄ Í≥ÑÏÜçÎêòÏóàÎã§. ÏõêÎçîÎü¨Ïóê ÎåÄÌïú ÏùëÎãµÏúºÎ°ú ÎßàÎ•¥ÌÉÄÏù∏ ÏΩîÏä§ÌÑ∞Îäî 1993ÎÖÑ 10Ïõî Archie-Like Indexing of the Web, Ï¶â ALIWEBÏùÑ ÎßåÎì§ÏóàÎã§. Ïù¥Î¶ÑÏóêÏÑú Ïïå Ïàò ÏûàÎìØÏù¥ ALIWEBÏùÄ ÏïÑÌÇ§Ïùò HTTP Î≤ÑÏ†ÑÏù¥ÏóàÏúºÎ©∞, Ïù¥ ÎïåÎ¨∏Ïóê Ïó¨Îü¨ Î©¥ÏóêÏÑú Ïó¨Ï†ÑÌûà ÎèÖÌäπÌïòÎã§. ALIWEBÏóêÎäî Ïõπ Í≤ÄÏÉâ Î°úÎ¥áÏù¥ ÏóÜÎã§. ÎåÄÏã†, Ï∞∏Ïó¨ ÏÇ¨Ïù¥Ìä∏Ïùò ÏõπÎßàÏä§ÌÑ∞Îäî Í∞Å Î™©Î°ùÏóê Ïò¨Î¶¨Í≥† Ïã∂ÏùÄ ÌéòÏù¥ÏßÄÏóê ÎåÄÌïú ÏûêÏ≤¥ ÏÉâÏù∏ Ï†ïÎ≥¥Î•º Í≤åÏãúÌïúÎã§. Ïù¥ Î∞©Î≤ïÏùò Ïû•Ï†êÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûêÏã†Ïùò ÏÇ¨Ïù¥Ìä∏Î•º ÏÑ§Î™ÖÌï† Ïàò ÏûàÍ≥†, Î°úÎ¥áÏù¥ ÎÑ§Ìä∏ÏõåÌÅ¨ ÎåÄÏó≠Ìè≠ÏùÑ Ïû°ÏïÑÎ®πÏßÄ ÏïäÎäîÎã§Îäî Í≤ÉÏù¥Îã§. ALIWEBÏùò Îã®Ï†êÏùÄ Ïò§ÎäòÎÇ† Îçî ÌÅ∞ Î¨∏Ï†úÏù¥Îã§. Ï£ºÏöî Îã®Ï†êÏùÄ ÌäπÎ≥ÑÌïú ÏÉâÏù∏ ÌååÏùºÏùÑ Ï†úÏ∂úÌï¥Ïïº ÌïúÎã§Îäî Í≤ÉÏù¥Îã§. ÎåÄÎ∂ÄÎ∂ÑÏùò ÏÇ¨Ïö©ÏûêÎäî Ïù¥Îü¨Ìïú ÌååÏùºÏùÑ ÎßåÎìúÎäî Î∞©Î≤ïÏùÑ Ïù¥Ìï¥ÌïòÏßÄ Î™ªÌïòÎØÄÎ°ú ÌéòÏù¥ÏßÄÎ•º Ï†úÏ∂úÌïòÏßÄ ÏïäÎäîÎã§. Ïù¥Îäî ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏûëÏùÄ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î°ú Ïù¥Ïñ¥ÏßÄÎ©∞, Ïù¥Îäî ÏÇ¨Ïö©ÏûêÍ∞Ä ÎåÄÍ∑úÎ™® Î¥á Í∏∞Î∞ò ÏÇ¨Ïù¥Ìä∏Î≥¥Îã§ ALIWEBÎ•º Í≤ÄÏÉâÌï† Í∞ÄÎä•ÏÑ±Ïù¥ ÎÇÆÎã§Îäî Í≤ÉÏùÑ ÏùòÎØ∏ÌïúÎã§. Ïù¥ Ï∫êÏπò-22Îäî Îã§Î•∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ALIWEB Í≤ÄÏÉâÏóê ÌÜµÌï©Ìï®ÏúºÎ°úÏç® Ïñ¥Îäê Ï†ïÎèÑ ÏÉÅÏáÑÎêòÏóàÏßÄÎßå, Ïó¨Ï†ÑÌûà ÏïºÌõÑ!ÎÇò ÎùºÏù¥ÏΩîÏä§ÏôÄ Í∞ôÏùÄ Í≤ÄÏÉâ ÏóîÏßÑÏùò ÎåÄÏ§ëÏ†ÅÏù∏ Îß§Î†•ÏùÄ ÏóÜÎã§.[69] Ï≤òÏùåÏóêÎäî ÏïÑÌÇ§ÌÖçÏä§Ìä∏(Architext)ÎùºÍ≥† Î∂àÎ†∏Îçò ÏùµÏÇ¨Ïù¥Ìä∏Îäî 1993ÎÖÑ 2Ïõî Ïä§ÌÉ†ÌçºÎìú ÎåÄÌïôÍµê 6Î™ÖÏùò ÌïôÎ∂ÄÏÉùÏù¥ ÏãúÏûëÌñàÎã§. Í∑∏Îì§Ïùò ÏïÑÏù¥ÎîîÏñ¥Îäî Ïù∏ÌÑ∞ÎÑ∑Ïóê ÏûàÎäî Î∞©ÎåÄÌïú Ï†ïÎ≥¥ ÏÜçÏóêÏÑú Îçî Ìö®Ïú®Ï†ÅÏù∏ Í≤ÄÏÉâÏùÑ Ï†úÍ≥µÌïòÍ∏∞ ÏúÑÌï¥ Îã®Ïñ¥ Í¥ÄÍ≥ÑÏóê ÎåÄÌïú ÌÜµÍ≥Ñ Î∂ÑÏÑùÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏù¥ÏóàÎã§.\nÍ∑∏Îì§Ïùò ÌîÑÎ°úÏ†ùÌä∏Îäî 1993ÎÖÑ Ï§ëÎ∞òÍπåÏßÄ Ï†ÑÏï° ÏûêÍ∏à ÏßÄÏõêÏùÑ Î∞õÏïòÎã§. ÏûêÍ∏àÏù¥ ÌôïÎ≥¥ÎêòÏûêÎßàÏûê Í∑∏Îì§ÏùÄ ÏõπÎßàÏä§ÌÑ∞Îì§Ïù¥ ÏûêÏã†Ïùò ÏõπÏÇ¨Ïù¥Ìä∏ÏóêÏÑú ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎäî Í≤ÄÏÉâ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Î≤ÑÏ†ÑÏùÑ Ï∂úÏãúÌñàÎã§. ÎãπÏãú Ïù¥ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Îäî ÏïÑÌÇ§ÌÖçÏä§Ìä∏ÎùºÍ≥† Î∂àÎ†∏ÏßÄÎßå, ÏßÄÍ∏àÏùÄ Ïõπ ÏÑúÎ≤ÑÏö© ÏùµÏÇ¨Ïù¥Ìä∏ÎùºÎäî Ïù¥Î¶ÑÏúºÎ°ú ÏÇ¨Ïö©ÎêúÎã§.[69] ÏùµÏÇ¨Ïù¥Ìä∏Îäî 1995ÎÖÑÏóê Ï∂úÏãúÎêú ÏµúÏ¥àÏùò ÏßÑÏßÄÌïú ÏÉÅÏóÖÏö© Í≤ÄÏÉâ ÏóîÏßÑÏù¥ÏóàÎã§.[71] Ïä§ÌÉ†ÌçºÎìúÏóêÏÑú Í∞úÎ∞úÎêòÏóàÍ≥† @HomeÏóê 65Ïñµ Îã¨Îü¨Ïóê Ïù∏ÏàòÎêòÏóàÎã§. 2001ÎÖÑÏóê ÏùµÏÇ¨Ïù¥Ìä∏ÏôÄ @HomeÏùÄ ÌååÏÇ∞ÌñàÍ≥† InfoSpaceÎäî ÏùµÏÇ¨Ïù¥Ìä∏Î•º 1Ï≤úÎßå Îã¨Îü¨Ïóê Ïù∏ÏàòÌñàÎã§. Ïõπ Í≤ÄÏÉâÏóê ÎåÄÌïú ÏµúÏ¥àÏùò Î∂ÑÏÑù Ï§ë ÏùºÎ∂ÄÎäî ÏùµÏÇ¨Ïù¥Ìä∏Ïùò Í≤ÄÏÉâ Î°úÍ∑∏ÏóêÏÑú ÏàòÌñâÎêòÏóàÎã§.[72][38] 1994ÎÖÑ 4Ïõî, Ïä§ÌÉ†ÌçºÎìú ÎåÄÌïôÍµê Î∞ïÏÇ¨ Í≥ºÏ†ï ÌïôÏÉùÏù∏ Îç∞Ïù¥ÎπÑÎìú ÌååÏùºÎ°úÏôÄ Ï†úÎ¶¨ ÏñëÏùÄ ÏÉÅÎãπÌûà Ïù∏Í∏∞ ÏûàÎäî ÌéòÏù¥ÏßÄÎì§ÏùÑ ÎßåÎì§ÏóàÎã§. Í∑∏Îì§ÏùÄ Ïù¥ ÌéòÏù¥ÏßÄ Î™®ÏùåÏùÑ ÏïºÌõÑ!ÎùºÍ≥† Î∂àÎ†ÄÎã§. Ïù¥Î¶Ñ ÏÑ†ÌÉùÏóê ÎåÄÌïú Í≥µÏãùÏ†ÅÏù∏ ÏÑ§Î™ÖÏùÄ Í∑∏Îì§ Ïä§Ïä§Î°úÎ•º Ïñ¥Î¶¨ÏàôÌïú ÏïºÌõÑÎùºÍ≥† Ïó¨Í≤ºÍ∏∞ ÎïåÎ¨∏Ïù¥ÎùºÎäî Í≤ÉÏù¥ÏóàÎã§. ÎßÅÌÅ¨ ÏàòÍ∞Ä ÎäòÏñ¥ÎÇòÍ≥† ÌéòÏù¥ÏßÄÍ∞Ä ÌïòÎ£®Ïóê ÏàòÏ≤ú Í±¥Ïùò Ï°∞ÌöåÎ•º Î∞õÍ∏∞ ÏãúÏûëÌïòÎ©¥ÏÑú ÌåÄÏùÄ Îç∞Ïù¥ÌÑ∞Î•º Îçî Ïûò Ï†ïÎ¶¨ÌïòÎäî Î∞©Î≤ïÏùÑ ÎßåÎì§ÏóàÎã§. Îç∞Ïù¥ÌÑ∞ Í≤ÄÏÉâÏùÑ ÎèïÍ∏∞ ÏúÑÌï¥ ÏïºÌõÑ!(www.yahoo.com)Îäî Í≤ÄÏÉâ Í∞ÄÎä•Ìïú ÎîîÎ†âÌÑ∞Î¶¨Í∞Ä ÎêòÏóàÎã§. Í≤ÄÏÉâ Í∏∞Îä•ÏùÄ Í∞ÑÎã®Ìïú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ÏóàÎã§. ÏïºÌõÑ! Ìï≠Î™©ÏùÄ ÏàòÎèôÏúºÎ°ú ÏûÖÎ†•ÎêòÍ≥† Î∂ÑÎ•òÎêòÏóàÍ∏∞ ÎïåÎ¨∏Ïóê ÏïºÌõÑ!Îäî Ïã§Ï†úÎ°ú Í≤ÄÏÉâ ÏóîÏßÑÏúºÎ°ú Î∂ÑÎ•òÎêòÏßÄ ÏïäÏïòÎã§. ÎåÄÏã†, ÏùºÎ∞òÏ†ÅÏúºÎ°ú Í≤ÄÏÉâ Í∞ÄÎä•Ìïú ÎîîÎ†âÌÑ∞Î¶¨Î°ú Í∞ÑÏ£ºÎêòÏóàÎã§. ÏïºÌõÑ!Îäî Ïù¥ÌõÑ ÏàòÏßë Î∞è Î∂ÑÎ•ò Í≥ºÏ†ïÏùò ÏùºÎ∂Ä Ï∏°Î©¥ÏùÑ ÏûêÎèôÌôîÌïòÏó¨ ÏóîÏßÑÍ≥º ÎîîÎ†âÌÑ∞Î¶¨ Í∞ÑÏùò Íµ¨Î∂ÑÏùÑ Î™®Ìò∏ÌïòÍ≤å ÎßåÎì§ÏóàÎã§. ÏõêÎçîÎü¨Îäî URLÎßå ÏàòÏßëÌñàÍ∏∞ ÎïåÎ¨∏Ïóê URLÎ°ú Î™ÖÏãúÏ†ÅÏúºÎ°ú ÏÑ§Î™ÖÎêòÏßÄ ÏïäÏùÄ Í≤ÉÏùÑ Ï∞æÍ∏∞Í∞Ä Ïñ¥Î†§Ïõ†Îã§. URLÏùÄ Ï≤òÏùåÎ∂ÄÌÑ∞ Îã§ÏÜå ÏïîÌò∏ Í∞ôÏïòÍ∏∞ ÎïåÎ¨∏Ïóê ÏùºÎ∞ò ÏÇ¨Ïö©ÏûêÏóêÍ≤åÎäî ÎèÑÏõÄÏù¥ ÎêòÏßÄ ÏïäÏïòÎã§. ÏïºÌõÑ!ÎÇò Í∞§Îü≠ÏãúÎ•º Í≤ÄÏÉâÌïòÎäî Í≤ÉÏù¥ Ìõ®Ïî¨ Îçî Ìö®Í≥ºÏ†ÅÏù¥ÏóàÎäîÎç∞, Í∑∏Îì§ÏùÄ ÏÉâÏù∏ÌôîÎêú ÏÇ¨Ïù¥Ìä∏Ïóê ÎåÄÌïú Ï∂îÍ∞Ä ÏÑ§Î™Ö Ï†ïÎ≥¥Î•º Ìè¨Ìï®ÌïòÍ≥† ÏûàÏóàÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§. 1994ÎÖÑ 7Ïõî, Ïπ¥ÎÑ§Í∏∞ Î©úÎü∞ ÎåÄÌïôÍµêÏóêÏÑú ÎßàÏù¥ÌÅ¥ Î™®Îì§Î¶∞ÏùÄ ÎùºÏù¥ÏΩîÏä§ Í≤ÄÏÉâ ÏóîÏßÑÏùÑ Í∞úÎ∞úÌñàÎã§. Ïõπ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Îã§Î•∏ ÏÇ¨Ïù¥Ìä∏Ïóê Ï†ÄÏû•Îêú ÏΩòÌÖêÏ∏†Î•º Í≤ÄÏÉâÌïòÎäî Í∏∞Îä•ÏùÑ Í∞ñÏ∂ò ÏÇ¨Ïù¥Ìä∏Ïù¥Îã§. Îã§ÏñëÌïú Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏûëÎèôÌïòÎäî Î∞©ÏãùÏóêÎäî Ï∞®Ïù¥Í∞Ä ÏûàÏßÄÎßå, Î™®Îëê ÏÑ∏ Í∞ÄÏßÄ Í∏∞Î≥∏ ÏûëÏóÖÏùÑ ÏàòÌñâÌïúÎã§.[73] Ïù¥ Í≥ºÏ†ïÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä Ï†úÍ≥µÎêú Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î•º ÌÜµÌï¥ ÏãúÏä§ÌÖúÏóê ÏøºÎ¶¨ Î¨∏ÏùÑ ÏûÖÎ†•Ìï† Îïå ÏãúÏûëÎêúÎã§. Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÏÑ∏ Í∞ÄÏßÄ Ïú†ÌòïÏùò Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏûàÎã§. Î°úÎ¥á(ÌÅ¨Î°§Îü¨; Í∞úÎØ∏ ÎòêÎäî Ïä§ÌååÏù¥Îçî)Ïóê ÏùòÌï¥ Íµ¨ÎèôÎêòÎäî Í≤ÉÍ≥º Ïù∏Í∞Ñ Ï†úÏ∂úÏóê ÏùòÌï¥ Íµ¨ÎèôÎêòÎäî Í≤É, Í∑∏Î¶¨Í≥† Ïù¥ Îëê Í∞ÄÏßÄÏùò ÌïòÏù¥Î∏åÎ¶¨ÎìúÏù¥Îã§. ÌÅ¨Î°§Îü¨ Í∏∞Î∞ò Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏûêÎèôÌôîÎêú ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóêÏù¥Ï†ÑÌä∏(ÌÅ¨Î°§Îü¨ÎùºÍ≥† Î∂àÎ¶º)Î•º ÏÇ¨Ïö©ÌïòÎäî Í≤ÄÏÉâ ÏóîÏßÑÏúºÎ°ú, ÏõπÏÇ¨Ïù¥Ìä∏Î•º Î∞©Î¨∏ÌïòÍ≥† Ïã§Ï†ú ÏÇ¨Ïù¥Ìä∏Ïùò Ï†ïÎ≥¥Î•º ÏùΩÏúºÎ©∞, ÏÇ¨Ïù¥Ìä∏Ïùò Î©îÌÉÄ ÌÉúÍ∑∏Î•º ÏùΩÍ≥†, ÎòêÌïú ÏÇ¨Ïù¥Ìä∏Í∞Ä Ïó∞Í≤∞ÎêòÎäî ÎßÅÌÅ¨Î•º Îî∞ÎùºÍ∞Ä Î™®Îì† Ïó∞Í≤∞Îêú ÏõπÏÇ¨Ïù¥Ìä∏Ïóê ÎåÄÌï¥ÏÑúÎèÑ ÏÉâÏù∏ÌôîÎ•º ÏàòÌñâÌïúÎã§. ÌÅ¨Î°§Îü¨Îäî Ïù¥ Î™®Îì† Ï†ïÎ≥¥Î•º Ï§ëÏïô Ï†ÄÏû•ÏÜåÎ°ú Îã§Ïãú Î≥¥ÎÇ¥Í≥†, Í±∞Í∏∞ÏÑú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏÉâÏù∏ÌôîÎêúÎã§. ÌÅ¨Î°§Îü¨Îäî Ï£ºÍ∏∞Ï†ÅÏúºÎ°ú ÏÇ¨Ïù¥Ìä∏Î•º Îã§Ïãú Î∞©Î¨∏ÌïòÏó¨ Î≥ÄÍ≤ΩÎêú Ï†ïÎ≥¥Í∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏ÌïúÎã§. Ïù¥ ÏûëÏóÖÏù¥ Î∞úÏÉùÌïòÎäî ÎπàÎèÑÎäî Í≤ÄÏÉâ ÏóîÏßÑ Í¥ÄÎ¶¨ÏûêÍ∞Ä Í≤∞Ï†ïÌïúÎã§. Ïù∏Í∞Ñ Í∏∞Î∞ò Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ïù∏Í∞ÑÏù¥ Ï†ïÎ≥¥Î•º Ï†úÏ∂úÌïòÎäî Î∞©ÏãùÏóê ÏùòÏ°¥ÌïòÎ©∞, Ï†úÏ∂úÎêú Ï†ïÎ≥¥Îäî Ïù¥ÌõÑ ÏÉâÏù∏ÌôîÎêòÍ≥† Î∂ÑÎ•òÎêúÎã§. Ï†úÏ∂úÎêú Ï†ïÎ≥¥Îßå ÏÉâÏù∏Ïóê Ìè¨Ìï®ÎêúÎã§. Îëê Í≤ΩÏö∞ Î™®Îëê, ÏÇ¨Ïö©ÏûêÍ∞Ä Ï†ïÎ≥¥Î•º Ï∞æÍ∏∞ ÏúÑÌï¥ Í≤ÄÏÉâ ÏóîÏßÑÏóê ÏøºÎ¶¨Î•º Î≥¥ÎÇ¥Î©¥, Ïã§Ï†úÎ°úÎäî Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏÉùÏÑ±Ìïú ÏÉâÏù∏ÏùÑ Í≤ÄÏÉâÌïòÎäî Í≤ÉÏù¥ÏßÄ Ïõπ ÏûêÏ≤¥Î•º Í≤ÄÏÉâÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÎã§. Ïù¥Îü¨Ìïú ÏÉâÏù∏ÏùÄ ÏàòÏßë Î∞è Ï†ÄÏû•Îêú Ï†ïÎ≥¥Ïùò Í±∞ÎåÄÌïú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïù¥Î©∞ Ïù¥ÌõÑ Í≤ÄÏÉâÎêúÎã§. Ïù¥Í≤ÉÏù¥ ÏïºÌõÑ!ÎÇò Íµ¨Í∏ÄÍ≥º Í∞ôÏùÄ ÏÉÅÏóÖÏö© Í≤ÄÏÉâ ÏóîÏßÑÏóêÏÑú Í≤ÄÏÉâÌñàÏùÑ Îïå ÎïåÎïåÎ°ú Îçî Ïù¥ÏÉÅ Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ ÎßÅÌÅ¨Í∞Ä Î∞òÌôòÎêòÎäî Ïù¥Ïú†Î•º ÏÑ§Î™ÖÌïúÎã§. Í≤ÄÏÉâ Í≤∞Í≥ºÎäî ÏÉâÏù∏ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÌïòÎØÄÎ°ú, Ïõπ ÌéòÏù¥ÏßÄÍ∞Ä Ïú†Ìö®ÌïòÏßÄ ÏïäÍ≤å Îêú Ïù¥ÌõÑ ÏÉâÏù∏Ïù¥ ÏóÖÎç∞Ïù¥Ìä∏ÎêòÏßÄ ÏïäÏïòÎã§Î©¥ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Ìï¥Îãπ ÌéòÏù¥ÏßÄÎ•º Ïó¨Ï†ÑÌûà ÌôúÏÑ± ÎßÅÌÅ¨Î°ú Í∞ÑÏ£ºÌïúÎã§. Ïù¥Îäî ÏÉâÏù∏Ïù¥ ÏóÖÎç∞Ïù¥Ìä∏Îê† ÎïåÍπåÏßÄ Í≥ÑÏÜçÎêúÎã§. Í∑∏Î†áÎã§Î©¥ Ïôú Îã§Î•∏ Í≤ÄÏÉâ ÏóîÏßÑÏóêÏÑú ÎèôÏùºÌïú Í≤ÄÏÉâÏù¥ Îã§Î•∏ Í≤∞Í≥ºÎ•º ÏÉùÏÑ±Ìï†Íπå? Í∑∏ ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎãµÏùò ÏùºÎ∂ÄÎäî Î™®Îì† ÏÉâÏù∏Ïù¥ Ï†ïÌôïÌûà Í∞ôÏßÄÎäî ÏïäÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§. Í∑∏Í≤ÉÏùÄ Ïä§ÌååÏù¥ÎçîÍ∞Ä Î¨¥ÏóáÏùÑ Ï∞æÎäîÏßÄ ÎòêÎäî Ïù∏Í∞ÑÏù¥ Î¨¥ÏóáÏùÑ Ï†úÏ∂úÌñàÎäîÏßÄÏóê Îã¨Î†§ ÏûàÎã§. ÌïòÏßÄÎßå Îçî Ï§ëÏöîÌïú Í≤ÉÏùÄ Î™®Îì† Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏÉâÏù∏ÏùÑ Í≤ÄÏÉâÌïòÎäî Îç∞ ÎèôÏùºÌïú ÏïåÍ≥†Î¶¨Ï¶òÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÎäîÎã§Îäî Ï†êÏù¥Îã§. ÏïåÍ≥†Î¶¨Ï¶òÏùÄ Í≤ÄÏÉâ ÏóîÏßÑÏù¥ ÏÉâÏù∏Ïóê ÏûàÎäî Ï†ïÎ≥¥Í∞Ä ÏÇ¨Ïö©ÏûêÍ∞Ä Í≤ÄÏÉâÌïòÎäî ÎÇ¥Ïö©Í≥º ÏñºÎßàÎÇò Í¥ÄÎ†®ÏÑ±Ïù¥ ÎÜíÏùÄÏßÄÎ•º Í≤∞Ï†ïÌïòÎäî Îç∞ ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏù¥Îã§. Í≤ÄÏÉâ ÏóîÏßÑ ÏïåÍ≥†Î¶¨Ï¶òÏù¥ Ïä§Ï∫îÌïòÎäî ÏöîÏÜå Ï§ë ÌïòÎÇòÎäî Ïõπ ÌéòÏù¥ÏßÄÏóê ÏûàÎäî ÌÇ§ÏõåÎìúÏùò ÎπàÎèÑÏôÄ ÏúÑÏπòÏù¥Îã§. ÎπàÎèÑÍ∞Ä ÎÜíÏùÄ ÌÇ§ÏõåÎìúÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú Îçî Í¥ÄÎ†®ÏÑ±Ïù¥ ÎÜíÏùÄ Í≤ÉÏúºÎ°ú Í∞ÑÏ£ºÎêúÎã§. Í∑∏Îü¨ÎÇò Í≤ÄÏÉâ ÏóîÏßÑ Í∏∞Ïà†ÏùÄ ÌÇ§ÏõåÎìú Ïä§ÌÑ∞Ìïë ÎòêÎäî Ïä§Ìå∏Îç±Ïã±ÏúºÎ°ú ÏïåÎ†§ÏßÑ Í≤ÉÏùÑ ÏñµÏ†úÌïòÍ∏∞ ÏúÑÌï¥ Ï†êÏ†ê Îçî Ï†ïÍµêÌï¥ÏßÄÍ≥† ÏûàÎã§. ÏïåÍ≥†Î¶¨Ï¶òÏù¥ Î∂ÑÏÑùÌïòÎäî Îòê Îã§Î•∏ ÏùºÎ∞òÏ†ÅÏù∏ ÏöîÏÜåÎäî ÌéòÏù¥ÏßÄÍ∞Ä ÏõπÏùò Îã§Î•∏ ÌéòÏù¥ÏßÄÏóê ÎßÅÌÅ¨ÎêòÎäî Î∞©ÏãùÏù¥Îã§. ÌéòÏù¥ÏßÄÍ∞Ä ÏÑúÎ°ú Ïñ¥ÎñªÍ≤å ÎßÅÌÅ¨ÎêòÎäîÏßÄ Î∂ÑÏÑùÌï®ÏúºÎ°úÏç® ÏóîÏßÑÏùÄ ÌéòÏù¥ÏßÄÍ∞Ä Î¨¥ÏóáÏóê Í¥ÄÌïú Í≤ÉÏù∏ÏßÄ(ÎßÅÌÅ¨Îêú ÌéòÏù¥ÏßÄÏùò ÌÇ§ÏõåÎìúÍ∞Ä ÏõêÎ≥∏ ÌéòÏù¥ÏßÄÏùò ÌÇ§ÏõåÎìúÏôÄ Ïú†ÏÇ¨Ìïú Í≤ΩÏö∞) Í∑∏Î¶¨Í≥† Ìï¥Îãπ ÌéòÏù¥ÏßÄÍ∞Ä \"Ï§ëÏöî\"ÌïòÎã§Í≥† Í∞ÑÏ£ºÎêòÏñ¥ ÏàúÏúÑ ÏÉÅÏäπÏóê ÎèÑÏõÄÏù¥ ÎêòÎäîÏßÄ ÌåêÎã®Ìï† Ïàò ÏûàÎã§. Í∏∞Ïà†Ïù¥ ÌÇ§ÏõåÎìú Ïä§ÌÑ∞ÌïëÏùÑ Î¨¥ÏãúÌïòÍ∏∞ ÏúÑÌï¥ Ï†êÏ†ê Îçî Ï†ïÍµêÌï¥ÏßÄÎäî Í≤ÉÏ≤òÎüº, Ïù∏ÏúÑÏ†ÅÏù∏ ÏàúÏúÑÎ•º ÎÜíÏù¥Í∏∞ ÏúÑÌï¥ ÏÇ¨Ïù¥Ìä∏Ïóê Ïù∏ÏúÑÏ†ÅÏù∏ ÎßÅÌÅ¨Î•º Íµ¨Ï∂ïÌïòÎäî ÏõπÎßàÏä§ÌÑ∞ÏóêÍ≤åÎèÑ Ï†êÏ†ê Îçî ÌòÑÎ™ÖÌï¥ÏßÄÍ≥† ÏûàÎã§. ÌòÑÎåÄ Ïõπ Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏàòÎÖÑÏóê Í±∏Ï≥ê ÏßÑÌôîÌïú Í∏∞Ïà†ÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í≥†ÎèÑÎ°ú Î≥µÏû°Ìïú ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏãúÏä§ÌÖúÏù¥Îã§. ÌäπÏ†ï 'ÌÉêÏÉâ' ÏöîÍµ¨Ïóê Í∞úÎ≥ÑÏ†ÅÏúºÎ°ú Ï†ÅÏö© Í∞ÄÎä•Ìïú Ïó¨Îü¨ ÌïòÏúÑ Î≤îÏ£ºÏùò Í≤ÄÏÉâ ÏóîÏßÑ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Í∞Ä ÏûàÎã§. Ïó¨Í∏∞ÏóêÎäî Ïõπ Í≤ÄÏÉâ ÏóîÏßÑ(Ïòà: Íµ¨Í∏Ä), Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÎòêÎäî Íµ¨Ï°∞ÌôîÎêú Îç∞Ïù¥ÌÑ∞ Í≤ÄÏÉâ ÏóîÏßÑ(Ïòà: Dieselpoint), Í∑∏Î¶¨Í≥† ÌòºÌï© Í≤ÄÏÉâ ÏóîÏßÑ ÎòêÎäî ÏóîÌÑ∞ÌîÑÎùºÏù¥Ï¶à Í≤ÄÏÉâÏù¥ Ìè¨Ìï®ÎêúÎã§. Íµ¨Í∏ÄÍ≥º ÏïºÌõÑ!ÏôÄ Í∞ôÏùÄ Îçî ÎÑêÎ¶¨ ÏÇ¨Ïö©ÎêòÎäî Í≤ÄÏÉâ ÏóîÏßÑÏùÄ ÏàòÏã≠Îßå ÎåÄÏùò Ïª¥Ìì®ÌÑ∞Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏàòÏ°∞ Í∞úÏùò Ïõπ ÌéòÏù¥ÏßÄÎ•º Ï≤òÎ¶¨ÌïòÏó¨ ÏÉÅÎãπÌûà Ï†ïÌôïÌïú Í≤∞Í≥ºÎ•º Î∞òÌôòÌïúÎã§. Ïù¥Îü¨Ìïú Î∞©ÎåÄÌïú ÏøºÎ¶¨ ÏñëÍ≥º ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨Î°ú Ïù∏Ìï¥ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Îäî ÎÜíÏùÄ Ï§ëÎ≥µÏÑ±ÏùÑ Í∞ÄÏßÑ Í≥†ÎèÑÎ°ú Î∂ÑÏÇ∞Îêú ÌôòÍ≤ΩÏóêÏÑú Ïã§ÌñâÎêòÏñ¥Ïïº ÌïúÎã§. Îòê Îã§Î•∏ Î≤îÏ£ºÏùò Í≤ÄÏÉâ ÏóîÏßÑÏùÄ Í≥ºÌïô Í≤ÄÏÉâ ÏóîÏßÑÏù¥Îã§. Ïù¥Îì§ÏùÄ Í≥ºÌïô Î¨∏ÌóåÏùÑ Í≤ÄÏÉâÌïòÎäî Í≤ÄÏÉâ ÏóîÏßÑÏù¥Îã§. Í∞ÄÏû• Ïûò ÏïåÎ†§ÏßÑ ÏòàÎäî Íµ¨Í∏Ä Ïä§ÏπºÎùºÏù¥Îã§. Ïó∞Íµ¨ÏûêÎì§ÏùÄ Ïù¥Î°†Ï†Å Íµ¨ÏÑ±Ïù¥ÎÇò ÌïµÏã¨ Ïó∞Íµ¨ Í≤∞Í≥ºÎ•º Ï∂îÏ∂úÌïòÎäî Îì± Í∏∞ÏÇ¨Ïùò ÏΩòÌÖêÏ∏† ÏöîÏÜåÎ•º Ïù¥Ìï¥ÌïòÎèÑÎ°ù Í≤ÄÏÉâ ÏóîÏßÑ Í∏∞Ïà†ÏùÑ Í∞úÏÑ†ÌïòÎäî ÏûëÏóÖÏùÑ ÌïòÍ≥† ÏûàÎã§.[74]"
  },
  {
    "url": "https://hy.wikipedia.org/wiki/%D5%88%D6%80%D5%B8%D5%B6%D5%B8%D5%B2%D5%A1%D5%AF%D5%A1%D5%B6_%D5%B0%D5%A1%D5%B4%D5%A1%D5%AF%D5%A1%D6%80%D5%A3",
    "title": "’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£ - ’é’´÷Ñ’´’∫’•’§’´’°",
    "content": "’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’® ’£’∏÷Ä’Æ’´÷Ñ ’ß, ’∏÷Ä’® ’∂’°’≠’°’ø’•’Ω’æ’°’Æ ’ß ’∞’°’¥’°’∫’°’ø’°’Ω’≠’°’∂ ’¢’°’º’•÷Ä’∏’æ ’Ä’°’¥’°’∑’≠’°÷Ä’∞’°’µ’´’∂ ÷Å’°’∂÷Å’∏÷Ç’¥ ’∏÷Ä’∏’∂’∏÷Ç’¥’∂’•÷Ä ’Ø’°’ø’°÷Ä’•’¨’∏÷Ç ’∞’°’¥’°÷Ä÷â ’ç’ø’•’≤’Æ’æ’°’Æ ’ß ’∞’°’¥’°÷Å’°’∂÷Å’∏÷Ç’¥ ÷á FTP ’Ω’•÷Ä’æ’•÷Ä’∂’•÷Ä’∏÷Ç’¥ ’´’∂÷Ü’∏÷Ä’¥’°÷Å’´’° ÷É’∂’ø÷Ä’•’¨’∏÷Ç ’∞’°’¥’°÷Ä÷â ’ì’∂’ø÷Ä’æ’°’Æ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’® ’®’∂’§’∞’°’∂÷Ä’°’∫’•’Ω ’∂’•÷Ä’Ø’°’µ’°÷Å’æ’∏÷Ç’¥ ’•’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’´ ÷Å’°’∂’Ø’∏÷Ç’¥ ÷á ’Ω’∏’æ’∏÷Ä’°’¢’°÷Ä ’Ø’∏’π’æ’∏÷Ç’¥ ’•’∂ ’∂’∫’°’ø’°’Ø’°’Ø’°’Ø’•’ø, ’∞’´’©÷â ‘ª’∂÷Ü’∏÷Ä’¥’°÷Å’´’°’∂ ’Ø’°÷Ä’∏’≤ ’ß ’¢’°’≤’Ø’°÷Å’°’Æ ’¨’´’∂’•’¨ ’æ’•’¢ ’ß’ª’•÷Ä’´÷Å, ’∂’Ø’°÷Ä’∂’•÷Ä’´÷Å, ’´’∂÷Ü’∏÷Ä’¥’°÷Å’´’°’∂’•÷Ä’´÷Å ÷á ’°’µ’¨ ’ø’´’∫’´ ÷Ü’°’µ’¨’•÷Ä’´÷Å ’∏÷Ç ’ø’æ’µ’°’¨’∂’•÷Ä’´÷Å÷â ‘±’µ’∂ ’Ø’°÷Ä’∏’≤ ’ß ÷Ö’£’ø’°’£’∏÷Ä’Æ’æ’•’¨ ’ø’°÷Ä’¢’•÷Ä ’ø’•’Ω’°’Ø’´ ’ø’•’≤’•’Ø’°’ø’æ’∏÷Ç’©’µ’∏÷Ç’∂ ’∏÷Ä’∏’∂’•’¨’∏÷Ç ’∞’°’¥’°÷Ä, ’∂’•÷Ä’°’º’µ’°’¨’ù ’Ø’°’µ÷Ñ’•÷Ä, ÷Ü’∏÷Ä’∏÷Ç’¥’∂’•÷Ä, ’∂’Ø’°÷Ä’∂’•÷Ä, ’æ’´’§’•’∏’∂’•÷Ä, ÷Ü’°’µ’¨’•÷Ä ÷á ’°’µ’¨’∂÷â ’à÷Ä’∏’∑ ’Ø’°’µ÷Ñ’•÷Ä ’°÷Ä’§’•’∂ ’´÷Ä’•’∂÷Å’´÷Å ’∂’•÷Ä’Ø’°’µ’°÷Å’∂’∏÷Ç’¥ ’•’∂ ’´’∂’π-’∏÷Ä ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£, ÷Ö÷Ä’´’∂’°’Ø’ù Dailymotion, YouTube ÷á Google Videos ’´’∂’ø’•÷Ä’∂’•’ø’∏÷Ç’¥ ’ø’•’≤’°’§÷Ä’æ’°’Æ ’ø’•’Ω’°’∞’∏’¨’∏’æ’°’Ø’∂’•÷Ä’´ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’•÷Ä ’•’∂÷â ’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’® ’¢’°’≤’Ø’°÷Å’°’Æ ’ß \"’º’∏’¢’∏’ø’∂’•÷Ä’´÷Å\", ’∏÷Ä’∏’∂÷Å ’°’∂’æ’°’∂’∏÷Ç’¥ ’•’∂ ’∂’°÷á bot, spider, crawler, ’∏÷Ä’∏’∂÷Ñ ’°’æ’ø’∏’¥’°’ø ’Ø’•÷Ä’∫’∏’æ, ’°’º’°’∂÷Å ’¥’°÷Ä’§’Ø’°’µ’´’∂ ’¥’´’ª’°’¥’ø’∏÷Ç’©’µ’°’∂ ’∫’°÷Ä’¢’•÷Ä’°’¢’°÷Ä ’∞’•’ø’°’¶’∏’ø’∏÷Ç’¥ ’•’∂ ’Ø’°’µ÷Ñ’•÷Ä’®÷â ’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’•÷Ä’® ’∞’•’ø÷á’∏÷Ç’¥ ’•’∂ ’∞’≤’∏÷Ç’¥’∂’•÷Ä’´’∂, ’∏÷Ä’∏’∂÷Ñ ’Ø’°’∫’æ’°’Æ ’¨’´’∂’•’¨’∏’æ ’´÷Ä’°÷Ä ’∞’•’ø ’´’∂’§’•÷Ñ’Ω’°’æ’∏÷Ä’∏÷Ç’¥ ’ß ’µ’∏÷Ç÷Ä’°÷Ñ’°’∂’π’µ’∏÷Ç÷Ä ’ß’ª ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’°’µ’∏÷Ç’¥’ù ’∞’•’ø’°’£’°’µ’∏÷Ç’¥ ’¢’°’∂’°’¨’´ ’¢’°’º’•÷Ä’´ ÷Ö’£’∂’∏÷Ç’©’µ’°’¥’¢ ’§’°’º’∂’°’¨’∏’æ ’∞’°’Ω’°’∂’•’¨’´ ’´’∂’ø’•÷Ä’∂’•’ø’´÷Å ÷Ö’£’ø’æ’∏’≤’∂’•÷Ä’´ ’∞’°’¥’°÷Ä÷â ’ç’≠’°’¨’¥’°’¥’¢, ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’•÷Ä ’•’∂ ’°’∂’æ’°’∂’∏÷Ç’¥ ’∂’°÷á ’°’µ’∂ ’Ø’°’µ÷Ñ’•÷Ä’®, ’∏÷Ä’∏’∂÷Ñ ’´÷Ä’•’∂÷Å’´÷Å ’∂’•÷Ä’Ø’°’µ’°÷Å’∂’∏÷Ç’¥ ’•’∂ ’Ø’°’µ÷Ñ’°’µ’´’∂ ’ø’•’≤’•’Ø’°’ø’∏÷Ç’∂’•÷Ä÷â ‘±’µ’Ω ’Ø’°’µ÷Ñ’•÷Ä’∏÷Ç’¥ ’∏÷Ç’∑’°’§÷Ä’∏÷Ç’©’µ’°’∂ ’°÷Ä’™’°’∂’´ ’Ø’°’µ÷Ñ’•÷Ä’® ÷Å’∏÷Ç÷Å’°’Ø’°’£÷Ä’æ’∏÷Ç’¥ ÷á ’§’°’Ω’°’Ø’°÷Ä’£’æ’∏÷Ç’¥ ’•’∂ ’¥’°÷Ä’§’Ø’°’µ’´’∂ ’º’•’Ω’∏÷Ç÷Ä’Ω’∂’•÷Ä’´ ’∑’∂’∏÷Ä’∞’´’æ, ’°’µ’¨ ’∏’π ’©’• ’¢’∏’ø’•÷Ä’´ ’Ø’°’¥ ’º’∏’¢’•’ø’∂’•÷Ä’´ ’¥’´’ª’∏÷Å’∏’æ÷â ‘±’µ’§ ’Ø’°’µ÷Ñ’•÷Ä’´÷Å ’Ø’°÷Ä’•’¨’´ ’ß ’∂’∑’•’¨ ÷Ö÷Ä’´’∂’°’Ø’ù Yahoo!÷â Yahoo!-’´ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’® ’£’ø’∂’æ’∏÷Ç’¥ ’ß ’°’µ’Ω’ø’•’≤÷â ‘≤’∏’¨’∏÷Ä ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’® ’∂’°’≠’°’ø’•’Ω’æ’°’Æ ’•’∂ ’´’∂’ø’•÷Ä’∂’•’ø’∏÷Ç’¥ ’∏÷Ä’∏’∂’∏÷Ç’¥ ’´÷Ä’°’Ø’°’∂’°÷Å’∂’•’¨’∏÷Ç ’∞’°’¥’°÷Ä, ’Ω’°’Ø’°’µ’∂ ’Ø’°’∂ ’∏÷Ä’∏’∑ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ’ø’°÷Ä’°’ø’•’Ω’°’Ø’∂’•÷Ä, ’∏÷Ä’∏’∂÷Ñ ’∞’°’¥’°’Ø’°÷Ä’£’π’°’µ’´’∂ ’Æ÷Ä’°’£÷Ä’•÷Ä ’•’∂ ÷á ’∞’•’ø÷á’°’¢’°÷Ä ’ø’•’≤’°’Ø’°’µ’æ’∏÷Ç’¥ ’•’∂ ’∞’°’¥’°’Ø’°÷Ä’£’π’´ ’¥’•’ª÷â ‘±’µ’Ω ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’® ’Ø’∏’π’æ’∏÷Ç’¥ ’•’∂ desktop÷â ’é’•÷Ä’ª’´’∂’•÷Ä’Ω ’∞’∂’°÷Ä’°’æ’∏÷Ä’∏÷Ç’©’µ’∏÷Ç’∂ ’•’∂ ’ø’°’¨’´’Ω ’∏÷Ä’∏’∂’•’¨’∏÷Ç ’©’• ’∞’°’¥’°’Ø’°÷Ä’£’π’´ ’¥’•’ª ’Ø’∏÷Ç’ø’°’Ø’æ’°’Æ ÷Ü’°’µ’¨’•’®, ’©’• ’Ø’°’µ÷Ñ’•÷Ä’∏÷Ç’¥ ’ø’•’≤’°’§÷Ä’æ’°’Æ ’º’•’Ω’∏÷Ç÷Ä’Ω’∂’•÷Ä’®÷â ‘±’µ’§ ’Æ÷Ä’°’£÷Ä’•÷Ä’´÷Å ’°’¥’•’∂’°’∞’°’µ’ø’∂’´’∂’•÷Ä’∂ ’•’∂’ù Exalead Desktop, Copernic Desktop Search ‘±÷Ä’≠’´’æ’°÷Å’æ’°’Æ 2009-02-17  Wayback Machine ‘≥’∏’µ’∏÷Ç’©’µ’∏÷Ç’∂ ’∏÷Ç’∂’•’∂ ’∂’°÷á ’¥’•’ø’°-’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä, ’°’µ’Ω’´’∂÷Ñ’∂ ’Ø’°’µ÷Ñ’•÷Ä, ’∏÷Ä ’∂’∏÷Ç’µ’∂ ’∏÷Ä’∏’∂’∏÷Ç’¥’® ’Ø’°’ø’°÷Ä’∏÷Ç’¥ ’•’∂ ’¥’´’°’™’°’¥’°’∂’°’Ø ’ø’°÷Ä’¢’•÷Ä ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’•÷Ä’´ ’¥’´’ª’∂’∏÷Ä’§’∏÷Ç’©’µ’°’¥’¢÷â ’à÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’® ’∞’•’ø’∏ ’§’°’Ω’°’Ø’°÷Ä’£’æ’∏÷Ç’¥ ’•’∂ ’∏÷Ä’∫’•’Ω’¶’´ ’∂’•÷Ä’Ø’°’µ’°÷Å’æ’•’∂ ÷Ö’£’ø’°’£’∏÷Ä’Æ’∏’≤’´’∂÷â ’Ñ’•’ø’°-’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ’∑’°÷Ä÷Ñ’´÷Å ’Ø’°÷Ä’•’¨’´ ’ß ’©’æ’°÷Ä’Ø’•’¨ ÷Ö÷Ä’´’∂’°’Ø’ù Mamma ÷á Kartoo ‘±÷Ä’≠’´’æ’°÷Å’æ’°’Æ 2010-01-20  Wayback Machine÷â ’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’® ’∞’°’ø’∏÷Ç’Ø ’æ’•’¢ ’∞’°’∂’£’∏÷Ç’µ÷Å ’ß, ’∏÷Ä’® ’∂’°’≠’°’ø’•’Ω’æ’°’Æ ’ß ’ø’•’≤’•’Ø’°’ø’æ’∏÷Ç’©’µ’°’∂ ’∏÷Ä’∏’∂’¥’°’∂ ’∞’°’¥’°÷Ä÷â ’à÷Ä’∏’∂’¥’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ’°’¥’•’∂’°’ø’°÷Ä’°’Æ’æ’°’Æ ’Ø’´÷Ä’°’º’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä’´÷Å ’¥’•’Ø’® ’∞’°’¥’°÷Å’°’∂÷Å’∏÷Ç’¥ ’ø’•÷Ñ’Ω’ø’°’µ’´’∂ ’Ø’°’¥ ’£÷Ä’°÷Ü’´’Ø’°’Ø’°’∂ ’ø’•’≤’•’Ø’°’ø’æ’∏÷Ç’©’µ’°’∂ ’∏÷Ä’∏’∂’¥’°’∂ ’æ’•’¢ ’Æ’°’º’°’µ’∏÷Ç’©’µ’∏÷Ç’∂’∂ ’ß÷â ‘ø’°’∂ ’∂’°’•÷Ç ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä, ’∏÷Ä’∏’∂÷Ñ ’Ø’°÷Ä’∏’≤ ’•’∂ FTP ’Ω’•÷Ä’æ’•÷Ä’∂’•÷Ä’∏÷Ç’¥ ÷É’∂’ø÷Ä’•’¨ ÷Ü’°’µ’¨’•÷Ä, ’°’º÷Å’°’∂÷Å ’≠’°’∂’∏÷Ç’©’∂’•÷Ä’∏÷Ç’¥ ’°÷Ä’ø’°’§÷Ä’∏’≤ ’°’∫÷Ä’°’∂÷Ñ’∂’•÷Ä, Usenet- ’´ ’¨÷Ä’°’ø’æ’°’Ø’°’∂ ’≠’¥’¢’•÷Ä’´ ’ø’•’≤’•’Ø’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä[1]÷â ’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ’¥’´’ª’∏÷Å’∏’æ ’∏÷Ä’∏’∂’•’¨’∏÷Ç ’∞’°’¥’°÷Ä ÷Ö’£’ø’°’£’∏÷Ä’Æ’∏’≤’® ’±’•÷Ç’°’æ’∏÷Ä’∏÷Ç’¥ ’ß ’∏÷Ä’∏’∂’¥’°’∂ ’∞’°÷Ä÷Å’∏÷Ç’¥’® ÷â ’à÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’´ ’°’∑’≠’°’ø’°’∂÷Ñ’®, ÷Ö’£’ø’°’£’∏÷Ä’Æ’∏’≤’´ ’≠’∂’§÷Ä’°’∂÷Ñ’∏’æ, ÷É’°’Ω’ø’°’©’≤’©’•÷Ä’´ ’∏÷Ä’∏’∂’∏÷Ç’¥’∂ ’ß, ’∏÷Ä’∏’∂÷Ñ ’∫’°÷Ä’∏÷Ç’∂’°’Ø’∏÷Ç’¥ ’•’∂ ’∂’∑’æ’°’Æ ’¢’°’º’•÷Ä’®÷â ‘±’µ’Ω ’§’•’∫÷Ñ’∏÷Ç’¥ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’® ’Ω’ø’•’≤’Æ’∏÷Ç’¥ ’ß ’∏÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’´ ’ß’ª÷â ’Ü’¥’°’∂ ’∏÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’® ’Ø’°÷Ä’∏’≤ ’•’∂ ’∫’°÷Ä’∏÷Ç’∂’°’Ø’•’¨ ’ø’°÷Ä’¢’•÷Ä ’ø’•’Ω’°’Ø’´ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä, ÷Ö÷Ä’´’∂’°’Ø `’æ’•’¢ ’ß’ª’•÷Ä, ’∫’°’ø’Ø’•÷Ä’∂’•÷Ä, ’°’∏÷Ç’§’´’∏ ÷Ü’°’µ’¨’•÷Ä÷â ’à÷Ä’∏’∑ ’∏÷Ä’∏’∂’¥’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä ’∂’°’•÷Ç ’ø’•’≤’•’Ø’°÷Å’∂’∏÷Ç’¥ ’•’∂ ’∞’°’¥’°÷Å’°’∂÷Å’∏÷Ç’¥ ’∞’°’¥’°’∫’°’ø’°’Ω’≠’°’∂ ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’°’∂’•÷Ä’´ ’•÷Ç ’°’º’Ø’°’µ’∏÷Ç’©’µ’°’∂ ’¥’°’Ω’´’∂÷â 2018 ’©’æ’°’Ø’°’∂’´ ’ø’æ’µ’°’¨’∂’•÷Ä’∏’æ Google- ’® ’°’∑’≠’°÷Ä’∞’∏÷Ç’¥ ’°’¥’•’∂’°’ø’°÷Ä’°’Æ’æ’°’Æ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’∂ ’ß[2]÷â ‘∏’Ω’ø ’∏÷Ä’∏’∂’¥’°’∂ ’¥’•’©’∏’§’∂’•÷Ä’´ ’•÷Ç ’Ω’∫’°’Ω’°÷Ä’Ø’¥’°’∂ ’±÷á’•÷Ä’´, ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’® ’¢’°’™’°’∂’æ’°’Æ ’•’∂ ’π’∏÷Ä’Ω ’ø’•’Ω’°’Ø’´ `’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’º’∏’¢’∏’ø’∂’•÷Ä, ’¥’°÷Ä’§’Ø’°’∂÷Å ’Ø’∏’≤’¥’´÷Å ’Ø’°’º’°’æ’°÷Ä’æ’∏’≤ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä, ’∞’´’¢÷Ä’´’§’°’µ’´’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä ’•÷Ç ’¥’•’ø’°-’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä÷â ’Ä’°’¥’°÷Å’°’∂÷Å’´ ’¶’°÷Ä’£’°÷Å’¥’°’∂ ’æ’°’≤ ÷É’∏÷Ç’¨’∏÷Ç’¥, ‘π’´’¥ ‘≤’•÷Ä’∂’•÷Ä’Ω ‘º’´’∂ ’ë‘µ’å’Ü- ’´ ’Ø’°’µ÷Ñ’∏÷Ç’¥ ’∞’Ω’Ø’∏÷Ç’¥ ’ß÷Ä ’æ’•’¢ ’Ω’•÷Ä’æ’•÷Ä’∂’•÷Ä’´ ÷Å’°’∂’Ø’®÷â ‘±’æ’•’¨’´ ’∏÷Ç ’°’æ’•’¨’´ ’∑’°’ø ’Ø’°’µ÷Ñ’•÷Ä’´ ’°’º’°’ª’°÷Å’∏÷Ç’¥’´÷Å ’∞’•’ø’∏  ’°’µ’§’∫’´’Ω’´ ÷Å’∏÷Ç÷Å’°’Ø’´ ’±’•’º÷Ñ’∏’æ ’∞’Ω’Ø’•’¨’® ’°’æ’•’¨’´ ’∏÷Ç ’°’æ’•’¨’´ ’§’™’æ’°÷Ä ’ß÷Ä ’§’°÷Ä’±’•’¨÷â NCSA- ’´ ’´’∂’ø’•÷Ä’∂’•’ø’°’µ’´’∂ ’Ø’°’µ÷Ñ’∏÷Ç’¥ ’Ø’°÷Ä ¬´‘ª’∂’π ’∂’∏÷Ä’∏÷Ç’©’µ’∏÷Ç’∂¬ª ’∞’°’ø’∏÷Ç’Ø ’¢’°’™’´’∂’®, ’∏÷Ä’ø’•’≤ ’∂÷Ä’°’∂÷Ñ ’∂’∏÷Ä ’Ø’°’µ÷Ñ’•÷Ä’∏’´ ’∞’≤’∏÷Ç’¥’∂’•÷Ä’∂ ’ß’´’∂ ’∞÷Ä’°’∫’°÷Ä’°’Ø’∏÷Ç’¥÷â\n‘ª’∂’ø’•÷Ä’∂’•’ø’∏÷Ç’¥ ’∏÷Ä’∏’∂’•’¨’∏÷Ç ’°’º’°’ª’´’∂ ’∞’°’¥’°’Ø’°÷Ä’£’π’°’µ’´’∂ ’Æ÷Ä’°’£’´÷Ä’® Archie-’∂ ’ß÷Ä÷â ‘±’µ’∂ ’Ω’ø’•’≤’Æ’æ’•’¨ ’ß 1990 ’©.-’´’∂ ’Ñ’∏’∂÷Ä’•’°’¨’∏÷Ç’¥ McGill ’∞’°’¥’°’¨’Ω’°÷Ä’°’∂’´ ’∞’°’¥’°’Ø’°÷Ä’£’π’°’µ’´’∂ ’£’´’ø’∏÷Ç’©’µ’°’∂ ’∏÷Ç’Ω’°’∂’∏’≤’∂’•÷Ä’´ ’Ø’∏’≤’¥’´÷Å[3]÷â ‘æ÷Ä’°’£’´÷Ä’® ’∂’•÷Ä’¢’•’º’∂’•’¨ ’ß ’¢’∏’¨’∏÷Ä ÷Ü’°’µ’¨’•÷Ä’´ ÷Å’°’∂’Ø’® ’¢’∏’¨’∏÷Ä ’¥’°’ø’π’•’¨’´ ’°’∂’°’∂’∏÷Ç’∂ FTP ’Ω’•÷Ä’æ’•÷Ä’∂’•÷Ä’´÷Å ’•÷Ç ’Ø’°’º’∏÷Ç÷Å’•’¨ ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’°, ’∏÷Ä’ø’•’≤ ’∞’∂’°÷Ä’°’æ’∏÷Ä’∏÷Ç’©’µ’∏÷Ç’∂ ’ß ’•’≤’•’¨ ’∏÷Ä’∏’∂’∏÷Ç’¥ ’Ø’°’ø’°÷Ä’•’¨ ÷Ü’°’µ’¨’´ ’°’∂’∏÷Ç’∂’∏’æ÷â ‘±’µ’∂’∏÷Ç’°’¥’•’∂’°’µ’∂’´’æ, Archie-’∂ ’π’´ ÷Å’∏÷Ç÷Å’°’¢’•÷Ä’•’¨ ’°’µ’§ ÷Ü’°’µ’¨’•÷Ä’´ ’¢’∏’æ’°’∂’§’°’Ø’∏÷Ç’©’µ’∏÷Ç’∂’®, ÷Ñ’°’∂’´ ’∏÷Ä ’ø’æ’µ’°’¨’∂’•÷Ä’´ ÷Ñ’°’∂’°’Ø’® ’°’µ’∂÷Ñ’°’∂ ÷É’∏÷Ñ÷Ä ’ß÷Ä, ’∏÷Ä ’°’¥’•’∂ ’´’∂’π ’Ø’°÷Ä’•’¨’´ ’ß ’∞’•’∑’ø’∏÷Ç’©’µ’°’¥’¢ ’Ω’ø’°’∂’°’¨ ’°’º’°’∂÷Å ’∞’°’¥’°’Ø’°÷Ä’£’´ ÷Ö’£’∂’∏÷Ç’©’µ’°’¥’¢÷â Google ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’® ’∞’°’µ’ø’∂’´ ’ß 2000-’°’Ø’°’∂’∂’•÷Ä’´ ’Ω’Ø’¶’¢’´÷Å÷â ‘∏’∂’Ø’•÷Ä’∏÷Ç’©’µ’∏÷Ç’∂’® ’∞’°’Ω’•’¨ ’ß ’¢’°÷Ä’±÷Ä ’§’´÷Ä÷Ñ’´ `’¨’°’æ ’∏÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’´ ’∑’∂’∏÷Ä’∞’´’æ, ÷Ö’£’ø’°’£’∏÷Ä’Æ’•’¨’∏’æ PageRank ’°’¨’£’∏÷Ä’´’©’¥’®÷â ‘±’¨’£’∏÷Ä’´’©’¥’® ’∞’°’∂÷Ä’∏÷Ç’©’µ’°’∂’® ’∂’•÷Ä’Ø’°’µ’°÷Å’æ’•÷Å ¬´The Anatomy of Search Engine¬ª ’∞’∏’§’æ’°’Æ’∏÷Ç’¥[4], ’∏÷Ä’® ’£÷Ä’æ’•’¨ ’ß Google- ’´ ’∞’´’¥’∂’°’§’´÷Ä’∂’•÷Ä ’ç’•÷Ä’£’•’µ ‘≤÷Ä’´’∂’´ ’•÷Ç ‘º’°÷Ä’´ ’ì’•’µ’ª’´ ’Ø’∏’≤’¥’´÷Å÷â ‘±’µ’Ω ’°’¨’£’∏÷Ä’´’©’¥’® ’æ’•’¢ ’ß’ª’•÷Ä ’ß, ’∏÷Ä’® ’∞’´’¥’∂’æ’°’Æ ’ß ’æ’•’¢ ’ß’ª’´ ’∞’´’∫’•÷Ä’∞’∏’¨’•÷Ä’´ ÷Ñ’°’∂’°’Ø’´ ’£’∂’°’∞’°’ø’¥’°’∂ ’æ÷Ä’°÷â Google- ’´ ’´’∂’ø’•÷Ä÷Ü’•’µ’Ω’® ’∑’°’ø ’¥’°’ø’π’•’¨’´ ’ß, ’∏÷Ä’ø’•’≤ ’π’Ø’° ’°’æ’•’¨’∏÷Ä’§ ’¢’°’∂, ’´ ’ø’°÷Ä’¢’•÷Ä’∏÷Ç’©’µ’∏÷Ç’∂ ’´÷Ä ’¥÷Ä÷Å’°’Ø’´÷Å’∂’•÷Ä’´÷Å ’∑’°’ø’•÷Ä’´, ’∏÷Ä’∏’∂÷Ñ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’® ’æ’•÷Ä’°’Æ’•’¨ ’•’∂ ’æ’•’¢-’∫’∏÷Ä’ø’°’¨’´÷â Microsoft- ’® ’°’º’°’ª’´’∂ ’°’∂’£’°’¥ ’Ø’´÷Ä’°’º’•’¨ ’ß Microsoft Network Search[5]-’® (MSN Search) 1998 ’©. ’°’∑’∂’°’∂’®, ÷Ö’£’ø’°’£’∏÷Ä’Æ’•’¨’∏’æ Inktomi-’´ ’∏÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’®÷â 2004-’´’∂ Microsoft- ’® ’Ω’Ø’Ω’•÷Å ’°’∂÷Å’∏÷Ç’¥ ’Ø’°’ø’°÷Ä’•’¨ ’Ω’•÷É’°’Ø’°’∂ ’∏÷Ä’∏’∂’¥’°’∂ ’ø’•’≠’∂’∏’¨’∏’£’´’°’µ’´, ÷Ö’£’ø’°’£’∏÷Ä’Æ’•’¨’∏’æ ’Ω’•÷É’°’Ø’°’∂ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’º’∏’¢’∏’ø’®÷â Microsoft- ’´ ’æ’•÷Ä’°’±÷á’°’æ’∏÷Ä’∏÷Ç’¥’´÷Å ’∞’•’ø’∏, 2009 ’©. ’Ä’∏÷Ç’∂’´’Ω’´ 1-’´’∂, ’¥’•’Ø’∂’°÷Ä’Ø’•÷Å Bing[6] ’∏÷Ä’∏’∂’´’π’®÷â ’Ä’∏÷Ç’¨’´’Ω 29, 2009 Yahoo!-’∂  ’•÷Ç Microsoft- ’® ’Ω’ø’∏÷Ä’°’£÷Ä’•’¨ ’•’∂ ’∞’°’¥’°’±’°’µ’∂’°’£’´÷Ä, ’∞’°’¥’°’±’°’µ’∂ ’∏÷Ä’´ Yahoo!-’∂ ’°’∑’≠’°’ø’∏÷Ç’¥ ’ß Microsoft Bing ’ø’•’≠’∂’∏’¨’∏’£’´’°’µ’´ ’∞’´’¥’°’∂ ’æ÷Ä’°÷â ‘≥’∏’µ’∏÷Ç’©’µ’∏÷Ç’∂ ’∏÷Ç’∂’´ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ’π’∏÷Ä’Ω ’ø’•’Ω’°’Ø’∂’•÷Ä’ù ‘æ÷Ä’°’£÷Ä’´ ’∂’∫’°’ø’°’Ø’∂ ’ß ’£’∂’°’∞’°’ø’•’¨ ’∏÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’®÷â ’á’∂’∏÷Ä’∞’´’æ ’°’µ’∂ ’∞’°’∂’£’°’¥’°’∂÷Ñ’´, ’∏÷Ä ’°’µ’Ω ’¥’•’≠’°’∂’´’¶’¥’∏÷Ç’¥ ’∏÷Ä’∏’∂’¥’°’∂ ’º’∏’¢’∏’ø’® ’¥’∑’ø’°’∫’•’Ω ’∏÷Ç’Ω’∏÷Ç’¥’∂’°’Ω’´÷Ä’∏÷Ç’¥ ’ß ÷Å’°’∂÷Å’®, ’ø’•’≤’•’Ø’°’ø’æ’∏÷Ç’©’µ’∏÷Ç’∂’® ’°’æ’•’¨’´ ’Ø’°÷Ä’•÷Ç’∏÷Ä ’ß÷â ‘∫’°’¥’°’∂’°’Ø’°’Ø’´÷Å ’∏÷Ä’∏’∂’¥’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ’¥’•’Æ ’¥’°’Ω’® ’°’µ’Ω ’ø’•’Ω’°’Ø’´ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’∂ ’•’∂÷â ‘±’µ’Ω ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’® ’Ω’ø’°’∂’∏÷Ç’¥ ’•’∂ ’æ’•’¢ ’ß’ª’•÷Ä’´ ÷Å’∏÷Ç÷Å’°’Ø’∂’•÷Ä’®:’ë’∏÷Ç÷Å’°’Ø’® ’∫’°÷Ä’∏÷Ç’∂’°’Ø’∏÷Ç’¥ ’ß ’∞’°’Ω÷Å’•, ’æ’•÷Ä’∂’°’£’´÷Ä ÷á ’Ø’°’µ÷Ñ’´ ’Ø’°÷Ä’≥ ’∂’Ø’°÷Ä’°’£÷Ä’∏÷Ç’©’µ’∏÷Ç’∂÷â ’å’•’Ω’∏÷Ç÷Ä’Ω’∂’•÷Ä’´ ’Ø’°’ø’°’¨’∏’£’® ’∏÷Ä’∏’∂’∏÷Ç’¥ ’ß ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä ’¥’´’°’µ’∂ ’æ’•’¢ ’æ’°÷Ä’∫’•’ø’∂’•÷Ä’´ ’Ø’∏’≤’¥’´÷Å ’∂’•÷Ä’Ø’°’µ’°÷Å’æ’°’Æ ’ß’ª’´ ’∂’Ø’°÷Ä’°’£÷Ä’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä’´÷Å ’•’¨’∂’•’¨’∏’æ÷â ’ë’∏÷Ç÷Å’°’Ø’∂’•÷Ä’´ ’°’º’°’æ’•’¨’∏÷Ç’©’µ’∏÷Ç’∂’∂ ’°’µ’∂ ’ß, ’∏÷Ä ’¢’∏’¨’∏÷Ä ’º’•’Ω’∏÷Ç÷Ä’Ω’∂’•÷Ä’® ’Ω’ø’∏÷Ç’£’æ’∏÷Ç’¥ ’•’∂ ’±’•’º÷Ñ’∏’æ, ’∞’•’ø’•÷Ç’°’¢’°÷Ä, ’¢’∏’æ’°’∂’§’°’Ø’∏÷Ç’©’µ’°’∂ ’∏÷Ä’°’Ø’® ’Ø’¨’´’∂’´ ’°’æ’•’¨’´ ’¨’°’æ, ÷Ñ’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’π’°’µ’´’∂ ’°’æ’ø’∏’¥’°’ø ’Ω’ø’°÷Å’æ’°’Æ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä’®÷â ‘≤’°’µ÷Å ’Ø’° ’¥’´ ’©’•÷Ä’∏÷Ç’©’µ’∏÷Ç’∂ `’°’µ’§ ÷Å’∏÷Ç÷Å’°’Ø’∂’•÷Ä’´ ’©’°÷Ä’¥’°÷Å’∏÷Ç’¥’® ’Ø’°’ø’°÷Ä’æ’∏÷Ç’¥ ’ß ’±’•’º÷Ñ’∏’æ ÷á ’Ø’°÷Ä’∏’≤ ’ß ’¶’£’°’¨’´’∏÷Ä’•’∂ ’∞’•’ø ’¥’∂’°’¨ ’´÷Ä’°’Ø’°’∂ ’æ’´’≥’°’Ø’´÷Å÷â ’Ü’¥’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’´ ÷Ö÷Ä’´’∂’°’Ø’∂’•÷Ä ’∂’•÷Ä’°’º’∏÷Ç’¥ ’ß Yahoo- ’´ ’Ø’°’ø’°’¨’∏’£’®÷â ’à÷Ä’∏’∂’¥’°’∂ ’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’®,  ’´’∂’π’∫’´’Ω’´÷Ñ ’•’∂ Yahoo- ’∂, Google- ’®, MSN- ’®, ’∞’°’¥’°’ø’•’≤’∏÷Ç’¥ ’•’∂ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’º’∏’¢’∏’ø’∂’•÷Ä’´ ’Ø’´÷Ä’°’º’∏÷Ç’©’µ’∏÷Ç’∂’® ÷á ’¥’°÷Ä’§’∏÷Ç ’Ø’∏’≤’¥’´÷Å ’Ø’°’º’°’æ’°÷Ä’•’¨’∏÷Ç ’£’∏÷Ä’Æ’∏’∂’®÷â ’Ñ’•’ø’°-’∞’°’¥’°’Ø’°÷Ä’£’•÷Ä’® ’∞’°’¥’°’ø’•’≤’∏÷Ç’¥ ÷á ’§’°’Ω’°’æ’∏÷Ä’∏÷Ç’¥ ’•’∂ ’¥’´ ÷Ñ’°’∂’´ ’∏÷Ä’∏’∂’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∂’•÷Ä÷â ‘±’µ’Ω ’∏÷Ä’∏’∂’´’π’∂’•÷Ä’® ÷Ö’£’ø’°’Ø’°÷Ä ’ß’´’∂, ’•÷Ä’¢ ’µ’∏÷Ç÷Ä’°÷Ñ’°’∂’π’µ’∏÷Ç÷Ä ’∏÷Ä’∏’∂’´’π ’∏÷Ç’∂’•÷Ä ’µ’∏÷Ç÷Ä’°’∞’°’ø’∏÷Ç’Ø ’´’∂’§’•÷Ñ’Ω ’•÷Ç ’∏÷Ä’∏’∂’´’π’∂’•÷Ä’® ’°’µ’§÷Ñ’°’∂ ’ß’¨ ¬´’≠’•’¨’°÷Å’´¬ª ’π’ß’´’∂÷â ’î’°’∂’´ ’∏÷Ä ’∏÷Ä’∏’∂’∏÷Ç’¥’® ’∞’´’¥’° ’¢’°÷Ä’•’¨’°’æ’æ’•’¨ ’ß, ’∂÷Ä’°’∂÷Å ’°’∂’∞÷Ä’°’™’•’∑’ø’∏÷Ç’©’µ’∏÷Ç’∂’® ’∂’æ’°’¶’•’¨ ’ß÷â ’ï÷Ä’´’∂’°’Ø’∂’•÷Ä `MetaCrawler ÷á MSN ’à÷Ä’∏’∂’∏÷Ç’¥÷â ’Ä’°’¥’°’∑’≠’°÷Ä’∞’°’µ’´’∂ ’Ω’°÷Ä’§’∏’Ω’ø’°’µ’∂ ’Ä’°’¥’°’±’°’µ’∂ Comscore ‘±÷Ä’≠’´’æ’°÷Å’æ’°’Æ 2012-07-29(Timestamp length) archive.today-’´ 2007 ’©’æ’°’Ø’°’∂’´ ÷Ö’£’∏’Ω’ø’∏’Ω’´’∂ ’Ø’°’ø’°÷Ä’æ’°’Æ ’∏÷Ç’Ω’∏÷Ç’¥’∂’°’Ω’´÷Ä’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä’´, ’∞’´’¥’∂’°’Ø’°’∂ ’∏÷Ä’∏’∂’∏’≤’°’Ø’°’∂ ’Ø’°’µ÷Ñ’•÷Ä’∂ ’•’∂’ù"
  },
  {
    "url": "https://hi.wikipedia.org/wiki/%E0%A4%B5%E0%A5%87%E0%A4%AC_%E0%A4%96%E0%A5%8B%E0%A4%9C%E0%A5%80_%E0%A4%87%E0%A4%82%E0%A4%9C%E0%A4%A8",
    "title": "‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú‡•Ä ‡§á‡§Ç‡§ú‡§® - ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ",
    "content": "‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú‡•Ä ‡§á‡§Ç‡§ú‡§® (web search engine) ‡§µ‡§π ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§π‡•à ‡§ú‡•ã ‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡•ç‡§Ø‡§æ‡§™‡•Ä ‡§ú‡§æ‡§≤ (World Wide Web) ‡§™‡§∞ ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§ø‡§§ ‡§∏‡•Ç‡§ö‡§®‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§ñ‡•ã‡§ú‡§®‡•á ‡§ï‡•á ‡§ï‡§æ‡§Æ ‡§Ü‡§§‡§æ ‡§π‡•à‡•§[‡§â‡§¶‡•ç‡§ß‡§∞‡§£ ‡§ö‡§æ‡§π‡§ø‡§è] ‡§ñ‡•ã‡§ú ‡§ï‡•á ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡§∏‡•ç‡§µ‡§∞‡•Ç‡§™ ‡§Ø‡•á ‡§ñ‡•ã‡§ú‡•Ä ‡§á‡§Ç‡§ú‡§® ‡§µ‡§æ‡§Ç‡§õ‡§ø‡§§ ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§µ‡•á‡§¨ ‡§™‡•á‡§ú, ‡§õ‡§¨‡§ø‡§Ø‡§æ‡§Å, ‡§§‡§•‡§æ ‡§Ö‡§®‡•ç‡§Ø ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•Ä ‡§´‡§æ‡§á‡§≤‡•á‡§Ç ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡•Å‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§ï‡•Å‡§õ ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú‡•Ä ‡§á‡§Ç‡§ú‡§® ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§§‡§•‡§æ ‡§ñ‡•Å‡§≤‡•Ä ‡§°‡§æ‡§Ø‡§∞‡•á‡§ï‡•ç‡§ü‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§Ü‡§Å‡§ï‡§°‡•á ‡§≠‡•Ä ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡•Å‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§[‡§â‡§¶‡•ç‡§ß‡§∞‡§£ ‡§ö‡§æ‡§π‡§ø‡§è] ‡§ï‡•Å‡§õ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú‡•Ä ‡§á‡§Ç‡§ú‡§®:[‡§â‡§¶‡•ç‡§ß‡§∞‡§£ ‡§ö‡§æ‡§π‡§ø‡§è]"
  },
  {
    "url": "https://hr.wikipedia.org/wiki/Internetska_tra%C5%BEilica",
    "title": "Internetska tra≈æilica ‚Äì Wikipedija",
    "content": "Internetski pretra≈æivaƒç (tra≈æilica) je specijalizirano mre≈æno mjesto ƒçija je glavna funkcija pomoƒá u pronala≈æenju informacija pohranjenih na drugim mre≈ænim mjestima (domenama). Internetski pretra≈æivaƒç je pretra≈æivaƒç namijenjen pretra≈æivanju informacija na World Wide Web-u. Informacije mogu biti Web stranice, slike i ostale vrste datoteka. Neki pretra≈æivaƒçi, takoƒëer, pretra≈æuju podatke dostupne u tematskim grupama, bazama podataka ili u otvorenim imenicima. Za razliku od Web imenika koje odr≈æavaju ureƒëivaƒçi teksta (ljudi), internetski pretra≈æivaƒçi djeluju po algoritmu ili su kombinacija algoritma i ljudskog upisa. Najpoznatiji internetski pretra≈æivaƒç u svijetu je Google. U najjaƒçim tra≈æilicama postoji moguƒánost usmjerenog i specijalnog pretra≈æivanja, gdje je dovoljno upisati neku reƒçenicu ili vi≈°e kljuƒçnih rijeƒçi, odnosno natuknicu, pa se nakon razmjerno kratkog vremena (ovisno o brzini veze) dobiju brojne poveznice na tra≈æeni pojam. Internetski sadr≈æaj koji se ne mo≈æe pronaƒái pretra≈æivanjem internetskom tra≈æilicom opƒáenito nazivamo duboki Web. Prvi alat upotrijebljen za pretra≈æivanje na Internetu bio je Archie, stvoren 1990. godine. Pretra≈æivao je imena datoteka i naslove, no nije indeksirao sadr≈æaj tih datoteka. Prvi internetski pretra≈æivaƒç bio je Wandex, sada izumrli indeks sabran od strane World Wide Web Wanderer-a, programa za prikupljanje podataka s Web stranica razvijenog 1993. godine. Jedan od prvih internetskih pretra≈æivaƒça ƒçitavog teksta bio je WebCrawler, koji je iza≈°ao 1994. godine. Za razliku od svojih prethodnika, dopu≈°tao je korisnicima pretra≈æivanje bilo koje rijeƒçi s bilo koje stranice, ≈°to je od tada postalo pravilo za sve znaƒçajne pretra≈æivaƒçe. Takoƒëer, bio je to prvi pretra≈æivaƒç poznat javnosti u velikoj mjeri. Ubrzo nakon toga, pojavili su se mnogi pretra≈æivaƒçi nadmeƒáuƒái se za popularnost. Neki od njih bili su: Excite, Infoseek, Inktomi, Northern Light, AltaVista, Yahoo!, MSN Search (danas Live Search). Oko 2000. godine Googleov pretra≈æivaƒç uzdigao se na vrh. Poduzeƒáe je postiglo bolje rezultate za mnoge pretrage uz pomoƒá novine zvane PageRank. Ovaj uƒçestali algoritam rasporeƒëuje Web stranice temeljem broja i PageRank-a ostalih Web mjesta i stranica koje se na njih spajaju, s pretpostavkom da se na bolje i po≈æeljnije stranice ƒçe≈°ƒáe spaja. Isto tako, Google je odr≈æao minimalistiƒçko suƒçelje svog pretra≈æivaƒça. Suprotno tome, mnogi od njegovih konkurenata umetnuli su pretra≈æivaƒç na Web portal. Od kraja 2007. godine, Google je daleko najpopularniji internetski pretra≈æivaƒç ≈°irom svijeta. Internetski pretra≈æivaƒçi skupljaju razliƒçite informacije o internetskim stranicama, ukljuƒçuju ih u svoju bazu te nude svakom korisniku, koji tra≈æi odreƒëeni pojam, uslugu, proizvod ili bilo ≈°to drugo. Internetski pretra≈æivaƒç ima tri dijela: 1. program za prikupljanje podataka s Web stranica koje posjeƒáuje (eng. crawler, spider), 2. indeks koji sadr≈æi pojmove koje je program za prikupljanje prikupio tijekom svojih posjeta Web stranicama (eng. index), 3. pretra≈æivaƒç (postojeƒáeg indeksa) (eng. search engine). 1. Internetski pretra≈æivaƒçi rade prikupljajuƒái informacije o mnogim Web stranicama, koje pronaƒëu na samom World Wide Web-u. Te stranice je prikupio Web crawler, spider (hrv. pauk) ‚Äì automatizirani Web preglednik koji slijedi svaki link koji vidi. 2. Sadr≈æaj svake stranice se potom analizira, s ciljem ustanovljavanja naƒçina indeksiranja. Podaci o Web stranicama su spremljeni u bazu podataka indeksa za upotrebu u sljedeƒáim upitima. 3. Kada korisnik postavi upit pretra≈æivaƒçu (obiƒçno koristeƒái kljuƒçne rijeƒçi) pretra≈æivaƒç pregledava svoj indeks i osigurava listu najbolje usklaƒëenih Web stranica s kriterijima, u pravilu sa sa≈æetkom koji sadr≈æava naslov dokumenta, a ponekad i dijelove teksta. Korisnost pretra≈æivaƒça ovisi o relevantnosti skupa rezultata koje on daje. Iako mogu postojati milijuni Web stranica koje ukljuƒçuju odreƒëenu rijeƒç ili izraz, neke stranice mogu biti relevantnije, popularnije ili pouzdanije od drugih. Veƒáina pretra≈æivaƒça primjenjuje metode nizanja rezultata s ciljem pribavljanja prvo ‚Äûnajboljih‚Äú rezultata ‚Äì naƒçin rada razlikuje se od jednog do drugog pretra≈æivaƒça. Postoje 1. opƒái internetski pretra≈æivaƒçi koji pretra≈æuju razliƒçita brojna podruƒçja ljudskog znanja i djelovanja (npr. Google) te 2. specijalizirani internetski pretra≈æivaƒçi koji pretra≈æuju jedno u≈æe podruƒçje ljudskog znanja i djelovanja (npr. eBay). Google je danas na zapadu svakako najpoznatija i razmjerno najbolja tra≈æilica za regionalne teme na germanskim i romanskim jezicima latiniƒçnog pisma iz zapadne Europe, te obje Amerike i Australije, dok je znatno slabiji za istoƒçnu Europu, Afriku i Aziju (gdje uglavnom pokriva Izrael, Taiwan i Japan). Bing je tra≈æilica u vlasni≈°tvu kompanije Microsoft. To je jedna od najstarijih tra≈æilica, koja radi na principu tra≈æilice Google. Nakon pojave Googlea na zapadu se poƒçela manje upotrijebljavati. Osnovana je veƒá 1995., a od 2003. je u vlasni≈°tvu kompanije Yahoo!. Uga≈°ena je 8. srpnja 2013. godine. Wolfram Alpha, pravog naziva Wolfram|Alpha je znanstvena tra≈æilica, da je tako nazovemo. Razvijena je od strane kompanije Wolfram Research. Svekolikoj javnosti prikazana je 15.5.2009. Podloga tra≈æilice je program Mathematica, oko 6 milijuna linija programskog koda, a pogoni je preko 10 000 procesora. Naravno, ta se brojka stalno mijenja zbog nadogradnje. Alpha za sada nema snagu Mathematice, ali nas Wolfram Research uvjerava da da ƒáe razvijati Alphu upravo u tom smjeru. ƒåovjek koji stoji iza cijelog projekta je Stephen Wolfram, autor Mathematice. DuckDuckGo je tra≈æilica koja za razliku od ostalih veƒáih pretra≈æivaƒça ne prikuplja osobne podatke korisnika niti ih prosljeƒëuje ogla≈°ivaƒçima (treƒáoj strani). Od poƒçetka rada u sijeƒçnju 2017. bilje≈æi stalan rast pretra≈æivanja te se prometnula u glavnu alternativnu tra≈æilicu, i sama se nameƒáuƒái kao zamjena monopolu velikih tra≈æilica, posebice Googlea. Meta-pretra≈æivaƒçi su vrsta internetskog pretra≈æivaƒça uz pomoƒá ƒçijeg suƒçelja je moguƒáe pretra≈æivati nekoliko drugih izvora informacija (najƒçe≈°ƒáe pretra≈æivaƒça) odjednom. Korisnici upit unose samo jednom, a on se potom distribuira prema vi≈°e drugih pretra≈æivaƒça i/ili baza podataka, uz zajedniƒçki prikaz rezultata sa svakog od njih. Postoje 1. Web meta-pretra≈æivaƒçi koji objedinjuju i rangiraju rezultate na jednoj Web stranici (npr. Metacrawler) i 2. samostalni programi za pretra≈æivanje s vlastitim suƒçeljem (npr. Copernic Agent, FirstStop Websearch)."
  },
  {
    "url": "https://id.wikipedia.org/wiki/Mesin_pencari",
    "title": "Mesin pencari - Wikipedia bahasa Indonesia, ensiklopedia bebas",
    "content": "Mesin pencari web atau mesin telusur web (bahasa Inggris: web search engine) adalah program komputer yang dirancang untuk melakukan pencarian atas berkas-berkas yang tersimpan dalam layanan www, ftp, publikasi milis, ataupun news group dalam sebuah ataupun sejumlah komputer peladen dalam suatu jaringan. Mesin pencari merupakan perangkat penelusur informasi dari dokumen-dokumen yang tersedia. Hasil pencarian umumnya ditampilkan dalam bentuk daftar yang sering kali diurutkan menurut tingkat akurasi ataupun rasio pengunjung atas suatu berkas yang disebut sebagai hits. Informasi yang menjadi target pencarian bisa terdapat dalam berbagai macam jenis berkas seperti halaman situs web, gambar, ataupun berkas lainnya. Beberapa mesin pencari juga diketahui melakukan pengumpulan informasi atas data yang tersimpan dalam suatu basis data ataupun direktori laman/situs (web).\nSebagian besar mesin pencari dijalankan oleh perusahaan swasta yang menggunakan algoritme kepemilikan dan basis data tertutup, diantaranya yang paling populer adalah safari Google (MSN Search dan Yahoo!). Telah ada beberapa upaya menciptakan mesin pencari dengan sumber terbuka (open source), contohnya adalah Htdig, Nutch, Egothor dan OpenFTS.[1] Saat awal perkembangan internet, Tim Berners-Lee membuat sebuah situs web yang berisikan daftar situs web yang ada di internet melalui peladen web CERN. Sejarah yang mencatat sejak tahun 1992 masih ada hingga kini.[2] Dengan semakin banyaknya situs web yang aktif membuat daftar ini tidak lagi memungkinkan untuk dikelola oleh manusia. Utilitas pencari yang pertama kali digunakan untuk melakukan pencarian di internet adalah Archie yang berasal dari kata \"archive\" tanpa menggunakan huruf \"v\".[3] Archie dibuat tahun 1990 oleh Alan Emtage, Bill Heelan dan J. Peter Deutsch, saat itu adalah mahasiswa ilmu komputer Universitas McGill, Amerika Serikat. Cara kerja program tersebut adalah mengunduh daftar direktori serta berkas yang terdapat pada layanan ftp publik (anonim) kemudian memuatnya ke dalam basis data yang memungkinkan pencarian. Mesin pencari lainnya seperti Aliweb, muncul di 1993 dan masih berjalan hingga saat ini. Salah satu mesin pencari pertama yang sekarang berkembang menjadi usaha komersial yang cukup besar adalah Lycos, yang dimulai di Carnegie Mellon University sebagai proyek riset pada tahun 1994. Segera setelah itu, banyak mesin pencari yang bermunculan dan bersaing memperebutkan popularitas. Termasuk di antaranya adalah Safari (sebuah mesin pencarian) yang aman dan untuk publik. Masing-masing bersaing dengan menambahkan layakan-layanan tambahan seperti yang dilakukan oleh Yahoo. Tahun 2002 Yahoo! mengakuisisi Inktomi, setahun kemudian mengakuisisi AlltheWeb dan Altavista kemudian meluncurkan mesin pencari sendiri yang didasarkan pada teknologi gabungan dari mesin-mesin pencari yang telah diakuisisinya serta memberikan layanan yang mengutamakan situs pencarian  daripada layanan-layanan lainnya. Di bulan desember 2003, Orase menerbitkan versi pertama dari teknologi situs atau laman pencarian. Mesin ini memiliki banyak fungsi baru dan tingkat unjuk kerja yang jauh lebih baik. Mesin pencari juga dikenal sebagai target investasi internet yang terjadi pada akhir tahun 1990-an. Beberapa perusahaan mesin pencari yang masuk ke dalam pasar saham diketahui mencatat keuntungan besar. Sebagian lagi sama sekali menonaktifkan layanan mesin pencari, dan hanya memasarkannya pada edisi perusahaan (entreprise) saja, contoh Northern Light, sebelumnya diketahui merupakan salah satu perintis layanan mesin pencari di internet. Buku Osmar R. Za√Øane From Resource Discovery to Knowledge Discovery on the Internet menjelaskan secara rinci sejarah teknologi mesin pencari sebelum munculnya Google. Mesin-mesin pencari lainnya mencakup a9.com, AlltheWeb, Ask Jeeves, Clusty, Gigablast, Teoma, Wisenut, GoHook, Kartoo, dan Vivisimo. Google muncul pada akhir tahun 1997, di mana Google memasuki pasar yang telah diisi oleh para pesaing lain dalam penyediaan layanan mesin pencari, seperti Yahoo, Altavista, HotBot, Excite, InfoSeek dan Lycos, di mana perusahaan-perusahaan tersebut mengklaim sebagai perusahaan yang bergerak dalam bidang layanan pencarian di internet. Hingga akhirnya Google mampu menjadi sebagai penyedia mesin pencari yang cukup diperhitungkan di dunia. Saat tingginya persaingan antar mesin pencari yang ada, namun mesin pencari lain tidak mampu menghentikan kesuksesan Google. Setelah Yahoo mampu pada posisi puncak di sekitar tahun 2000, Google mampu menerobos liga besar tersebut. sehingga Google dipandang sebagai mesin pencari yang utama seperti yang kita ketahui pada hari ini. Yahoo! raja direktori di internet, di samping para pengguna internet melihat DMOZ serta LookSmart berusaha menurunkan nya dari posisi puncak tersebut. Akhir-akhir ini, telah tumbuh secara cepat dalam ukurannya, mereka pun sudah memiliki harga sehingga mudah untuk memasukinya, dengan demikian, mendapatkan sebuah daftar pada direktori Yahoo memang memiliki nilai yang tinggi. pada tahun 2001, mesin pencari Google berkembang besar. Keberhasilan ini didasarkan pada bagian konsep dasar dari link popularity dan PageRank. Setiap halaman diurutkan berdasarkan seberapa banyak situs yang terkait, dari sebuah premis bahwa situs yang diinginkan pasti lebih banyak terhubung daripada yang lain. Rangking situs (The PageRank) dari sebuah link halaman dan jumlah link dari halaman-halaman tersebut merupakan masukan bagi Rangking situs yang bersangkutan. Hal ini memungkinkan bagi Google untuk mengurutkan hasilnya berdasarkan seberapa banyak halaman situs yang menuju ke halaman yang ditemukannya. User interface Google sangat disukai oleh pengguna, dan hal ini berkembang ke para pesaingnya. Mesin pencari web bekerja dengan cara menyimpan informasi tentang banyak halaman web, yang diambil langsung dari WWW. Halaman-halaman ini diambil dengan web crawler ‚Äî browser web otomatis yang mengikuti setiap pranala/link yang dilihatnya. Isi setiap halaman lalu dianalisis untuk menentukan cara indeks-nya (misalnya, kata-kata diambil dari judul, subjudul, atau field khusus yang disebut meta tag). Data tentang halaman web disimpan dalam sebuah indeks basis data untuk digunakan dalam pencarian selanjutnya. Sebagian mesin pencari, seperti Google, menyimpan seluruh atau sebagian halaman sumber (yang disebut tembolok/cache) maupun informasi tentang halaman situs/laman itu sendiri. Selain halaman situs (web), Mesin pencari juga menyimpan dan memberikan informasi hasil pencarian berupa pranala yang merujuk pada file, seperti dokumen/file audio, dokumen/file video, gambar, foto dan sebagainya, serta informasi tentang seseorang, suatu produk, layanan, dan informasi beragam lainnya yang semakin terus berkembang sesuai dengan perkembangan teknologi informasi. Ketika seseorang mengunjungi mesin pencari dan memasukkan query, biasanya dengan memasukkan kata kunci, mesin mencari indeks dan memberikan daftar halaman web yang paling sesuai dengan kriterianya, biasanya disertai ringkasan singkat mengenai judul dokumen dan kadang-kadang sebagian teksnya. Ada jenis mesin pencari lain: mesin pencari real-time. Mesin seperti ini tidak menggunakan indeks. Informasi yang diperlukan mesin tersebut hanya dikumpulkan jika ada pencarian baru. Jika dibandingkan dengan sistem berbasis indeks yang digunakan mesin-mesin seperti Google, sistem real-time ini unggul dalam beberapa hal: informasi selalu mutakhir, (hampir) tak ada pranala mati, dan lebih sedikit sumber daya sistem yang diperlukan. (Google menggunakan hampir 100.000 komputer, Orase hanya satu.) Tetapi, ada juga kelemahannya: pencarian lebih lama rampungnya. Manfaat mesin pencari bergantung pada relevansi hasil-hasil yang diberikannya. Meskipun mungkin ada jutaan halaman web yang mengandung suatu kata atau frasa, sebagian halaman mungkin lebih relevan, populer, atau autoritatif daripada yang lain. Kebanyakan mesin pencari menggunakan berbagai metode untuk menentukan peringkat hasil pencarian agar mampu memberikan hasil \"terbaik\" lebih dahulu. Cara mesin menentukan halaman mana yang paling sesuai, dan urutan halaman-halaman itu diperlihatkan, sangat bervariasi. Metode-metode nya juga berubah seiring waktu dengan berubahnya penggunaan internet dan berevolusinya teknik-teknik baru. Sebagian besar mesin pencari web adalah usaha komersial yang didukung pemasukan iklan dan karenanya sebagian menjalankan praktik kontroversial, yaitu membolehkan pengiklan membayar agar halaman mereka diberi peringkat lebih tinggi dalam hasil pencarian. Melakukan pencarian dokumen yang dimuat pada suatu situs bisa begitu mudah dan kelihatannya mungkin sulit juga. apalagi mengingat begitu menyebarnya informasi di mana-mana, bahkan University of California menyebutkan saat ini telah terdapat lebih dari 50 miliar halaman web di internet, meskipun tidak ada ada satupun yang benar-benar tahu jumlah persisnya. Kesulitan yang mungkin terjadi adalah karena WWW tersebut tidak terdata dalam bentuk yang terstandardisasi isinya. Tidak sama halnya dengan katalog yang ada di perpustakaan, yang memiliki standardisasi secara mendunia berdasarkan subjek dari judul buku, meskipun jumlahnya juga tidak sedikit. Dalam pencarian di web, pengguna selalu memperkirakan kata apa yang kira-kira terdapat pada halaman yang ingin di temukan. Atau kira-kira apa subjek yang dipilih oleh seseorang untuk mengelola halaman situs yang mereka kelola, topik apa saja kira-kira yang di bahas. Jika pengguna melakukan apa yang dikenal dengan pencarian pada halaman web, sebenarnya tidaklah melakukan pencarian. Tidak mungkin melakukan pencarian di WWW secara langsung. Pada web benar-benar terdiri dari banyak sekali halaman web yang disimpan dari berbagai server diseluruh dunia. Komputer pengguna tidak langsung melakukan pencarian kepada seluruh komputer tersebut secara langsung. Apa yang mungkin pengguna lakukan hanyalah melalui komputer untuk mengakses satu atau lebih perantara yang disebut dengan alat bantu pencarian yang ada saat ini. Melakukan pencarian pada alat bantu itu tadi ke database yang dimiliki. Database tersebut mengkoleksi situs-situs yang ditemukan dan simpan. Alat bantu pencarian ini menyediakan hasil pencarian dalam bentuk hypertext link dengan URL menuju halaman lainnya. Saat diklik, dan menuju ke alamat tersebut maka dokumen, gambar, suara dan banyak lagi bentuk lainnya yang ada pada server tersebut disediakan, sesuai dengan informasi yang terdapat di dalamnya. Layanan ini bisa menjangkau ke manapun di seluruh dunia. Tidak mungkin seseorang melakukan pencarian ke seluruh komputer yang terhubung ke internet, atau bahkan alat bantu pencarian yang mengklaim bahwa melakukannya, tidak benar. Saat ini, tiga bentuk dari alat bantu pencarian ini. Menggunakan strategi yang berbeda untuk memanfaatkan kemampuan potensial dari masing-masing nya, yaitu Karakteristik: Karakteristik: Sistem kinerja mesin ini ada beberapa hal yang perlu di perhatikan terutama keterkaitannya dengan masalah arsitektur dan mekanismenya. Merupakan program yang men-download halaman-halaman yang mereka temukan, mirip dengan browser. Perbedaannya adalah bahwa browser menampilkan secara langsung informasi yang ada (baik tekas, gambar, dll). Untuk kepentingan manusia yang menggunakannya pada saat itu, sedangkan spider tidak melakukan untuk menampilkan dalam bentuk yang terlihat seperti itu, karena kepentingannya adalah untuk mesin, bukan untuk manusia, spider pun dijalankan oleh mesin secara otomatis. Kepentingannya adalah untuk mengambil halaman-halaman yang dikunjunginya untuk disimpan kedalam database yang dimiliki oleh search engine. Merupakan program yang dimiliki mesin pencari untuk melacak dan menemukan link yang terdapat dari setiap halaman yang ditemuinya. Tugasnya adalah untuk menentukan spider harus pergi ke mana dan mengevaluasi link berdasarkan alamat yang ditentukan dari awal. Crawler mengikuti link dan mencoba menemukan dokumen yang belum dikenal oleh mesin pencari. Komponen ini melakukan aktivitas untuk menguraikan masing-masing halaman dan meneliti berbagai unsur, seperti teks, headers, struktur atau fitur dari gaya penulisan, tag HTML khusus, dll. Merupakan tempat standar untuk menyimpan data-data dari halaman yang telah dikunjungi, di-download dan sudah dianalisis. Kadang kala disebut juga dengan indeks dari suatu mesin pencari. Mesin yang melakukan penggolongan dan penentuan peringkat dari hasil pencarian pada mesin pencari. Mesin ini menentukan halaman mana yang menemui kriteria terbaik dari hasil pencarian berdasarkan permintaan penggunanya, dan bagaimana bentuk penampilan yang akan ditampilkan. Proses ini dilaksanakan berdasarkan algoritme perangkingan yang dimiliki oleh mesin pencari tersebut, mengikuti kaidah perangkingan halaman yang dipergunakan oleh mereka adalah hak mereka, para peneliti mempelajari sifat-sifat yang mereka gunakan, terutama untuk meningkatkan pencarian yang dihasilkan oleh mesin pencari tersebut. Merupakan komponen yang melayani permintaan dan memberikan respon balik dari permintaan tersebut. Web Server ini biasanya menghasilkan informasi atau dokumen dalam format HTML. Pada halaman tersebut tersedia layanan untuk mengisikan kata kunci pencarian yang diinginkan oleh usernya. Web Server ini juga bertanggung jawab dalam menyampaikan hasil pencarian yang dikirimkan kepada komputer yang meminta informasi. Berikut ini adalah beberapa mesin pencari populer hingga saat ini: Templat:Pencarian Internet"
  },
  {
    "url": "https://is.wikipedia.org/wiki/Leitarv%C3%A9l",
    "title": "Leitarv√©l - Wikipedia, frj√°lsa alfr√¶√∞iriti√∞",
    "content": "Leitarv√©l getur √Ωmist v√≠sa√∞ til s√©rstakra vefja e√∞a virkni √° vefs√≠√∞u er hefur √æ√° virkni a√∞ gera notandanum kleift a√∞ setja inn leitaror√∞ e√∞a -frasa og finna √æ√¶r tilteknu s√≠√∞ur sem innihalda √æa√∞ sem s√≥st er eftir. √ûr√≥a√∞ri leitarv√©lar reyna a√∞ greina samhengi or√∞a og or√∞asambanda √≠ √æeim tilgangi a√∞ birta eing√∂ngu ni√∞urst√∂√∞ur tengdar √æv√≠ sem notandinn var √≠ raun a√∞ leita eftir, til a√∞ mynda me√∞ √æv√≠ a√∞ √∫tiloka √≥tengdar merkingar or√∞a."
  },
  {
    "url": "https://he.wikipedia.org/wiki/%D7%9E%D7%A0%D7%95%D7%A2_%D7%97%D7%99%D7%A4%D7%95%D7%A9_(%D7%90%D7%99%D7%A0%D7%98%D7%A8%D7%A0%D7%98)",
    "title": "◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© (◊ê◊ô◊†◊ò◊®◊†◊ò) ‚Äì ◊ï◊ô◊ß◊ô◊§◊ì◊ô◊î",
    "content": "◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊î◊ô◊ê ◊™◊ï◊õ◊†◊î ◊©◊û◊ï◊¶◊ê◊™ ◊ì◊§◊ô ◊ê◊ô◊†◊ò◊®◊†◊ò ◊î◊™◊ï◊ê◊û◊ô◊ù ◊ú◊ó◊ô◊§◊ï◊© ◊ë◊ê◊ô◊†◊ò◊®◊†◊ò. ◊î◊û◊†◊ï◊¢ ◊û◊ó◊§◊© ◊ë◊®◊©◊™ ◊î◊¢◊ï◊ú◊û◊ô◊™ ◊ë◊¶◊ï◊®◊î ◊©◊ô◊ò◊™◊ô◊™ ◊ê◊ó◊® ◊û◊ô◊ì◊¢ ◊û◊°◊ï◊ô◊ù ◊©◊¶◊ï◊ô◊ü ◊ë◊©◊ê◊ô◊ú◊™◊™ ◊î◊ó◊ô◊§◊ï◊© ◊î◊ò◊ß◊°◊ò◊ï◊ê◊ú◊ô◊™. ◊™◊ï◊¶◊ê◊ï◊™ ◊î◊ó◊ô◊§◊ï◊© ◊û◊ï◊¶◊í◊ï◊™ ◊ë◊ì◊®◊ö ◊õ◊ú◊ú ◊ë◊©◊ï◊®◊î ◊©◊ú ◊™◊ï◊¶◊ê◊ï◊™, ◊î◊û◊õ◊ï◊†◊î ◊ú◊®◊ï◊ë ◊ì◊§◊ô ◊™◊ï◊¶◊ê◊ï◊™ ◊©◊ú ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© (SERP). ◊î◊û◊ô◊ì◊¢ ◊¢◊©◊ï◊ô ◊ú◊î◊ô◊ï◊™ ◊©◊ô◊ú◊ï◊ë ◊©◊ú ◊î◊ô◊§◊®-◊ß◊ô◊©◊ï◊®◊ô◊ù ◊ú◊ì◊§◊ô ◊ê◊ô◊†◊ò◊®◊†◊ò, ◊™◊û◊ï◊†◊ï◊™, ◊°◊®◊ò◊ï◊†◊ô◊ù, ◊ê◊ô◊†◊§◊ï◊í◊®◊§◊ô◊ß◊î, ◊û◊ê◊û◊®◊ô◊ù ◊ï◊°◊ï◊í◊ô◊ù ◊ê◊ó◊®◊ô◊ù ◊©◊ú ◊ß◊ë◊¶◊ô◊ù. ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊û◊°◊ï◊ô◊û◊ô◊ù ◊í◊ù ◊õ◊ï◊®◊ô◊ù ◊†◊™◊ï◊†◊ô◊ù ◊î◊ñ◊û◊ô◊†◊ô◊ù ◊ë◊û◊°◊ì◊ô ◊†◊™◊ï◊†◊ô◊ù ◊ê◊ï ◊ë◊°◊§◊®◊ô◊ï◊™ ◊§◊™◊ï◊ó◊ï◊™. ◊©◊ú◊ê ◊õ◊û◊ï ◊°◊§◊®◊ô◊ï◊™ ◊ê◊ô◊†◊ò◊®◊†◊ò ◊©◊û◊™◊ï◊ó◊ñ◊ß◊ô◊ù ◊¢◊ú ◊ô◊ì◊ô ◊¢◊ï◊®◊õ◊ô◊ù ◊ê◊†◊ï◊©◊ô◊ô◊ù, ◊û◊†◊ï◊¢◊ô ◊î◊ó◊ô◊§◊ï◊© ◊í◊ù ◊©◊ï◊û◊®◊ô◊ù ◊¢◊ú ◊û◊ô◊ì◊¢ ◊ë◊ñ◊û◊ü ◊ê◊û◊™ ◊¢◊ú ◊ô◊ì◊ô ◊î◊§◊¢◊ú◊™ ◊ê◊ú◊í◊ï◊®◊ô◊™◊ù ◊©◊°◊ï◊®◊ß ◊ê◊™ ◊î◊ê◊ô◊†◊ò◊®◊†◊ò. ◊õ◊ú ◊™◊ï◊õ◊ü ◊û◊ë◊ï◊°◊° ◊ê◊ô◊†◊ò◊®◊†◊ò ◊©◊ú◊ê ◊†◊ô◊™◊ü ◊ú◊ê◊ô◊†◊ì◊ß◊° ◊ï◊ú◊ó◊§◊© ◊ë◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊ê◊ô◊†◊ò◊®◊†◊ò◊ô ◊†◊ï◊§◊ú ◊ú◊ß◊ò◊í◊ï◊®◊ô◊î ◊©◊ú \"◊ê◊ô◊†◊ò◊®◊†◊ò ◊¢◊û◊ï◊ß\". ◊û◊¢◊®◊õ◊™ ◊ú◊ê◊ô◊™◊ï◊® ◊û◊ô◊ì◊¢ ◊û◊§◊ï◊®◊°◊ù ◊©◊†◊ï◊¢◊ì◊î ◊ú◊î◊™◊í◊ë◊® ◊¢◊ú ◊î◊ß◊ï◊©◊ô ◊î◊î◊ï◊ú◊ö ◊ï◊í◊ï◊ë◊® ◊ú◊ê◊™◊® ◊û◊ô◊ì◊¢ ◊ë◊ê◊ô◊†◊ì◊ß◊°◊ô◊ù ◊û◊®◊õ◊ñ◊ô◊ô◊ù ◊î◊ï◊ú◊õ◊ô◊ù ◊ï◊í◊ì◊ú◊ô◊ù ◊©◊ú ◊¢◊ë◊ï◊ì◊î ◊û◊ì◊¢◊ô◊™ ◊™◊ï◊ê◊®◊î ◊ë-1945 ◊¢◊ú ◊ô◊ì◊ô ◊ï◊ê◊†◊ë◊® ◊ë◊ï◊©, ◊©◊õ◊™◊ë ◊û◊ê◊û◊® ◊ë◊ê◊ò◊ú◊†◊ò◊ô◊ß ◊û◊ê◊†◊™◊ú◊ô ◊ë◊©◊ù \"◊õ◊§◊ô ◊©◊ê◊†◊ï ◊¢◊©◊ï◊ô◊ô◊ù ◊ú◊ó◊©◊ï◊ë\" (◊ê◊†')[1] ◊©◊ë◊ï ◊ó◊ñ◊î ◊°◊§◊®◊ô◊ï◊™ ◊û◊ó◊ß◊® ◊¢◊ù ◊î◊¢◊®◊ï◊™ ◊û◊ß◊ï◊©◊®◊ï◊™ ◊ú◊ê ◊ë◊†◊ô◊í◊ï◊ì ◊ú◊ß◊ô◊©◊ï◊®◊ô ◊î◊ô◊§◊®◊ò◊ß◊°◊ò ◊û◊ï◊ì◊®◊†◊ô◊ô◊ù. ◊†◊ô◊™◊ï◊ó ◊ß◊ô◊©◊ï◊®◊ô◊ù ◊ú◊ë◊°◊ï◊£ ◊ô◊î◊§◊ï◊ö ◊ú◊®◊õ◊ô◊ë ◊û◊õ◊®◊ô◊¢ ◊ë◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊ë◊ê◊û◊¶◊¢◊ï◊™ ◊ê◊ú◊í◊ï◊®◊ô◊™◊û◊ô◊ù ◊õ◊û◊ï Hyper Search ◊ï-PageRank. ◊û◊†◊ï◊¢◊ô ◊î◊ó◊ô◊§◊ï◊© ◊î◊®◊ê◊©◊ï◊†◊ô◊ù ◊ë◊ê◊ô◊†◊ò◊®◊†◊ò ◊ß◊ì◊û◊ï ◊ú◊î◊ï◊§◊¢◊™ ◊î◊®◊©◊™ ◊ë◊ì◊¶◊û◊ë◊® 1990: ◊ó◊ô◊§◊ï◊© ◊û◊©◊™◊û◊©◊ô WHOIS(◊ê◊†') ◊ï◊©◊ô◊®◊ï◊™ ◊û◊ô◊ì◊¢ Knowbot ◊ú◊ó◊ô◊§◊ï◊© ◊û◊©◊™◊û◊©◊ô◊ù ◊®◊ë-◊®◊©◊™◊ô ◊ô◊ï◊©◊ù ◊ú◊®◊ê◊©◊ï◊†◊î ◊ë-1989. ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊û◊™◊ï◊¢◊ì ◊î◊ô◊ò◊ë ◊î◊®◊ê◊©◊ï◊ü ◊©◊ó◊ô◊§◊© ◊ß◊ï◊ë◊¶◊ô ◊™◊ï◊õ◊ü, ◊ï◊ë◊§◊®◊ò ◊ß◊ï◊ë◊¶◊ô FTP, ◊î◊ô◊î ◊ê◊®◊¶'◊ô, ◊©◊î◊ï◊§◊ô◊¢ ◊ú◊®◊ê◊©◊ï◊†◊î ◊ë-10 ◊ë◊°◊§◊ò◊û◊ë◊® 1990. ◊ú◊§◊†◊ô ◊°◊§◊ò◊û◊ë◊® 1993, ◊î◊®◊©◊™ ◊î◊¢◊ï◊ú◊û◊ô◊™ (World Wide Web) ◊ê◊ï◊†◊ì◊ß◊°◊î ◊õ◊ï◊ú◊î ◊ë◊ê◊ï◊§◊ü ◊ô◊ì◊†◊ô. ◊î◊ô◊ô◊™◊î ◊®◊©◊ô◊û◊î ◊©◊ú ◊©◊®◊™◊ô ◊®◊©◊™ ◊¢◊ï◊ú◊û◊ô◊™ ◊©◊¢◊®◊ö ◊ò◊ô◊ù ◊ë◊®◊†◊®◊°-◊ú◊ô ◊ï◊ê◊ô◊®◊ó ◊ë◊©◊®◊™ CERN. ◊†◊ï◊™◊® ◊™◊ô◊¢◊ï◊ì ◊ê◊ó◊ì ◊©◊ú ◊î◊®◊©◊ô◊û◊î ◊û-1992[2]. ◊õ◊õ◊ú ◊©◊ô◊ï◊™◊® ◊ï◊ô◊ï◊™◊® ◊©◊®◊™◊ô ◊®◊©◊™ ◊î◊ó◊ú◊ï ◊ú◊§◊¢◊ï◊ú ◊û◊ß◊ï◊ï◊†◊™, ◊î◊®◊©◊ô◊û◊î ◊î◊û◊®◊õ◊ñ◊ô◊™ ◊ú◊ê ◊ô◊õ◊ú◊î ◊¢◊ï◊ì ◊ú◊¢◊ß◊ï◊ë ◊ê◊ó◊® ◊î◊û◊¶◊ë. ◊ë◊ê◊™◊® NCSA ◊î◊ï◊õ◊®◊ñ◊ï ◊©◊®◊™◊ô◊ù ◊ó◊ì◊©◊ô◊ù ◊™◊ó◊™ ◊î◊õ◊ï◊™◊®◊™ \"◊û◊î ◊ó◊ì◊©!\" ◊î◊õ◊ú◊ô ◊î◊®◊ê◊©◊ï◊ü ◊©◊©◊ô◊û◊© ◊ú◊ó◊ô◊§◊ï◊© ◊™◊ï◊õ◊ü (◊ú◊¢◊ï◊û◊™ ◊û◊©◊™◊û◊©◊ô◊ù) ◊ë◊ê◊ô◊†◊ò◊®◊†◊ò ◊î◊ô◊î ◊ê◊®◊¶'◊ô. ◊î◊©◊ù ◊û◊ô◊ô◊¶◊í ◊ê◊™ ◊î◊û◊ô◊ú◊î ◊î◊ê◊†◊í◊ú◊ô◊™ ◊ú\"◊ê◊®◊õ◊ô◊ï◊ü\" ◊ú◊ú◊ê ◊î-\"◊ï◊ü\". ◊î◊õ◊ú◊ô ◊†◊ï◊¶◊® ◊¢◊ú ◊ô◊ì◊ô ◊ê◊ú◊ü ◊ê◊û◊ò◊ê◊í', ◊°◊ò◊ï◊ì◊†◊ò ◊ú◊û◊ì◊¢◊ô ◊î◊û◊ó◊©◊ë ◊ë◊ê◊ï◊†◊ô◊ë◊®◊°◊ô◊ò◊™ ◊û◊ß◊í◊ô◊ú ◊ë◊û◊ï◊†◊ò◊®◊ô◊ê◊ï◊ú, ◊ß◊ï◊ï◊ô◊ë◊ß, ◊ß◊†◊ì◊î. ◊î◊™◊ï◊õ◊†◊î ◊î◊ï◊®◊ô◊ì◊î ◊ê◊™ ◊®◊©◊ô◊û◊ï◊™ ◊î◊™◊ô◊ß◊ô◊ï◊™ ◊©◊ú ◊õ◊ú ◊î◊ß◊ë◊¶◊ô◊ù ◊î◊û◊û◊ï◊ß◊û◊ô◊ù ◊ë◊ê◊™◊®◊ô FTP ◊¶◊ô◊ë◊ï◊®◊ô◊ô◊ù ◊ê◊†◊ï◊†◊ô◊û◊ô◊ô◊ù, ◊ï◊ô◊¶◊®◊î ◊ë◊°◊ô◊° ◊†◊™◊ï◊†◊ô◊ù ◊†◊ô◊™◊ü ◊ú◊ó◊ô◊§◊ï◊© ◊©◊ú ◊©◊û◊ï◊™ ◊ß◊ë◊¶◊ô◊ù; ◊¢◊ù ◊ñ◊ê◊™, ◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊ê◊®◊¶'◊ô ◊ú◊ê ◊ê◊ô◊†◊ì◊ß◊° ◊ê◊™ ◊™◊ï◊õ◊ü ◊î◊ê◊™◊®◊ô◊ù ◊î◊ê◊ú◊î ◊û◊õ◊ô◊ï◊ï◊ü ◊©◊õ◊û◊ï◊™ ◊î◊†◊™◊ï◊†◊ô◊ù ◊î◊ô◊ô◊™◊î ◊õ◊î ◊û◊ï◊í◊ë◊ú◊™ ◊©◊†◊ô◊™◊ü ◊î◊ô◊î ◊ú◊ó◊§◊© ◊ë◊î ◊ô◊ì◊†◊ô◊™ ◊ë◊ß◊ú◊ï◊™. ◊¢◊ú◊ô◊ô◊™ ◊§◊®◊ï◊ò◊ï◊ß◊ï◊ú ◊î◊™◊ß◊©◊ï◊®◊™ ◊í◊ï◊§◊® (◊©◊†◊ï◊¶◊®◊î ◊ë-1991 ◊¢◊ú ◊ô◊ì◊ô ◊û◊ê◊®◊ß ◊û◊ß'◊ß◊ê◊î◊ô◊ú ◊û◊ê◊ï◊†◊ô◊ë◊®◊°◊ô◊ò◊™ ◊û◊ô◊†◊°◊ï◊ò◊î) ◊î◊ï◊ë◊ô◊ú◊î ◊ú◊©◊†◊ô ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊ó◊ì◊©◊ô◊ù, ◊ï◊®◊ï◊†◊ô◊ß◊î ◊ï◊í'◊ê◊í◊î◊ì. ◊õ◊û◊ï ◊ê◊®◊¶'◊ô, ◊î◊ù ◊ó◊ô◊§◊©◊ï ◊ë◊©◊û◊ï◊™ ◊î◊ß◊ë◊¶◊ô◊ù ◊ï◊î◊õ◊ï◊™◊®◊ï◊™ ◊î◊û◊ê◊ï◊ó◊°◊†◊ô◊ù ◊ë◊û◊¢◊®◊õ◊ï◊™ ◊î◊ê◊ô◊†◊ì◊ß◊° ◊©◊ú ◊í◊ï◊§◊®. ◊ï◊®◊ï◊†◊ô◊ß◊î (◊ê◊ô◊†◊ì◊ß◊° ◊®◊©◊™◊ô ◊ß◊ú ◊û◊ê◊ï◊ì ◊ú◊î◊§◊¢◊ú◊î ◊©◊ú ◊ê◊®◊õ◊ô◊ï◊†◊ô◊ù ◊û◊û◊ï◊ó◊©◊ë◊ô◊ù) ◊°◊ô◊§◊ß◊î ◊ó◊ô◊§◊ï◊© ◊û◊ô◊ú◊ï◊™ ◊û◊§◊™◊ó ◊©◊ú ◊®◊ï◊ë ◊õ◊ï◊™◊®◊ï◊™ ◊î◊™◊§◊®◊ô◊ò ◊©◊ú ◊í◊ï◊§◊® ◊ë◊õ◊ú ◊®◊©◊ô◊û◊ï◊™ ◊î◊í◊ï◊§◊®. ◊í'◊ê◊í◊î◊ì (◊ó◊§◊ô◊®◊î ◊î◊ô◊®◊®◊õ◊ô◊™ ◊ê◊ï◊†◊ô◊ë◊®◊°◊ú◊ô◊™ ◊©◊ú ◊í'◊ï◊†◊ñ◊ô ◊ï◊™◊¶◊ï◊í◊î ◊©◊ú◊î◊ù) ◊î◊ô◊î ◊õ◊ú◊ô ◊ú◊î◊©◊í◊™ ◊û◊ô◊ì◊¢ ◊™◊§◊®◊ô◊ò◊ô ◊û◊©◊®◊™◊ô ◊í◊ï◊§◊® ◊°◊§◊¶◊ô◊§◊ô◊ô◊ù. ◊ë◊ß◊ô◊• 1993, ◊ú◊ê ◊î◊ô◊î ◊ß◊ô◊ô◊ù ◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊ë◊®◊©◊™, ◊ú◊û◊®◊ï◊™ ◊©◊ß◊ò◊ú◊ï◊í◊ô◊ù ◊û◊ß◊¶◊ï◊¢◊ô◊ô◊ù ◊®◊ë◊ô◊ù ◊™◊ó◊ñ◊ß◊ï ◊ô◊ì◊†◊ô◊™. ◊ê◊ï◊°◊ß◊® ◊†◊ô◊ô◊®◊©◊ò◊®◊ê◊ñ ◊û◊î◊ê◊ï◊†◊ô◊ë◊®◊°◊ô◊ò◊î ◊©◊ú ◊ñ'◊†◊ë◊î ◊õ◊™◊ë ◊°◊ì◊®◊î ◊©◊ú ◊™◊°◊®◊ô◊ò◊ô Perl ◊©◊î◊¢◊™◊ô◊ß◊ï ◊û◊ì◊ô ◊§◊¢◊ù ◊ì◊§◊ô◊ù ◊ê◊ú◊î ◊ï◊õ◊™◊ë◊ï ◊ê◊ï◊™◊ù ◊û◊ó◊ì◊© ◊ë◊§◊ï◊®◊û◊ò ◊ê◊ó◊ô◊ì. ◊ñ◊î ◊¢◊ô◊¶◊ë ◊ê◊™ ◊î◊ë◊°◊ô◊° ◊¢◊ë◊ï◊® W3Catalog, ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊§◊®◊ô◊û◊ô◊ò◊ô◊ë◊ô ◊î◊®◊ê◊©◊ï◊ü ◊©◊ú ◊î◊®◊©◊™, ◊©◊ô◊¶◊ê ◊ú◊ê◊ï◊® ◊ë-2 ◊ë◊°◊§◊ò◊û◊ë◊® 1993. ◊ë◊ô◊ï◊†◊ô 1993, ◊û◊™◊ô◊ï ◊í◊®◊ô◊ô, ◊ê◊ñ ◊ë-MIT, ◊î◊§◊ô◊ß ◊õ◊†◊®◊ê◊î ◊ê◊™ \"◊®◊ï◊ë◊ï◊ò ◊î◊®◊©◊™\" ◊î◊®◊ê◊©◊ï◊ü, ◊î◊†◊ï◊ì◊ì ◊ë◊®◊ó◊ë◊ô ◊î◊®◊©◊™ ◊î◊¢◊ï◊ú◊û◊ô◊™ ◊ë◊§◊®◊ú, ◊ï◊î◊©◊™◊û◊© ◊ë◊ï ◊õ◊ì◊ô ◊ú◊ô◊ô◊¶◊® ◊ê◊ô◊†◊ì◊ß◊° ◊ë◊©◊ù \"Wandex\". ◊û◊ò◊®◊™ ◊î◊®◊ï◊ë◊ï◊ò ◊î◊ô◊ô◊™◊î ◊ú◊û◊ì◊ï◊ì ◊ê◊™ ◊í◊ï◊ì◊ú ◊î◊®◊©◊™ ◊î◊¢◊ï◊ú◊û◊ô◊™, ◊û◊î ◊©◊¢◊©◊î ◊¢◊ì ◊°◊ï◊£ 1995. ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊©◊†◊ô ◊ë◊®◊©◊™, ◊ê◊ú◊ô◊ï◊ï◊ë, ◊î◊ï◊§◊ô◊¢ ◊ë◊†◊ï◊ë◊û◊ë◊® 1993. ◊ê◊ú◊ô◊ï◊ï◊ë ◊ú◊ê ◊î◊©◊™◊û◊© ◊ë◊®◊ï◊ë◊ï◊ò ◊®◊©◊™, ◊ê◊ú◊ê ◊î◊°◊™◊û◊ö ◊¢◊ú ◊î◊ï◊ì◊¢◊î ◊û◊û◊†◊î◊ú◊ô ◊ê◊™◊®◊ô ◊ê◊ô◊†◊ò◊®◊†◊ò ◊¢◊ú ◊ß◊ô◊ï◊û◊ï ◊©◊ú ◊ß◊ï◊ë◊• ◊ê◊ô◊†◊ì◊ß◊° ◊ë◊§◊ï◊®◊û◊ò ◊û◊°◊ï◊ô◊ù ◊ë◊õ◊ú ◊ê◊™◊®. JumpStation (◊†◊ï◊¶◊® ◊ë◊ì◊¶◊û◊ë◊® 1993 ◊¢◊ú ◊ô◊ì◊ô ◊í'◊ï◊†◊™◊ï◊ü ◊§◊ú◊ò◊¶'◊®) ◊î◊ï◊ê ◊î◊©◊™◊û◊© ◊ë◊®◊ï◊ë◊ï◊ò ◊®◊©◊™ ◊õ◊ì◊ô ◊ú◊û◊¶◊ï◊ê ◊ì◊§◊ô ◊®◊©◊™ ◊ï◊ú◊ë◊†◊ï◊™ ◊ê◊™ ◊î◊ê◊ô◊†◊ì◊ß◊° ◊©◊ú◊ï, ◊ï◊î◊©◊™◊û◊© ◊ë◊ò◊ï◊§◊° ◊®◊©◊™ ◊õ◊û◊û◊©◊ß ◊ú◊™◊ï◊õ◊†◊™ ◊î◊©◊ê◊ô◊ú◊™◊î ◊©◊ú◊ï. ◊ú◊õ◊ü, ◊ñ◊ï ◊î◊ô◊ô◊™◊î ◊î◊õ◊ú◊ô ◊î◊®◊ê◊©◊ï◊ü ◊ú◊í◊ô◊ú◊ï◊ô ◊û◊©◊ê◊ë◊ô WWW ◊©◊©◊ô◊ú◊ë ◊ê◊™ ◊©◊ú◊ï◊©◊™ ◊î◊û◊ê◊§◊ô◊ô◊†◊ô◊ù ◊î◊ó◊ô◊ï◊†◊ô◊ô◊ù ◊©◊ú ◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊®◊©◊™ (◊ñ◊ó◊ô◊ú◊î, ◊ê◊ô◊†◊ì◊ï◊ß◊¶◊ô◊î ◊ï◊ó◊ô◊§◊ï◊©) ◊õ◊û◊™◊ï◊ê◊® ◊ú◊î◊ú◊ü. ◊ë◊í◊ú◊ú ◊î◊û◊©◊ê◊ë◊ô◊ù ◊î◊û◊ï◊í◊ë◊ú◊ô◊ù ◊©◊î◊ô◊ï ◊ñ◊û◊ô◊†◊ô◊ù ◊¢◊ú ◊î◊§◊ú◊ò◊§◊ï◊®◊û◊î ◊©◊§◊¢◊ú◊î ◊¢◊ú◊ô◊î ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú◊î ◊î◊ï◊í◊ë◊ú ◊ú◊õ◊ï◊™◊®◊ï◊™ ◊ï◊õ◊ï◊™◊®◊ï◊™ ◊©◊†◊û◊¶◊ê◊ï ◊ë◊ì◊§◊ô ◊î◊®◊©◊™ ◊©◊û◊¶◊ê ◊î◊®◊ï◊ë◊ï◊ò. ◊ê◊ó◊ì ◊û◊û◊†◊ï◊¢◊ô ◊î◊ó◊ô◊§◊ï◊© ◊î◊®◊ê◊©◊ï◊†◊ô◊ù \"◊õ◊ú ◊î◊ò◊ß◊°◊ò\" ◊¢◊ú ◊ë◊°◊ô◊° ◊®◊ï◊ë◊ï◊ò ◊®◊©◊™ ◊î◊ô◊î WebCrawler, ◊©◊ô◊¶◊ê ◊ë-1994. ◊ë◊†◊ô◊í◊ï◊ì ◊ú◊ß◊ï◊ì◊û◊ô◊ï, ◊î◊ï◊ê ◊ê◊ô◊§◊©◊® ◊ú◊û◊©◊™◊û◊©◊ô◊ù ◊ú◊ó◊§◊© ◊õ◊ú ◊û◊ô◊ú◊î ◊ë◊õ◊ú ◊ì◊£ ◊®◊©◊™, ◊û◊î ◊©◊î◊§◊ö ◊ú◊°◊ò◊†◊ì◊®◊ò ◊¢◊ë◊ï◊® ◊õ◊ú ◊û◊†◊ï◊¢◊ô ◊î◊ó◊ô◊§◊ï◊© ◊î◊í◊ì◊ï◊ú◊ô◊ù ◊û◊ê◊ñ. ◊ñ◊î ◊í◊ù ◊î◊ô◊î ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊î◊ô◊î ◊û◊ï◊õ◊® ◊î◊ô◊ò◊ë ◊ú◊¶◊ô◊ë◊ï◊®. ◊õ◊û◊ï ◊õ◊ü, ◊ë-1994, Lycos (◊©◊î◊ó◊ú ◊ë◊ê◊ï◊†◊ô◊ë◊®◊°◊ô◊ò◊™ ◊ß◊®◊†◊í◊ô ◊û◊ú◊ï◊ü) ◊î◊ï◊©◊ß ◊ï◊î◊§◊ö ◊ú◊û◊ê◊û◊• ◊û◊°◊ó◊®◊ô ◊í◊ì◊ï◊ú. ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊§◊ï◊§◊ï◊ú◊®◊ô ◊î◊®◊ê◊©◊ï◊ü ◊ë◊®◊©◊™ ◊î◊ô◊î Yahoo! ◊ó◊ô◊§◊ï◊©. ◊î◊û◊ï◊¶◊® ◊î◊®◊ê◊©◊ï◊ü ◊û-Yahoo!, ◊©◊†◊ï◊°◊ì ◊¢◊ú ◊ô◊ì◊ô ◊í'◊®◊ô ◊ô◊ê◊†◊í ◊ï◊ì◊ô◊ô◊ï◊ï◊ô◊ì ◊§◊ô◊ú◊ï ◊ë◊ô◊†◊ï◊ê◊® 1994, ◊î◊ô◊î ◊°◊§◊®◊ô◊ô◊™ ◊®◊©◊™ ◊ë◊©◊ù ◊°◊§◊®◊ô◊ô◊™ Yahoo! ◊ë-1995 ◊†◊ï◊°◊§◊î ◊§◊ï◊†◊ß◊¶◊ô◊ô◊™ ◊ó◊ô◊§◊ï◊©, ◊©◊ê◊ô◊§◊©◊®◊î ◊ú◊û◊©◊™◊û◊©◊ô◊ù ◊ú◊ó◊§◊© ◊ë◊°◊§◊®◊ô◊ô◊™ Yahoo! ◊ñ◊î ◊î◊§◊ö ◊ú◊ê◊ó◊™ ◊î◊ì◊®◊õ◊ô◊ù ◊î◊§◊ï◊§◊ï◊ú◊®◊ô◊ï◊™ ◊ë◊ô◊ï◊™◊® ◊¢◊ë◊ï◊® ◊ê◊†◊©◊ô◊ù ◊ú◊û◊¶◊ï◊ê ◊ì◊§◊ô ◊®◊©◊™ ◊û◊¢◊†◊ô◊ô◊†◊ô◊ù, ◊ê◊ë◊ú ◊§◊ï◊†◊ß◊¶◊ô◊ô◊™ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú◊ï ◊§◊¢◊ú◊î ◊¢◊ú ◊°◊§◊®◊ô◊ô◊™ ◊î◊®◊©◊™ ◊©◊ú◊î, ◊ï◊ú◊ê ◊¢◊ú ◊î◊¢◊™◊ß◊ô ◊î◊ò◊ß◊°◊ò ◊î◊û◊ú◊ê ◊©◊ú ◊ì◊§◊ô ◊î◊®◊©◊™. ◊ñ◊û◊ü ◊ß◊¶◊® ◊ú◊ê◊ó◊® ◊û◊õ◊ü, ◊î◊ï◊§◊ô◊¢◊ï ◊û◊°◊§◊® ◊®◊ë ◊©◊ú ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊ï◊î◊™◊ó◊®◊ï ◊¢◊ú ◊§◊ï◊§◊ï◊ú◊®◊ô◊ï◊™. ◊ê◊ú◊î ◊õ◊ú◊ú◊ï ◊û◊í◊ú◊ü, ◊ê◊ß◊°◊ô◊ô◊ò, ◊ê◊ô◊†◊§◊ï◊°◊ô◊ß, ◊ê◊ô◊†◊ß◊ò◊ï◊û◊ô, Northern Light ◊ï-AltaVista. ◊û◊ó◊§◊©◊ô ◊û◊ô◊ì◊¢ ◊ô◊õ◊ú◊ï ◊í◊ù ◊ú◊¢◊ô◊ô◊ü ◊ë◊°◊§◊®◊ô◊ô◊î ◊ë◊û◊ß◊ï◊ù ◊ú◊ë◊¶◊¢ ◊ó◊ô◊§◊ï◊© ◊û◊ë◊ï◊°◊° ◊û◊ô◊ú◊ï◊™ ◊û◊§◊™◊ó. ◊ë-1996, ◊®◊ï◊ë◊ô◊ü ◊ú◊ô ◊§◊ô◊™◊ó ◊ê◊™ ◊ê◊ú◊í◊ï◊®◊ô◊™◊ù ◊ì◊ô◊®◊ï◊í ◊î◊ê◊™◊®◊ô◊ù RankDex ◊¢◊ë◊ï◊® ◊ì◊ô◊®◊ï◊í ◊™◊ï◊¶◊ê◊ï◊™ ◊ì◊£ ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊ï◊ß◊ô◊ë◊ú ◊§◊ò◊†◊ò ◊ê◊û◊®◊ô◊ß◊ê◊ô ◊¢◊ú ◊î◊ò◊õ◊†◊ï◊ú◊ï◊í◊ô◊î. ◊ñ◊î ◊î◊ô◊î ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊®◊ê◊©◊ï◊ü ◊©◊î◊©◊™◊û◊© ◊ë◊ß◊ô◊©◊ï◊®◊ô ◊î◊ô◊§◊®-◊ò◊ß◊°◊ò ◊õ◊ì◊ô ◊ú◊û◊ì◊ï◊ì ◊ê◊™ ◊ê◊ô◊õ◊ï◊™ ◊î◊ê◊™◊®◊ô◊ù ◊ë◊ê◊ô◊†◊ì◊ß◊°, ◊§◊ò◊†◊ò ◊ì◊ï◊û◊î ◊û◊ê◊ï◊ì ◊î◊ï◊í◊© ◊¢◊ú ◊ô◊ì◊ô Google ◊©◊†◊™◊ô◊ô◊ù ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊® ◊ë-1998. ◊ú◊ê◊®◊ô ◊§◊ô◊ô◊í' ◊î◊™◊ô◊ô◊ó◊° ◊ú◊¢◊ë◊ï◊ì◊™◊ï ◊©◊ú ◊ú◊ô ◊ë◊ó◊ú◊ß ◊û◊î◊§◊ò◊†◊ò◊ô◊ù ◊î◊ê◊û◊®◊ô◊ß◊ê◊ô◊ô◊ù ◊©◊ú◊ï ◊¢◊ë◊ï◊® PageRank. ◊û◊ê◊ï◊ó◊® ◊ô◊ï◊™◊® ◊ú◊ô ◊î◊©◊™◊û◊© ◊ë◊ò◊õ◊†◊ï◊ú◊ï◊í◊ô◊ô◊™ Rankdex ◊©◊ú◊ï ◊¢◊ë◊ï◊® ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© Baidu, ◊©◊ê◊ï◊™◊ï ◊ô◊ô◊°◊ì ◊ë◊°◊ô◊ü ◊ï◊î◊©◊ô◊ß ◊ë◊©◊†◊™ 2000. ◊ë-1996, ◊†◊ò◊°◊ß◊ô◊ô◊§ ◊ó◊ô◊§◊©◊î ◊ú◊™◊™ ◊¢◊°◊ß◊î ◊ë◊ú◊¢◊ì◊ô◊™ ◊ú◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊ê◊ó◊ì ◊õ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊û◊ï◊¶◊í ◊ë◊ì◊§◊ì◊§◊ü ◊î◊®◊©◊™ ◊©◊ú ◊†◊ò◊°◊ß◊ô◊ô◊§. ◊î◊ô◊î ◊õ◊ú ◊õ◊ö ◊î◊®◊ë◊î ◊¢◊†◊ô◊ô◊ü ◊¢◊ì ◊©◊ë◊û◊ß◊ï◊ù ◊ñ◊ê◊™, ◊†◊ò◊°◊ß◊ô◊ô◊§ ◊ó◊™◊û◊î ◊¢◊°◊ß◊ê◊ï◊™ ◊¢◊ù ◊ó◊û◊ô◊©◊î ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊í◊ì◊ï◊ú◊ô◊ù: ◊™◊û◊ï◊®◊™ 5 ◊û◊ô◊ú◊ô◊ï◊ü ◊ì◊ï◊ú◊® ◊ë◊©◊†◊î, ◊õ◊ú ◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊ô◊î◊ô◊î ◊ë◊®◊ï◊ò◊¶◊ô◊î ◊ë◊ì◊£ ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊©. ◊°◊ë◊ô◊ë ◊©◊†◊™ 2000, ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú ◊í◊ï◊í◊ú ◊¢◊ú◊î ◊ú◊™◊ï◊ì◊¢◊î. ◊î◊ó◊ë◊®◊î ◊î◊©◊ô◊í◊î ◊™◊ï◊¶◊ê◊ï◊™ ◊ò◊ï◊ë◊ï◊™ ◊ô◊ï◊™◊® ◊¢◊ë◊ï◊® ◊ó◊ô◊§◊ï◊©◊ô◊ù ◊®◊ë◊ô◊ù ◊ë◊ê◊û◊¶◊¢◊ï◊™ ◊ê◊ú◊í◊ï◊®◊ô◊™◊ù ◊ë◊©◊ù PageRank, ◊õ◊§◊ô ◊©◊î◊ï◊°◊ë◊® ◊ë◊û◊ê◊û◊® \"◊ê◊†◊ò◊ï◊û◊ô◊î ◊©◊ú ◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊©\" ◊©◊†◊õ◊™◊ë ◊¢◊ú ◊ô◊ì◊ô ◊°◊®◊í◊ô◊ô ◊ë◊®◊ô◊ü ◊ï◊ú◊ê◊®◊ô ◊§◊ô◊ô◊í', ◊î◊û◊ô◊ô◊°◊ì◊ô◊ù ◊î◊¢◊™◊ô◊ì◊ô◊ô◊ù ◊©◊ú ◊í◊ï◊í◊ú. ◊ê◊ú◊í◊ï◊®◊ô◊™◊ù ◊ê◊ô◊ò◊®◊ò◊ô◊ë◊ô ◊ñ◊î ◊û◊ì◊®◊í ◊ì◊§◊ô ◊ê◊ô◊†◊ò◊®◊†◊ò ◊ë◊î◊™◊ë◊°◊° ◊¢◊ú ◊û◊°◊§◊® ◊ï-PageRank ◊©◊ú ◊ê◊™◊®◊ô ◊ê◊ô◊†◊ò◊®◊†◊ò ◊ï◊ì◊§◊ô◊ù ◊ê◊ó◊®◊ô◊ù ◊î◊û◊ß◊©◊®◊ô◊ù ◊ê◊ú◊ô◊î◊ù, ◊¢◊ú ◊î◊î◊†◊ó◊î ◊©◊ì◊§◊ô◊ù ◊ò◊ï◊ë◊ô◊ù ◊ê◊ï ◊®◊¶◊ï◊ô◊ô◊ù ◊û◊ß◊ï◊©◊®◊ô◊ù ◊ô◊ï◊™◊® ◊û◊ê◊ó◊®◊ô◊ù. ◊ë◊ß◊©◊™ ◊î◊§◊ò◊†◊ò ◊©◊ú ◊ú◊ê◊®◊ô ◊§◊ô◊ô◊í' ◊¢◊ú PageRank ◊û◊¶◊ô◊ô◊†◊™ ◊ê◊™ ◊ë◊ß◊©◊™ ◊î◊§◊ò◊†◊ò ◊î◊û◊ï◊ß◊ì◊û◊™ ◊ô◊ï◊™◊® ◊©◊ú ◊®◊ï◊ë◊ô◊ü ◊ú◊ô ◊¢◊ú RankDex ◊õ◊î◊©◊§◊¢◊î. ◊í◊ï◊í◊ú ◊í◊ù ◊©◊û◊®◊î ◊¢◊ú ◊û◊û◊©◊ß ◊û◊ô◊†◊ô◊û◊ú◊ô◊°◊ò◊ô ◊ú◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú◊î. ◊ú◊¢◊ï◊û◊™ ◊ñ◊ê◊™, ◊®◊ë◊ô◊ù ◊û◊û◊™◊ó◊®◊ô◊î ◊©◊ô◊ú◊ë◊ï ◊û◊†◊ï◊¢ ◊ó◊ô◊§◊ï◊© ◊ë◊§◊ï◊®◊ò◊ú ◊ê◊ô◊†◊ò◊®◊†◊ò. ◊ú◊û◊¢◊©◊î, ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú ◊í◊ï◊í◊ú ◊î◊§◊ö ◊õ◊ú ◊õ◊ö ◊§◊ï◊§◊ï◊ú◊®◊ô ◊¢◊ì ◊©◊î◊ï◊§◊ô◊¢◊ï ◊û◊†◊ï◊¢◊ô ◊ó◊ô◊§◊ï◊© ◊û◊ñ◊ï◊ô◊§◊ô◊ù ◊õ◊û◊ï Mystery Seeker. ◊¢◊ì ◊©◊†◊™ 2000 ◊°◊ô◊§◊ß◊î Yahoo! ◊©◊ô◊®◊ï◊™◊ô ◊ó◊ô◊§◊ï◊© ◊û◊ë◊ï◊°◊°◊ô◊ù ◊¢◊ú ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú ◊ê◊ô◊†◊ß◊ò◊ï◊û◊ô. Yahoo! ◊®◊õ◊©◊î ◊ê◊™ ◊ê◊ô◊†◊ß◊ò◊ï◊û◊ô ◊ë-2002, ◊ï◊ê◊™ ◊ê◊ï◊ë◊®◊¶'◊® (◊©◊ë◊ë◊¢◊ú◊ï◊™◊î AlltheWeb ◊ï-AltaVista) ◊ë-2003. Yahoo! ◊¢◊ë◊®◊î ◊ú◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú ◊í◊ï◊í◊ú ◊¢◊ì 2004, ◊¢◊™ ◊©◊ó◊®◊®◊î ◊ê◊™ ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊©◊ú◊î ◊©◊î◊™◊ë◊°◊° ◊¢◊ú ◊î◊ò◊õ◊†◊ï◊ú◊ï◊í◊ô◊ï◊™ ◊î◊û◊©◊ï◊ú◊ë◊ï◊™ ◊©◊ú ◊®◊õ◊ô◊©◊ï◊™◊ô◊î. ◊û◊ô◊ß◊®◊ï◊°◊ï◊§◊ò ◊©◊ó◊®◊®◊î ◊ú◊®◊ê◊©◊ï◊†◊î ◊ê◊™ MSN Search ◊ë◊°◊™◊ô◊ï 1998 ◊™◊ï◊ö ◊©◊ô◊û◊ï◊© ◊ë◊™◊ï◊¶◊ê◊ï◊™ ◊ó◊ô◊§◊ï◊© ◊û◊ê◊ô◊†◊ß◊ò◊ï◊û◊ô. ◊ë◊™◊ó◊ô◊ú◊™ 1999, ◊î◊ê◊™◊® ◊î◊ó◊ú ◊ú◊î◊¶◊ô◊í ◊®◊©◊ô◊û◊ï◊™ ◊û◊ú◊ï◊ß◊°◊û◊ê◊®◊ò, ◊û◊¢◊ï◊®◊ë◊ë◊ï◊™ ◊¢◊ù ◊™◊ï◊¶◊ê◊ï◊™ ◊û◊ê◊ô◊†◊ß◊ò◊ï◊û◊ô. ◊ú◊§◊®◊ß ◊ñ◊û◊ü ◊ß◊¶◊® ◊ë-1999, MSN Search ◊î◊©◊™◊û◊©◊î ◊ë◊™◊ï◊¶◊ê◊ï◊™ ◊û-AltaVista ◊ë◊û◊ß◊ï◊ù. ◊ë-2004, ◊û◊ô◊ß◊®◊ï◊°◊ï◊§◊ò ◊î◊ó◊ú◊î ◊ë◊û◊¢◊ë◊® ◊ú◊ò◊õ◊†◊ï◊ú◊ï◊í◊ô◊ô◊™ ◊ó◊ô◊§◊ï◊© ◊û◊©◊ú◊î, ◊î◊û◊ï◊†◊¢◊™ ◊û◊ñ◊ó◊ú◊ü ◊ê◊ô◊†◊ò◊®◊†◊ò ◊û◊©◊ú◊î (◊î◊†◊ß◊®◊ê msnbot). ◊û◊†◊ï◊¢ ◊î◊ó◊ô◊§◊ï◊© ◊î◊û◊û◊ï◊™◊í ◊û◊ó◊ì◊© ◊©◊ú ◊û◊ô◊ß◊®◊ï◊°◊ï◊§◊ò, Bing, ◊î◊ï◊©◊ß ◊ë-1 ◊ë◊ô◊ï◊†◊ô 2009. ◊ë-29 ◊ë◊ô◊ï◊ú◊ô 2009, Yahoo! ◊ï◊û◊ô◊ß◊®◊ï◊°◊ï◊§◊ò ◊°◊ô◊õ◊û◊ï ◊¢◊ú ◊¢◊°◊ß◊î ◊©◊ë◊î ◊ó◊ô◊§◊ï◊© Yahoo! ◊ô◊ï◊†◊¢ ◊¢◊ú ◊ô◊ì◊ô ◊ò◊õ◊†◊ï◊ú◊ï◊í◊ô◊ô◊™ Bing ◊©◊ú ◊û◊ô◊ß◊®◊ï◊°◊ï◊§◊ò."
  },
  {
    "url": "https://kn.wikipedia.org/wiki/%E0%B2%B8%E0%B2%B0%E0%B3%8D%E0%B2%9A%E0%B3%8D_%E0%B2%8E%E0%B2%82%E0%B2%9C%E0%B2%BF%E0%B2%A8%E0%B3%8D",
    "title": "‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç - ‡≤µ‡≤ø‡≤ï‡≤ø‡≤™‡≥Ä‡≤°‡≤ø‡≤Ø",
    "content": "‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™‡≤ø ‡≤ú‡≤æ‡≤≤‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤ó‡≤§‡≥ç‡≤Ø‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤§‡≤ï‡≥ç‡≤ï‡≤Ç‡≤§‡≥Ü ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤≤‡≥Å ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤∂‡≥ã‡≤ß‡≤® ‡≤ö‡≤æ‡≤≤‡≤ï ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≥Å ‡≤∏‡≤π‡≤æ‡≤Ø‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü. ‡≤ó‡≥Ç‡≤ó‡≤≤‡≥ç, ‡≤¨‡≤ø‡≤Ç‡≤ó‡≥ç ‡≤á‡≤µ‡≥Ü‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤â‡≤¶‡≤æ‡≤π‡≤∞‡≤£‡≥Ü‡≤ó‡≤≥‡≥Å[‡≥ß]. ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤ï‡≥Å‡≤∞‡≤ø‡≤§‡≥Å ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™‡≤ø ‡≤ú‡≤æ‡≤≤‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤á‡≤∞‡≤¨‡≤π‡≥Å‡≤¶‡≤æ‡≤¶ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤§‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤∏‡≥Å‡≤≤‡≤≠‡≤µ‡≤æ‡≤ó‡≤ø ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤ø‡≤ï‡≥ä‡≤°‡≥Å‡≤µ ‡≤à ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≥Å ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤¶‡≤æ‡≤¶‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤á‡≤∞‡≥Å‡≤µ ‡≤Ö‡≤Ç‡≤§‡≤∞‡≤ú‡≤æ‡≤≤ ‡≤¨‡≤≥‡≤ï‡≥Ü‡≤¶‡≤æ‡≤∞‡≤∞‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Ö‡≤§‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤ú‡≤®‡≤™‡≥ç‡≤∞‡≤ø‡≤Ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤µ‡≥Ü. ‡≤µ‡≤ø‡≤µ‡≤ø‡≤ß ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤™‡≤ü‡≥ç‡≤ü ‡≤™‡≤†‡≥ç‡≤Ø‡≤∞‡≥Ç‡≤™‡≤¶ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤∑‡≥ç‡≤ü‡≥á ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤¶‡≥Ü ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å, ‡≤∏‡≥Å‡≤¶‡≥ç‡≤¶‡≤ø‡≤ó‡≤≥‡≥Å, ‡≤á-‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï‡≤ó‡≤≥‡≥Å, ‡≤≠‡≥Ç‡≤™‡≤ü‡≤ó‡≤≥‡≥Å ‡≤Æ‡≥Å‡≤Ç‡≤§‡≤æ‡≤¶ ‡≤Ö‡≤®‡≥á‡≤ï ‡≤∞‡≥Ç‡≤™‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤ø‡≤ï‡≥ä‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü. ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤á‡≤ö‡≥ç‡≤õ‡≥Ü‡≤Ø ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ó‡≤≥‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™‡≤ø ‡≤ú‡≤æ‡≤≤‡≤¶ ‡≤™‡≥Å‡≤ü‡≤ó‡≤≥ ‡≤®‡≤°‡≥Å‡≤µ‡≥Ü ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü ‡≤®‡≤°‡≥Ü‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥ ‡≤ï‡≥Ü‡≤≤‡≤∏. ‡≤®‡≤æ‡≤µ‡≥Å ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤∞‡≥Å‡≤µ ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤ø‡≤∏‡≤ø‡≤¶ ‡≤Æ‡≥Å‡≤ñ‡≥ç‡≤Ø ‡≤™‡≤¶‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å (‡≤ï‡≥Ä ‡≤µ‡≤∞‡≥ç‡≤°‡≥ç‡≤∏‡≥ç) ‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≤ø‡≤∑‡≥ç‡≤ü‡≤∞‡≥Ç‡≤™‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤¨‡≥Ü‡≤∞‡≤≥‡≤ö‡≥ç‡≤ö‡≤ø‡≤∏‡≤ø, ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≥Å‡≤µ ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø‡≤¶‡≤∞‡≥Ü, ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤®‡≤Æ‡≤ó‡≥Ü ‡≤¨‡≥á‡≤ï‡≤æ‡≤¶ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™‡≤ø ‡≤ú‡≤æ‡≤≤‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤é‡≤≤‡≥ç‡≤≤‡≥Ü‡≤≤‡≥ç‡≤≤‡≤ø ‡≤≤‡≤≠‡≥ç‡≤Ø‡≤µ‡≤ø‡≤¶‡≥Ü ‡≤é‡≤Ç‡≤¨‡≥Å‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤ø‡≤ï‡≥ä‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü; ‡≤ï‡≤°‡≤§‡≤ó‡≤≥‡≥Å, ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å, ‡≤∏‡≥Å‡≤¶‡≥ç‡≤¶‡≤ø‡≤ó‡≤≥‡≥Å, ‡≤µ‡≤ø‡≤°‡≤ø‡≤Ø‡≥ã‡≤ó‡≤≥‡≥Å - ‡≤π‡≥Ä‡≤ó‡≥Ü ‡≤®‡≤Æ‡≤ó‡≥Ü ‡≤¨‡≥á‡≤ï‡≤æ‡≤¶ ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤™‡≤ü‡≥ç‡≤ü, ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤∞‡≥Ç‡≤™‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤§‡≥ç‡≤§‡≥Ü‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü.\n‡≤π‡≥Ä‡≤ó‡≥Ü ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤ø‡≤¶ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤™‡≥ç‡≤∞‡≤æ‡≤Æ‡≥Å‡≤ñ‡≥ç‡≤Ø‡≤§‡≥Ü‡≤ó‡≥Ü ‡≤Ö‡≤®‡≥Å‡≤ó‡≥Å‡≤£‡≤µ‡≤æ‡≤ó‡≤ø ‡≤ú‡≥ã‡≤°‡≤ø‡≤∏‡≤ø ‡≤Ö‡≤µ‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Ü ‡≤™‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç‡≤∂‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü. ‡≤á‡≤Ç‡≤§‡≤π ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤Ø‡≥ä‡≤Ç‡≤¶‡≥Å ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≥Ç ‡≤í‡≤Ç‡≤¶‡≥ä‡≤Ç‡≤¶‡≥Å ‡≤§‡≤Ç‡≤§‡≥Å ‡≤Ö‡≤•‡≤µ‡≤æ '‡≤≤‡≤ø‡≤Ç‡≤ï‡≥ç'‡≤® ‡≤∞‡≥Ç‡≤™‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ‡≥Å‡≤¶‡≤∞‡≤ø‡≤Ç‡≤¶ ‡≤Ö‡≤µ‡≥Å‡≤ó‡≤≥ ‡≤Æ‡≥á‡≤≤‡≥Ü ‡≤ï‡≥ç‡≤≤‡≤ø‡≤ï‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤¨‡≥á‡≤ï‡≤æ‡≤¶ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤™‡≤°‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤à ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü ‡≤®‡≤°‡≥Ü‡≤∏‡≤≤‡≥Å ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤µ‡≥Ü‡≤¨‡≥ç ‡≤∏‡≥ç‡≤™‡≥à‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≥Ü‡≤Ç‡≤¨ ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤¨‡≤≥‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü. ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™‡≤ø ‡≤ú‡≤æ‡≤≤‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤≤‡≤ï‡≥ç‡≤∑‡≤æ‡≤Ç‡≤§‡≤∞ ‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å (‡≤µ‡≥Ü‡≤¨‡≥ç‚Äå‡≤∏‡≥à‡≤ü‡≥ç) ‡≤π‡≤æ‡≤ó‡≥Ç ‡≤Ö‡≤µ‡≥Å‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤™‡≥Å‡≤ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤µ‡≥Å‡≤ó‡≤≥ ‡≤ú‡≤®‡≤™‡≥ç‡≤∞‡≤ø‡≤Ø‡≤§‡≥Ü‡≤ó‡≥Ü ‡≤Ö‡≤®‡≥Å‡≤ó‡≥Å‡≤£‡≤µ‡≤æ‡≤ó‡≤ø ‡≤µ‡≤∞‡≥ç‡≤ó‡≥Ä‡≤ï‡≤∞‡≤ø‡≤∏‡≤ø, ‡≤Ü ‡≤™‡≥Å‡≤ü‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤Ø‡≤æ‡≤µ ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤ø‡≤∏‡≤ø‡≤¶‡≥ç‡≤¶‡≥Å ‡≤é‡≤Ç‡≤¨ ‡≤Ö‡≤Ç‡≤∂‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤¶‡≤æ‡≤ñ‡≤≤‡≤ø‡≤∏‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤á‡≤µ‡≥Å‡≤ó‡≤≥ ‡≤ï‡≥Ü‡≤≤‡≤∏. ‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∞‡≥Ç‡≤™‡≤ø‡≤∏‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤á‡≤Ç‡≤§‡≤π ‡≤∏‡≥ç‡≤™‡≥à‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø‡≤µ‡≤æ‡≤ó‡≤≤‡≥Ü‡≤Ç‡≤¶‡≥á ‡≤§‡≤Æ‡≥ç‡≤Æ ‡≤§‡≤æ‡≤£‡≤¶ ‡≤™‡≥Å‡≤ü‡≤ó‡≤≥ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å '‡≤Æ‡≥Ü‡≤ü‡≤æ ‡≤ü‡≥ç‡≤Ø‡≤æ‡≤ó‡≥ç'‡≤ó‡≤≥ ‡≤∞‡≥Ç‡≤™‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤∏‡≤Ç‡≤ï‡≥ç‡≤∑‡≤ø‡≤™‡≥ç‡≤§‡≤µ‡≤æ‡≤ó‡≤ø ‡≤∂‡≥á‡≤ñ‡≤∞‡≤ø‡≤∏‡≤ø‡≤ü‡≥ç‡≤ü‡≤ø‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤æ‡≤∞‡≥Ü. ‡≤∏‡≥ç‡≤™‡≥à‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≤≥ ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü ‡≤á‡≤¶‡≥á ‡≤Æ‡≥Ü‡≤ü‡≤æ ‡≤ü‡≥ç‡≤Ø‡≤æ‡≤ó‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤Ü‡≤ß‡≤∞‡≤ø‡≤∏‡≤ø‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤∏‡≥ç‡≤™‡≥à‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≤ø ‡≤§‡≤Æ‡≥ç‡≤Æ ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤§‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤™‡≥ç‡≤∞‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß ‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£‡≤ó‡≤≥‡≥Å ‡≤π‡≤æ‡≤ó‡≥Ç ‡≤Ö‡≤§‡≤ø‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å ‡≤¨‡≤≥‡≤ï‡≥Ü‡≤¶‡≤æ‡≤∞‡≤∞‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤ø‡≤Ç‡≤¶ ‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü. ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø‡≤Ç‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤Ü ‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£ ‡≤π‡≤æ‡≤ó‡≥Ç ‡≤Ü ‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç‚Äå‡≤®‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤é‡≤≤‡≥ç‡≤≤ ‡≤™‡≥Å‡≤ü‡≤ó‡≤≥ ‡≤Æ‡≥á‡≤≤‡≥Ç ‡≤í‡≤Æ‡≥ç‡≤Æ‡≥Ü ‡≤ï‡≤£‡≥ç‡≤£‡≤æ‡≤°‡≤ø‡≤∏‡≤ø ‡≤Ö‡≤µ‡≥Å‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤µ‡≤∞‡≥ç‡≤ó‡≥Ä‡≤ï‡≤∞‡≤ø‡≤∏‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ ‡≤ï‡≥Ü‡≤≤‡≤∏ ‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤é‡≤≤‡≥ç‡≤≤ ‡≤§‡≤Ç‡≤§‡≥Å‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Ç ‡≤à ‡≤ú‡≥á‡≤°‡≤ó‡≤≥‡≥Å ‡≤π‡≤ø‡≤Ç‡≤¨‡≤æ‡≤≤‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≤∞‡≤ø‡≤Ç‡≤¶ ‡≤Ö‡≤µ‡≥Å‡≤ó‡≤≥ ‡≤®‡≤ø‡≤≤‡≥Å‡≤ï‡≤ø‡≤ó‡≥Ü ‡≤∏‡≤ø‡≤ó‡≥Å‡≤µ ‡≤™‡≥Å‡≤ü‡≤ó‡≤≥ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤Ø‡≥Å‡≤§‡≥ç‡≤§‡≤≤‡≥á ‡≤π‡≥ã‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤∏‡≥ç‡≤™‡≥à‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤∏‡≤Ç‡≤ó‡≥ç‡≤∞‡≤π‡≤ø‡≤∏‡≥Å‡≤µ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø ‡≤Ö‡≤ß‡≤æ‡≤∞‡≤¶ ‡≤Æ‡≥á‡≤≤‡≥Ü ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤Ö‡≤ï‡≤æ‡≤∞‡≤æ‡≤¶‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å (‡≤á‡≤Ç‡≤°‡≥Ü‡≤ï‡≥ç‡≤∏‡≥ç) ‡≤§‡≤Ø‡≤æ‡≤∞‡≤ø‡≤∏‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤®‡≤Æ‡≤ó‡≥Ü ‡≤¨‡≥á‡≤ï‡≤æ‡≤¶ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤§‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤µ‡≥á‡≤ó‡≤µ‡≤æ‡≤ó‡≤ø ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü. ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤¶‡≤Ç‡≤§‡≥Ü ‡≤é‡≤≤‡≥ç‡≤≤‡≤¨‡≤ó‡≥Ü‡≤Ø ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Ç ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≥Å‡≤ï‡≥ä‡≤°‡≥Å‡≤µ ‡≤ó‡≥Ç‡≤ó‡≤≤‡≥ç‚Äå‡≤®‡≤Ç‡≤§‡≤π ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç‚Äå‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥ ‡≤ú‡≥ä‡≤§‡≥Ü‡≤ó‡≥Ü ‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≤ø‡≤∑‡≥ç‡≤ü ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü (‡≤â‡≤¶‡≥ç‡≤Ø‡≥ã‡≤ó‡≤æ‡≤µ‡≤ï‡≤æ‡≤∂‡≤ó‡≤≥‡≥Å, ‡≤µ‡≥à‡≤ú‡≥ç‡≤û‡≤æ‡≤®‡≤ø‡≤ï ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø, ‡≤™‡≥ç‡≤∞‡≤µ‡≤æ‡≤∏ ‡≤á‡≤§‡≥ç‡≤Ø‡≤æ‡≤¶‡≤ø) ‡≤Æ‡≤æ‡≤§‡≥ç‡≤∞‡≤µ‡≥á ‡≤∏‡≥Ä‡≤Æ‡≤ø‡≤§‡≤µ‡≤æ‡≤¶ ‡≤µ‡≤∞‡≥ç‡≤ü‡≤ø‡≤ï‡≤≤‡≥ç ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Ç ‡≤π‡≥Å‡≤ü‡≥ç‡≤ü‡≤ø‡≤ï‡≥ä‡≤Ç‡≤°‡≤ø‡≤µ‡≥Ü. ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å ‡≤™‡≥ç‡≤∞‡≤ö‡≤≤‡≤ø‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤™‡≤†‡≥ç‡≤Ø‡≤æ‡≤ß‡≤æ‡≤∞‡≤ø‡≤§ ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥ ‡≤ú‡≥ä‡≤§‡≥Ü‡≤ó‡≥Ü ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‡≤π‡≤æ‡≤ó‡≥Ç ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø‡≤Ø ‡≤®‡≥Ü‡≤∞‡≤µ‡≤ø‡≤®‡≤ø‡≤Ç‡≤¶ ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤∏‡≥Å‡≤µ ‡≤∏‡≤∞‡≥ç‡≤ö‡≥ç ‡≤é‡≤Ç‡≤ú‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Ç ‡≤á‡≤µ‡≥Ü."
  },
  {
    "url": "https://la.wikipedia.org/wiki/Machina_quaesitoria",
    "title": "Machina quaesitoria - Vicipaedia",
    "content": "Machina quaesitoria,[1] sive quaesitorium,[2]  est ratio informationis recuperandae, quae ad informationem in systemate computatrali inveniendam designatur. Exitus investigationis, plerumque in indicibus exhibiti, ictus usitate appellantur. Machinae quaerendi tempus informationis inveniendae summamque informationis consuluendae minuere adiuvant, aliarum artium ad nimium informationis curandum similes. Maxime apertum et aspectabile genus machinae quaerendi est machina quaerendi interretialis, quae informationem intra telam totius terrae quaerit."
  },
  {
    "url": "https://lt.wikipedia.org/wiki/Internetin%C4%97s_paie%C5%A1kos_sistema",
    "title": "Internetinƒós paie≈°kos sistema ‚Äì Vikipedija",
    "content": "Internetinƒós paie≈°kos sistema ‚Äì sistema, leid≈æianti ie≈°koti informacijos saityne. Pastaroji sistema veikia kompiuterini≈≥ program≈≥ (interneto robotai, ‚Äûtinklalapi≈≥ voriukai‚Äú) pagrindu, kurios nuskaito visas internetu pasiekiamas rinkmenas ir ƒØtraukia juos ƒØ internetinƒô rodyklƒô, atsi≈ævelgdama ƒØ tam tikrus rakta≈æod≈æius rinkmenose. Be to, kiekviena paie≈°kos sistema naudoja savus, vie≈°ai neatskied≈æiamus algoritmus sudarinƒójant internetines rodykles.[1] Kai kurie paie≈°kos sistem≈≥ robotai paiso robots.txt (Vikipedijos robots.txt byla) nurodom≈≥ apribojim≈≥. 2017 m. duomenimis ‚ÄûGoogle‚Äú yra populiariausia paie≈°kos sistema tiek pasaulyje, tiek JAV ir Europoje, atsiriekusi 78¬†% rinkos dalƒØ. ‚ÄûBing‚Äú ir ‚ÄûYahoo! Search‚Äú tenka atitinkamai 8¬†% ir 5¬†% pasaulinƒós rinkos dalies.[2] Rusijoje itin populiari ‚ÄûYandex‚Äú paie≈°kos sistema, o Kinijoje vie≈°patauja ‚ÄûBaidu‚Äú paie≈°kos sistema (ten JAV bendrovi≈≥ paie≈°kos sistemomis u≈ædrausta naudotis). ‚ÄûYahoo! Search‚Äú populiariausia Japonijoje."
  },
  {
    "url": "https://nia.wikipedia.org/wiki/Mesin_Wangalui",
    "title": "Mesin Wangalui - Wikipedia",
    "content": "Mesin Wangalui (li Indonesia: mesin pencari, li Inggris: search engine) ya'ia da'√∂ no sambua nahia heza tola la'alui ngawal√∂ zinura ba Internet niha. Mesin Wangalui fondrege ebua ba gulidan√∂ ya'ia Google, me 83.49% moroi fefu niha sangalui hadia ba internet me ndr√∂fi 2023, la'alui ia ba google.com. Furinia so Bing, ni'okh√∂g√∂ Microsoft, ba zi 9.19%.[1] Mesin Wangalui no komputer sangir√∂'√∂ khai-khai ba fefu nisura niha ba gu'√∂ Internet. Khai-khai andr√∂ to'√∂l√∂ lat√∂t√∂i pranala ba li Indonesia ma link ba li Inggris. Eluahania l√∂ i'ir√∂'√∂ zinura andr√∂ mesin wangalui, ha i'ir√∂'√∂ khai-khainia. Gofu hadia zinura si so ba internet no te'ir√∂'√∂ ia ba zi sambua komputer. Ero komputer andre so nomoronia nifot√∂i nomoro IP, same'e irege tola tes√∂ndra ia. Duma-dumania nomoro IP mbolokha gu'√∂ kabarnias.com ya'ia 117.53.44.147. Ena'√∂ aoha kh√∂ niha wan√∂t√∂i ya'ia ba aoha kh√∂da wanan√∂ ba d√∂d√∂, andr√∂ labe'e d√∂inia simane kabarnias.com. Na l√∂ kh√∂nia nomoro IP andr√∂, ba l√∂ tola tes√∂ndra kabarnias.com da'√∂. Ba duma-duma andre, ero zinura nifair√∂ ya≈µa ba mbolokha gu'√∂ kabarnias.com, so khai-khainia. Duma-dumania khai-khai zinura \"Ejaan Bahasa Nias yang Perlu Pembaharuan\" so ba https://kabarnias.com/sudut-pandang/ejaan-bahasa-nias-yang-perlu-pembaharuan-10503 Archived 2024-06-09 at the Wayback Machine Faoma khai-khai andr√∂ tola tabokai ba tabaso zinura andr√∂ ya≈µa, gofu hadia wuka gu'√∂ ni'oguna'√∂da, Google Chrome ma Microsoft Edge ma zui mesin wangalui tan√∂b√∂'√∂. Na tabe'e bakha ba nahia wangalui khai-khai da'√∂ ba tola tes√∂ndra ba tebokai ia. Nifalua mesin wangalui ya'ia da'√∂ ba wangowuloi khai-khai fefu zinura si so ba gulidan√∂. Moroi ba mesin wangalui Google tola tas√∂ndra khai-khai zinura andr√∂ no mege ya≈µa, he≈µa'ae sinura andr√∂ sam√∂sa te'ir√∂'√∂ ia ba komputer (nifot√∂i komputer server) kabarnias.com. Na l√∂ mesin wangalui, l√∂ lala kh√∂da wan√∂ndra ngawal√∂ zura nisura ba internet. Ha awai kh√∂da lala wan√∂ndra sambua zinura, na m√∂i ita ba nomoro IP komputer server kh√∂nia. Bahiza haniha zi tola man√∂ng√∂ni fefu d√∂i server si so ba gulidan√∂? Eluahania mesin wangalui andre hul√∂ ono meza, heza ta'ir√∂'√∂ fefu mbal√∂ garate nisurada bakha ngawal√∂ nomoro telepon, ma ngawal√∂ nisurada somasi ita ta'ir√∂'√∂. Na m√∂i ita tabokai google.com, fakhili ira na tabokai nono meza andr√∂, ba ta'alui gofu hadia ia zi no mu'ir√∂'√∂ bakha ba da'√∂."
  },
  {
    "url": "https://hu.wikipedia.org/wiki/Keres%C5%91rendszer_(informatika)",
    "title": "Keres≈ërendszer (informatika) ‚Äì Wikip√©dia",
    "content": "Ez a lap egy ellen≈ërz√∂tt v√°ltozata Pontoss√°gellen≈ërz√∂tt Keres≈ërendszer alatt az informatik√°ban olyan webes fel√ºlet≈± vagy szoftveres szolg√°ltat√°st √©rtenek, ami multim√©di√°s tartalmak vagy adatb√°zisok rendszeres vagy egy√©ni k√©r√©sre t√∂rt√©n≈ë rendez√©s√©t √©s/vagy nyomon k√∂vet√©s√©t √©s/vagy kivonatol√°s√°t, √©s a tartalomnak a felhaszn√°l√≥, √©s √°ltal√°ban a sz√©lesebb nyilv√°noss√°g r√©sz√©re t√∂rt√©n≈ë rendelkez√©s√©re bocs√°t√°s√°t ny√∫jtja. A megjelen√≠tend≈ë tartalom neve, ami sz√≥ vagy (szavakat, logikai oper√°torokat √©s egy√©b attrib√∫tumokat tartalmaz√≥) √∂sszetett nyelvi kifejez√©s lehet, a keres≈ësz√≥, teh√°t ezt kell megadni a keres≈ërendszernek, √©s az megkeresi √©s kijelzi mindazt, amit ezzel kapcsolatban tud. √Åltal√°ban kulcsszavas keres√©s t√∂rt√©nik, vagyis a rendszer bek√©ri a keresend≈ë sz√≥t, a felhaszn√°l√≥ bet√°pl√°lja (p√©ld√°ul beg√©peli egy ≈±rlapmez≈ëbe), majd a rendszer megjelen√≠ti azokat a tartalmi egys√©geket, tal√°latokat, amelyek a rendszer szerint a kulcssz√≥hoz kapcsol√≥dnak. A kulcsszavas keres≈ëk seg√≠ts√©g√©vel adott szavak vagy kifejez√©sek el≈ëfordul√°s√°ra kereshet√ºnk. Ilyen keres≈ë p√©ld√°ul a Google (www.google.com). Ha valaki p√©ld√°ul szeretne t√∂bbet tudni Britney Spearsr≈ël (a statisztik√°k szerint az ≈ë neve volt 2000-ben az egyik leggyakrabban megadott keres≈ësz√≥ a legt√∂bb keres≈ërendszerben, l√°sd itt), akkor a webb√∂ng√©sz≈ëj√©vel elnavig√°l valamelyik keres≈ërendszer weboldal√°ra (p√©ld√°ul Google), ott a megfelel≈ë mez≈ëbe be√≠rja, hogy \"Britney Spears\", majd megjelenik t√∂bb sz√°z weboldal c√≠me, r√∂vid le√≠r√°ssal, ami esetleg Spearsszel foglalkozik. Persze lehet, hogy semmit sem tal√°l: p√©ld√°ul a ‚ÄûBritney Spears nyekereg‚Äù keres≈ëkifejez√©sre a Google rendszer 2004. j√∫lius 26-√°n semmit sem tal√°lt (√°m most m√°r tal√°l, mivel annak a sz√≥cikknek az oldal√°t, amit most olvasol, m√°r meg fogja jelen√≠teni, mert szerepel rajta az a kifejez√©s, hogy ‚ÄûBritney Spears nyekereg‚Äù: illusztr√°ci√≥‚Ä¶). Az egyik legismertebb webes c√≠msz√≥keres≈ë rendszer a Google, ami a World Wide Web tartalm√°t pr√≥b√°lja feldolgozni √©s szolg√°ltatni. A webes keres≈ëk mellett a keres≈ërendszerek legfontosabb p√©ld√°i az adatb√°ziskezel≈ë programok keres≈ërendszerei."
  },
  {
    "url": "https://mr.wikipedia.org/wiki/%E0%A4%B6%E0%A5%8B%E0%A4%A7%E0%A4%AF%E0%A4%82%E0%A4%A4%E0%A5%8D%E0%A4%B0",
    "title": "‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞ - ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ",
    "content": "‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü‡§æ‡§µ‡§∞/‡§Æ‡§π‡§æ‡§ú‡§æ‡§≤‡§æ‡§§ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä‡§ö‡§æ ‡§∂‡•ã‡§ß ‡§ò‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§∏‡§Ç‡§ï‡•á‡§§‡§∏‡•ç‡§•‡§≥‡§æ‡§Ç‡§®‡§æ '‡§∂‡•ã‡§ß ‡§Ø‡§Ç‡§§‡•ç‡§∞' (‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂:Search Engine) ‡§Ö‡§∏‡•á ‡§Æ‡•ç‡§π‡§£‡§§‡§æ‡§§. ‡§è‡§ñ‡§æ‡§¶‡§æ ‡§ï‡•ã‡§£‡§§‡§æ‡§π‡•Ä ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∂‡§¨‡•ç‡§¶ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§∂‡§¨‡•ç‡§¶‡§∏‡§Æ‡•Ç‡§π  ‡§ú‡•ç‡§Ø‡§æ-‡§ú‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§Ç‡§µ‡§∞‡•Ä‡§≤ ‡§Æ‡§ú‡§ï‡•Å‡§∞‡§æ‡§§ ‡§Ö‡§∏‡•á‡§≤, ‡§Ö‡§∂‡•Ä ‡§∏‡§∞‡•ç‡§µ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡•á ‡§¶‡§æ‡§ñ‡§µ‡§£‡•ç‡§Ø‡§æ‡§ö‡•á ‡§ï‡§æ‡§Æ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞ ‡§ï‡§∞‡§§‡•á. ‡§¨‡§π‡•Å‡§§‡§æ‡§Ç‡§∂ ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡•á ‡§π‡•Ä ‡§ï‡•á‡§µ‡§≥ ‡§Æ‡§ú‡§ï‡•Ç‡§∞‡§ö ‡§®‡§µ‡•ç‡§π‡•á ‡§§‡§∞, ‡§è‡§ñ‡§æ‡§¶‡•ç‡§Ø‡§æ ‡§∂‡§¨‡•ç‡§¶‡§æ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ö‡§ø‡§§‡•ç‡§∞‡•á, ‡§ö‡§≤‡§ö‡§ø‡§§‡•ç‡§∞‡•á ‡§µ ‡§á‡§§‡§∞ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∂‡•ã‡§ß‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§∏‡§∞‡•ç‡§µ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£‡§™‡§£‡•á '‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞' ‡§π‡•Ä ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ ‡§´‡§ï‡•ç‡§§ ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü‡§æ‡§µ‡§∞‡•Ä‡§≤ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∂‡•ã‡§ß‡§£‡•ç‡§Ø‡§æ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠‡§æ‡§§ ‡§µ‡§æ‡§™‡§∞‡§≤‡•Ä ‡§ú‡§æ‡§§‡•á; ‡§∏‡§Ç‡§ó‡§£‡§ï‡§æ‡§µ‡§∞ ‡§∏‡§æ‡§†‡§µ‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§∂‡•ã‡§ß ‡§ò‡•á‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§æ‡§™‡§∞‡§≤‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ö‡§∞‡§æ‡§Ç‡§®‡§æ '‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞' ‡§Æ‡•ç‡§π‡§£‡§≤‡•á ‡§ú‡§æ‡§§ ‡§®‡§æ‡§π‡•Ä. ‡§Æ‡§π‡§æ‡§ú‡§æ‡§≤‡§æ‡§§ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§æ‡§Ç‡§ö‡•Ä ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡•á ‡§µ‡§æ‡§™‡§∞‡§≤‡•Ä ‡§ú‡§æ‡§§‡§æ‡§§. ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§ß‡§ø‡§ï ‡§≤‡•ã‡§ï ‡§Ü‡§™‡§≤‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§µ‡§∞ ‡§Ø‡•á‡§£‡•á ‡§π‡•á ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡§æ‡§®‡•á ‡§¶‡§ø‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡§æ‡§Ç‡§ï‡§®‡§æ‡§µ‡§∞ ‡§Ö‡§µ‡§≤‡§Ç‡§¨‡•Ç‡§® ‡§Ü‡§π‡•á; ‡§§‡§∏‡•á‡§ö ‡§§‡•á ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞ ‡§Æ‡•à‡§§‡•ç‡§∞‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£‡§§‡•á‡§µ‡§∞‡§π‡•Ä ‡§Ö‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑‡§™‡§£‡•á ‡§Ö‡§µ‡§≤‡§Ç‡§¨‡•Ç‡§® ‡§Ü‡§π‡•á. ‡§ó‡•Ç‡§ó‡§≤ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡§æ‡§ö‡•á ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§Ü‡§£‡§ø ‡§µ‡§æ‡§™‡§∞ ‡•®‡•¶‡•¶‡•ß ‡§∏‡§æ‡§≤‡§æ‡§™‡§æ‡§∏‡•Ç‡§® ‡§µ‡§æ‡§¢‡§≤‡§æ. ‡§ó‡•Ç‡§ó‡§≤ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡§æ‡§ö‡•á ‡§Ø‡§∂ ‡§¶‡•Å‡§µ‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó‡§æ‡§ö‡•á ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£ ‡§µ ‡§§‡•ç‡§Ø‡§æ-‡§§‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡§æ‡§Ç‡§ï‡§®‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∏‡§Ç‡§ï‡§≤‡•ç‡§™‡§®‡•á‡§§ ‡§Ü‡§π‡•á. ‡§è‡§ñ‡§æ‡§¶‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§ö‡§æ ‡§¶‡•Å‡§µ‡§æ ‡§á‡§§‡§∞ ‡§ï‡§ø‡§§‡•Ä ‡§Ü‡§£‡§ø ‡§ï‡§ø‡§§‡•Ä ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§Ç‡§®‡•Ä ‡§¶‡§ø‡§≤‡§æ ‡§Ü‡§π‡•á ‡§Ø‡§æ‡§µ‡§∞ ‡§§‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§ö‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡§æ‡§Ç‡§ï‡§® ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§π‡•ã‡§§‡•á. ‡§Ø‡§æ‡§ï‡§∞‡§ø‡§§‡§æ ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§µ‡§∞ ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§Ü‡§£‡§ø ‡§ú‡§æ‡§∏‡•ç‡§§‡•Ä‡§§ ‡§ú‡§æ‡§∏‡•ç‡§§ ‡§≤‡•ã‡§ï‡§æ‡§Ç‡§ï‡§°‡•Ç‡§® ‡§∂‡•ã‡§ß‡§≤‡•á ‡§ú‡§æ‡§£‡§æ‡§∞‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠‡§∂‡§¨‡•ç‡§¶ ‡§Ö‡§∏‡§£‡•á ‡§ñ‡•Ç‡§™ ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§†‡§∞‡§§‡•á. ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ‡§ö‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠  ‡§ó‡•Ç‡§ó‡§≤ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§Ü‡§µ‡•É‡§§‡•ç‡§§‡•Ä‡§§ ‡§∏‡§π‡§ú ‡§Æ‡§ø‡§≥‡§§‡§æ‡§§; ‡§™‡§£ ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ‡§ö‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ó‡•Ç‡§ó‡§≤ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§á‡§Ç‡§ó‡•ç‡§∞‡§ú‡•Ä ‡§Ü‡§µ‡•É‡§§‡•ç‡§§‡•Ä‡§§ ‡§â‡§∂‡§ø‡§∞‡§æ ‡§Æ‡§ø‡§≥‡§§‡§æ‡§§. ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ‡§§‡•Ä‡§≤ ‡§∏‡•Å‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§∂‡§¨‡•ç‡§¶‡§æ‡§Ç‡§ö‡•á ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§¨‡§∞‡•ã‡§¨‡§∞‡§ö ‡§∞‡•ã‡§Æ‡§® ‡§≤‡§ø‡§™‡•Ä‡§§‡•Ä‡§≤ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡§π‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§∏ ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§∂‡•ã‡§ß ‡§Ø‡§Ç‡§§‡•ç‡§∞ ‡§Æ‡•à‡§§‡•ç‡§∞‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•ã‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§Æ‡§¶‡§§ ‡§π‡•ã‡§à‡§≤. ‡§Ø‡§æ‡§π‡•Ç ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ '‡§Ø‡§æ‡§π‡•Ç ‡§¨‡§ù ‡§á‡§Ç‡§°‡•á‡§ï‡•ç‡§∏'‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞ ‡§ï‡§∞‡•Ç‡§® ‡§∏‡§∞‡•ç‡§µ‡§æ‡§Ç‡§§ ‡§ú‡§æ‡§∏‡•ç‡§§ ‡§∂‡•ã‡§ß‡§≤‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§∂‡§¨‡•ç‡§¶‡§æ‡§Ç‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§§‡•á. ‡§Ö‡§∂‡§æ ‡§∂‡§¨‡•ç‡§¶‡§æ‡§Ç‡§ö‡§æ ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§µ‡§æ‡§™‡§∞ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§ö‡•Ä ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞ ‡§Æ‡•à‡§§‡•ç‡§∞‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£‡§§‡§æ ‡§µ‡§æ‡§¢‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§§‡•ã. ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞ ‡§°‡§æ‡§Ø‡§®‡•Ö‡§Æ‡§ø‡§ï ‡§´‡§æ‡§Å‡§ü ‡§µ‡§æ‡§™‡§∞‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§µ‡•á‡§¨‡§™‡§æ‡§®‡§æ‡§Ç‡§ö‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡§æ‡§Ç‡§ï‡§® ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä. ‡§´‡§ï‡•ç‡§§ ‡§Ø‡•Å‡§®‡§ø‡§ï‡•ã‡§° ‡§ö‡§æ‡§≤‡§§‡•á. ‡§â‡§¶‡§æ‡§π‡§∞‡§£‡§æ‡§∞‡•ç‡§• ‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞ ‡§ü‡§æ‡§á‡§Æ‡•ç‡§∏ ‡§∂‡•ã‡§ß‡§Ø‡§Ç‡§§‡•ç‡§∞‡§æ‡§Ç‡§Æ‡§æ‡§∞‡•ç‡§´‡§§ ‡§∂‡•ã‡§ß‡§§‡§æ ‡§Ø‡•á‡§§‡•ã; ‡§™‡§£ ‡§à-‡§∏‡§ï‡§æ‡§≥ ‡§∂‡•ã‡§ß‡§§‡§æ ‡§Ø‡•á‡§§ ‡§®‡§æ‡§π‡•Ä. . (first original results)"
  },
  {
    "url": "https://ms.wikipedia.org/wiki/Enjin_gelintar_web",
    "title": "Enjin gelintar web - Wikipedia Bahasa Melayu, ensiklopedia bebas",
    "content": "Enjin carian sesawang ialah sebuah enjin carian direka khas untuk mencari maklumat dalam Jaringan Sejagat yang turut merangkumi laman sesawang, imej, dan pelbagai jenis fail lain. Sesetengah enjin carian juga mengorek data yang boleh didapati dalam newsbook, pangkalan data, atau direktori terbuka. Tidak seperti direktori web yang diselenggara oleh manusia, enjin carian dikelola secara algoritma atau campuran algoritma dan masukan manusia.[1]"
  },
  {
    "url": "https://min.wikipedia.org/wiki/Masin_paruntun_web",
    "title": "Masin paruntun web - Wikipedia baso Minang",
    "content": "Mesin paruntun web (Baso Inggirih: search engine) iolah sabuah program komputer nan bapaliek-gan untuak mambuek paruntunan ka aleh file nan taasek bakeh layanan www, ftp, pambasuikan pangiriman surek, sarato news group bakeh sabuah/kabara server komputer bakeh sabuah tangkokan (network). Search engine marupoan alaik paruntun maklumaik daripado data-data nan dionyok-gan alah. Acoknyo pulo, hasil paruntunan nangko dipaliek-gan bakeh bantuak lirikan nan kodoknyo balirik-gan basangkalan kabakeh darajaik kaaluihan, buliah pulo basangkalan rasio urang-urang nan manjalang ka aleh sabuah file nan disabuik hits. Maklumaik nan jadi pusek paruntunan dapek disuo bakeh jinih-jinih file nan balainan saroman laman web, gambar, sarato jinih-jinih file lainnyo. Kabara mesin paruntun dikana pulo sadang manyauak maklumaik untuak data nan taasek bakeh sabuah data nan batampaik-gan sarato pulo lirikan-lirikan web. Sabagian gadang mesin paruntun bapalabuah-gan dek sarikaik basurang-surang nan mampaguno-gan algoritma kapunyo-an sarato tampaik data nan talimpok, di antaro etan sadoalahnyo nan amaik tamusahua adolah Google (MSN Search sarato Yahoo!). Ado kabara alah caro-caro untuak mampacipto-gan mesin paruntun dek sumber-sumber nan taungkai (open source) co Htdig, Nutch, Egothor sarato OpenFTS."
  },
  {
    "url": "https://my.wikipedia.org/wiki/%E1%80%9D%E1%80%98%E1%80%BA%E1%80%9B%E1%80%BE%E1%80%AC%E1%80%96%E1%80%BD%E1%80%B1%E1%80%9B%E1%80%B1%E1%80%B8%E1%80%85%E1%80%80%E1%80%BA%E1%80%85%E1%80%94%E1%80%85%E1%80%BA",
    "title": "·Äù·Äò·Ä∫·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫ - ·Äù·ÄÆ·ÄÄ·ÄÆ·Äï·ÄÆ·Ä∏·Äí·ÄÆ·Ä∏·Äö·Ä¨·Ä∏",
    "content": "·Äù·Äò·Ä∫·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫ (·Ä°·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä≠·Äï·Ä∫: web search engine) ·Äû·Ää·Ä∫ ·ÄÜ·Ä± ·ÄÖ·Ä∫·ÄÅ·ÄØ·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã ·Åé·ÄÑ·Ä∫·Ä∏·ÄÜ·Ä±·Ä¨·Ä∑·Äñ·Ä∫·Äù·Ä≤·ÄÄ·Ä≠·ÄØ ·Ä°·ÄÑ·Ä∫·Äê·Ä¨·Äî·ÄÄ·Ä∫ World Wide Web ·Äï·Ä±·Ä´·Ä∫·Äõ·Äæ·Ä≠ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä¨·Äê·ÄΩ·ÄÑ·Ä∫ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·Äû·Ää·Ä∫·Åã ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Äõ·Äæ·Ä≠·Äú·Ä¨·Äû·Ä±·Ä¨ ·Äõ·Äú·Äí·Ä∫·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·ÄÖ·Ä¨·Äô·Äª·ÄÄ·Ä∫·Äî·Äæ·Ä¨·Äï·Ä±·Ä´·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ ·Äê·ÄÖ·Ä∫·ÄÄ·Äº·Ä±·Ä¨·ÄÑ·Ä∫·ÄÅ·Äª·ÄÑ·Ä∫·Ä∏·ÄÖ·ÄÆ ·Äï·Äº·Äû·Äë·Ä¨·Ä∏·Äû·Ää·Ä∫·Åã ·Äõ·Äú·Äí·Ä∫·Äô·Äª·Ä¨·Ä∏·Äê·ÄΩ·ÄÑ·Ä∫ ·Äù·Äò·Ä∫·ÄÖ·Ä¨·Äô·Äª·ÄÄ·Ä∫·Äî·Äæ·Ä¨·Äô·Äª·Ä¨·Ä∏·Åä ·Äõ·ÄØ·Äï·Ä∫·Äï·ÄØ·Ä∂·Äô·Äª·Ä¨·Ä∏·Åä ·Ä°·ÄÅ·Äº·Ä¨·Ä∏·Äû·Ä±·Ä¨ ·Äñ·Ä≠·ÄØ·ÄÑ·Ä∫·Äï·ÄØ·Ä∂·ÄÖ·Ä∂·Äô·Äª·Ä¨·Ä∏·ÄÖ·ÄΩ·Ä¨·Äú·Ää·Ä∫·Ä∏ ·Äï·Ä´·Äù·ÄÑ·Ä∫·Äû·Ää·Ä∫·Åã ·Ä°·ÄÅ·Äº·Ä¨·Ä∏·Äû·Ä±·Ä¨ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·Äô·Äª·Ä¨·Ä∏·Äû·Ää·Ä∫ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Äô·Ä∫·Ä∏·ÄÖ·Ä≠·Äê·Ä∫·Äñ·Äº·Ä¨·Äû·Ää·Ä∑·Ä∫ ·ÄÖ·Äî·ÄÖ·Ä∫·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·ÄÄ·Äº·Äû·Ää·Ä∫·Åã ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·Äô·Äª·Ä¨·Ä∏·Äû·Ää·Ä∫ ·Ä°·ÄÅ·Äª·Ä≠·Äî·Ä∫·Äî·Äæ·ÄÑ·Ä∑·Ä∫·Äê·ÄÖ·Ä∫·Äï·Äº·Ä±·Ä∏·Ää·ÄÆ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ Algorithm ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·ÄÄ·Ä¨ ·Äë·Ä≠·Äî·Ä∫·Ä∏·Äû·Ä≠·Äô·Ä∫·Ä∏·Äô·ÄΩ·Äô·Ä∫·Ä∏·Äô·Ä∂·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏ ·Äï·Äº·ÄØ·Äú·ÄØ·Äï·Ä∫·ÄÄ·Äº·Äû·Ää·Ä∫·Åã ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·Äû·Ää·Ä∫ ·Äù·Äò·Ä∫ Directories ·Äô·Äª·Ä¨·Ä∏·Äî·Äæ·ÄÑ·Ä∑·Ä∫·Äô·Äê·Ä∞·Äï·Ä±·Åã ·Äù·Äò·Ä∫ Directories ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ·Äô·Ä∞ ·Äï·Äº·ÄØ·Äï·Äº·ÄÑ·Ä∫·Äô·ÄΩ·Äô·Ä∫·Ä∏·Äô·Ä∂·Äõ·Äî·Ä∫ ·Äú·Ä∞·ÄÄ·Ä≠·ÄØ·Äö·Ä∫·Äê·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ä¨·Äú·Äª·Äæ·ÄÑ·Ä∫ ·Äï·Äº·ÄØ·Äú·ÄØ·Äï·Ä∫·Äô·Äæ ·Äõ·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ää·Ä∫·Åã ·ÅÇ·ÅÄ·ÅÄ·ÅÄ ·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫·Äï·Äê·Ä∫·Äú·Ää·Ä∫·Äú·Ä±·Ä¨·ÄÄ·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ ·ÄÇ·Ä∞·ÄÇ·Ä≤·Äú·Ä∫·Åè ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·Äû·Ää·Ä∫ ·Äë·ÄÑ·Ä∫·Äõ·Äæ·Ä¨·Ä∏·Äú·Ä∞·Äû·Ä≠·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä¨ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·Äô·Äæ·ÄØ ·Äô·Äº·ÄÑ·Ä∑·Ä∫·Äê·ÄÄ·Ä∫·Äú·Ä¨·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã[·ÅÅ] ·ÄÄ·ÄØ·Äô·Äπ·Äï·Äè·ÄÆ·Äû·Ää·Ä∫ ·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äô·ÄΩ·Äî·Ä∫·Äû·Ää·Ä∑·Ä∫ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äô·Äæ·ÄØ·Äõ·Äú·Äí·Ä∫·Äï·Ä±·Ä´·ÄÑ·Ä∫·Ä∏·Äô·Äª·Ä¨·Ä∏·ÄÖ·ÄΩ·Ä¨·ÄÄ·Ä≠·ÄØ ·Äë·Ä±·Ä¨·ÄÄ·Ä∫·Äï·Ä∂·Ä∑·ÄÄ·Ä¨ ·Äõ·Äæ·Ä¨·Äï·Ä±·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ää·Ä∫·Åã PageRank ·Äü·ÄØ·ÄÅ·Ä±·Ä´·Ä∫·Äû·Ää·Ä∑·Ä∫ ·Äê·ÄÆ·Äë·ÄΩ·ÄÑ·Ä∫·Äô·Äæ·ÄØ·Äî·Ää·Ä∫·Ä∏·Äï·Ää·Ä¨·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äï·Ä±·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã[·ÅÇ] ·ÅÇ·ÅÄ·ÅÄ·ÅÄ ·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ Yahoo! ·Äû·Ää·Ä∫ Inktomi ·Åè ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·Ä°·Äï·Ä±·Ä´·Ä∫ ·Ä°·ÄÅ·Äº·Ä±·ÄÅ·Ä∂·Äë·Ä¨·Ä∏·Äû·Ää·Ä∑·Ä∫ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·Äù·Äî·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äë·Ä±·Ä¨·ÄÄ·Ä∫·Äï·Ä∂·Ä∑·Äï·Ä±·Ä∏·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã Yahoo! ·Äû·Ää·Ä∫ Inktomi ·ÄÄ·Ä≠·ÄØ ·ÅÇ·ÅÄ·ÅÄ·ÅÇ ·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ ·Äõ·Äõ·Äæ·Ä≠·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã Overture ·ÄÄ·Ä≠·ÄØ ·ÅÇ·ÅÄ·ÅÄ·ÅÉ ·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ ·Äõ·Äõ·Äæ·Ä≠·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã Overture ·Äû·Ää·Ä∫ AlltheWeb ·Äî·Äæ·ÄÑ·Ä∑·Ä∫ AltaVista ·Äê·Ä≠·ÄØ·Ä∑·ÄÄ ·Äï·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÜ·Ä≠·ÄØ·Ä∫·ÄÑ·Ä∫·ÄÄ·Äº·Äû·Ää·Ä∫·Åã Yahoo! ·Äû·Ää·Ä∫ ·Äõ·Äõ·Äæ·Ä≠·Äë·Ä¨·Ä∏·Äû·Ää·Ä∫ ·Äî·Ää·Ä∫·Ä∏·Äï·Ää·Ä¨·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äï·Ä±·Ä´·ÄÑ·Ä∫·Ä∏·ÄÖ·Äï·Ä∫·ÄÄ·Ä¨ ·ÄÄ·Ä≠·ÄØ·Äö·Ä∫·Äï·Ä≠·ÄØ·ÄÑ·Ä∫·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·ÄÄ·Ä≠·ÄØ ·ÄÖ·Äê·ÄÑ·Ä∫·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã ·Äô·Ä≠·ÄØ·ÄÄ·Ä∫·ÄÅ·Äõ·Ä≠·ÄØ·ÄÜ·Ä±·Ä¨·Ä∑·Äñ·Ä∫·Äû·Ää·Ä∫ Bing ·Äü·ÄØ·ÄÅ·Ä±·Ä´·Ä∫·Äû·Ää·Ä∑·Ä∫ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·ÄÄ·Ä≠·ÄØ ·ÅÇ·ÅÄ·ÅÄ·Åâ ·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫·Åä ·Äá·ÄΩ·Äî·Ä∫·Äú ·ÅÅ ·Äõ·ÄÄ·Ä∫·Äî·Ä±·Ä∑·Äê·ÄΩ·ÄÑ·Ä∫ ·ÄÖ·Äê·ÄÑ·Ä∫·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã ·ÄÇ·Ä∞·ÄÇ·Ä≤·Äú·Ä∫·Äû·Ää·Ä∫ ·ÄÄ·Äô·Äπ·Äò·Ä¨·Äï·Ä±·Ä´·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ ·Äú·Ä∞·Äû·ÄØ·Ä∂·Ä∏·Ä°·Äô·Äª·Ä¨·Ä∏·ÄÜ·ÄØ·Ä∂·Ä∏ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫ ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ ·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã ·ÅÇ·ÅÄ·ÅÅ·Åá ·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫·Åä ·Äô·Äê·Ä∫·Äú·Äë·Ä≠ ·Äà·Ä±·Ä∏·ÄÄ·ÄΩ·Åè·ÄÄ·Ä∫·Åè ·Åà·ÅÄ.·Åâ·ÅÇ ·Äõ·Ä¨·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏·ÄÄ·Ä≠·ÄØ ·Äï·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÜ·Ä≠·ÄØ·ÄÑ·Ä∫·Äë·Ä¨·Ä∏·Äû·Ää·Ä∫·Åã[·ÅÉ] ·ÄÄ·Äô·Äπ·Äò·Ä¨·Äï·Ä±·Ä´·Ä∫·Äê·ÄΩ·ÄÑ·Ä∫ ·Äú·Ä∞·Äû·ÄØ·Ä∂·Ä∏·Äô·Äª·Ä¨·Ä∏·Äû·Ä±·Ä¨ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫·Äô·Äª·Ä¨·Ä∏ (·Äà·Ä±·Ä∏·ÄÄ·ÄΩ·ÄÄ·Ä∫·Äù·Ä±·ÄÖ·ÄØ ·ÅÅ ·Äõ·Ä¨·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏·Äë·ÄÄ·Ä∫·Äï·Ä≠·ÄØ·Äû·Ä±·Ä¨) ·Äô·Äæ·Ä¨ ·Ä°·Äõ·Äæ·Ä±·Ä∑·Ä°·Ä¨·Äõ·Äæ ·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Ä°·ÄÅ·Äª·Ä≠·ÄØ·Ä∑ ·Äî·Äæ·ÄÑ·Ä∑·Ä∫ ·Äõ·ÄØ·Äõ·Äæ·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äê·Ä≠·ÄØ·Ä∑·Äê·ÄΩ·ÄÑ·Ä∫ ·ÄÇ·Ä∞·ÄÇ·Ä≤·Äú·Ä∫·Äû·Ää·Ä∫ ·Äú·Ä∞·Äû·Ä≠·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä¨ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Ä°·Äô·Äª·Ä¨·Ä∏·ÄÜ·ÄØ·Ä∂·Ä∏ ·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äõ·Ä±·Ä∏ ·ÄÖ·ÄÄ·Ä∫·ÄÖ·Äî·ÄÖ·Ä∫ ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ ·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã ·Äõ·ÄØ·Äõ·Äæ·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äê·ÄΩ·ÄÑ·Ä∫ Yandex ·Äû·Ää·Ä∫ ·Äà·Ä±·Ä∏·ÄÄ·ÄΩ·ÄÄ·Ä∫·Åè ·ÅÜ·ÅÅ.·Åâ ·Äõ·Ä¨·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏ ·Äõ·Äõ·Äæ·Ä≠·Äë·Ä¨·Ä∏·Äï·Äº·ÄÆ·Ä∏ ·ÄÇ·Ä∞·ÄÇ·Ä≤·Äú·Ä∫·Äô·Äæ·Ä¨·Äô·Ä∞ ·ÅÇ·Åà.·ÅÉ ·Äõ·Ä¨·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏·Äû·Ä¨ ·Äõ·Äõ·Äæ·Ä≠·Äû·Ää·Ä∫·Åã[·ÅÑ] ·Äê·Äõ·ÄØ·Äê·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äê·ÄΩ·ÄÑ·Ä∫ Baidu ·Äû·Ää·Ä∫ ·Äú·Ä∞·Äû·ÄØ·Ä∂·Ä∏·Ä°·Äô·Äª·Ä¨·Ä∏·ÄÜ·ÄØ·Ä∂·Ä∏ ·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã[·ÅÖ] ·Äê·Ä±·Ä¨·ÄÑ·Ä∫·ÄÄ·Ä≠·ÄØ·Äõ·ÄÆ·Ä∏·Äö·Ä¨·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äê·ÄΩ·ÄÑ·Ä∫ ·Ä°·ÄΩ·Äî·Ä∫·Äú·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äõ·Äæ·Ä¨·Äñ·ÄΩ·Ä±·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏·Äï·Äº·ÄØ·Äú·ÄØ·Äï·Ä∫·Äõ·Ä¨·Äê·ÄΩ·ÄÑ·Ä∫ Naver ·ÄÄ·Ä≠·ÄØ ·Åá·ÅÄ ·Äõ·Ä¨·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·ÄÄ·Äº·Äû·Ää·Ä∫·Åã[·ÅÜ] Yahoo! ·ÄÇ·Äª·Äï·Äî·Ä∫ ·Äî·Äæ·ÄÑ·Ä∑·Ä∫Yahoo! ·Äë·Ä≠·ÄØ·ÄÑ·Ä∫·Äù·Äô·Ä∫ ·Äê·Ä≠·ÄØ·Ä∑·Äû·Ää·Ä∫ ·ÄÇ·Äª·Äï·Äî·Ä∫ ·Äî·Äæ·ÄÑ·Ä∑·Ä∫ ·Äë·Ä≠·ÄØ·ÄÑ·Ä∫·Äù·Äô·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äê·Ä≠·ÄØ·Ä∑·Äê·ÄΩ·ÄÑ·Ä∫ ·Äú·Ä∞·Äû·ÄØ·Ä∂·Ä∏·Äô·Äª·Ä¨·Ä∏·ÄÄ·Äº·Äû·Ää·Ä∫·Åã[·Åá] ·ÄÅ·Äª·ÄÄ·Ä∫·Äû·Äô·Äπ·Äô·Äê·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äô·Äæ·Äê·Äï·Ä´·Ä∏ ·Ä°·Äî·Ä±·Ä¨·ÄÄ·Ä∫·Ä•·Äõ·Ä±·Ä¨·Äï·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Ä°·Äô·Äª·Ä¨·Ä∏·ÄÖ·ÄØ·Äê·ÄΩ·ÄÑ·Ä∫ ·ÄÇ·Ä∞·ÄÇ·Ä≤·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äô·Äª·Ä¨·Ä∏·ÄÄ·Äº·Äû·Ää·Ä∫·Åã ·ÄÅ·Äª·ÄÄ·Ä∫·Äû·Äô·Äπ·Äô·Äê·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂·Äê·ÄΩ·ÄÑ·Ä∫ Seznam ·Äû·Ää·Ä∫ ·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äô·ÄΩ·Äî·Ä∫·Äû·Ää·Ä∑·Ä∫ ·Äï·Äº·Ä≠·ÄØ·ÄÑ·Ä∫·Äò·ÄÄ·Ä∫·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·Äú·Ää·Ä∫·Ä∏ ·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã[·Åà]"
  },
  {
    "url": "https://ne.wikipedia.org/wiki/%E0%A4%B5%E0%A5%87%E0%A4%AC_%E0%A4%96%E0%A5%8B%E0%A4%9C_%E0%A4%B8%E0%A4%82%E0%A4%AF%E0%A4%A8%E0%A5%8D%E0%A4%A4%E0%A5%8D%E0%A4%B0",
    "title": "‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ - ‡§µ‡§ø‡§ï‡§ø‡§™‡§ø‡§°‡§ø‡§Ø‡§æ",
    "content": "‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§µ‡§æ ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§µ‡§æ ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü‡§Æ‡§æ ‡§ñ‡•ã‡§ú ‡§ó‡§∞‡•ç‡§®‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∏‡•É‡§ú‡§®‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§è‡§ï ‡§∏‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§π‡•ã ‡§ú‡§∏‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§• ‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡•ç‡§Ø‡§æ‡§™‡•Ä ‡§µ‡•á‡§¨‡§≤‡§æ‡§à ‡§è‡§ï ‡§Æ‡•Å‡§≤‡§™‡§æ‡§† ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§Æ‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü‡§ø‡§§, ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§§‡§∞‡•Ä‡§ï‡§æ‡§≤‡•á ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§®‡•Å ‡§π‡•ã‡•§[‡•ß]\n‡§µ‡§æ ‡§Ö‡§∞‡•ç‡§ï‡•ã ‡§∂‡§¨‡•ç‡§¶‡§Æ‡§æ ‡§≠‡§®‡•ç‡§®‡•Å ‡§™‡§∞‡•ç‡§¶‡§æ ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§è‡§ï ‡§µ‡•á‡§¨ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§π‡•ã ‡§ú‡§∏‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§¨‡§æ‡§ü ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§≤‡•á ‡§∂‡§¨‡•ç‡§¶‡§π‡§∞‡•Ç‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ  ‡§≠‡§£‡•ç‡§°‡§æ‡§∞‡§¨‡§æ‡§ü ‡§∏‡•ç‡§∞‡•ã‡§§‡§π‡§∞‡•Ç ‡§´‡•á‡§≤‡§æ ‡§™‡§æ‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ‡§®‡•ç‡•§ ‡§Ø‡§∏‡§ï‡§æ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®‡§Æ‡§æ ‡§µ‡•á‡§¨ ‡§™‡•É‡§∑‡•ç‡§†, ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§Æ‡§û‡•ç‡§ö ‡§≤‡•á‡§ñ, ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞, ‡§∂‡•ç‡§∞‡§µ‡•ç‡§Ø ‡§¶‡•É‡§∂‡•ç‡§Ø, ‡§´‡§æ‡§á‡§≤, ‡§™‡•Å‡§∏‡•ç‡§§‡§ï, ‡§∂‡•à‡§ï‡•ç‡§∑‡§ø‡§ï ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü, ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó, ‡§ñ‡•Å‡§≤‡§æ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§∏‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞, ‡§Ü‡§¶‡§ø ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç‡•§[‡•®] ‡§ï‡•á‡§π‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§≤‡•á ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§≤‡§æ‡§à ‡§â‡§®‡•Ä‡§π‡§∞‡•Ç‡§ï‡•ã ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ ‡§ó‡§∞‡•ç‡§¶‡§õ‡§®‡•ç ‡§ú‡§∏‡§≤‡§æ‡§à ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§≠‡§®‡§ø‡§è‡§ï‡•ã ‡§õ ‡§ú‡•Å‡§® ‡§Æ‡§æ‡§®‡§µ ‡§π‡§∏‡•ç‡§§‡§ï‡•ç‡§∑‡•á‡§™ ‡§¨‡§ø‡§®‡§æ ‡§µ‡•á‡§¨‡§Æ‡§æ ‡§Ö‡§®‡•Å‡§∏‡§®‡•ç‡§ß‡§æ‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§â‡§™‡§ï‡§∞‡§£‡§π‡§∞‡•Ç ‡§™‡§®‡§ø ‡§π‡•Å‡§®‡•ç‡•§ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§Ø‡§æ ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç \"‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡§∞‡•Ä‡§∏‡•É‡§™\"‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç ‡§ú‡§∏‡§≤‡•á ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§Ö‡§®‡•ç‡§§‡§∞‡§æ‡§≤‡§Æ‡§æ ‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•á ‡§∞ ‡§®‡§Ø‡§æ‡§Å ‡§†‡•á‡§ó‡§æ‡§®‡§æ‡§π‡§∞‡•Ç ‡§™‡§§‡•ç‡§§‡§æ ‡§≤‡§ó‡§æ‡§â‡§® ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§Æ‡§¶‡•ç‡§¶‡§§ ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§ ‡§∏‡•á‡§µ‡§æ‡§π‡§∞‡•Ç‡§≤‡•á ‡§∏‡•Ç‡§§‡•ç‡§∞ ‡§™‡§õ‡•ç‡§Ø‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡§ú‡§∏‡§≤‡•á ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§è‡§ï ‡§™‡§õ‡§ø ‡§Ö‡§∞‡•ç‡§ï‡•ã ‡§ó‡§∞‡•ç‡§¶‡•à ‡§∏‡•Ç‡§§‡•ç‡§∞‡§¨‡§¶‡•ç‡§ß ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§™‡§π‡§ø‡§ö‡§æ‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§™‡•É‡§∑‡•ç‡§† ‡§§‡•ç‡§Ø‡§∏‡§™‡§õ‡§ø ‡§≠‡§£‡•ç‡§°‡§æ‡§∞‡§Æ‡§æ ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç ‡§∞ ‡§™‡§õ‡§ø ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§π‡§∞‡•Ç‡§≤‡•á ‡§∂‡§¨‡•ç‡§¶‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§™‡§π‡•Å‡§Å‡§ö ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ‡§®‡•ç‡•§ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü‡§Æ‡§æ ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§≤‡§æ‡§ó‡•Ç ‡§π‡•Å‡§Å‡§¶‡•à‡§®‡•§ ‡§ï‡•á‡§π‡•Ä ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç‡§≤‡•á ‡§∏‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ó‡§∞‡•ç‡§¶‡§õ‡§®‡•ç ‡§ú‡•Å‡§® ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∏‡•Å‡§ñ‡§æ‡§ô‡•ç‡§ñ‡•ç‡§Ø‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç‡•§ ‡§Ø‡•Ä ‡§§‡§•‡§æ‡§ï‡§•‡§ø‡§§ ‡§∏‡•Å‡§∂‡§æ‡§ô‡•ç‡§ñ‡•ç‡§Ø ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç ‡§ú‡§∏‡§≤‡•á ‡§∏‡•Å‡§∂‡§æ‡§ô‡•ç‡§ñ‡•ç‡§Ø‡§Æ‡§æ ‡§≠‡§£‡•ç‡§°‡§æ‡§∞ ‡§ó‡§∞‡§ø‡§è‡§ï‡§æ ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç‡§ï‡•ã ‡§¨‡•Ä‡§ö‡§Æ‡§æ ‡§ñ‡•ã‡§ú‡•Ä ‡§∞ ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§ï‡•ã ‡§¨‡•Ä‡§ö‡§Æ‡§æ ‡§ú‡•ã‡§°‡•á‡§∞ ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§ ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§Æ‡§û‡•ç‡§ö‡§Æ‡§æ ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞‡§ø‡§§ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç ‡§™‡§®‡§ø ‡§∞‡§π‡•á‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç ‡§ú‡§∏‡§≤‡•á ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞‡§ø‡§§ ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§®‡•á ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•ç‡§¶‡§õ‡§®‡•ç‡•§[‡•©] ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§≤‡•á ‡§°‡§ø‡§∏‡•á‡§Æ‡•ç‡§¨‡§∞ ‡•ß‡•Ø‡•Ø‡•¶ ‡§Æ‡§æ, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡•ç‡§Ø‡§æ‡§™‡•Ä ‡§µ‡•á‡§¨‡§Æ‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§™‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ [‡•™] ‡•ß‡•¶ ‡§∏‡•á‡§™‡•ç‡§ü‡•á‡§Æ‡•ç‡§¨‡§∞ ‡•ß‡•Ø‡•Ø‡•¶ ‡§Æ‡§æ, ‡§™‡§π‡§ø‡§≤‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§Ü‡§∞‡•ç‡§ö‡•Ä‡§≤‡•á ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü‡§Æ‡§æ ‡§ï‡§¶‡§Æ ‡§∞‡§æ‡§ñ‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§Ü‡§∞‡•ç‡§ö‡•Ä, ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§π‡§∞‡•Ç‡§ï‡•ã ‡§ñ‡•ã‡§ú‡•Ä‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§™‡§π‡§ø‡§≤‡•ã ‡§â‡§™‡§ï‡§∞‡§£ ‡§•‡§ø‡§Ø‡•ã‡•§[‡•´] ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§ï‡•ç‡§Ø‡§æ‡§®‡§°‡§æ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡•Å‡§¨‡•á‡§ï‡§ï‡•ã ‡§Æ‡•ã‡§®‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø‡§≤‡§ï‡•ã ‡§Æ‡•ç‡§Ø‡§æ‡§ï‡§ó‡§ø‡§≤ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø‡§ï‡§æ ‡§ï‡§Æ‡•ç‡§™‡•ç‡§Ø‡•Å‡§ü‡§∞ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§è‡§≤‡§® ‡§á‡§Æ‡•ç‡§ú‡•á‡§ü, ‡§¨‡§ø‡§≤ ‡§π‡•á‡§≤‡§® ‡§∞ ‡§ú‡•á ‡§™‡§ø‡§ü‡§∞ ‡§¶‡•ã‡§è‡§ö‡•ç‡§∏‡§≤‡•á ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è‡•§ ‡§â‡§™‡§ï‡§∞‡§£‡§≤‡•á ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§´‡§æ‡§á‡§≤ ‡§®‡§æ‡§Æ‡§π‡§∞‡•Ç ‡§ñ‡•ã‡§ú‡•Ä‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§≠‡§£‡•ç‡§°‡§æ‡§∞‡§Æ‡§æ ‡§∏‡•É‡§ú‡§®‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à ‡§´‡§æ‡§á‡§≤ ‡§Ü‡§¶‡§®‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§∏‡•å‡§ú‡§®‡•ç‡§Ø‡§µ‡§ø‡§ß‡§ø ‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§Ö‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§∏‡§¨‡•à ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§∏‡•Ç‡§ö‡•Ä‡§¨‡§¶‡•ç‡§ß ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§Ö‡§≠‡§ø‡§≠‡§æ‡§∞‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•¨] ‡§Ü‡§∞‡•ç‡§ö‡•Ä ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§Ü‡§Å‡§ï‡§°‡§æ ‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§≠‡§è‡§ï‡•ã ‡§∞ ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§∏‡§ú‡§ø‡§≤‡•à‡§∏‡§Å‡§ó ‡§ó‡•à‡§∞ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Ø‡§∏‡§≤‡•á ‡§Ø‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§ï‡•ã ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§≤‡§æ‡§à ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡§£‡§ø‡§ï‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§è‡§®‡•§[‡•≠] ‡§µ‡•á‡§¨‡§Æ‡§æ ‡§™‡§π‡§ø‡§≤‡•ã ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§≠‡§®‡•á‡§ï‡•ã ‡§Ø‡§æ‡§π‡•Å‡§ï‡•ã ‡§Ø‡§æ‡§π‡•Å! ‡§ñ‡•ã‡§ú ‡§•‡§ø‡§Ø‡•ã ‡§ú‡§∏‡§≤‡§æ‡§à ‡§ú‡•á‡§∞‡§ø ‡§Ø‡§æ‡§ô ‡§∞ ‡§°‡•á‡§≠‡§ø‡§° ‡§´‡§ø‡§≤‡•ã‡§≤‡•á ‡§ú‡§®‡§µ‡§∞‡•Ä ‡•ß‡•Ø‡•Ø‡•™ ‡§Æ‡§æ, ‡§è‡§ï ‡§µ‡•á‡§¨ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§∏‡•É‡§ú‡§®‡§æ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è‡•§[‡•Æ] ‡§Ø ‡§Ø‡§æ‡§π‡•Å‡§ï‡•ã ‡§™‡§π‡§ø‡§≤‡•ã ‡§µ‡•á‡§¨ ‡§∏‡•á‡§µ‡§æ ‡§™‡§®‡§ø ‡§π‡•ã‡•§ ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•´ ‡§Æ‡§æ, ‡§Ø‡§∏‡§Æ‡§æ ‡§ñ‡•ã‡§ú ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ ‡§•‡§™‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡§ú‡§∏‡§≤‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§Ø‡§∏‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§® ‡§Ö‡§≠‡§ø‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•Ø] ‡§Ø‡•ã ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§π‡§∞‡•Ç‡§ï‡•ã ‡§∞‡•Ç‡§ö‡§ø ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§µ‡•á‡§¨ ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç ‡§´‡•á‡§≤‡§æ ‡§™‡§æ‡§∞‡•ç‡§® ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§§‡§∞‡§ø‡§ï‡§æ‡§π‡§∞‡•Ç ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§è‡§ï ‡§¨‡§®‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡§∞ ‡§™‡§õ‡§ø ‡§Ø‡§æ‡§π‡•Å ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ‡§≤‡§æ‡§à ‡§Ø‡§æ‡§π‡•Å! ‡§ñ‡•ã‡§ú‡§Æ‡§æ ‡§™‡•Å‡§®‡§∞‡•ç‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•ß‡•¶][‡•ß‡•ß] ‡§ï‡•á‡§π‡•Ä ‡§µ‡§∞‡•ç‡§∑ ‡§™‡§õ‡§ø, ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç ‡§¶‡•á‡§ñ‡§æ ‡§™‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡§ú‡§∏‡§Æ‡§æ ‡§è‡§ï‡•ç‡§∏‡§æ‡§á‡§ü, ‡§á‡§®‡•ç‡§´‡•ã‡§∏‡§ø‡§ï, ‡§á‡§ô‡•ç‡§ï‡§ü‡•ã‡§Æ‡•Ä, ‡§®‡§∞‡•ç‡§•‡§® ‡§≤‡§æ‡§á‡§ü, ‡§Ö‡§≤‡•ç‡§ü‡§æ ‡§≠‡§ø‡§∏‡•ç‡§ü‡§æ ‡§Ü‡§¶‡•Ä ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§õ ‡§ú‡§∏‡§ï‡•ã ‡§Æ‡§¶‡•ç‡§¶‡§§‡§≤‡•á ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§ñ‡•ã‡§ú‡•ç‡§®‡•á‡§π‡§∞‡•Ç‡§≤‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§π‡§∞‡•Ç‡§≤‡•á ‡§ï‡•Å‡§û‡•ç‡§ú‡•Ä ‡§∂‡§¨‡•ç‡§¶‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§®‡•Å‡§ï‡•ã ‡§∏‡§ü‡•ç‡§ü‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§ñ‡•ã‡§ú‡•Ä ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§•‡§ø‡§è‡•§ ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•¨ ‡§Æ‡§æ, ‡§∞‡•ã‡§¨‡§ø‡§® ‡§≤‡§ø‡§≤‡•á ‡§∞‡•á‡§ô‡•ç‡§ï‡§°‡•á‡§ï‡•ç‡§∏ ‡§®‡§æ‡§Æ‡§ï ‡§∏‡•á‡§µ‡§æ‡§ï‡•ã ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡§ú‡§∏‡§≤‡•á ‡§™‡§õ‡§ø ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø‡§ï‡•ã ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§Æ‡§æ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§è‡§ï‡§∂‡•ç‡§µ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•ß‡•®][‡•ß‡•©] ‡§∏‡•Ç‡§§‡•ç‡§∞ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§ï‡•ã ‡§ó‡•Å‡§£‡§∏‡•ç‡§§‡§∞ ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ø‡•ã ‡§è‡§ï ‡§™‡§π‡§ø‡§≤‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§Ø‡§∏‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§® ‡§ï‡§≤‡§® ‡§µ‡§ø‡§ß‡§ø ‡§≠‡§è‡§ï‡•ã ‡§è‡§ï‡§∂‡•ç‡§µ‡§≤‡§æ‡§à ‡§™‡§õ‡§ø ‡§ó‡•Å‡§ó‡§≤‡§≤‡•á ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•Æ ‡§Æ‡§æ, ‡§¶‡§∞‡•ç‡§§‡§æ ‡§ó‡§∞‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•ß‡•™] ‡§≤‡•ç‡§Ø‡§æ‡§∞‡•Ä ‡§™‡•á‡§ú‡§≤‡•á ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ‡§ï‡•ã ‡§ï‡•á‡§π‡•Ä ‡§è‡§ï‡§∂‡•ç‡§µ‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§™‡•É‡§∑‡•ç‡§† ‡§µ‡§∞‡§ø‡§Ø‡§§‡§æ‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§≤‡§ø‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§≤‡§æ‡§à ‡§∏‡§æ‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è‡•§[‡•ß‡•´] ‡§™‡§õ‡§ø ‡§∞‡•ã‡§¨‡§ø‡§® ‡§≤‡§ø‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∞‡•á‡§ô‡•ç‡§ï‡§°‡•á‡§ï‡•ç‡§∏ ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø ‡§¨‡§æ‡§Ø‡§¶‡•Å ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡§ú‡§∏‡§≤‡§æ‡§à ‡§ö‡•Ä‡§®‡§Æ‡§æ ‡§∞‡•ã‡§¨‡§ø‡§® ‡§≤‡§ø‡§≤‡•á ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡§≠‡§®‡•á ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§∏‡§®‡•ç ‡•®‡•¶‡•¶‡•¶ ‡§Æ‡§æ ‡§∏‡§û‡•ç‡§ö‡§æ‡§≤‡§®‡§Æ‡§æ ‡§≤‡•ç‡§Ø‡§æ‡§á‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ [‡•ß‡•¨][‡•ß‡•≠] ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•¨ ‡§Æ‡§æ, ‡§®‡•á‡§ü‡§∏‡•ç‡§ï‡•á‡§™‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§µ‡•á‡§¨ ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§∞‡§Æ‡§æ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§Æ‡§æ ‡§≤‡•ç‡§Ø‡§æ‡§â‡§®‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§ó‡•É‡§π‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§•‡§æ‡§≤‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•ß‡•Æ][‡•ß‡•Ø] ‡§ó‡•Å‡§ó‡§≤‡§≤‡•á ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•Æ ‡§Æ‡§æ ‡§ó‡•á‡§ü‡•ã ‡§°‡§ü‡§ï‡§Æ ‡§®‡§æ‡§Æ‡§ï‡•ã ‡§è‡§ï ‡§∏‡§æ‡§®‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§¨‡§æ‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§∞‡•ç‡§§‡§π‡§∞‡•Ç ‡§¨‡•á‡§ö‡•ç‡§®‡•á ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§Ö‡§™‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•®‡•¶] ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•¨ ‡§Æ‡§æ, ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§≠‡§è‡§ï‡•ã ‡§∞‡•Ç‡§∏‡•Ä ‡§¨‡§π‡•Å‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§®‡§ø‡§ó‡§Æ ‡§Ø‡§æ‡§®‡•ç‡§¶‡§ø‡§ï‡•ç‡§∏‡§≤‡•á ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•≠ ‡§Æ‡§æ, ‡§Ø‡§æ‡§®‡•ç‡§¶‡§ø‡§ï‡•ç‡§∏ ‡§ñ‡•ã‡§ú‡§ï‡•ã ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡§ú‡§∏‡§≤‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø‡§§‡§Ø‡§æ ‡§∞‡•Ç‡§∏ ‡§∞ ‡§∏‡•ç‡§µ‡§§‡§®‡•ç‡§§‡•ç‡§∞ ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§∏‡§ô‡•ç‡§ò‡§Æ‡§æ ‡§™‡•Ç‡§∞‡•ç‡§£‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§[‡•®‡•ß][‡•®‡•®] ‡§Ø‡•ã ‡§∞‡•Ç‡§∏‡§ï‡•ã ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§¨‡§®‡•ç‡§® ‡§∏‡§´‡§≤ ‡§≠‡§è‡§ï‡•ã ‡§õ‡•§[‡•®‡•©][‡•®‡•™] ‡§∏‡§®‡•ç ‡•®‡•¶‡•¶‡•¶ ‡§¶‡•á‡§ñ‡§ø, ‡§Ø‡§æ‡§π‡•Å!‡§≤‡•á ‡§á‡§ô‡•ç‡§ï‡§ü‡•ã‡§Æ‡•Ä ‡§ñ‡•ã‡§ú‡•Ä ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ñ‡•ã‡§ú‡•Ä ‡§∏‡•á‡§µ‡§æ‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§Ø‡§æ‡§π‡•Å!‡§≤‡•á ‡§∏‡§®‡•ç ‡•®‡•¶‡•¶‡•® ‡§Æ‡§æ ‡§á‡§ô‡•ç‡§ï‡§ü‡•ã‡§Æ‡•Ä ‡§∞ ‡§∏‡§®‡•ç ‡•®‡•¶‡•¶‡•© ‡§Æ‡§æ, ‡§ì‡§≠‡§∞‡•ç‡§ö‡§ï‡•ã ‡§Ö‡§ß‡§ø‡§ó‡•ç‡§∞‡§π‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡§ú‡•Å‡§® ‡§Ö‡§≤ ‡§¶ ‡§µ‡•á‡§¨ ‡§∞ ‡§Ö‡§≤‡•ç‡§ü‡§æ ‡§≠‡§ø‡§∏‡•ç‡§ü‡§æ‡§ï‡•ã ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§Ø‡§æ‡§π‡•Å!‡§≤‡•á ‡§∏‡§®‡•ç ‡•®‡•¶‡•¶‡•™ ‡§∏‡§Æ‡•ç‡§Æ ‡§ó‡•Å‡§ó‡§≤‡§ï‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡§≠‡§®‡•á ‡§™‡§õ‡§ø ‡§Ø‡§∏‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∏‡•ç‡§µ‡§§‡§®‡•ç‡§§‡•ç‡§∞ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§∏‡§´‡•ç‡§ü‡§≤‡•á ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•Æ ‡§ï‡•ã ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§§‡§ø‡§∞, ‡§á‡§ô‡•ç‡§ï‡§ü‡•ã‡§Æ‡•Ä‡§ï‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§¶‡•à ‡§è‡§Æ‡§è‡§∏‡§è‡§® ‡§ñ‡•ã‡§ú‡§ï‡•ã ‡§™‡•ç‡§∞‡§ï‡•ç‡§∑‡•á‡§™‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§∏‡§®‡•ç ‡•ß‡•Ø‡•Ø‡•Ø ‡§Æ‡§æ, ‡§õ‡•ã‡§ü‡•ã ‡§∏‡§Æ‡§Ø‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§Ø‡§∏‡§≤‡•á ‡§Ö‡§≤‡•ç‡§ü‡§æ ‡§≠‡§ø‡§∏‡•ç‡§ü‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ ‡§Ø‡§∏‡§≤‡•á ‡§™‡§õ‡§ø ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∏‡•ç‡§µ‡§§‡§®‡•ç‡§§‡•ç‡§∞ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡§∞ ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§∏‡§´‡•ç‡§ü‡§≤‡•á ‡•ß ‡§ú‡•Å‡§® ‡•®‡•¶‡•¶‡•Ø ‡§Æ‡§æ, ‡§Ø‡§∏‡§ï‡•ã ‡§∏‡•ç‡§µ‡§§‡§®‡•ç‡§§‡•ç‡§∞ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§≤‡§æ‡§à ‡§¨‡§ø‡§ô‡§Æ‡§æ ‡§™‡•Å‡§®‡§∞‡•ç‡§ó‡§†‡§® ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§ ‡•®‡•Ø ‡§ú‡•Å‡§≤‡§æ‡§à ‡•®‡•¶‡•¶‡•Ø ‡§Æ‡§æ, ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§∏‡§´‡•ç‡§ü ‡§∞ ‡§Ø‡§æ‡§π‡•Å! ‡§è‡§ï ‡§∏‡§Æ‡•ç‡§ù‡•å‡§§‡§æ‡§Æ‡§æ ‡§π‡§∏‡•ç‡§§‡§æ‡§ï‡•ç‡§∑‡§∞ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡§ú‡§∏‡§Æ‡§æ ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§∏‡§´‡•ç‡§ü‡§ï‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§¨‡§ø‡§ô‡§≤‡•á ‡§Ø‡§æ‡§π‡•Å! ‡§ñ‡•ã‡§ú‡§≤‡§æ‡§à ‡§•‡§™ ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•®‡•´] ‡§∏‡§®‡•ç ‡•®‡•¶‡•®‡•¶ ‡§ï‡§æ ‡§Ö‡§§‡§ø ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç, ‡§Ø‡§æ‡§®‡•ç‡§¶‡§ø‡§ï‡•ç‡§∏, ‡§ó‡•Å‡§ó‡§≤, ‡§¨‡§ø‡§ô, ‡§¨‡§æ‡§Ø‡§¶‡•Å, ‡§∏‡•ã‡§∏‡•ã, ‡§∏‡•ã‡§ó‡•å, ‡§°‡§ï‡§°‡§ï‡§ó‡•ã, ‡§Ø‡§æ‡§π‡•Å! ‡§Ü‡§¶‡§ø ‡§π‡•Å‡§®‡•ç‡•§ ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç‡§≤‡•á ‡§µ‡•á‡§¨ ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç‡§ï‡•ã ‡§¨‡§æ‡§∞‡•á‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§ô‡•ç‡§ï‡§≤‡§® ‡§ó‡§∞‡•ç‡§¶‡•à ‡§§‡§ø‡§®‡•Ä‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§Ü‡§´‡•ç‡§®‡•ã ‡§≠‡§£‡•ç‡§°‡§æ‡§∞‡§£‡§Æ‡§æ ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§ó‡§∞‡•ç‡§¶‡§õ ‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§π‡§∞‡•Ç‡§ï‡§æ ‡§Æ‡§æ‡§ù ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡•Å‡§§ ‡§ó‡§∞‡•ç‡§®‡•á ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§‡§∏‡§Ç‡§∏‡§æ‡§∞‡§ï‡•ã ‡§¨‡§æ‡§∞‡•á‡§Æ‡§æ ‡§∏‡§¨‡•à ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ñ‡•ã‡§ú ‡§á‡§®‡•ç‡§ú‡§ø‡§® ‡§Æ‡§æ‡§∞‡•ç‡§´‡§§ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ó‡§∞‡§ø‡§®‡•ç‡§õ‡•§[‡•®‡•¨] ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§§‡•Ä‡§® ‡§≠‡§æ‡§ó‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç‡•§ ‡§ï‡•Å‡§®‡•à ‡§™‡§®‡§ø ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§≤‡•á ‡§≠‡•ç‡§∞‡§Æ‡§£ ‡§ó‡§∞‡•ç‡§®‡•á ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§¨‡§æ‡§ü ‡§Ü‡§Å‡§ï‡§°‡§æ ‡§∏‡§ô‡•ç‡§ï‡§≤‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ ‡§∞ ‡§Ø‡§∏‡§ï‡•ã ‡§∏‡§ô‡•ç‡§ó‡•ç‡§∞‡§π ‡§â‡§™‡§ï‡§∞‡§£‡§≤‡•á ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§Ü‡§´‡•ç‡§®‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ô‡•ç‡§ï‡§≤‡§® ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§∞‡•ç‡§§‡§π‡§∞‡•Ç ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡•Ç‡§ö‡§ï‡§æ‡§ô‡•ç‡§ï ‡§Ø‡§§‡§æ‡§µ‡§§ ‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∂‡•Ä‡§≤ ‡§∞‡§æ‡§ñ‡•á‡§ï‡•ã ‡§π‡•Å‡§®‡•ç‡§õ‡•§[‡•®‡•≠] ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç‡§≤‡•á ‡§ß‡•á‡§∞‡•à ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü‡§π‡§∞‡•Ç‡§ï‡•ã ‡§¨‡§æ‡§∞‡•á‡§Æ‡§æ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§ô‡•ç‡§ï‡§≤‡§® ‡§ó‡§∞‡•á‡§∞ ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•ç‡§¶‡§õ ‡§ú‡§∏‡§≤‡§æ‡§à ‡§∏‡•á‡§µ‡§æ‡§≤‡•á ‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡•ç‡§Ø‡§æ‡§™‡•Ä ‡§µ‡•á‡§¨‡§Æ‡§æ ‡§´‡•á‡§≤‡§æ ‡§™‡§æ‡§∞‡•ç‡§¶‡§õ‡•§ ‡§Ø‡•Ä ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§è‡§ï ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§â‡§™‡§ï‡§∞‡§£‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§ô‡•ç‡§ï‡§≤‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•Å‡§®‡•ç‡§õ ‡§∞ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§™‡§∞‡•á‡§ï‡•ã ‡§ñ‡§£‡•ç‡§°‡§Æ‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§™‡•É‡§∑‡•ç‡§†‡§ï‡•ã ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡§£‡§ø‡§ï‡§æ ‡§µ‡§ø‡§ß‡§ø ‡§™‡§π‡§ø‡§ö‡§æ‡§® ‡§ó‡§∞‡•ç‡§® ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ó‡§∞‡§ø‡§®‡•ç‡§õ‡•§[‡•®‡•Æ][‡•®‡•Ø] ‡§µ‡•á‡§¨ ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç‡§ï‡§æ ‡§¨‡§æ‡§∞‡•á‡§Æ‡§æ ‡§§‡§•‡•ç‡§Ø‡§æ‡§ô‡•ç‡§ï‡§π‡§∞‡•Ç ‡§Ü‡§Å‡§ï‡§°‡§æ ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡§£‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§≠‡§£‡•ç‡§°‡§æ‡§∞‡§£ ‡§ó‡§∞‡§ø‡§®‡•ç‡§õ‡•§‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§≤‡•á ‡§∏‡•á‡§µ‡§æ‡§ï‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•Ä ‡§ñ‡•ã‡§ú ‡§ó‡§∞‡•ç‡§¶‡§æ (‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§Ø‡§æ ‡§ï‡•Å‡§û‡•ç‡§ú‡•Ä ‡§∂‡§¨‡•ç‡§¶‡§π‡§∞‡•Ç‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞), ‡§ñ‡•ã‡§ú‡•Ä ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§≤‡•á ‡§Ø‡§∏‡§ï‡•ã ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ‡§£‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§õ‡§æ‡§®‡§¨‡§ø‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ ‡§∞ ‡§Æ‡§æ‡§™‡§¶‡§£‡•ç‡§°‡§ï‡•ã ‡§∏‡§æ‡§• ‡§â‡§§‡•ç‡§§‡§Æ ‡§®‡§ú‡§ø‡§§‡§æ‡§π‡§∞‡•Ç ‡§∏‡§æ‡§• ‡§µ‡•á‡§¨ ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç‡§ï‡•ã ‡§∏‡•Ç‡§ö‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ ‡§ú‡§∏‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§Ø‡§æ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä, ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞, ‡§®‡§ï‡•ç‡§∏‡§æ, ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§§‡•ç‡§§‡§∞, ‡§ï‡§æ‡§ó‡§ú‡§æ‡§§, ‡§∂‡•ç‡§∞‡§µ‡•ç‡§Ø ‡§¶‡•É‡§∂‡•ç‡§Ø ‡§Ü‡§¶‡§ø ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§π‡•Å‡§®‡•ç‡§õ‡•§ [‡•©‡•¶] ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§∏‡§ô‡•ç‡§ó‡§ø‡§ï‡§§‡§æ‡§Æ‡§æ ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞ ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§ ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç‡§≤‡•á ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§§‡§•‡§æ ‡§â‡§§‡•ç‡§§‡§Æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§¶‡•á‡§ñ‡§æ‡§â‡§®‡•á ‡§ó‡§∞‡•ç‡§¶‡§õ‡§®‡•ç ‡§∞ ‡§ï‡•Å‡§®‡•à ‡§ï‡•Å‡§®‡•à ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç‡§≤‡•á ‡§Ö‡§∂‡•ç‡§≤‡•Ä‡§≤ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡§¶‡•à‡§®‡§®‡•ç‡•§[‡•©‡•ß] ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç‡§≤‡•á ‡§Æ‡§æ‡§®‡§µ ‡§ú‡•ç‡§û‡§æ‡§® ‡§∞ ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Æ‡§æ ‡§ú‡•ã‡§° ‡§¶‡§ø‡§®‡•á ‡§ó‡§∞‡•á‡§ï‡§æ ‡§õ‡§®‡•ç‡•§ ‡§∏‡•á‡§™‡•ç‡§ü‡•á‡§Æ‡•ç‡§¨‡§∞ ‡•®‡•¶‡•ß‡•Ø ‡§Æ‡§æ, ‡§ó‡•Å‡§ó‡§≤ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡•ã ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§•‡§ø‡§Ø‡•ã ‡§ú‡§∏‡§≤‡•á ‡§ï‡•Å‡§≤ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡•Ø‡•®.‡•Ø‡•¨% ‡§¨‡§ú‡§æ‡§∞ ‡§∏‡§æ‡§ù‡•á‡§¶‡§æ‡§∞‡•Ä ‡§ó‡§∞‡•á‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§[‡•©‡•®] ‡§∞‡•Ç‡§∏‡§Æ‡§æ ‡§Ø‡§æ‡§®‡•ç‡§¶‡§ø‡§ï‡•ç‡§∏‡§ï‡•ã ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ‡•§ ‡§Ø‡§∏‡§≤‡•á ‡§π‡§æ‡§≤ ‡§ï‡•Å‡§≤ ‡§¨‡§ú‡§æ‡§∞ ‡§∏‡§æ‡§ù‡•á‡§¶‡§æ‡§∞‡•Ä‡§ï‡•ã ‡•¨‡•ß.‡•Ø% ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡§≠‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§™‡§∞‡•ç‡§ß‡•Ä ‡§ó‡•Å‡§ó‡§≤‡§≤‡•á ‡§ú‡§Æ‡•ç‡§Æ‡§æ ‡•®‡•Æ.‡•©% ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ‡•§[‡•©‡•©] ‡§ö‡•Ä‡§®‡§ï‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ, ‡§¨‡§æ‡§Ø‡§¶‡•Å ‡§§‡•ç‡§Ø‡§π‡§æ‡§Å‡§ï‡•ã ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§π‡•ã ‡§ú‡§∏‡§≤‡•á ‡•≠‡•®% ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ‡•§[‡•©‡•™][‡•©‡•´] ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§ï‡•ã‡§∞‡§ø‡§Ø‡§æ‡§ï‡•ã ‡§≠‡§®‡•á ‡§®‡§æ‡§≠‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§õ ‡§ú‡§∏‡§≤‡•á ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡•≠‡•¶% ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§[‡•©‡•¨] ‡§ú‡§æ‡§™‡§æ‡§® ‡§∞ ‡§§‡§æ‡§á‡§µ‡§æ‡§®‡§Æ‡§æ ‡§ï‡•ç‡§∞‡§Æ‡§∂: ‡§Ø‡§æ‡§π‡•Å! ‡§ú‡§æ‡§™‡§æ‡§® ‡§∞ ‡§Ø‡§æ‡§π‡•Å! ‡§§‡§æ‡§á‡§µ‡§® ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§õ‡§®‡•ç‡•§ ‡§ö‡•Ä‡§® ‡§∞ ‡§∞‡•Ç‡§∏ ‡§Ø‡§∏‡•ç‡§§‡§æ ‡§¶‡•á‡§∂‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç ‡§ú‡§∏‡§Æ‡§æ ‡§∂‡•Ä‡§∞‡•ç‡§∑ ‡•© ‡§≠‡§ø‡§§‡•ç‡§∞ ‡§ó‡•Å‡§ó‡§≤ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ‡•à‡§®‡•§\n[‡•©‡•≠] ‡§Ø‡•Å‡§∞‡•ã‡§™‡§ï‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§¶‡•á‡§∂‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§ó‡•Å‡§ó‡§≤‡§ï‡•ã ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§∞‡§π‡•á‡§§‡§æ ‡§™‡§®‡§ø ‡§ö‡•á‡§ï ‡§ó‡§£‡§§‡§®‡•ç‡§§‡•ç‡§∞‡§Æ‡§æ ‡§∏‡•á‡§ú‡•ç‡§®‡§æ‡§Æ ‡§Ø‡§∏‡§ï‡•ã ‡§ï‡§°‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§™‡§∞‡•ç‡§ß‡•Ä ‡§π‡•ã‡•§ [‡•©‡•Æ] ‡§π‡§æ‡§≤‡§ï‡•ã ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§ï‡•ã ‡§ó‡•ã‡§™‡§®‡§ø‡§Ø‡§§‡§æ‡§≤‡§æ‡§à ‡§Æ‡§ß‡•ç‡§Ø‡§®‡§ú‡§∞ ‡§ó‡§∞‡•ç‡§®‡•á ‡§∞ ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡•ç‡§®‡•á ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§°‡§ï‡§°‡§ï‡§ó‡•ã[‡•™‡•¶], ‡§Æ‡•ã‡§ú‡§ø‡§ï[‡•™‡•ß] ‡§∞ ‡§∏‡•ç‡§ü‡§æ‡§∞‡•ç‡§ü‡§™‡•á‡§ú‡§≤‡§æ‡§à[‡•™‡•®][‡•™‡•©][‡•™‡•™] ‡§≤‡§ø‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ‡•§ ‡§µ‡•á‡§¨ ‡§ñ‡•ã‡§ú ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞ ‡§ï‡§∞‡•ç‡§≤‡•Ä‡§Æ‡§æ"
  },
  {
    "url": "https://ja.wikipedia.org/wiki/%E6%A4%9C%E7%B4%A2%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%B3",
    "title": "Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥ - Wikipedia",
    "content": "Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥Ôºà„Åë„Çì„Åï„Åè„Ç®„É≥„Ç∏„É≥„ÄÅËã±: search engineÔºâ„ÅØ„ÄÅÁã≠Áæ©„Å´„ÅØ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Å´Â≠òÂú®„Åô„ÇãÊÉÖÂ†±Ôºà„Ç¶„Çß„Éñ„Éö„Éº„Ç∏„ÄÅ„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÄÅÁîªÂÉè„Éï„Ç°„Ç§„É´„ÄÅ„Éç„ÉÉ„Éà„Éã„É•„Éº„Çπ„Å™„Å©Ôºâ„ÇíÊ§úÁ¥¢„Åô„ÇãÊ©üËÉΩ„Åä„Çà„Å≥„Åù„ÅÆ„Éó„É≠„Ç∞„É©„É†„ÄÇ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÅÆÊôÆÂèäÂàùÊúü„Å´„ÅØ„ÄÅÊ§úÁ¥¢„Å®„Åó„Å¶„ÅÆÊ©üËÉΩ„ÅÆ„Åø„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åü„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„Åù„ÅÆ„ÇÇ„ÅÆ„ÇíÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å®Âëº„Çì„Å†„Åå„ÄÅÁèæÂú®„Åß„ÅØÊßò„ÄÖ„Å™„Çµ„Éº„Éì„Çπ„ÅåÂä†„Çè„Å£„Åü„Éù„Éº„Çø„É´„Çµ„Ç§„ÉàÂåñ„ÅåÈÄ≤„Çì„Å†„Åü„ÇÅ„ÄÅÊ§úÁ¥¢„Çí„Çµ„Éº„Éì„Çπ„ÅÆ‰∏Ä„Å§„Å®„Åó„Å¶Êèê‰æõ„Åô„Çã„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÇíÂçò„Å´Ê§úÁ¥¢„Çµ„Ç§„Éà„Å®Âëº„Å∂„Åì„Å®„ÅØ„Å™„Åè„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇÂ∫ÉÁæ©„Å´„ÅØ„ÄÅ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Å´ÈôêÂÆö„Åõ„ÅöÊÉÖÂ†±„ÇíÊ§úÁ¥¢„Åô„Çã„Ç∑„Çπ„ÉÜ„É†ÂÖ®Ëà¨„ÇíÂê´„ÇÄ„ÄÇ Áã≠Áæ©„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅØ„ÄÅ„É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÄÅ„Éá„Ç£„É¨„ÇØ„Éà„É™ÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÄÅ„É°„ÇøÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å™„Å©„Å´ÂàÜÈ°û„Åï„Çå„Çã„ÄÇÂ∫ÉÁæ©„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å®„Åó„Å¶„ÅØ„ÄÅ„ÅÇ„ÇãÁâπÂÆö„ÅÆ„Ç¶„Çß„Éñ„Çµ„Ç§„ÉàÂÜÖ„Å´ÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Çã„ÉÜ„Ç≠„Çπ„ÉàÊÉÖÂ†±„ÅÆÂÖ®ÊñáÊ§úÁ¥¢Ê©üËÉΩ„ÇíÂÇô„Åà„Åü„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢ÔºàÂÖ®ÊñáÊ§úÁ¥¢„Ç∑„Çπ„ÉÜ„É†ÔºâÁ≠â„Åå„ÅÇ„Çã„ÄÇ Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅØ„ÄÅÊ§úÁ¥¢Á™ì„Å®Âëº„Å∞„Çå„Çã„ÉÜ„Ç≠„Çπ„Éà„Éú„ÉÉ„ÇØ„Çπ„Å´„Ç≠„Éº„ÉØ„Éº„Éâ„ÇíÂÖ•Âäõ„Åó„Å¶Ê§úÁ¥¢„Çí„Åã„Åë„Çã„ÇÇ„ÅÆ„Åß„ÄÅÂÖ®ÊñáÊ§úÁ¥¢„ÅåÂèØËÉΩ„Å™„ÇÇ„ÅÆ„Å®‰∏çÂèØËÉΩ„Å™„ÇÇ„ÅÆ„Å®„Åå„ÅÇ„Çã„ÄÇÊ§úÁ¥¢„Çµ„Ç§„Éà„Çí‰∏ÄËà¨„Å´„ÄåÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Äç„Å®Âëº„Å∂„Åì„Å®„ÅØ„ÅÇ„Çã„Åå„ÄÅÂé≥ÂØÜ„Å´„ÅØÊ§úÁ¥¢„Çµ„Ç§„ÉàËá™‰Ωì„ÅØÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åß„Å™„ÅÑ„ÄÇ ‰∏é„Åà„Çâ„Çå„ÅüÊ§úÁ¥¢Âºè„Å´Âæì„Å£„Å¶„ÄÅ„Ç¶„Çß„Éñ„Éö„Éº„Ç∏Á≠â„ÇíÊ§úÁ¥¢„Åô„Çã„Çµ„Éº„Éê„ÄÅ„Ç∑„Çπ„ÉÜ„É†„ÅÆ„Åì„Å®„ÄÇÊ§úÁ¥¢Âºè„ÅØ„ÄÅÊúÄ„ÇÇÂçòÁ¥î„Å™Â†¥Âêà„ÅØ„Ç≠„Éº„ÉØ„Éº„Éâ„Å®„Å™„ÇãÊñáÂ≠óÂàó„ÅÆ„Åø„Åß„ÅÇ„Çã„Åå„ÄÅË§áÊï∞„ÅÆ„Ç≠„Éº„ÉØ„Éº„Éâ„Å´ANDÔºà„Äå„Åã„Å§„Äç„ÄÅË´ñÁêÜÁ©çÔºâ„ÇÑORÔºà„Äå„Åæ„Åü„ÅØ„Äç„ÄÅË´ñÁêÜÂíåÔºâÁ≠â„ÅÆË´ñÁêÜÊù°‰ª∂„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Å¶ÊåáÂÆö„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÇÇ„ÅÆ„ÅåÂ§ö„ÅÑ„ÄÇ „É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂ§ß„Åç„Å™ÁâπÂæ¥„ÅÆ‰∏Ä„Å§„Å®„Åó„Å¶„ÄÅ„ÇØ„É≠„Éº„É©Ôºà„É≠„Éú„ÉÉ„Éà„Éª„Çπ„Éë„Ç§„ÉÄ„ÉºÔºâ„ÇíÁî®„ÅÑ„Çã„Åì„Å®„ÅåÊåô„Åí„Çâ„Çå„Çã„ÄÇ„Åì„ÅÆ„Åì„Å®„Å´„Çà„Çä„ÄÅWWW‰∏ä„Å´„ÅÇ„ÇãÂ§öÊï∞„ÅÆÊÉÖÂ†±„ÇíÂäπÁéá„Çà„ÅèÂèéÈõÜÔºàÊó•Êú¨„ÅÆËëó‰ΩúÊ®©Ê≥ï„Åß„ÅØË§áË£ΩÔºâ„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÄÇÂ§ßË¶èÊ®°„Å™Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åß„ÅØ„ÄÅ80ÂÑÑ„Éö„Éº„Ç∏‰ª•‰∏ä„ÅÆ„Éö„Éº„Ç∏„Åã„ÇâÊ§úÁ¥¢„ÅåÂèØËÉΩ„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇ ÂèéÈõÜ„Åó„Åü„Éö„Éº„Ç∏„ÅÆÊÉÖÂ†±„ÅØ„ÄÅÂâç„ÇÇ„Å£„Å¶Ëß£Êûê„Åó„ÄÅÁ¥¢ÂºïÊÉÖÂ†±Ôºà„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºâ„Çí‰ΩúÊàê„Åô„ÇãÔºàÊó•Êú¨„ÅÆËëó‰ΩúÊ®©Ê≥ï„Åß„ÅØÁ∑®ÈõÜÔºâ„ÄÇÊó•Êú¨Ë™û„Å™„Å©„ÅÆË®ÄË™û„Åß„ÅØ„ÄÅËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜÊ©üËÉΩ„ÅåÁîüÊàê„Åï„Çå„ÇãÁ¥¢Âºï„ÅÆË≥™„Å´ÂΩ±Èüø„Åô„Çã„ÄÇ„Åì„ÅÆ„Åü„ÇÅ„ÄÅÂ§öË®ÄË™ûÂØæÂøú„Åó„ÅüÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÊñπ„ÅåÁ≤æÂ∫¶„ÅÆÈ´ò„ÅÑÊ§úÁ¥¢„ÅåÂèØËÉΩ„Å®„Å™„Çã„ÄÇ Ê§úÁ¥¢ÁµêÊûú„ÅÆË°®Á§∫È†Ü„ÅØ„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆË≥™„ÅåÊúÄ„ÇÇÂïè„Çè„Çå„ÇãÈÉ®ÂàÜ„Åß„ÅÇ„Çã„ÄÇ„É¶„Éº„Ç∂„Éº„ÅåÊúüÂæÖ„Åó„Åü„Éö„Éº„Ç∏„ÇíÊ§úÁ¥¢ÁµêÊûú„ÅÆ‰∏ä‰Ωç„Å´Ë°®Á§∫„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Å™„Åë„Çå„Å∞„ÄÅ„É¶„Éº„Ç∂„Éº„ÅåÈõ¢„Çå„Å¶„Åó„Åæ„ÅÜ„Åã„Çâ„Åß„ÅÇ„Çã„ÄÇ„Åù„ÅÆ„Åü„ÇÅ„ÄÅÂ§ö„Åè„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åå„ÄÅË°®Á§∫È†Ü„ÇíÊ±∫ÂÆö„Åô„Çã„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÇíÈùûÂÖ¨Èñã„Å´„Åó„ÄÅ„Åù„ÅÆÊÄßËÉΩ„ÇíÁ´∂„Å£„Å¶„ÅÑ„Çã„ÄÇÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥ÊúÄÈÅ©ÂåñÊ•≠ËÄÖ„ÅÆÂ≠òÂú®„ÇÇ„ÄÅ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÇíÂÖ¨Èñã„Åó„Å™„ÅÑË¶ÅÂõ†„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇGoogle„ÅØ„ÄÅ„Åù„ÅÆ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÅÆ‰∏ÄÈÉ®„Åß„ÅÇ„Çã„Éö„Éº„Ç∏„É©„É≥„ÇØ„ÇíÂÖ¨Èñã„Åó„Å¶„Åç„Åü„Åå„ÄÅ„ÇÑ„ÅØ„Çä„ÄÅÂ§ö„Åè„ÅÆÈÉ®ÂàÜ„ÅåÈùûÂÖ¨Èñã„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇGoogle„ÅÆÂ†¥Âêà„ÄÅÂâµË®≠ÂàùÊúü„Å´„Åä„Åë„Çã„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅÂâµË®≠ËÄÖËá™Ë∫´„Åå„Ç¶„Çß„Éñ‰∏ä„ÅßÂÖ¨Ë°®„Åó„Å¶„ÅÑ„ÇãË´ñÊñá„Åß„Åù„ÅÆ‰∏ÄÁ´Ø„ÇíÁü•„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÄÇ\nÂèÇÁÖß Ëã±Ë™ûÂéüÊñá[1] Êó•Êú¨Ë™û„ÅÆËß£Ë™¨[2] „Ç¶„Çß„Éñ„Éö„Éº„Ç∏„ÅÆÊõ¥Êñ∞ÊôÇÂàª„ÅÆÊÉÖÂ†±„ÇíÁî®„ÅÑ„Å¶„ÄÅÊñ∞„Åó„ÅÑÊÉÖÂ†±„Å´ÈôêÂÆö„Åó„Å¶Ê§úÁ¥¢„Åß„Åç„Çã„ÇÇ„ÅÆ„ÇÑ„ÄÅÊ§úÁ¥¢ÁµêÊûú„Çí„Ç´„ÉÜ„Ç¥„É™Âåñ„Åó„Å¶Ë°®Á§∫„Åô„Çã„ÇÇ„ÅÆ„Å™„Å©„ÄÅÁâπÈï∑„ÅÆ„ÅÇ„ÇãÊ©üËÉΩ„ÇíÊê≠Ëºâ„Åó„Åü„Çä„ÄÅÊ§úÁ¥¢ÁµêÊûú„Çí„É¶„Éº„Ç∂„Éº„Å∏ÊúÄÈÅ©Âåñ„Åó„Å¶„ÅÑ„ÅèÂãï„Åç„ÇÇ„ÅÇ„Çã„ÄÇ ÂæìÊù•„ÅÆ„Ç¶„Çß„Éñ„Éö„Éº„Ç∏„ÇíÊ§úÁ¥¢„Åô„Çã„Å†„Åë„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å´„Å®„Å©„Åæ„Çâ„Åö„ÄÅÊúÄËøë„Åß„ÅØ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞Â∞ÇÁî®„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å™„Å©„ÄÅÁâπÂÆö„ÅÆÂàÜÈáé„Å´ÁâπÂåñ„Åó„ÅüÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÈñãÁô∫„ÇÇÊï£Ë¶ã„Åï„Çå„Çã„ÄÇÂïÜÂìÅÊ§úÁ¥¢„Åß„ÅØ„ÄÅ‰æ°Ê†ºÊØîËºÉ„Çµ„Éº„Éì„ÇπÊó•Êú¨ÊúÄÂ§ßÊâã„ÅÆ‰æ°Ê†º.com„ÇÑ„ÄÅ„Éô„É≥„ÉÅ„É£„Éº‰ºÅÊ•≠„ÅåÈñãÁô∫„Åô„ÇãQOOPIE„Å™„Å©„ÅÇ„Çã„ÄÇ„Åæ„Åü„ÄÅËÅ∑Ê•≠Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å®„Åó„Å¶„ÅØCraigslist„Å™„Å©„Åå„ÅÇ„Çã„ÄÇ\nGoogle„ÄÅYahoo!„ÄÅÂçÉÈáåÁúºÔºàÁµÇ‰∫ÜÔºâ„ÄÅ„Ç§„É≥„Éï„Ç©„Ç∑„Éº„ÇØ„ÄÅ„ÉÜ„ÇØ„Éé„É©„ÉÜ„Ç£„ÄÅMARSFLAG„ÄÅAltavista„ÄÅ„É†„Éº„Çø„Éº„ÄÅAlltheWeb„ÄÅTeomaÔºàËã±Ë™ûÁâàÔºâÔºàÁµÇ‰∫ÜÔºâ„ÄÅWiseNutÔºàËã±Ë™ûÁâàÔºâ„ÄÅInktomiÔºàÁµÇ‰∫ÜÔºâ„ÄÅSAGOOL„ÄÅYahoo! JAPAN (2005.10„Äú2010.11[Ë¶ÅÂá∫ÂÖ∏]) „Å™„Å©„ÄÇ ‰∫∫Êâã„ÅßÊßãÁØâ„Åó„Åü„Ç¶„Çß„Éñ„Éá„Ç£„É¨„ÇØ„Éà„É™ÂÜÖ„ÇíÊ§úÁ¥¢„Åô„Çã„Çµ„Éº„Éê„ÄÅ„Ç∑„Çπ„ÉÜ„É†„ÅÆ„Åì„Å®„ÄÇ ‰∫∫Êâã„ÅßÊßãÁØâ„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅË≥™„ÅÆÈ´ò„ÅÑ„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÇíÊ§úÁ¥¢ÂèØËÉΩ„ÄÇÊ¶ÇË¶Å„Çí‰∫∫Êâã„ÅßË®òÂÖ•„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÊ§úÁ¥¢ÁµêÊûú„ÅÆ‰∏ÄË¶ß„Åã„ÇâÁõÆÁöÑ„ÅÆ„Çµ„Ç§„Éà„ÇíÊé¢„Åó„ÇÑ„Åô„ÅÑ„ÄÅ„Çµ„Ç§„Éà„ÅÆ„Ç´„ÉÜ„Ç¥„É™ÂàÜ„Åë„Åå„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®„Åã„Çâ„ÄÅÁâπÂÆöÂàÜÈáé„ÇÑÂú∞Âå∫„Å™„Å©„Å´ÈôêÂÆö„Åó„Åü„Çµ„Ç§„Éà„ÇíÊé¢„Åó„ÇÑ„Åô„ÅÑ„Å®„ÅÑ„ÅÜÁâπÈï∑„Åå„ÅÇ„Çã„ÄÇ „Åó„Åã„Åó„ÄÅÊ§úÁ¥¢ÂØæË±°„Å®„Å™„Çã„Çµ„Ç§„Éà„ÅØ‰∫∫Êâã„ÅßÂÖ•Âäõ„Åô„Çã„Åü„ÇÅ„ÄÅÊ§úÁ¥¢ÂØæË±°„Å®„Å™„Çã„Çµ„Ç§„ÉàÊï∞„ÅåÂ§ö„Åè„Åß„Åç„Å™„ÅÑ„Å®„ÅÑ„ÅÜÊ¨†ÁÇπ„Åå„ÅÇ„Çã„ÄÇ „Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Åå‰∏ÄËà¨„Å´‰Ωø„Çè„Çå„Çã„Çà„ÅÜ„Å´„Å™„Å£„ÅüÂàùÊúüÔºà1990Âπ¥‰ª£Ôºâ„ÅÆ„Åì„Çç„Å´„ÅØ„ÄÅ„Éá„Ç£„É¨„ÇØ„Éà„É™Âûã„Åå‰∏ª‰Ωì„Åß„ÅÇ„Å£„Åü„Åå„ÄÅWWW„ÅÆÁàÜÁô∫ÁöÑ„Å™Êã°Â§ß„Å´„Çà„Å£„Å¶„ÄÅ„ÅÇ„Çâ„ÇÜ„Çã„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÇíÂç≥ÊôÇ„Å´„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´ÂèçÊò†„Åï„Åõ„Çã„Åì„Å®„Åå‰∫ãÂÆü‰∏ä‰∏çÂèØËÉΩ„Å´„Å™„Çä„ÄÅÁèæÂú®„Åß„ÅØ‰∏ªÊµÅ„Åß„ÅØ„Å™„Åè„Å™„Å£„Å¶„ÅÑ„Çã[„ÅÑ„Å§?]„ÄÇ\n„Åì„ÅÆ„Åü„ÇÅ„ÄÅ„Éá„Ç£„É¨„ÇØ„Éà„É™ÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åß„ÅØ„ÄÅÊ§úÁ¥¢„Å´„Éí„ÉÉ„Éà„Åô„Çã„Çµ„Ç§„Éà„ÅåÁÑ°„Åã„Å£„ÅüÂ†¥Âêà„ÄÅ„É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÇíÁî®„ÅÑ„Å¶ÁµêÊûú„ÇíË°®Á§∫„Åô„Çã„Çà„ÅÜ„Å™„ÄÅ‰ΩµÁî®Âûã„ÅÆ„ÇÇ„ÅÆ„ÅåÂ§ö„ÅÑ[„ÅÑ„Å§?]„ÄÇ Êó•Á´ãÂõΩÈöõ„Éì„Ç∏„Éç„Çπ„ÅÆHole-in-OneÔºà - 2004Âπ¥11ÊúàÔºâ„ÄÅYahoo!JAPAN„ÅÆYahoo!„Ç´„ÉÜ„Ç¥„É™Ôºà - 2018Âπ¥3Êúà[3]Ôºâ„ÄÅLookSmart JapanÔºà - 2006Âπ¥6Êúà[4]Ôºâ„ÄÅgoo„ÅÆgoo„Ç´„ÉÜ„Ç¥„É™„ÉºÊ§úÁ¥¢Ôºà - 2019Âπ¥8Êúà[5]Ôºâ„ÄÅOpen Directory Project„Åì„Å®DMOZÔºà - 2017Âπ¥3ÊúàÔºâ„Å™„Å©„ÄÇ P2PÈÄö‰ø°„Å´„Çà„Å£„Å¶„Ç¶„Çß„Éñ„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÇíÂ§öÊï∞„ÅÆ„Éî„Ç¢„Å´ÂàÜÊï£„Åï„Åõ„ÄÅP2P„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂÖ®‰Ωì„ÅßÂêÑ„Éî„Ç¢„ÅÆÊåÅ„Å§„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÇíÂÖ±Êúâ„Åô„ÇãÊ§úÁ¥¢„Ç∑„Çπ„ÉÜ„É†„ÅÆ„Åì„Å®„ÄÇ „Ç¶„Çß„Éñ„ÅÆ„ÇØ„É≠„Éº„É´„ÅØÂêÑ„Éî„Ç¢„ÅåÁã¨Ëá™„Å´Ë°å„ÅÑ„ÄÅ„Ç§„É≥„Éá„ÇØ„Çµ„Éº„ÅØRWI(Reverse Word Index)„Çí‰ΩúÊàê„Åô„Çã„ÄÇ‰ΩúÊàê„Åï„Çå„Åü„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅÆ‰∏ÄÈÉ®„ÅØDHT(ÂàÜÊï£„Éè„ÉÉ„Ç∑„É•„ÉÜ„Éº„Éñ„É´„ÄÅDistributed Hash Table)„Å®„Åó„Å¶‰ªñ„ÅÆ„Éî„Ç¢„Å´ÂàÜÈÖç„Åï„Çå„Çã„ÄÇ Ê§úÁ¥¢„ÅØËá™ÂàÜ„ÅÆ„Éî„Ç¢„ÅÆÁ´ØÊú´„Åã„ÇâP2P„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ‰∏ä„Å´„ÅÇ„Çã‰ªñ„ÅÆ„Éî„Ç¢„Å´„É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°„Åô„Çã„Åì„Å®„Å´„Çà„ÇäË°å„ÅÜ„Åì„Å®„Åå„Åß„Åç„Çã„ÄÇ ÂàÜÊï£ÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆ‰æã„Å®„Åó„Å¶„ÅØYaCy„Åå„ÅÇ„Çã„ÄÇYaCy„ÅØ„Äå‰∫∫Ê∞ë„Å´„Çà„Çã‰∫∫Ê∞ë„ÅÆ„Åü„ÇÅ„ÅÆ„Ç¶„Çß„ÉñÊ§úÁ¥¢„Äç„ÇíÊ®ôÊ¶ú„Åó„ÄÅÂàÜÊï£Âûã„Åß„ÅÇ„Çã„Åì„Å®„Å´„Çà„ÇäÊ§úÈñ≤„ÇíÈò≤„Åê„Åì„Å®„Åå„Åß„Åç„Çã„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ[6] „Å≤„Å®„Å§„ÅÆÊ§úÁ¥¢„ÉØ„Éº„Éâ„ÇíË§áÊï∞„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅßÊ§úÁ¥¢„Åô„Çã„Åì„Å®„Çí„É°„ÇøÊ§úÁ¥¢„Å®„ÅÑ„ÅÜÔºàÊ®™Êñ≠Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å®Âëº„Å∂„Åì„Å®„ÇÇ„ÅÇ„ÇãÔºâ„ÄÇ\nË©≥Á¥∞„ÅØ„Äå„É°„ÇøÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Äç„ÇíÂèÇÁÖß„ÅÆ„Åì„Å®„ÄÇ ‰∏é„Åà„Çâ„Çå„ÅüÊñáÊõ∏Áæ§„Åã„Çâ„ÄÅÊ§úÁ¥¢ÂºèÔºà„Ç≠„Éº„ÉØ„Éº„Éâ„Å™„Å©Ôºâ„Å´„Çà„ÇãÂÖ®ÊñáÊ§úÁ¥¢Ê©üËÉΩ„ÇíÊèê‰æõ„Åô„Çã„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢„ÄÅ„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ∑èÁß∞„Åß„ÄÅ„Ç¶„Çß„Éñ„Çµ„Éº„Éê„Å´ÁµÑ„ÅøËæº„Çì„ÅßÂà©Áî®„Åï„Çå„Çã„Åì„Å®„ÅåÂ§ö„ÅÑ„ÄÇ„Çπ„Çø„É≥„Éâ„Ç¢„É≠„Éº„É≥Áí∞Â¢É„ÅßÁî®„ÅÑ„Çâ„Çå„ÇãÂÄã‰∫∫Áî®ÈÄî„ÅÆ„ÇÇ„ÅÆ„ÇÇ„ÅÇ„Çä„ÄÅ„Åù„ÅÜ„ÅÑ„Å£„Åü„ÇÇ„ÅÆ„ÅØÁâπ„Å´„Äå„Éá„Çπ„ÇØ„Éà„ÉÉ„ÉóÊ§úÁ¥¢„Äç„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„Çã„ÄÇ‰ºÅÊ•≠ÂÜÖ„ÅÆ„Éï„Ç°„Ç§„É´„Çµ„Éº„Éê„Éº„ÇÑ‰ºÅÊ•≠ÂÜÖ„Éù„Éº„Çø„É´„ÇíÂØæË±°„Å®„Åô„Çã„ÇÇ„ÅÆ„ÅØ„Äå„Ç®„É≥„Çø„Éº„Éó„É©„Ç§„Ç∫„Çµ„Éº„ÉÅ„Äç„Å®Âëº„Å∞„Çå„Çã„ÄÇ Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆ„ÅØ„Åó„Çä„ÅØ1994Âπ¥„Å´„Çπ„Çø„É≥„Éï„Ç©„Éº„ÉâÂ§ßÂ≠¶„ÅÆ„Ç∏„Çß„É™„Éº„Éª„É§„É≥„Å®„Éá„Éì„ÉÉ„Éâ„Éª„Éï„Ç°„Ç§„É≠„ÅåÈñãÁô∫„Åó„ÅüYahoo!„Åß„ÅÇ„Çã[7]„ÄÇYahoo!„ÅØ„Éá„Ç£„É¨„ÇØ„Éà„É™Âûã„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åß„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÅÆÊôÆÂèä„Å´Â§ß„Åç„Å™ÂΩπÂâ≤„ÇíÊûú„Åü„Åó„Åü[7]„ÄÇ „Åù„ÅÆÂæå„ÄÅ„Ç¶„Çß„Éñ‰∏ä„ÅÆÊÉÖÂ†±„ÇíËá™ÂãïÁöÑ„Å´Êé¢Á¥¢„Åó„Å¶ÊÉÖÂ†±„ÇíÁ¥¢Âºï„Å®„Åó„Å¶Êï¥ÁêÜ„Åô„Çã„É≠„Éú„ÉÉ„Éà„Åæ„Åü„ÅØ„ÇØ„É≠„Éº„É©„Å®Âëº„Å∞„Çå„Çã„Éó„É≠„Ç∞„É©„É†„ÅåÈñãÁô∫„Åï„Çå„Åü[7]„ÄÇ „É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆ‰∏≠„Åß„ÇÇ„É©„É™„Éº„Éª„Éö„Ç§„Ç∏„Å®„Çª„É´„Ç≤„Ç§„Éª„Éñ„É™„É≥„ÅåÈñãÁô∫„Åó„ÅüGoogleÊ§úÁ¥¢„ÅØÊ§úÁ¥¢ÁµêÊûú„ÅÆ„É©„É≥„Ç≠„É≥„Ç∞„Å®È´òÈÄüÊ§úÁ¥¢„Å´ÂÑ™„Çå„Å¶„ÅÑ„Åü„Åü„ÇÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆ„Éà„ÉÉ„Éó„Å´Ë∫ç„ÇäÂá∫„Åü[7]„ÄÇGoogle„Åå1998Âπ¥„Å´Á®ºÂãï„Åï„Åõ„ÅüGoogleÊ§úÁ¥¢„ÅØ„ÄÅÂæìÊù•„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åå„Éù„Éº„Çø„É´„Çµ„Ç§„ÉàÂåñ„Å∏„Å®ÈÄ≤„ÇÄÊµÅ„Çå„Å´ÈÄÜË°å„Åó„ÄÅÁã¨ÂâµÁöÑ„Å™Ê§úÁ¥¢ÊäÄË°ì„Å´ÁâπÂåñ„Åó„ÄÅ„Éê„Éä„ÉºÂ∫ÉÂëäÁ≠â„ÇíÊéíÈô§„Åó„Åü„Ç∑„É≥„Éó„É´„Å™ÁîªÈù¢„Å†„Å£„Åü„ÄÇ Google„ÅØ2000Âπ¥„Å´„ÅØÁ±≥Yahoo!„ÅÆ„É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å´Êé°Áî®„Åï„Çå„Åü„Åå„ÄÅGoogleË∫çÈÄ≤„Å´Âç±Ê©üÊÑü„ÇíÂãü„Çâ„Åõ„ÅüÁ±≥Yahoo!„ÅØ„ÄÅ2004Âπ¥„Å´„É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÇíÁã¨Ëá™ÊäÄË°ìYahoo! Search Technology (YST)ÔºàYahoo!„ÅåË≤∑Âèé„Åó„ÅüInktomi„Å®„ÄÅOverture„ÅåË≤∑Âèé„Åó„ÅüAltaVista„ÄÅAllthewebÁ≠â„ÅÆÊäÄË°ì„ÇíÁµ±Âêà„Åó„ÅüÔºâ„Å´Âàá„ÇäÊõø„Åà„Åü„ÄÇ 2009Âπ¥„Å´„ÅØ„Éû„Ç§„ÇØ„É≠„ÇΩ„Éï„Éà„ÅåÊñ∞„Åü„Å™Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å®„Åó„Å¶Bing„ÇíÁô∫Ë°®„Åó„Åü[7]„ÄÇ Ê§úÁ¥¢„Å®„ÅÑ„ÅÜË°åÁÇ∫„Åå‰∏ÄËà¨Âåñ„Åô„Çã„Å´„Å§„Çå„Å¶„ÄÅÂêÑÁ®ÆÁõÆÁöÑÂà•„Å´Â§öÊßòÂåñ„Åó„ÅüÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅåÁèæ„Çå„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÄÇ„Éñ„É≠„Ç∞„ÅÆÊÉÖÂ†±„Å´ÁâπÂåñ„Åó„ÅüÊ§úÁ¥¢Technorati„ÇÑblogWatcher„ÄÅÂïÜÂìÅÊÉÖÂ†±„ÅÆÊ§úÁ¥¢„Å´ÁâπÂåñ„Åó„ÅüÂïÜÂìÅÊ§úÁ¥¢„Çµ„Ç§„Éà„ÄÅ„Çµ„Ç§„Éà„ÅÆË¶ã„ÅüÁõÆ„ÅßÊ§úÁ¥¢„Åô„ÇãMARSFLAG„ÄÅÈü≥Ê•ΩÊ§úÁ¥¢„ÄÅÂãïÁîªÊ§úÁ¥¢„ÄÅ„Éï„Ç°„Ç§„É´Ê§úÁ¥¢„ÄÅ„Ç¢„ÉÉ„Éó„É≠„Éº„ÉÄÊ§úÁ¥¢„Åª„Åã„ÄÅÊ¨°„ÄÖ„Å®Êñ∞„Åó„ÅÑÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅåÁîü„Åæ„Çå„Å¶„ÅÑ„Çã„ÄÇ Êó•Êú¨„ÅÆ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„ÉàÊôÆÂèäÂàùÊúü„Åã„ÇâÂ≠òÂú®„Åó„ÅüÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å´„ÅØ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™„ÇÇ„ÅÆ„Åå„ÅÇ„Çã„ÄÇÈªéÊòéÊúü„Å´„ÅØ„ÄÅË±äÊ©ãÊäÄË°ìÁßëÂ≠¶Â§ßÂ≠¶„ÅÆÂ≠¶Áîü„Åå‰ΩúÊàê„Åó„ÅüYahho[8] „ÇÑ„ÄÅÊù±‰∫¨Â§ßÂ≠¶„ÅÆÂ≠¶Áîü„Åå‰ΩúÊàê„Åó„ÅüODiN„ÄÅÊó©Á®≤Áî∞Â§ßÂ≠¶„ÅÆÂ≠¶Áîü„Åå‰ΩúÊàê„Åó„ÅüÂçÉÈáåÁúº„Å™„Å©„ÄÅÂÄã‰∫∫„ÅÆÂ≠¶Áîü„Åå‰ΩúÊàê„Åó„Åü„ÇÇ„ÅÆ„ÅåÂïÜÁî®„Å´ÂØæ„Åó„Å¶ÂÖàË°å„Åó„Å¶„ÅÑ„ÅüÔºà„ÅÑ„Åö„Çå„ÇÇ1995Âπ¥„Å´‰ΩúÊàê„ÄÅÊó•Êú¨Èõª‰ø°ÈõªË©±Ê†™Âºè‰ºöÁ§æÔºàÁèæ„ÉªNTTÊ†™Âºè‰ºöÁ§æÔºâ„ÅÆNTT DIRCECTORY[9]„ÄÅ„Çµ„Ç§„Éê„Éº„Çπ„Éö„Éº„Çπ„Ç∏„É£„Éë„É≥ÔºàÁèæ„Éª„Ç¶„Çß„Éñ„Ç§„É≥„Éë„ÇØ„ÉàÔºâ„ÅÆCSJ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅØ1994Âπ¥„Å´‰ΩúÊàêÔºâ[10]„ÄÇ„Åì„Çå„Çâ„ÅØÂçò„Å´ÂÆüÈ®ìÁî®„Å´ÂÖ¨Èñã„Åï„Çå„Å¶„ÅÑ„Åü„Å†„Åë„Åß„Å™„Åè„ÄÅÂ§ö„Åè„ÅÆ‰∫∫„Å´Áî®„ÅÑ„Çâ„Çå„Å¶„ÅÑ„Åü„ÇÇ„ÅÆ„Åß„ÅÇ„Çä„ÄÅÈªéÊòéÊúü„ÅÆ„É¶„Éº„Ç∂„Å´„Å®„Å£„Å¶„ÅØÁü•ÂêçÂ∫¶„ÄÅÂÆüÁî®Â∫¶„Å®„ÇÇ„Å´È´ò„ÅÑ„ÇÇ„ÅÆ„Åß„ÅÇ„Å£„Åü„ÄÇ„Åæ„ÅüMondou„Å™„Å©„ÅÆ„Çà„ÅÜ„Å´Á†îÁ©∂ÂÆ§Ôºà‰∫¨ÈÉΩÂ§ßÂ≠¶Ôºâ„Åß‰ΩúÊàê„Åó„Åü„ÇÇ„ÅÆ„ÇÇ„ÅÇ„Å£„Åü„ÄÇ 1995Âπ¥12Êúà„Å´„ÇΩ„Éï„Éà„Éê„É≥„ÇØ„Åå„Ç¢„É°„É™„Ç´ÂêàË°ÜÂõΩYahoo!Ê†™„Çí‰∏ÄÈÉ®Ë≤∑„ÅÑÂèñ„Çä„ÄÅÁøåÂπ¥4Êúà„Åã„ÇâÊó•Êú¨Áâà„Å´„É≠„Éº„Ç´„É©„Ç§„Ç∫„Åó„ÅüYahoo! JAPAN„Çí„Çµ„Éº„Éì„ÇπÈñãÂßã„Åó„Åü„ÄÇÂêåÂπ¥7Êúà„ÅÆÂ±ïÁ§∫‰ºöInterop„Åß„ÅØÊú∫2„Å§„Å∂„Çì‰∏¶„Åπ„ÇãÁ®ãÂ∫¶„ÅÆÂ∞èË¶èÊ®°„Éñ„Éº„Çπ„ÅßÂá∫Â±ï„Åô„ÇãÁ®ãÂ∫¶„ÅÆÂäõ„ÅÆÂÖ•„ÇåÂÖ∑Âêà„Åß„ÄÅ„ÇΩ„Éï„Éà„Éê„É≥„ÇØ„ÅÆ‰∏ÄÈÉ®ÁΩ≤„Å®„Åó„Å¶ÈñãÂßã„Åô„ÇãÁ®ãÂ∫¶„Å†„Å£„Åü„ÇÇ„ÅÆ„Åå„ÄÅ„ÇÇ„Å®„ÇÇ„Å®„ÅÆÁ±≥ÂõΩYahoo!„ÅÆÁü•ÂêçÂ∫¶„ÄÅ90Âπ¥‰ª£ÂæåÂçä„ÅÆ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„ÉàÂà©Áî®ËÄÖ‰∫∫Âè£„ÅÆÂ¢óÂä†„ÄÅ„Éá„Ç£„É¨„ÇØ„Éà„É™Âûã„Å†„Åë„Å†„Å£„ÅüÊ§úÁ¥¢„Çí„É≠„Éú„ÉÉ„ÉàÂûã„ÇÇËøΩÂä†„ÄÅ„Çµ„Ç§„ÉàÁôªÈå≤„Åó„Åü‰∏ÄÈÉ®„ÅÆ„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÅÆÁ¥π‰ªã„Çí„Åô„ÇãYahoo! Internet GuideÔºà„ÇΩ„Éï„Éà„Éê„É≥„ÇØ„ÇØ„É™„Ç®„Ç§„ÉÜ„Ç£„ÉñÂá∫ÁâàÔºâ„Å®„ÅÆÈÄ£Êê∫„ÄÅÊó•Êú¨Yahoo!Ê†™È´òÈ®∞„ÅÆ„Éã„É•„Éº„Çπ„Åß„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÇíÂà©Áî®„Åó„Å™„ÅÑ‰∫∫„Å´„ÇÇÂêçÂâç„ÅåÁü•„ÇåÊ∏°„Çã„Å™„Å©„ÄÅÊßò„ÄÖ„Å™„Éó„É©„ÇπË¶ÅÂõ†„Å®ÁµåÂñ∂Êà¶Áï•„ÅåË¶ã‰∫ã„Å´ÂΩì„Åü„Çä„ÄÅÊ§úÁ¥¢„Çµ„Ç§„ÉàÈ¶ñ‰Ωç„ÅÆÂ∫ß„ÇíÂõ∫„ÇÅ„Åü„ÄÇ„Åù„Åó„Å¶„ÄÅÊ§úÁ¥¢„Çµ„Ç§„Éà„ÅÆÈõÜÂÆ¢Âäõ„ÇíÊ≠¶Âô®„Å´„Éã„É•„Éº„Çπ„ÄÅ„Ç™„Éº„ÇØ„Ç∑„Éß„É≥„Å™„Å©„ÄÅÊ§úÁ¥¢„Çµ„Éº„Éì„Çπ‰ª•Â§ñ„ÅÆ„Çµ„Éº„Éì„Çπ„ÇíÂê´„ÇÅ„Åü„Éù„Éº„Çø„É´„Çµ„Ç§„Éà„Å®„Åó„Å¶„ÅÆÁã¨Ëµ∞„ÇíÂßã„ÇÅ„Åü„ÄÇ 1997Âπ¥È†É„Åã„Çâ„ÄÅWWW„ÅÆÁàÜÁô∫ÁöÑ„Å™Êã°Â§ß„Å´‰º¥„Å£„Å¶„ÄÅ„Éá„Ç£„É¨„ÇØ„Éà„É™Âûã„ÅÆ„Åø„Åß„ÅÇ„Å£„ÅüYahoo!„ÅÆ„Ç¶„Çß„Éñ„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆÈô≥ËÖêÂåñ„ÅåÊÄ•ÈÄü„Å´ÈÄ≤„Çì„Å†„ÄÇ2000Âπ¥‰ª£„Å´„ÅØ„ÄÅÊó•Êú¨„Åß„ÇÇGoogle„Å´‰ª£Ë°®„Åï„Çå„Çã„É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åå‰∫∫Ê∞ó„ÇíÈõÜ„ÇÅÂßã„ÇÅ„ÄÅÂõΩÁî£„Åß„ÅØinfoseek„ÇÑgoo„ÅåÁôªÂ†¥ÔºàYahoo! JAPAN„Åå„É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å´goo„ÇíÊé°Áî®Ôºâ„ÄÅ2004Âπ¥„Å´„ÅØGoogle„ÇÑYahoo!„ÅÆ„Ç®„É≥„Ç∏„É≥„Å´ÂåπÊïµ„Åô„Çã„Å®Ë¨≥„ÅÜTeoma„ÇíÂà©Áî®„Åó„ÅüÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÄÅAsk JeevesÔºàÁèæ„ÉªAsk.comÔºâ„Åå„ÄåAsk.jp„Äç„Å®„Åó„Å¶Êó•Êú¨‰∏äÈô∏„ÄÅ2005Âπ¥„Å´„ÅØ„Ç™„Éº„Çπ„Éà„É©„É™„Ç¢„ÅßË™ïÁîü„Åó„ÅüMooter„ÅåÊó•Êú¨‰∏äÈô∏„Å™„Å©„ÄÅÁæ§ÈõÑÂâ≤Êã†„ÅÆÊôÇ‰ª£„Å´„Å™„Å£„Åü„ÄÇÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÇíÂà©Áî®„Åô„Çã„Åì„Å®Ôºù„Äå„Ç∞„Ç∞„Çã„Äç„Å®„ÅÑ„ÅÜ„Éç„ÉÉ„Éà„Çπ„É©„É≥„Ç∞„ÇÇÁîü„Åæ„Çå„Åü„ÄÇ „Åæ„Åü„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åß„ÅØÂà§Êñ≠„Åß„Åç„Å™„ÅÑÊäΩË±°ÁöÑ„Å™Êù°‰ª∂„Å™„Å©„Åß„ÅÆÊ§úÁ¥¢„Çí‰∫∫Êâã„Å´Ê±Ç„ÇÅ„Åü„ÄÅOKWave„ÇÑ‰∫∫ÂäõÊ§úÁ¥¢„ÅØ„Å¶„Å™„Å™„Å©„ÅÆ„Äå‰∫∫ÂäõÊ§úÁ¥¢„Äç„Äå„Éä„É¨„ÉÉ„Ç∏„Ç≥„Éü„É•„Éã„ÉÜ„Ç£„Äç„Å®Âëº„Å∞„Çå„Çã„Çµ„Éº„Éì„Çπ„ÇÇÁôªÂ†¥„Åó„Åü„ÄÇ „É¢„Éê„Ç§„É´Ê§úÁ¥¢„ÅÆÂàÜÈáé„ÅØÈï∑„Çâ„ÅèÂÖ¨Âºè„Çµ„Ç§„Éà„Å®Âëº„Å∞„Çå„Çã‰∏ñÁïå„Åå„É¶„Éº„Ç∂„Éº„ÅÆÂõ≤„ÅÑËæº„Åø„ÇíË°å„Å£„Å¶„ÅÑ„Åü„Åü„ÇÅ„ÄÅËÑöÂÖâ„ÇíÊµ¥„Å≥„Çã„Åì„Å®„ÅåÂ∞ë„Å™„Åã„Å£„Åü„ÄÇÊ¨°Á¨¨„Å´„Éë„ÇΩ„Ç≥„É≥„Å†„Åë„Åß„Å™„Åè„Éï„Ç£„Éº„ÉÅ„É£„Éº„Éï„Ç©„É≥„ÇÑÊê∫Â∏ØÂûã„Ç≤„Éº„É†Ê©ü„Åã„Çâ„ÇÇ„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÅåÊ§úÁ¥¢„Åï„Çå„ÇãÂÇæÂêë„ÅåÈ´ò„Åè„Å™„Çä„ÄÅGoogle„ÇÑYahoo!„Çí„ÅØ„Åò„ÇÅ„Å®„Åô„ÇãÊê∫Â∏ØÂêë„Åë„ÅÆ„É¢„Éê„Ç§„É´Ê§úÁ¥¢„Çµ„Ç§„Éà„ÅåÁôªÂ†¥„Åó„Åü„ÄÇ„ÇΩ„Éï„Éà„Éê„É≥„ÇØ„ÉªYahoo! JAPAN„Åå„Éú„Éº„ÉÄ„Éï„Ç©„É≥„ÇíË≤∑Âèé„Åó„ÄÅKDDI„ÅåGoogle„Å®ÊèêÊê∫„Åô„Çã„Å™„Å©„Åó„Åü„ÄÇ 2010Âπ¥„ÄÅYahoo! JAPAN„ÅåGoogle„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÇíÊé°Áî®„Åó„ÄÅÊó•Êú¨„Åß„ÇÇ‰∫ãÂÆü‰∏äGoogle„ÅåÂúßÂÄíÁöÑ„Å™„Ç∑„Çß„Ç¢„Çí‰øùÊúâ„Åô„Çã„Å´Ëá≥„Å£„Åü[11]„ÄÇ Google„Å™„Å©„ÅÆ„Ç¶„Çß„ÉñÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Åß„ÅØ„ÄÅ„Éá„Éº„Çø„Éô„Éº„Çπ„ÅÆÊ§úÁ¥¢ÁµêÊûú„Å™„Å©Â§ö„Åè„ÅÆÂãïÁöÑ„Éö„Éº„Ç∏„ÅåÊ§úÁ¥¢ÂØæË±°„Å´„Å™„Å£„Å¶„ÅÑ„Å™„ÅÑ„ÄÇ„Åì„ÅÆ„Çà„ÅÜ„Å™ÂãïÁöÑ„Éö„Éº„Ç∏„ÅØ„ÄåÊ∑±Â±§„Ç¶„Çß„Éñ„Äç„ÄåË¶ã„Åà„Å™„ÅÑ„Ç¶„Çß„Éñ„Äç„ÄåÈö†„Åï„Çå„Åü„Ç¶„Çß„Éñ„Äç„Å™„Å©„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„Çã„ÄÇÈùôÁöÑ„Éö„Éº„Ç∏„ÅÆ500ÂÄç„ÅÆÈáè„ÅåÂ≠òÂú®„Åó„ÄÅÂ§ö„Åè„ÅØÁÑ°Êñô„Å†„Å®„ÅÑ„Çè„Çå„Çã„ÄÇÊ∑±Â±§„Ç¶„Çß„Éñ„ÅØ„ÄÅ‰∏ÄËà¨„ÅÆÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å™„Å©„Åã„Çâ„Éá„Éº„Çø„Éô„Éº„Çπ„Å™„Å©„ÇíË¶ã„Å§„ÅëÂá∫„Åô„Åã„ÄÅÁõ¥Êé•„Ç¢„ÇØ„Çª„Çπ„Åó„Åü‰∏ä„Åß„ÄÅ„Åù„Çå„Åû„Çå„ÅÆÊ§úÁ¥¢Ê©üËÉΩ„Åã„ÇâÂÜçÂ∫¶Ê§úÁ¥¢„Åó„Å™„Åë„Çå„Å∞„Å™„Çâ„Å™„ÅÑ„ÄÇ„Åæ„Åü„ÄÅ„ÉÄ„Éº„ÇØ„Ç¶„Çß„Éñ„ÇíÊé¢Á¥¢„Åô„ÇãÈöõ„Å´‰Ωø„Çè„Çå„ÇãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥Ahmia„ÇÇÂ≠òÂú®„Åó„Å¶„ÅÑ„Çã„ÄÇ „É≠„Éú„ÉÉ„ÉàÂûãÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅØ„ÄÅ„Åù„ÅÆÂéüÁêÜ‰∏ä„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà‰∏ä„ÅÆ„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÇíË§áË£Ω„ÅÆ‰∏ä„Åß„ÄÅÊ§úÁ¥¢„ÇíÁõÆÁöÑ„Å®„Åó„ÅüËìÑÁ©ç„Å´ÈÅ©„Åó„ÅüÂΩ¢ÊÖã„Åß‰øùÂ≠ò„Åô„Çã‰ªñ„ÄÅÂ†¥Âêà„Å´„Çà„Å£„Å¶„ÅØ„Ç≠„É£„ÉÉ„Ç∑„É•„Å®„Åó„Å¶Êèê‰æõ„Åß„Åç„Çã„Çà„ÅÜ„Å™ÂΩ¢ÊÖã„Åß„ÇÇ‰øùÂ≠ò„Åô„ÇãÂ†¥Âêà„Åå„ÅÇ„Çã„ÄÇËëó‰ΩúÊ®©„Çí„Åü„Å¶„Å´„ÄÅ„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÅÆÈñ≤Ë¶ßÂà©Áî®Ë¶èÁ¥ÑÁ≠â„Å®Áß∞„Åó„Å¶„ÄÅ‰∏ÄÂàá„ÅÆ„ÅÑ„Åã„Å™„ÇãË§áË£Ω„ÇÇÁ¶Å„Åö„Çã„Å®„Åô„Çã„Çµ„Ç§„ÉàÁ≠â„Åå„ÅÇ„Çä„ÄÅ„Å©„ÅÜ„ÅÑ„Å£„Åü„ÇÇ„ÅÆ„Åã„Å®Âè§„Åè„Çà„ÇäË©±È°å„Å´„Å™„Å£„Å¶„ÅÑ„Åü[12]„ÄÇ „Åæ„Åü„ÄÅ2006Âπ¥11Êúà„Å´„ÅØ„ÄÅÊó•Êú¨„ÅÆÁü•ÁöÑË≤°Áî£Êà¶Áï•Êú¨ÈÉ®„Ç≥„É≥„ÉÜ„É≥„ÉÑÂ∞ÇÈñÄË™øÊüª‰ºöÁ¨¨3Âõû‰ºÅÁîªWG„Å´„Åä„ÅÑ„Å¶„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å´Èñ¢„Åó„Å¶„ÄåËëó‰ΩúÊ®©Ê≥ï‰∏ä„ÄÅË§áË£Ω„ÄÅÁ∑®ÈõÜ„Å´„ÅØÊ®©Âà©ËÄÖ„ÅÆË®±Ë´æ„ÅåÂøÖË¶Å„Åß„ÅÇ„Çä„ÄÅYahoo!„ÄÅGoogle„Å™„Å©Â§ßÊâãÊ§úÁ¥¢„Ç∑„Çπ„ÉÜ„É†„ÅÆ„Çµ„Éº„Éê„Éº„ÅØÊµ∑Â§ñ„Å´ÁΩÆ„Åã„Çå„Å¶„ÅÑ„Çã„ÅÆ„ÅåÁèæÁä∂„ÄÇ„Äç[13] „Å®Â†±Âëä„Åï„Çå„ÄÅ„Åì„Çå„Çí„ÅÜ„Åë„Å¶ÁµåÊ∏àÁî£Ê•≠ÁúÅ„ÅåÊó•Êú¨ÂõΩÂÜÖ„Åß„ÇÇÂêàÊ≥ïÁöÑ„Å´Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Çµ„Éº„Éì„Çπ„ÅåË°å„Åà„Çã„Çà„ÅÜ„Å´Ëëó‰ΩúÊ®©Ê≥ï„ÅÆÊîπÊ≠£„ÇÑÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÈñãÁô∫„Å´Âèñ„ÇäÁµÑ„ÇÄ„Å®Áô∫Ë°®„Åó[Ë¶ÅÂá∫ÂÖ∏]„ÄÅ2010Âπ¥1Êúà„ÅÆÊîπÊ≠£„ÅßË§áË£Ω„ÅåÂêàÊ≥ï„Å®„Åï„Çå„Åü„ÄÇ 2006Âπ¥È†É„Åã„ÇâÊó•Êú¨„Åß„ÅØURLÔºà„Ç¢„Éâ„É¨„ÇπÔºâ„ÇíË°®Á§∫„Åõ„Åö„ÄÅÁ§æÂêç„ÇÑÂïÜÂìÅÂêç„Å™„Å©„ÅÆÊ§úÁ¥¢„Ç≠„Éº„ÉØ„Éº„Éâ„ÇíË°®Á§∫„Åó„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅßÊ§úÁ¥¢„Åï„Åõ„Çã„Çà„ÅÜ„Å´‰ªïÂêë„Åë„Çã„ÉÜ„É¨„Éì„Ç≥„Éû„Éº„Ç∑„É£„É´„Å™„Å©„ÅÆÂ∫ÉÂëäË°®Áèæ„ÅåÊÄ•Â¢ó„Åó„Å¶„ÅÑ„Çã„ÄÇÂ§ßÊäµ„ÅØ„Ç≠„Éº„ÉØ„Éº„Éâ„ÅåÊõ∏„Åã„Çå„ÅüÁä∂ÊÖã„ÅÆÊ§úÁ¥¢„Éï„Ç©„Éº„É†„Å®„Éú„Çø„É≥„ÇíË°®Á§∫„Åó„ÄÅ„Éû„Ç¶„Çπ„ÇØ„É™„ÉÉ„ÇØ„Çí‰øÉ„ÅôÊºîÂá∫„Åå„Å™„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇ„Åì„ÅÆ„Çà„ÅÜ„Å™Â§âÂåñ„ÅåÁîü„Åò„ÅüÁêÜÁî±„ÅØ‰∏çÊòé„Åß„ÅÇ„Çã„Åå„ÄÅÂêÑ„É°„Éá„Ç£„Ç¢„ÅÆÂ∫ÉÂëäÊé≤ËºâÂü∫Ê∫ñ„ÅÆÂ§âÊõ¥„ÇÑ„ÄÅ„Ç≥„Éû„Éº„Ç∑„É£„É´„ÅßURL„ÇíË°®Á§∫„Åô„Çã„ÅÆ„Å´ÊØî„Åπ„Å¶„Ç¢„ÇØ„Çª„ÇπÊï∞„ÇíÁç≤Âæó„Åó„ÇÑ„Åô„ÅÑ„Åì„Å®„ÅåÂ¢óÂä†„ÅÆË¶ÅÂõ†„Åß„ÅÇ„Çã„ÄÇ„Åó„Åã„ÅóÊ§úÁ¥¢ÁµêÊûú„Å´‰ºÅÊ•≠„Å´„Å®„Å£„Å¶‰∏çÈÉΩÂêà„Å™ÊÉÖÂ†±„ÅåÁèæ„Çå„ÇãÂ†¥Âêà„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅ„Ç∞„Éº„Ç∞„É´ÂÖ´ÂàÜ„ÅÆ„Çà„ÅÜ„Å™Ê§úÁ¥¢ÁµêÊûú„ÅÆÊìç‰Ωú„ÅåË°å„Çè„Çå„Çã„Ç±„Éº„Çπ„ÇÇËÄÉ„Åà„Çâ„Çå„Çã„ÄÇ ÁèæÂú®„ÄÅ‰∏ªÊµÅ„Å®„Å™„Å£„Å¶„ÅÑ„ÇãÂ∫ÉÂëäÊâãÊ≥ï„Å®„Åó„Å¶„ÄÅ„É¶„Éº„Ç∂„Éº„ÅÆÊ§úÁ¥¢ÁµêÊûúÂæå„Å´Â∫ÉÂëä„ÇíÈú≤Âá∫„Åï„Åõ„ÇãÊ§úÁ¥¢ÈÄ£ÂãïÂûãÂ∫ÉÂëä„Å®„ÄÅ„Çµ„Ç§„Éà„ÅÆ‰∏≠„ÇíÂàÜÊûê„Åó„ÄÅ„Åù„ÅÆ„Çµ„Ç§„Éà„Å´Âêà„Å£„ÅüÂ∫ÉÂëä„ÇíÈÖç‰ø°„Åô„Çã„Ç≥„É≥„ÉÜ„É≥„ÉÑÈÄ£ÂãïÂûãÂ∫ÉÂëä„Åå‰∏ªÊµÅ„Åß„ÅÇ„Çã„ÄÇ Ëã±Ë™ûÂúè„Åß„ÇÇ2013Âπ¥„Åî„Çç„Åã„Çâ„Äå#wikipedia„Äç„ÅÆ„Çà„ÅÜ„Å™Áï™Âè∑Ë®òÂè∑„Çí‰Ωø„Å£„ÅüÂ∫ÉÂëäÊ¥ªÂãï„Çí„Åä„Åì„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇ „ÅÑ„Çè„ÇÜ„Çã„Äå‰ΩøÁî®Ë®ÄË™û„Åã„Çâ„Åø„Åü„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà‰∫∫Âè£„ÅÆÂâ≤Âêà„Äç„ÅØ Internet Archive „ÇíÁî®„ÅÑ„Å¶ Euro Marketing „Å® Global Reach „Åã„ÇâÈÅéÂéª„ÅÆÊúàÊ¨°Ë≥áÊñô„ÇíÊï¥ÁêÜ„Åô„Çã„Å®Ê¨°„ÅÆ„Çà„ÅÜ„Å™Êé®Áßª„ÇíËæø„Å£„Å¶„ÅÑ„Çã„ÄÇ ‚Äª2005Âπ¥2Êúà2Êó•„ÅÆÊôÇÁÇπ„Åß„ÄÅWWWÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆ‰ª£Ë°®Ê†º„Åß„ÅÇ„ÇãGoogle„Åß„ÅØ80ÂÑÑ„ÇíË∂ä„Åô8,058,044,651„Ç¶„Çß„Éñ„Éö„Éº„Ç∏„ÅåÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Åü„ÄÇ 1995Âπ¥‰ª•Ââç„ÅÆInternet Society„Å´„Çà„Çå„Å∞„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÅßÁî®„ÅÑ„Çâ„Çå„Å¶„ÅÑ„ÇãË®ÄË™û„ÅÆ„ÅÜ„Å°Ëã±Ë™û„ÅåÂç†„ÇÅ„ÇãÂâ≤Âêà„ÅØ85%„Å®„Åï„Çå„Å¶„ÅÑ„Åü„Åå„ÄÅ„Åù„ÅÆÂæå„ÅÆIT„ÅÆÈÄ≤Ê≠©„ÇÑÂêÑÂõΩ„ÅÆ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÅÆÊôÆÂèä„Å´„Çà„ÇäÂ§öË®ÄË™ûÂåñ„ÅåÈÄ≤„Åø„ÄÅ‰∏äË°®„Å´Ë¶ã„Çâ„Çå„Çã„Çà„ÅÜ„Å´2000Âπ¥„ÅÆÂπ¥Êú´„Å´„ÅØËã±Ë™û„Å®ÈùûËã±Ë™û„ÅÆË®ÄË™û‰∫∫Âè£„ÅåÈÄÜËª¢„Åó„ÄÅ„Åù„ÅÆÂÇæÂêë„ÅØÁ∂ôÁ∂ö„Åó„Å¶„ÅÑ„Å£„Åü„ÄÇ„Åì„ÅÆ„Åü„ÇÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥ÂêÑÁ§æ„ÅØÂ§öË®ÄË™ûÂØæÂøú„Å´Ëã¶ÊÖÆ„Åô„Çã„Åì„Å®„Å®„Å™„Å£„Åü„ÄÇ Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅØ„ÄÅÂà©‰æøÊÄß„Åå„ÅÇ„Çã‰∏ÄÊñπ„ÄÅÂç±Èô∫ÊÄß„ÇÇÂ≠òÂú®„Åô„Çã‰∫ã„ÇÑ„Åù„ÅÆË¢´ÂÆ≥‰æã„Å´„Å§„ÅÑ„Å¶ÂèÇËÄÉÊñáÁåÆ„ÇÑË≥áÊñô„ÅåÂ≠òÂú®„Åô„Çã„ÄÇÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂÆâÂÖ®ÊÄß„Å´Èñ¢„Åô„ÇãË™øÊüªÂ†±Âëä„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅ„Ç¶„Ç§„É´„ÇπÂØæÁ≠ñ„ÇΩ„Éï„Éà„Å™„Å©„ÇíÊèê‰æõ„Åô„Çã„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éô„É≥„ÉÄ„Éº„ÅÆÁ±≥„Éû„Ç´„Éï„Ç£„Éº„Åå„ÄÅ2007Âπ¥6Êúà4Êó•„ÄåÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂÆâÂÖ®ÊÄß„Å´Èñ¢„Åô„ÇãË™øÊüªÂ†±Âëä„Äç„ÇíÁô∫Ë°®„Åó„ÄåÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅØÂç±Èô∫„Åß„ÅÇ„Çä„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„Å´„Ç≠„Éº„ÉØ„Éº„Éâ„ÇíÂÖ•Âäõ„Åó„Å¶‰∏ä‰Ωç„Å´Áèæ„Çå„Çã„Çµ„Ç§„Éà„ÅÆÂç±Èô∫Â∫¶„ÇíË™ø„Åπ„Åü„Çâ„ÄÅÂ∫ÉÂëä„Å®„Åó„Å¶Ë°®Á§∫„Åï„Çå„Çã„Çµ„Ç§„Éà„ÅØ„ÄÅ„Åù„ÅÜ„Åß„Å™„ÅÑ„Çµ„Ç§„Éà„ÅÆ2.4ÂÄç„ÇÇÂç±Èô∫Áéá„ÅåÈ´ò„ÅÑ„Äç„Å®„Åó„Å¶„ÅÑ„Çã[14][15]„ÄÇ „Åæ„Åü2006Âπ¥05Êúà12Êó•„Å´ÂÖ¨Ë°®„Åï„Çå„ÅüË™øÊüªÂ†±ÂëäÊõ∏„Å´„Çà„Çã„Å®Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆ„Ç≠„Éº„ÉØ„Éº„ÉâÊ§úÁ¥¢ÁµêÊûú„Å´„ÅØÂç±Èô∫„Å™„É™„É≥„ÇØ„Åå„ÅÇ„Çä„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅåËá™ÂàÜ„ÇíÂÆà„Å£„Å¶„Åè„Çå„Çã„Å®ÊÄù„Å£„Å¶„ÅØ„ÅÑ„Åë„Å™„ÅÑ„ÄÇ„Åù„Çå„Å©„Åì„Çç„ÅãÊ§úÁ¥¢ÁµêÊûú„É©„É≥„Ç≠„É≥„Ç∞„Åå„Çµ„Ç§„Éà„ÅÆÂÆâÂÖ®ÊÄß„ÇíÂèçÊò†„Åó„Å¶„ÅÑ„Å™„ÅÑ„Åì„Å®„ÇÇÂ§ö„Åè„ÄÅÁâπ„Å´Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥Â∫ÉÂëä„ÇíË®™„Çå„ÇãÂ†¥Âêà„ÄÅ„É¶„Éº„Ç∂„Éº„ÅØÈ´ò„ÅÑ„É™„Çπ„ÇØ„Å´„Åï„Çâ„Åï„Çå„Çã„Å®Ë≠¶Èêò„ÇíÈ≥¥„Çâ„Åó„Å¶„ÅÑ„Çã[16]„ÄÇ\n„Åï„Çâ„Å´„ÄÅÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÊèê‰æõ„Çµ„Ç§„Éà„ÅÆÂç±Èô∫Â∫¶„Å´„Å§„ÅÑ„Å¶„ÅÆË™øÊüªÂ†±Âëä„Åß„ÅØ„ÄÅÂêå„Éû„Ç´„Éï„Ç£„Éº„Åå„ÄåÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆÂÆâÂÖ®Â∫¶Ë™øÊüª„Äç„ÇíÁô∫Ë°®„Åó„ÄåÊúÄ„ÇÇÂç±Èô∫„Å™ÁµêÊûú„ÅåÂ§ö„ÅÑ„ÅÆ„ÅØÁ±≥„É§„Éï„Éº„Äç„Å®„Åó„Å¶„ÅÑ„Çã[17]„ÄÇ SEOÂØæÁ≠ñ„ÅÆÊäÄË°ì„ÅåÈÄ≤„Çì„Å†„Åì„Å®„ÇÇ„ÅÇ„Çä„ÄÅÊ§úÁ¥¢‰∏ä‰Ωç„ÅåÂ§ßÊâã„Çµ„Ç§„Éà„ÇÑ„Åæ„Å®„ÇÅ„Çµ„Ç§„Éà„Å∞„Åã„Çä„Å´„Å™„Çã„Å™„Å©„ÄÅË°®Á§∫„Åï„Çå„Çã„Çµ„Ç§„Éà„Å´ÂÅè„Çä„ÅåÁîü„Åò„Å¶„ÅÑ„Çã[18][19][20]„ÄÇÊòî„ÅÆ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÅÆ„Åª„ÅÜ„ÅåÁ≤æÂ∫¶„ÅåÈ´ò„Åã„Å£„Åü„Å®„ÅÑ„ÅÜÊÑüÊÉ≥„ÇÇÂ§ö„ÅÑ[21]„ÄÇ „Ç¶„Çß„Éñ„Çµ„Ç§„Éà„ÅÆ‰∫∫Ê∞ó„Å®Èñ¢ÈÄ£ÊÄß„ÅÆ„ÅÑ„Åè„Å§„Åã„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„Å´„ÇÇ„Å®„Å•„ÅÑ„Å¶„Åù„Çå„Çâ„ÇíÁï™‰ªò„Åô„Çã„Çà„ÅÜÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅØ„Éó„É≠„Ç∞„É©„É†„Åï„Çå„Å¶„ÅÑ„Çã„Åë„Çå„Å©„ÇÇ„ÄÅ„Åù„Çå„Çâ„Åå‰∏é„Åà„ÇãÊÉÖÂ†±„ÅÆ„Å™„Åã„ÅÆ„Åï„Åæ„Åñ„Åæ„Å™ÊîøÊ≤ªÁöÑ„ÄÅÁµåÊ∏àÁöÑ„ÄÅÁ§æ‰ºöÁöÑ„Å™„ÄÅ„Éê„Ç§„Ç¢„Çπ„Çí'ÁµåÈ®ìÁöÑ„Å™'ÔºàËã±: empiricalÔºâÁ†îÁ©∂„ÅØ„Åó„ÇÅ„Åô[22]„ÄÇ „Å™„Å©„ÄÇ"
  },
  {
    "url": "https://no.wikipedia.org/wiki/Webs%C3%B8kemotor",
    "title": "Webs√∏kemotor ‚Äì Wikipedia",
    "content": "En webs√∏kemotor er et programvaresystem som er utformet for √• s√∏ke etter informasjon p√• World Wide Web. S√∏keresultatene presenteres generelt p√• sider som ofte refereres til som search engine results pages (SERPs). Informasjonen kan v√¶re en miks av websider, bilder og andre typer filer. Noen s√∏kemotorer minerer ogs√• data tilgjengelig i databaser eller √•pne kataloger. Til forskjell fra webkataloger, som vedlikeholdes bare av menneskelige redakt√∏rer, opprettholder s√∏kemotorer ogs√• informasjon i sanntid ved √• kj√∏re en algoritme p√• en s√∏kerobot."
  },
  {
    "url": "https://mhr.wikipedia.org/wiki/%D0%9A%D1%8B%D1%87%D0%B0%D0%BB%D1%88%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B5",
    "title": "–ö—ã—á–∞–ª—à–µ —Å–∏—Å—Ç–µ–º–µ ‚Äî –í–∏–∫–∏–ø–µ–¥–∏–π",
    "content": "–ö—ã—á–∞–ª—à–µ —Å–∏—Å—Ç–µ–º–µ (—Ä—É—à–ª–∞ –ø–æ–∏—Å–∫–æÃÅ–≤–∞—è —Å–∏—Å—Ç–µÃÅ–º–∞) ‚Äî –ø–æ—Å–Ω–∞ –≤–æ—Ç—Å–∞–π—Ç, —Ç—É—à—Ç–æ –ø–∞–π–¥–∞–ª–∞–Ω—ã—à–µ —à–∫–µ –π–æ–¥–º–∞—à—ã–∂–ª–∞–Ω –∫–µ–ª—à—ã—à–µ —Å–∞–π—Ç—É—à—ã–∫—ã–º/—Å–∞–π—Ç–∫—ã–ª–≤–µ—Ä—ã–º –º—É—ã–Ω –∫–µ—Ä—Ç–µ—à."
  },
  {
    "url": "https://uz.wikipedia.org/wiki/Veb_qidiruv_tizimi",
    "title": "Veb qidiruv tizimi - Vikipediya",
    "content": "Veb qidiruv tizimi - foydalanuvchi so ªroviga javoban veb-sahifalarga giperhavolalar va Internetdagi boshqa tegishli ma ºlumotlarni taqdim qiluvchi dasturiy tizimdir. Foydalanuvchi veb-brauzer yoki mobil ilova ichida so ªrovni kiritadi va qidiruv natijalari ko ªpincha matnli xulosalar va rasmlar bilan birga giperhavolalar ro ªyxati bo ªladi. Foydalanuvchilar, qidiruvni rasmlar, videolar yoki yangiliklar kabi ma ºlum turdagi natijalar bilan cheklash imkoniyatiga ega. Qidiruv provayderi uchun uning mexanizmi butun dunyo bo ªylab ko ªplab ma ºlumotlar markazlarini qamrab oladigan taqsimlangan hisoblash tizimining bir qismidir. Mexanizmning so ªrovga javob tezligi va aniqligi avtomatlashtirilgan veb-brauzerlar tomonidan doimiy ravishda yangilanadigan murakkab indekslash tizimiga asoslanadi. Bunga veb-serverlarda saqlangan fayllar va ma ºlumotlar bazalari ma ºlumotlarini ishlab chiqarish kiradi. 1990-yillarda Internet paydo bo ªlganidan beri ko ªplab qidiruv tizimlari ishlab chiqildi, lekin Google Search 2000-yillarda dominant bo ªldi va shunday bo ªlib qoldi. Hozirda u 91% global bozor ulushiga ega[1][2]. Ba ºzi qidiruv tizimlari yangiliklar guruhlari, ma ºlumotlar bazalari yoki ochiq kataloglarda mavjud bo ªlgan ma ºlumotlarni ham ishlab chiqaradi. Inson muharrirlari tomonidan yuritiladigan veb-kataloglardan farqli o ªlaroq, qidiruv tizimlari algoritmik ishlaydi yoki algoritmik va inson ma ºlumotlarining aralashmasi sifatida ishlaydi. 1945-yilda Vannevar Bush foydalanuvchiga bir stolda katta hajmdagi ma ºlumotlarga kirish imkonini beradigan axborot qidirish tizimini tasvirlab berdi[3] va buni memeks deb nomladi. Bush The Atlantic Monthly jurnalida chop etilgan ‚ÄûBiz o ªylagandek‚Äú sarlavhali maqolasida tizimni tasvirlab bergan[4]. Memeks foydalanuvchiga ilmiy ishlarning doimiy o ªsib borayotgan markazlashtirilgan indekslarida ma ºlumotni topishning tobora ortib borayotgan qiyinchiliklarini yengish qobiliyatini berish uchun mo ªljallangan edi. Vannevar Bush zamonaviy giperhavolalarga o ªxshash bog ªlangan izohli tadqiqot kutubxonalarini nazarda tutgan[5]. Havola tahlili oxir-oqibat Hyper Search va PageRank kabi algoritmlar orqali qidiruv tizimlarining muhim tarkibiy qismiga aylandi[6][7]. Birinchi internet qidiruv tizimlari 1990-yil dekabrida Internet debyutidan oldin paydo bo ªlgan: WHOIS foydalanuvchi qidiruvi 1982-yilga borib taqaladi[8] va Knowbot Information Service ko ªp tarmoqli foydalanuvchi qidiruvi birinchi marta 1989-yilda amalga oshirilgan[9]. Kontent fayllarini, ya ºni FTP fayllarini qidiradigan birinchi yaxshi hujjatlashtirilgan qidiruv tizimi Archie bo ªlib, u 1990-yil 10-sentyabrda debyut qilgan[10]."
  },
  {
    "url": "https://pms.wikipedia.org/wiki/Motor_d%27arserca_web",
    "title": "Motor d'arserca web - Wikipedia an piemont√®is, l'encicloped√¨a l√¨bera e a gr√†tis",
    "content": "Un motor d'arserca web (an angl√®is web search engine) a l'√© un sistema software proget√† p√´r serch√© e trov√© d'anformassion an sla ragn√†. A analisa miliard √´d document, figure, video, e √†utri contn√π, organisandje an n'√¨ndes p√´rm√´ttend a j'utent √´d trov√© l√≤n ch'a l'han da manca an anserend √´d par√≤le-ciav. Esempi famos a son Google, Bing, DuckDuckGo, e Yahoo! Search. 1. Crawler (ragn√†): Scansion-a la Web p√´r trov√© contn√π neuv o modific√†.  \n2. √åndes: Archivi ch'a mapa par√≤le-ciav a document rilevant.  \n3. Algoritm √´d ranking: Valuta la rilevansa dij contn√π (es. Google PageRank).  \n4. Ant√´rfacia utent: P√†gina d'arserca andova j'utent a inserisso √´d query. Tecnologie avans√†:"
  },
  {
    "url": "https://pl.wikipedia.org/wiki/Wyszukiwarka_internetowa",
    "title": "Wyszukiwarka internetowa ‚Äì Wikipedia, wolna encyklopedia",
    "content": "Wyszukiwarka internetowa ‚Äì program komputerowy lub strona internetowa odnajdujƒÖca w internecie informacje wed≈Çug podanych przez u≈ºytkownika s≈Ç√≥w kluczowych lub wyra≈ºe≈Ñ sformu≈Çowanych w jƒôzyku naturalnym[1]. Umo≈ºliwia u≈ºytkownikom wyszukiwanie ‚Äì co do zasady ‚Äì wszystkich stron internetowych lub stron internetowych w danym jƒôzyku za pomocƒÖ zapytania na jakikolwiek temat przez podanie s≈Çowa kluczowego, wyra≈ºenia lub innej warto≈õci wej≈õciowej. W wyniku przedstawia odno≈õniki, pod kt√≥rymi mo≈ºna znale≈∫ƒá informacje zwiƒÖzane z zadanym zapytaniem[2]. Okre≈õlenie ‚Äûwyszukiwarka‚Äù stosowane jest w odniesieniu do: Wyszukiwarki gromadzƒÖ w spos√≥b automatyczny informacje o dokumentach tekstowych oraz plikach zgromadzonych w sieci (z obszaru wyznaczonego do indeksowania). Poniewa≈º Internet ro≈õnie znacznie szybciej ni≈º jakakolwiek grupa ludzi mo≈ºe go katalogowaƒá oraz z powodu wad katalog√≥w (np. pod danym has≈Çem mo≈ºe znajdowaƒá siƒô tysiƒÖce stron), powsta≈Çy wyszukiwarki, kt√≥re przeszukujƒÖ Internet, analizujƒÖc zawarto≈õƒá stron.\nKiedy u≈ºytkownik poda wyszukiwarce zapytanie, ona odpowie mu ≈ÇƒÖczami do stron, kt√≥re uzna, w zale≈ºno≈õci od u≈ºytego algorytmu, za najbardziej odpowiednie. Wyszukiwarki oparte na tej zasadzie mogƒÖ objƒÖƒá znacznie wiƒôkszƒÖ czƒô≈õƒá sieci ni≈º katalogi. Niestety sƒÖ one bardzo podatne na nadu≈ºycia, przez co u≈ºytkownik zamiast u≈ºytecznych informacji dostaje linki na strony niemajƒÖce nic wsp√≥lnego z jego zapytaniem. Szczeg√≥lnie wyspecjalizowa≈Çy siƒô w tym strony pornograficzne. ≈ªeby przeciwdzia≈Çaƒá temu, stosuje siƒô wyszukiwarki, w kt√≥rych na szczycie list pojawiajƒÖ siƒô strony, do kt√≥rych odnosi siƒô najwiƒôcej stron dotyczƒÖcych danego zapytania. Tak wiƒôc stronƒô uwa≈ºa siƒô za odpowiadajƒÖcƒÖ zapytaniu ‚Äûbritney spears‚Äù, je≈õli wiele stron na temat ‚Äûbritney spears‚Äù do niej linkuje. Strona porno z nagimi zdjƒôciami Britney, niezale≈ºnie od w≈Çasnej tre≈õci i niezale≈ºnie od ca≈Çkowitej liczby link√≥w (g≈Ç√≥wnie z innych stron porno) na niƒÖ, nie bƒôdzie w ten spos√≥b uznana za zwiƒÖzanƒÖ z tematem. Natomiast je≈õli zada siƒô zapytanie ‚Äûbritney spears nude‚Äù, strona ta zostanie uznana za istotnƒÖ, poniewa≈º linkuje na niƒÖ wiele stron o tematyce ‚Äûnude‚Äù. PoczƒÖtkowa istotno≈õƒá na podstawie prostej heurystyki, po czym zwykle u≈ºywa siƒô algorytmu losowego skakania po linkach. PierwszƒÖ wyszukiwarkƒÖ, kt√≥ra zastosowa≈Ça zaawansowane algorytmy analizy topologii sieci by≈Ç Google. Wyszukiwarki oparte na analizie topologicznej sƒÖ czƒôsto uwa≈ºane za bardzo odporne na nadu≈ºycia. W rzeczywisto≈õci stosunkowo czƒôstym atakiem sƒÖ spam-systemy automatycznej wymiany link√≥w. InnƒÖ formƒÖ ataku jest stworzenie du≈ºej ilo≈õci gƒôsto linkowanych stron, z czego wszystkie na ten sam temat. Jest to jednak zadanie trudne i wymagajƒÖce du≈ºego nak≈Çadu pracy, a modyfikujƒÖc heurystykƒô warto≈õci poczƒÖtkowych, mo≈ºna znacznie ograniczyƒá ten proceder, kt√≥rego skala na razie jest minimalna. Osobnym pomys≈Çem jest wprowadzony przez Overture system, gdzie strony p≈ÇacƒÖ wyszukiwarce kilka cent√≥w za ka≈ºde klikniƒôcie, przy czym miejsca sƒÖ licytowane ‚Äì strona, kt√≥ra daje wiƒôcej za klikniƒôcie znajdzie siƒô wy≈ºej na li≈õcie rezultat√≥w. Pozycje p≈Çatne sƒÖ oznaczone jako takie, razem z cenƒÖ. System ten jest korzystny dla w≈Ça≈õcicieli stron ‚Äì p≈ÇacƒÖ oni tylko za wej≈õcia nie za wy≈õwietlenia. Tw√≥rcy twierdzƒÖ, ≈ºe jest on r√≥wnie≈º korzystny dla u≈ºytkownika, gdy≈º tylko strony, kt√≥re oferujƒÖ co≈õ u≈ºytecznego z danej dziedziny mogƒÖ sobie pozwoliƒá na takƒÖ reklamƒô. Z drugiej jednak strony wiele u≈ºytecznych stron jest niekomercyjnych, a nawet przy stronach komercyjnych wyniki bƒôdƒÖ czƒôsto nieoptymalne ‚Äì np. na takƒÖ reklamƒô nie mogƒÖ sobie pozwoliƒá strony, kt√≥re majƒÖ niskie mar≈ºe i oferujƒÖ produkty po niskich cenach, a jedynie te, kt√≥re majƒÖ wysokie mar≈ºe i oferujƒÖ produkty dro≈ºej. Wyszukiwarki stanowiƒÖ wymarzony cel reklamodawc√≥w, poniewa≈º majƒÖ oni praktycznie pe≈ÇnƒÖ gwarancjƒô, ≈ºe osoba wyszukujƒÖca dane has≈Ço jest nim zainteresowana. Tak wiƒôc wiƒôkszo≈õƒá wyszukiwarek oferuje reklamy zale≈ºne od tre≈õci zapyta≈Ñ (np. Google Ads oferowany przez Google). Nie zawsze sƒÖ one w≈Ça≈õciwie oddzielone od wynik√≥w poszukiwa≈Ñ, co sta≈Ço siƒô ≈∫r√≥d≈Çem protest√≥w grup ochrony praw konsument√≥w oraz kilku do dzi≈õ nierozstrzygniƒôtych spraw sƒÖdowych. Ze wzglƒôdu na szerokƒÖ krytykƒô procederu nieoddzielania reklam od wynik√≥w, wiƒôkszo≈õƒá wyszukiwarek z niego zrezygnowa≈Ça i wyra≈∫nie zaznacza teraz reklamy. Oprogramowanie wyszukiwarek to zestaw program√≥w, modu≈Ç√≥w, z kt√≥rych ka≈ºdy ma oddzielne zadanie.\nW sk≈Çad zestawu wchodzƒÖ takie elementy jak: Oraz dochodzƒÖ do tego: Wsp√≥≈Çczesne oprogramowanie wyszukiwarek jest wysoce skomplikowanym systemem rozproszonym uruchamianym zwykle w wielu oddzielnych etapach na tysiƒÖcach oddzielnych komputer√≥w ‚Äì zar√≥wno ze wzglƒôdu na rozmiar i skalƒô przeszukiwanej sieci, jak i ze wzglƒôd√≥w na poprawienie dostƒôpno≈õci us≈Çugi w wypadku awarii poszczeg√≥lnych komponent√≥w. Algorytmy oceny istotno≈õci (tzw. relewancji) dokumentu wzglƒôdem szukanej frazy ‚Äì algorytmy oceny zawarto≈õci strony"
  },
  {
    "url": "https://qu.wikipedia.org/wiki/Mask%27ay_kuyuchina",
    "title": "Mask'ay kuyuchina - Wikipidiya",
    "content": "Mask'ay kuyuchiq icha Mask'a purichiqqa huk llamp'ukaq llikacham, web mask'aykunata ruwanapaq ch'antasqa. Paykunaqa World Wide Web kaqpi huk sistimatiku kaqpi mask'anku huk willakuy web mask'ana tapuypi willasqa partikular willayta. Mask'ana ruwasqakuna tukuypaq huk chiru ruwasqakunapi rikuchikunku, sapa kuti maskanapaq ruwasqa p'anqakuna (Inlish simipi: search engine results pages) nispa sutichasqa. Mayk'aq huk llamk'achiq huk tapuyta maskanaman yaykuchin, llamk'anaqa web p'anqakunap urquyninta qhawan, llamk'aqpa tapuyninwan tupaqkunata tarinanpaq. Chaymanta ruwasqakuna yachasqa kaqmanhina rankikunku chaymanta ruwaqman rikuchikunku. Willakuyqa web p'anqakunaman, siq'ikunaman, widiyukunaman, yachamanta qillqa, qillqakunaman, mask'ana qillqakunaman, waq laya willa√±iqikunaman t'inkikuna chaqrusqa kanman. Wakin mask'anakunapis willakuypa waqaychanankunapi utaq kichasqa directoriokunapi tarikuq willakuykunatam hurqunku. Mana web kamachikuna hinachu chaymanta rima markatur sitiyukuna hina, mayqinkunachus runa allichaqkunawan waqaychasqa kanku, maskanakuna chiqa pacha willayta waqaychankutaq huk allquritmu web watiqaq kaqpi purichispa. Ima intirnitpi ruwasqa willakuypis mana web mask'anawan urqusqa chaymanta mask'ay atikuq, ukhu web katikuriya kaqman urmaykun. Huk mask'ay kuyuchinaqa kay ruwaykunata yaqa chiqa pachapi waqaychan:"
  },
  {
    "url": "https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D0%B8%D1%81%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0",
    "title": "–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ ‚Äî –í–∏–∫–∏–ø–µ–¥–∏—è",
    "content": "–ü–æ–∏—Å–∫–æÃÅ–≤–∞—è —Å–∏—Å—Ç–µÃÅ–º–∞ (–∂–∞—Ä–≥. –ø–æ–∏—Å–∫–æ–≤–∏ÃÅ–∫) –∏–ª–∏ –ø–æ–∏—Å–∫–æÃÅ–≤—ã–π –¥–≤–∏–∂–æÃÅ–∫ (–∞–Ω–≥–ª.¬†search engine)¬†‚Äî –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Ä–µ–∞–ª–∏–∑—É—é—â–∞—è –∏—Ö —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º (–≤ —à–∏—Ä–æ–∫–æ–º —Å–º—ã—Å–ª–µ —ç—Ç–æ–≥–æ –ø–æ–Ω—è—Ç–∏—è, –≤–∫–ª—é—á–∞—è –∞–Ω–∞–ª–æ–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è), –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –µ–º—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –ø–æ–∏—Å–∫–∞ –≤ –æ–±—à–∏—Ä–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö[1]. –û–¥–Ω–æ –∏–∑ –Ω–∞–∏–±–æ–ª–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º¬†‚Äî –≤–µ–±-—Å–µ—Ä–≤–∏—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∏–ª–∏ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–æ –í—Å–µ–º–∏—Ä–Ω–æ–π –ø–∞—É—Ç–∏–Ω–µ. –°—É—â–µ—Å—Ç–≤—É—é—Ç —Ç–∞–∫–∂–µ —Å–∏—Å—Ç–µ–º—ã, —Å–ø–æ—Å–æ–±–Ω—ã–µ –∏—Å–∫–∞—Ç—å —Ñ–∞–π–ª—ã –Ω–∞ FTP-—Å–µ—Ä–≤–µ—Ä–∞—Ö, —Ç–æ–≤–∞—Ä—ã –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞—Ö, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –≥—Ä—É–ø–ø–∞—Ö –Ω–æ–≤–æ—Å—Ç–µ–π Usenet. –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[2]. –†–∞–±–æ—Ç–∞ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –ª–∏–±–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –ª–∏–±–æ —Å–ª–æ–≤–∞, –∫–∞–∫-–ª–∏–±–æ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏[3]. –ü—Ä–∏ —ç—Ç–æ–º –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞. –¢–∞–∫–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è –≤—ã–¥–∞—á–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä: –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Ç–∞–∫–∂–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–µ.\n–î–ª—è –ø–æ–∏—Å–∫–∞ –Ω—É–∂–Ω—ã—Ö —Å–≤–µ–¥–µ–Ω–∏–π —É–¥–æ–±–Ω–µ–µ –≤—Å–µ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø–æ–∏—Å–∫–æ–≤—ã–º–∏ –º–∞—à–∏–Ω–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –±—ã—Å—Ç—Ä–æ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å–≤–µ–¥–µ–Ω–∏—è –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç—É –ø–æ–∏—Å–∫–∞. –ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–∏–º–∏ –º–∞—à–∏–Ω–∞–º–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–∞–¥–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –Ω–∞–∏–±–æ–ª–µ–µ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—é—â–∏–µ –∏—Å–∫–æ–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∏–ª–∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –æ–±–ª–∞—Å—Ç–∏ –ø–æ–∏—Å–∫–∞. –ü–æ—Å–ª–µ –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–∏—Å–∫ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–µ, –æ–±—ã—á–Ω–æ –Ω–∞–∑—ã–≤–∞–µ–º—ã–µ web-—Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞. –û–±—ã—á–Ω–æ —Å—Å—ã–ª–∫–∏ –¥–æ–ø–æ–ª–Ω—è—é—Ç—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –ø–æ–º–æ–≥–∞—é—Ç —Å—Ä–∞–∑—É –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–µ–º–∞—Ç–∏–∫—É –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –©—ë–ª–∫–Ω—É–≤ –º—ã—à—å—é –Ω–∞ —Å—Å—ã–ª–∫–µ, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–π—Ç–∏ –∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É. –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç–µ–º –ª—É—á—à–µ, —á–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ–Ω–∞ –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –º–æ–≥—É—Ç —Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –º–µ–Ω–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –∏–∑-–∑–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏–ª–∏ –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞‚û§. –ü–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –Ω–∞ 2020¬†–≥–æ–¥ —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ–π –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π –≤ –º–∏—Ä–µ –∏, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –†–æ—Å—Å–∏–∏ —è–≤–ª—è–µ—Ç—Å—è Google[–∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω 1514 –¥–Ω–µ–π]. –ü–æ –º–µ—Ç–æ–¥–∞–º –ø–æ–∏—Å–∫–∞ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—Ç —á–µ—Ç—ã—Ä–µ —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º: —Å–∏—Å—Ç–µ–º—ã, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Ä–æ–±–æ—Ç–æ–≤, —Å–∏—Å—Ç–µ–º—ã, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —á–µ–ª–æ–≤–µ–∫–æ–º, –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –∏ –º–µ—Ç–∞-—Å–∏—Å—Ç–µ–º—ã‚û§. –í –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—ã—á–Ω–æ –≤—Ö–æ–¥—è—Ç: –ù–∞ —Ä–∞–Ω–Ω–µ–º —ç—Ç–∞–ø–µ —Ä–∞–∑–≤–∏—Ç–∏—è —Å–µ—Ç–∏ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –¢–∏–º –ë–µ—Ä–Ω–µ—Ä—Å-–õ–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª —Å–ø–∏—Å–æ–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–æ–≤, —Ä–∞–∑–º–µ—â—ë–Ω–Ω—ã–π –Ω–∞ —Å–∞–π—Ç–µ –¶–ï–†–ù[4]. –°–∞–π—Ç–æ–≤ —Å—Ç–∞–Ω–æ–≤–∏–ª–æ—Å—å –≤—Å—ë –±–æ–ª—å—à–µ, –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –≤—Ä—É—á–Ω—É—é —Ç–∞–∫–æ–π —Å–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω–æ–≤–∏–ª–æ—Å—å –≤—Å—ë —Å–ª–æ–∂–Ω–µ–µ. –ù–∞ —Å–∞–π—Ç–µ NCSA –±—ã–ª —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª ¬´–ß—Ç–æ –Ω–æ–≤–æ–≥–æ!¬ª (–∞–Ω–≥–ª.¬†What's New!)[5], –≥–¥–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ–≤—ã–µ —Å–∞–π—Ç—ã. –ü–µ—Ä–≤–æ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–æ–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –±—ã–ª–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ê—Ä—á–∏[–∞–Ω–≥–ª.] (–∞–Ω–≥–ª.¬†archie¬†‚Äî –∞—Ä—Ö–∏–≤ –±–µ–∑ –±—É–∫–≤—ã ¬´–≤¬ª). –û–Ω–∞ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –≤ 1990¬†–≥–æ–¥—É –ê–ª–∞–Ω–æ–º –≠–º—Ç—ç–¥–∂–µ–º (Alan Emtage), –ë–∏–ª–ª–æ–º –•–∏–ª–∞–Ω–æ–º (Bill Heelan) –∏ –î–∂. –ü–∏—Ç–µ—Ä–æ–º –î–æ–π—á–µ–º (J. Peter Deutsch), —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏, –∏–∑—É—á–∞—é—â–∏–º–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫—É –≤ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–µ –ú–∞–∫–≥–∏–ª–ª–∞ –≤ –ú–æ–Ω—Ä–µ–∞–ª–µ. –ü—Ä–æ–≥—Ä–∞–º–º–∞ —Å–∫–∞—á–∏–≤–∞–ª–∞ —Å–ø–∏—Å–∫–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ —Å–æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–Ω–æ–Ω–∏–º–Ω—ã—Ö FTP-—Å–µ—Ä–≤–µ—Ä–æ–≤ –∏ —Å—Ç—Ä–æ–∏–ª–∞ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö, –≤ –∫–æ—Ç–æ—Ä–æ–π –º–æ–∂–Ω–æ –±—ã–ª–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤. –û–¥–Ω–∞–∫–æ, –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ê—Ä—á–∏ –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–ª–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —ç—Ç–∏—Ö —Ñ–∞–π–ª–æ–≤, —Ç–∞–∫ –∫–∞–∫ –æ–±—ä—ë–º –¥–∞–Ω–Ω—ã—Ö –±—ã–ª –Ω–∞—Å—Ç–æ–ª—å–∫–æ –º–∞–ª, —á—Ç–æ –≤—Å—ë –º–æ–∂–Ω–æ –±—ã–ª–æ –ª–µ–≥–∫–æ –Ω–∞–π—Ç–∏ –≤—Ä—É—á–Ω—É—é. –†–∞–∑–≤–∏—Ç–∏–µ –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Ç–µ–≤–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ Gopher, –ø—Ä–∏–¥—É–º–∞–Ω–Ω–æ–≥–æ –≤ 1991¬†–≥–æ–¥—É –ú–∞—Ä–∫–æ–º –ú–∞–∫–∫—ç—Ö–∏–ª–æ–º (Mark McCahill) –≤ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–µ –ú–∏–Ω–Ω–µ—Å–æ—Ç—ã, –ø—Ä–∏–≤–µ–ª–æ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –¥–≤—É—Ö –Ω–æ–≤—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º, Veronica[–∞–Ω–≥–ª.] –∏ Jughead[–∞–Ω–≥–ª.]. –ö–∞–∫ –∏ –ê—Ä—á–∏, –æ–Ω–∏ –∏—Å–∫–∞–ª–∏ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≤ –∏–Ω–¥–µ–∫—Å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö Gopher. Veronica (–∞–Ω–≥–ª.¬†Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) –ø–æ–∑–≤–æ–ª—è–ª–∞ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –º–µ–Ω—é Gopher –≤–æ –≤—Å–µ—Ö —Å–ø–∏—Å–∫–∞—Ö Gopher. –ü—Ä–æ–≥—Ä–∞–º–º–∞ Jughead (–∞–Ω–≥–ª.¬†Jonzy's Universal Gopher Hierarchy Excavation And Display) –∏–∑–≤–ª–µ–∫–∞–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ–Ω—é –æ—Ç –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö Gopher-—Å–µ—Ä–≤–µ—Ä–æ–≤. –•–æ—Ç—è –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞ –ê—Ä—á–∏ –Ω–µ –∏–º–µ–ª–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ü–∏–∫–ª—É –∫–æ–º–∏–∫—Å–æ–≤ ¬´–ê—Ä—á–∏¬ª[–∞–Ω–≥–ª.], —Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ Veronica –∏ Jughead¬†‚Äî –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ —ç—Ç–∏—Ö –∫–æ–º–∏–∫—Å–æ–≤. –ö –ª–µ—Ç—É 1993¬†–≥–æ–¥–∞ –µ—â—ë –Ω–µ –±—ã–ª–æ –Ω–∏ –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–±–µ, —Ö–æ—Ç—è –≤—Ä—É—á–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª–∏—Å—å –º–Ω–æ–≥–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏. –û—Å–∫–∞—Ä –ù–∏—Ä—à—Ç—Ä–∞—Å—Å (Oscar Nierstrasz) –≤ –ñ–µ–Ω–µ–≤—Å–∫–æ–º —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–µ –Ω–∞–ø–∏—Å–∞–ª —Ä—è–¥ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ Perl, –∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–ª–∏ —ç—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–ª–∏ –∏—Ö –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –≠—Ç–æ —Å—Ç–∞–ª–æ –æ—Å–Ω–æ–≤–æ–π –¥–ª—è W3Catalog, –ø–µ—Ä–≤–æ–π –ø—Ä–∏–º–∏—Ç–∏–≤–Ω–æ–π –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã —Å–µ—Ç–∏, –∑–∞–ø—É—â–µ–Ω–Ω–æ–π 2 —Å–µ–Ω—Ç—è–±—Ä—è 1993¬†–≥–æ–¥–∞[6]. –í–µ—Ä–æ—è—Ç–Ω–æ, –ø–µ—Ä–≤—ã–º –ø–æ–∏—Å–∫–æ–≤—ã–º —Ä–æ–±–æ—Ç–æ–º, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–º –Ω–∞ —è–∑—ã–∫–µ Perl, –±—ã–ª ¬´World Wide Web Wanderer¬ª¬†‚Äî –±–æ—Ç –ú—ç—Ç—å—é –ì—Ä—ç—è (Matthew Gray) –∏–∑ –ú–∞—Å—Å–∞—á—É—Å–µ—Ç—Å–∫–æ–≥–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Å—Ç–∏—Ç—É—Ç–∞ –≤ –∏—é–Ω–µ 1993¬†–≥–æ–¥–∞. –≠—Ç–æ—Ç —Ä–æ–±–æ—Ç —Å–æ–∑–¥–∞–≤–∞–ª –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å ¬´Wandex¬ª. –¶–µ–ª—å —Ä–æ–±–æ—Ç–∞ Wanderer —Å–æ—Å—Ç–æ—è–ª–∞ –≤ —Ç–æ–º, —á—Ç–æ–±—ã –∏–∑–º–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä –≤—Å–µ–º–∏—Ä–Ω–æ–π –ø–∞—É—Ç–∏–Ω—ã –∏ –Ω–∞–π—Ç–∏ –≤—Å–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞. –í 1993¬†–≥–æ–¥—É –ø–æ—è–≤–∏–ª–∞—Å—å –∏ –≤—Ç–æ—Ä–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ ¬´Aliweb¬ª. Aliweb –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Ä–æ–±–æ—Ç–∞, –Ω–æ –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –æ–∂–∏–¥–∞–ª–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ –≤–µ–±-—Å–∞–π—Ç–æ–≤ –æ –Ω–∞–ª–∏—á–∏–∏ –Ω–∞ –∏—Ö —Å–∞–π—Ç–∞—Ö –∏–Ω–¥–µ–∫—Å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. JumpStation[–∞–Ω–≥–ª.], [7] —Å–æ–∑–¥–∞–Ω–Ω—ã–π –≤ –¥–µ–∫–∞–±—Ä–µ 1993¬†–≥–æ–¥–∞ –î–∂–æ–Ω–∞—Ç–∞–Ω–æ–º –§–ª–µ—Ç—á–µ—Ä–æ–º, –∏—Å–∫–∞–ª –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Å—Ç—Ä–æ–∏–ª –∏—Ö –∏–Ω–¥–µ–∫—Å—ã —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Ä–æ–±–æ—Ç–∞, –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –≤–µ–±-—Ñ–æ—Ä–º—É –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤. –≠—Ç–æ –±—ã–ª –ø–µ—Ä–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–∏—Å–∫–∞ –≤ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—á–µ—Ç–∞–ª —Ç—Ä–∏ –≤–∞–∂–Ω–µ–π—à–∏—Ö —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã (–ø—Ä–æ–≤–µ—Ä–∫–∞, –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–∏—Å–∫). –ò–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–≤ —Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–∏—Å–∫ –±—ã–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã–º —Ä–æ–±–æ—Ç–æ–º. –ü–µ—Ä–≤–æ–π –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–π –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é—â–µ–π —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ä–æ–±–æ—Ç–∞ (¬´craweler-based¬ª) –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π, —Å—Ç–∞–ª–∞ —Å–∏—Å—Ç–µ–º–∞ ¬´WebCrawler¬ª[–∞–Ω–≥–ª.], –∑–∞–ø—É—â–µ–Ω–Ω–∞—è –≤ 1994¬†–≥–æ–¥—É. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å–≤–æ–∏—Ö –ø—Ä–µ–¥—à–µ—Å—Ç–≤–µ–Ω–Ω–∏—Ü, –æ–Ω–∞ –ø–æ–∑–≤–æ–ª—è–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏—Å–∫–∞—Ç—å –ø–æ –ª—é–±—ã–º —Å–ª–æ–≤–∞–º, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–º –Ω–∞ –ª—é–±–æ–π –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ¬†‚Äî —Å —Ç–µ—Ö –ø–æ—Ä —ç—Ç–æ —Å—Ç–∞–ª–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, —ç—Ç–æ –±—ã–ª –ø–µ—Ä–≤—ã–π –ø–æ–∏—Å–∫–æ–≤–∏–∫, –ø–æ–ª—É—á–∏–≤—à–∏–π —à–∏—Ä–æ–∫–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ. –í 1994¬†–≥–æ–¥—É –±—ã–ª–∞ –∑–∞–ø—É—â–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ ¬´Lycos¬ª, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–µ –ö–∞—Ä–Ω–µ–≥–∏¬†‚Äî –ú–µ–ª–ª–æ–Ω –∏ —Å—Ç–∞–≤—à–∞—è —Å–µ—Ä—å—ë–∑–Ω—ã–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ–º. –í—Å–∫–æ—Ä–µ –ø–æ—è–≤–∏–ª–æ—Å—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥—Ä—É–≥–∏—Ö –∫–æ–Ω–∫—É—Ä–∏—Ä—É—é—â–∏—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –º–∞—à–∏–Ω, —Ç–∞–∫–∏—Ö –∫–∞–∫: ¬´Magellan¬ª[–∞–Ω–≥–ª.], ¬´Excite¬ª, ¬´Infoseek¬ª[–∞–Ω–≥–ª.], ¬´Inktomi¬ª[–∞–Ω–≥–ª.], ¬´Northern Light¬ª[–∞–Ω–≥–ª.] –∏ ¬´AltaVista¬ª. –í –Ω–µ–∫–æ—Ç–æ—Ä–æ–º —Å–º—ã—Å–ª–µ –æ–Ω–∏ –∫–æ–Ω–∫—É—Ä–∏—Ä–æ–≤–∞–ª–∏ —Å –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–∫–∞—Ç–∞–ª–æ–≥–∞–º–∏, —Ç–∞–∫–∏–º–∏ –∫–∞–∫ ¬´Yahoo!¬ª. –ù–æ –ø–æ–∏—Å–∫–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–ª–∏—Å—å –ø–æ–∏—Å–∫–æ–º –ø–æ —Å–∞–º–∏–º –∫–∞—Ç–∞–ª–æ–≥–∞–º, –∞ –Ω–µ –ø–æ —Ç–µ–∫—Å—Ç–∞–º –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü. –ü–æ–∑–∂–µ –∫–∞—Ç–∞–ª–æ–≥–∏ –æ–±—ä–µ–¥–∏–Ω—è–ª–∏—Å—å –∏–ª–∏ —Å–Ω–∞–±–∂–∞–ª–∏—Å—å –ø–æ–∏—Å–∫–æ–≤—ã–º–∏ —Ä–æ–±–æ—Ç–∞–º–∏ —Å —Ü–µ–ª—å—é —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞. –í 1996¬†–≥–æ–¥—É –∫–æ–º–ø–∞–Ω–∏—è Netscape —Ö–æ—Ç–µ–ª–∞ –∑–∞–∫–ª—é—á–∏—Ç—å —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—É—é —Å–¥–µ–ª–∫—É —Å –æ–¥–Ω–æ–π –∏–∑ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º, —Å–¥–µ–ª–∞–≤ –µ—ë –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞ –≤–µ–±-–±—Ä–∞—É–∑–µ—Ä–µ Netscape. –≠—Ç–æ –≤—ã–∑–≤–∞–ª–æ –Ω–∞—Å—Ç–æ–ª—å–∫–æ –±–æ–ª—å—à–æ–π –∏–Ω—Ç–µ—Ä–µ—Å, —á—Ç–æ Netscape –∑–∞–∫–ª—é—á–∏–ª–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç —Å—Ä–∞–∑—É —Å –ø—è—Ç—å—é –∫—Ä—É–ø–Ω–µ–π—à–∏–º–∏ –ø–æ–∏—Å–∫–æ–≤—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ (Yahoo!, Magellan, Lycos, Infoseek –∏ Excite). –ó–∞ 5¬†–º–ª–Ω –¥–æ–ª–ª–∞—Ä–æ–≤ –°–®–ê –≤ –≥–æ–¥ –æ–Ω–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∏—Å—å –ø–æ –æ—á–µ—Ä–µ–¥–∏ –Ω–∞ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ Netscape[8][9]. –ü–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ ¬´–ü—É–∑—ã—Ä–µ –¥–æ—Ç–∫–æ–º–æ–≤¬ª –∫–æ–Ω—Ü–∞ 1990-—Ö[10]. –ù–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–Ω–∏–π —ç—Ñ—Ñ–µ–∫—Ç–Ω–æ –≤—ã—à–ª–∏ –Ω–∞ —Ä—ã–Ω–æ–∫, –ø–æ–ª—É—á–∏–≤ —Ä–µ–∫–æ—Ä–¥–Ω—É—é –ø—Ä–∏–±—ã–ª—å –≤–æ –≤—Ä–µ–º—è –∏—Ö –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –ø—É–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∫–∞–∑–∞–ª–∏—Å—å –æ—Ç —Ä—ã–Ω–∫–∞ –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤ –∏ —Å—Ç–∞–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º —Å–µ–∫—Ç–æ—Ä–æ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, Northern Light[–∞–Ω–≥–ª.]. Google –≤–∑—è–ª –Ω–∞ –≤–æ–æ—Ä—É–∂–µ–Ω–∏–µ –∏–¥–µ—é –ø—Ä–æ–¥–∞–∂–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ 1998¬†–≥–æ–¥—É, —Ç–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–∞ –º–∞–ª–µ–Ω—å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è, –æ–±–µ—Å–ø–µ—á–∏–≤–∞–≤—à–∞—è —Ä–∞–±–æ—Ç—É –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ –∞–¥—Ä–µ—Å—É goto.com[–∞–Ω–≥–ª.]. –≠—Ç–æ—Ç —à–∞–≥ –æ–∑–Ω–∞–º–µ–Ω–æ–≤–∞–ª –¥–ª—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º –∫ –æ–¥–Ω–æ–º—É –∏–∑ —Å–∞–º—ã—Ö –≤—ã–≥–æ–¥–Ω—ã—Ö –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π –≤ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–µ[11]. –ü–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–ª–∏ –ø—Ä–æ–¥–∞–≤–∞—Ç—å –ø–µ—Ä–≤—ã–µ –º–µ—Å—Ç–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏—è–º. –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ Google –∑–∞–Ω–∏–º–∞–µ—Ç –≤–∏–¥–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ —Å –Ω–∞—á–∞–ª–∞ 2000-—Ö[12]. –ö–æ–º–ø–∞–Ω–∏—è –¥–æ–±–∏–ª–∞—Å—å –≤—ã—Å–æ–∫–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –±–ª–∞–≥–æ–¥–∞—Ä—è —Ö–æ—Ä–æ—à–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–∏—Å–∫–∞ —Å –ø–æ–º–æ—â—å—é –∞–ª–≥–æ—Ä–∏—Ç–º–∞ PageRank. –ê–ª–≥–æ—Ä–∏—Ç–º –±—ã–ª –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å—Ç–∞—Ç—å–µ ¬´The Anatomy of Search Engine¬ª, –Ω–∞–ø–∏—Å–∞–Ω–Ω–æ–π –°–µ—Ä–≥–µ–µ–º –ë—Ä–∏–Ω–æ–º –∏ –õ–∞—Ä—Ä–∏ –ü–µ–π–¥–∂–µ–º, –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—è–º–∏ Google[13]. –≠—Ç–æ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –æ—Ü–µ–Ω–∫–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–∏, —á—Ç–æ –Ω–∞ ¬´—Ö–æ—Ä–æ—à–∏–µ¬ª –∏ ¬´–≤–∞–∂–Ω—ã–µ¬ª —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å—Å—ã–ª–∞—é—Ç—Å—è –±–æ–ª—å—à–µ, —á–µ–º –Ω–∞ –¥—Ä—É–≥–∏–µ. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Google –≤—ã–¥–µ—Ä–∂–∞–Ω –≤ —Å–ø–∞—Ä—Ç–∞–Ω—Å–∫–æ–º —Å—Ç–∏–ª–µ, –≥–¥–µ –Ω–µ—Ç –Ω–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ, –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –º–Ω–æ–≥–∏—Ö —Å–≤–æ–∏—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–∞–∏–≤–∞–ª–∏ –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –≤ –≤–µ–±-–ø–æ—Ä—Ç–∞–ª. –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ Google —Å—Ç–∞–ª–∞ –Ω–∞—Å—Ç–æ–ª—å–∫–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ–π, —á—Ç–æ –ø–æ—è–≤–∏–ª–∏—Å—å –ø–æ–¥—Ä–∞–∂–∞—é—â–∏–µ –µ–π —Å–∏—Å—Ç–µ–º—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, Mystery Seeker[–∞–Ω–≥–ª.](—Ç–∞–π–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤–∏–∫). –ö 2000¬†–≥–æ–¥—É Yahoo! –æ—Å—É—â–µ—Å—Ç–≤–ª—è–ª –ø–æ–∏—Å–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏—Å—Ç–µ–º—ã Inktomi. Yahoo! –≤ 2002¬†–≥–æ–¥—É –∫—É–ø–∏–ª Inktomi, –∞ –≤ 2003¬†–≥–æ–¥—É –∫—É–ø–∏–ª Overture, –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞–ª–∏ AlltheWeb[–∞–Ω–≥–ª.] –∏ AltaVista. –ó–∞—Ç–µ–º Yahoo! —Ä–∞–±–æ—Ç–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã Google –≤–ø–ª–æ—Ç—å –¥–æ 2004¬†–≥–æ–¥–∞, –ø–æ–∫–∞ –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª, –Ω–∞–∫–æ–Ω–µ—Ü, —Å–≤–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –∫—É–ø–ª–µ–Ω–Ω—ã—Ö —Ä–∞–Ω–µ–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π. –§–∏—Ä–º–∞ Microsoft –≤–ø–µ—Ä–≤—ã–µ –∑–∞–ø—É—Å—Ç–∏–ª–∞ –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É Microsoft Network Search (MSN Search) –æ—Å–µ–Ω—å—é 1998¬†–≥–æ–¥–∞, –∏—Å–ø–æ–ª—å–∑—É—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –æ—Ç Inktomi. –°–æ–≤—Å–µ–º —Å–∫–æ—Ä–æ –≤ –Ω–∞—á–∞–ª–µ 1999¬†–≥–æ–¥–∞ —Å–∞–π—Ç –Ω–∞—á–∞–ª –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –≤—ã–¥–∞—á—É Looksmart[–∞–Ω–≥–ª.], —Å–º–µ—à–∞–Ω–Ω—É—é —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ Inktomi. –ù–µ–¥–æ–ª–≥–æ (–≤ 1999¬†–≥–æ–¥—É) MSN search –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –æ—Ç AltaVista. –í 2004¬†–≥–æ–¥—É —Ñ–∏—Ä–º–∞ Microsoft –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–æ–∏—Å–∫–æ–≤–æ–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Ä–æ–±–æ—Ç–∞¬†‚Äî msnbot[–∞–Ω–≥–ª.]. –ü–æ—Å–ª–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–µ–±—Ä–µ–Ω–¥–∏–Ω–≥–∞ –∫–æ–º–ø–∞–Ω–∏–µ–π Microsoft 1 –∏—é–Ω—è 2009¬†–≥–æ–¥–∞ –±—ã–ª–∞ –∑–∞–ø—É—â–µ–Ω–∞ –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ Bing. 29 –∏—é–ª—è 2009 Yahoo! –∏ Microsoft –ø–æ–¥–ø–∏—Å–∞–ª–∏ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ, —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ—Ç–æ—Ä–æ–º—É Yahoo! Search —Ä–∞–±–æ—Ç–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ Microsoft Bing. –ù–∞ –º–æ–º–µ–Ω—Ç 2015¬†–≥–æ–¥–∞ —Å–æ—é–∑ Bing –∏ Yahoo! –¥–∞–ª –ø–µ—Ä–≤—ã–µ –Ω–∞—Å—Ç–æ—è—â–∏–µ –ø–ª–æ–¥—ã. –¢–µ–ø–µ—Ä—å Bing –∑–∞–Ω–∏–º–∞–µ—Ç 20,1¬†% —Ä—ã–Ω–∫–∞, –∞ Yahoo! 12,7¬†%, —á—Ç–æ –≤ –æ–±—â–µ–º –∑–∞–Ω–∏–º–∞–µ—Ç 32,60¬†% –æ—Ç –æ–±—â–µ–≥–æ —Ä—ã–Ω–∫–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –≤ –°–®–ê –ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –í 1996¬†–≥–æ–¥—É –±—ã–ª —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–∏—Å–∫ —Å —É—á—ë—Ç–æ–º —Ä—É—Å—Å–∫–æ–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ –Ω–∞ –ø–æ–∏—Å–∫–æ–≤–æ–π –º–∞—à–∏–Ω–µ Altavista –∏ –∑–∞–ø—É—â–µ–Ω—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –º–∞—à–∏–Ω—ã –†–∞–º–±–ª–µ—Ä –∏ –ê–ø–æ—Ä—Ç. 23 —Å–µ–Ω—Ç—è–±—Ä—è 1997¬†–≥–æ–¥–∞ –±—ã–ª–∞ –æ—Ç–∫—Ä—ã—Ç–∞ –ø–æ–∏—Å–∫–æ–≤–∞—è –º–∞—à–∏–Ω–∞ –Ø–Ω–¥–µ–∫—Å. –í 2014¬†–≥–æ–¥—É –∫–æ–º–ø–∞–Ω–∏—è –†–æ—Å—Ç–µ–ª–µ–∫–æ–º –æ—Ç–∫—Ä—ã–ª–∞ –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –ø–æ–∏—Å–∫–æ–≤—É—é –º–∞—à–∏–Ω—É –°–ø—É—Ç–Ω–∏–∫, –∫–æ—Ç–æ—Ä–∞—è –±—ã–ª–∞ –∑–∞–∫—Ä—ã—Ç–∞ –≤ 2017¬†–≥–æ–¥—É, –ø–æ—Å–∫–æ–ª—å–∫—É –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç –±—ã–ª –ø—Ä–∏–∑–Ω–∞–Ω –Ω–µ—É–¥–∞—á–Ω—ã–º, —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–≤—à–∏–º —Ç–æ–ª—å–∫–æ –±–ª–∞–≥–æ–¥–∞—Ä—è –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–µ. –ë–æ–ª—å—à—É—é –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏–ª–∏ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø–æ–∏—Å–∫–∞ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º. –ò–∑ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –º–∞—à–∏–Ω —Ç–∞–∫–æ–≥–æ –ø–ª–∞–Ω–∞ –Ω–∞–∏–±–æ–ª—å—à—É—é –∏–∑–≤–µ—Å—Ç–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏–ª–∞ ¬´Clusty¬ª[–∞–Ω–≥–ª.] –∫–æ–º–ø–∞–Ω–∏–∏ Vivisimo[–∞–Ω–≥–ª.]. –í 2005¬†–≥–æ–¥—É –≤ –†–æ—Å—Å–∏–∏ –ø—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ –ú–ì–£ –∑–∞–ø—É—â–µ–Ω –ø–æ–∏—Å–∫–æ–≤–∏–∫ ¬´–ù–∏–≥–º–∞¬ª, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é. –í 2006¬†–≥–æ–¥—É –æ—Ç–∫—Ä—ã–ª–∞—Å—å —Ä–æ—Å—Å–∏–π—Å–∫–∞—è –º–µ—Ç–∞–º–∞—à–∏–Ω–∞ Quintura, –ø—Ä–µ–¥–ª–∞–≥–∞—é—â–∞—è –≤–∏–∑—É–∞–ª—å–Ω—É—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –≤ –≤–∏–¥–µ –æ–±–ª–∞–∫–∞ —Ç–µ–≥–æ–≤. ¬´–ù–∏–≥–º–∞¬ª —Ç–æ–∂–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª–∞[14] —Å –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π. –û—Å–Ω–æ–≤–Ω—ã–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã: –ø–æ–∏—Å–∫–æ–≤—ã–π —Ä–æ–±–æ—Ç, –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä, –ø–æ–∏—Å–∫–æ–≤–∏–∫[15]. –ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, —Å–∏—Å—Ç–µ–º—ã —Ä–∞–±–æ—Ç–∞—é—Ç –ø–æ—ç—Ç–∞–ø–Ω–æ. –°–Ω–∞—á–∞–ª–∞ –ø–æ–∏—Å–∫–æ–≤—ã–π —Ä–æ–±–æ—Ç –ø–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, –∑–∞—Ç–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω–¥–µ–∫—Å, –∏ –Ω–∞–∫–æ–Ω–µ—Ü, –ø–æ–∏—Å–∫–æ–≤–∏–∫ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ß—Ç–æ–±—ã –æ–±–Ω–æ–≤–∏—Ç—å –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É, —ç—Ç–æ—Ç —Ü–∏–∫–ª –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ[15]. –ü–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Ä–∞–±–æ—Ç–∞—é—Ç, —Ö—Ä–∞–Ω—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–Ω–æ–≥–∏—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω–∏ –ø–æ–ª—É—á–∞—é—Ç –∏–∑ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü. –ü–æ–∏—Å–∫–æ–≤—ã–π —Ä–æ–±–æ—Ç (–∞–Ω–≥–ª.¬†Crawler)¬†‚Äî –ø—Ä–æ–≥—Ä–∞–º–º–∞, –∫–æ—Ç–æ—Ä–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –≤—Å–µ–º —Å—Å—ã–ª–∫–∞–º, –Ω–∞–π–¥–µ–Ω–Ω—ã–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –∏ –≤—ã–¥–µ–ª—è–µ—Ç –∏—Ö. –ü–æ–∏—Å–∫–æ–≤—ã–π —Ä–æ–±–æ—Ç, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Å—Å—ã–ª–∫–∞—Ö –∏–ª–∏ –∏—Å—Ö–æ–¥—è –∏–∑ –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∞–¥—Ä–µ—Å–æ–≤, –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç –ø–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –µ—â—ë –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ. –í–ª–∞–¥–µ–ª–µ—Ü —Å–∞–π—Ç–∞ –º–æ–∂–µ—Ç –∏—Å–∫–ª—é—á–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–∏ –ø–æ–º–æ—â–∏ robots.txt, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∑–∞–ø—Ä–µ—Ç–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤, —Å—Ç—Ä–∞–Ω–∏—Ü –∏–ª–∏ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ —Å–∞–π—Ç–∞. –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è. –°–ª–æ–≤–∞ –º–æ–≥—É—Ç –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π¬†‚Äî –º–µ—Ç–∞—Ç–µ–≥–æ–≤. –ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä¬†‚Äî —ç—Ç–æ –º–æ–¥—É–ª—å, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤ –µ—ë –Ω–∞ —á–∞—Å—Ç–∏, –ø—Ä–∏–º–µ–Ω—è—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã. –í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã—á–ª–µ–Ω—è—é—Ç—Å—è –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ. –î–∞–Ω–Ω—ã–µ –æ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –∏–Ω–¥–µ–∫—Å–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö. –ò–Ω–¥–µ–∫—Å –ø–æ–∑–≤–æ–ª—è–µ—Ç –±—ã—Å—Ç—Ä–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è[16]. –†—è–¥ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º, –ø–æ–¥–æ–±–Ω—ã—Ö Google, —Ö—Ä–∞–Ω—è—Ç –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ü–µ–ª–∏–∫–æ–º –∏–ª–∏ –µ—ë —á–∞—Å—Ç—å, —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–π –∫—ç—à, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–ª–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ. –î—Ä—É–≥–∏–µ —Å–∏—Å—Ç–µ–º—ã, –ø–æ–¥–æ–±–Ω—ã–µ —Å–∏—Å—Ç–µ–º–µ AltaVista, —Ö—Ä–∞–Ω—è—Ç –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—ç—à–∞ –ø–æ–º–æ–≥–∞–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å —É–∂–µ –ø–æ—Å–µ—â—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü[16]. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—Å–µ–≥–¥–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ—Ç —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –≤ –ø–æ–∏—Å–∫–æ–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–æ –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –∫–æ–≥–¥–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–±–Ω–æ–≤–∏–ª–∞—Å—å, —Ç–æ –µ—Å—Ç—å —É–∂–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤ –∫—ç—à–µ –µ—â—ë —Å—Ç–∞—Ä–∞—è[16]. –≠—Ç–∞ —Å–∏—Ç—É–∞—Ü–∏—è —Å–≤—è–∑–∞–Ω–∞ —Å –ø–æ—Ç–µ—Ä–µ–π —Å—Å—ã–ª–æ–∫ (–∞–Ω–≥–ª.¬†linkrot) –∏ –¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (—é–∑–∞–±–∏–ª–∏—Ç–∏) –ø–æ–¥—Ö–æ–¥–æ–º Google. –≠—Ç–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –≤—ã–¥–∞—á—É –∏–∑ –∫—ç—à–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞. –î–µ–π—Å—Ç–≤—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø –Ω–∞–∏–º–µ–Ω—å—à–µ–≥–æ —É–¥–∏–≤–ª–µ–Ω–∏—è, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–±—ã—á–Ω–æ –æ–∂–∏–¥–∞–µ—Ç —É–≤–∏–¥–µ—Ç—å –∏—Å–∫–æ–º—ã–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (User expectations[–∞–Ω–≥–ª.]). –ö—Ä–æ–º–µ —Ç–æ–≥–æ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —É—Å–∫–æ—Ä—è–µ—Ç –ø–æ–∏—Å–∫, —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –∫—ç—à–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–∞–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –Ω–∏–≥–¥–µ –±–æ–ª–µ–µ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–∏—Å–∫–æ–≤–∏–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –≤—ã—Ö–æ–¥–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –æ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞. –ü–æ–∏—Å–∫–æ–≤–∏–∫ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∏–Ω–¥–µ–∫—Å–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞[15]. –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–æ–¥–∏—Ç –∑–∞–ø—Ä–æ—Å –≤ –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É (–æ–±—ã—á–Ω–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤), —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–æ–π –∏–Ω–¥–µ–∫—Å –∏ –≤—ã–¥–∞—ë—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –∫–∞–∫–æ–º—É-–ª–∏–±–æ –∫—Ä–∏—Ç–µ—Ä–∏—é), –æ–±—ã—á–Ω–æ —Å –∫—Ä–∞—Ç–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π, —Å–æ–¥–µ—Ä–∂–∞—â–µ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏–Ω–æ–≥–¥–∞ —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞[16]. –ü–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –º–µ—Ç–æ–¥–∏–∫–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∏–∑–≤–ª–µ—á—ë–Ω–Ω–æ–π –∏–∑ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü[12]. –° 2007¬†–≥–æ–¥–∞ –ø–æ–∏—Å–∫–æ–≤–∏–∫ Google –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫–∞—Ç—å —Å —É—á—ë—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å–∫–æ–º—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤—ã–∑–æ–≤ –º–µ–Ω—é ¬´–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ–∏—Å–∫–∞¬ª –∏ —É–∫–∞–∑–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞). –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ –ò, –ò–õ–ò, –ù–ï, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏—Å–∫–æ–º—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤. –ü—Ä–∏ —ç—Ç–æ–º —Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Å–ª–æ–≤–∞ –∏–ª–∏ —Ñ—Ä–∞–∑—ã —Ç–æ—á–Ω–æ —Ç–∞–∫, –∫–∞–∫ –±—ã–ª–æ –≤–≤–µ–¥–µ–Ω–æ. –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞[–∞–Ω–≥–ª.], –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Ä–∞—Å—à–∏—Ä—è—é—Ç –æ–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞, —É–∫–∞–∑—ã–≤–∞—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤[16]. –ï—Å—Ç—å —Ç–∞–∫–∂–µ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫[–∞–Ω–≥–ª.], –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏—Å–∫–æ–º—ã—Ö —Å–ª–æ–≤ –∏ —Ñ—Ä–∞–∑ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü. –≠—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∑–≤–æ–ª—è—é—Ç —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ. –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü –∏ –º–æ–≥—É—Ç –≤–∫–ª—é—á–∞—Ç—å –Ω–µ–∫–æ–µ —Å–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑—É, –Ω–æ –æ–¥–Ω–∏ –∏–∑ –Ω–∏—Ö –º–æ–≥—É—Ç –±—ã—Ç—å –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã, –ø–æ–ø—É–ª—è—Ä–Ω—ã –∏–ª–∏ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã, —á–µ–º –¥—Ä—É–≥–∏–µ. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤—ã–≤–µ—Å—Ç–∏ –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞ ¬´–ª—É—á—à–∏–µ¬ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ü–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Ä–µ—à–∞—é—Ç, –∫–∞–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã, –∏ –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–∫–∞–∑–∞–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø–æ-—Ä–∞–∑–Ω–æ–º—É[16]. –ú–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞, –∫–∞–∫ –∏ —Å–∞–º –ò–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –º–µ–Ω—è—é—Ç—Å—è. –¢–∞–∫ –ø–æ—è–≤–∏–ª–∏—Å—å –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º: —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö –∏ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ —Å–∏—Å—Ç–µ–º—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º —è–≤–ª—è—é—Ç—Å—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º–∏ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—É—á–∞—é—Ç –ø—Ä–∏–±—ã–ª—å –∑–∞ —Å—á—ë—Ç —Ä–µ–∫–ª–∞–º—ã, –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞—Ö –º–æ–∂–Ω–æ –∫—É–ø–∏—Ç—å –∑–∞ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–ª–∞—Ç—É –ø–µ—Ä–≤—ã–µ –º–µ—Å—Ç–∞ –≤ –≤—ã–¥–∞—á–µ –¥–ª—è –∑–∞–¥–∞–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤. –¢–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±–µ—Ä—É—Ç –¥–µ–Ω–µ–≥ –∑–∞ –ø–æ—Ä—è–¥–æ–∫ –≤—ã–¥–∞—á–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Ä–µ–∫–ª–∞–º–µ, –ø—Ä–∏ —ç—Ç–æ–º —Ä–µ–∫–ª–∞–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –¢–∞–∫–∞—è —Ä–µ–∫–ª–∞–º–∞ –≤—ã–≤–æ–¥–∏—Ç—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Å–æ —Å–ø–∏—Å–∫–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞, –∏ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∏ –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∫–ª–∏–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Ä–µ–∫–ª–∞–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –°—É—â–µ—Å—Ç–≤—É–µ—Ç —á–µ—Ç—ã—Ä–µ —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º: —Å –ø–æ–∏—Å–∫–æ–≤—ã–º–∏ —Ä–æ–±–æ—Ç–∞–º–∏, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —á–µ–ª–æ–≤–µ–∫–æ–º, –≥–∏–±—Ä–∏–¥–Ω—ã–µ –∏ –º–µ—Ç–∞-—Å–∏—Å—Ç–µ–º—ã[17]. Google¬†‚Äî —Å–∞–º–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤ –º–∏—Ä–µ —Å –¥–æ–ª–µ–π –Ω–∞ —Ä—ã–Ω–∫–µ 92,16¬†%. Bing –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ç–æ—Ä—É—é –ø–æ–∑–∏—Ü–∏—é, –µ–≥–æ –¥–æ–ª—è 2,88¬†%[18]. –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –≤ –º–∏—Ä–µ[19]: –í –≤–æ—Å—Ç–æ—á–Ω–æ–∞–∑–∏–∞—Ç—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∞—Ö –∏ –≤ –†–æ—Å—Å–∏–∏ Google¬†‚Äî –Ω–µ —Å–∞–º–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞. –í –ö–∏—Ç–∞–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, –±–æ–ª–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω–∞ –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ Soso. –í –Æ–∂–Ω–æ–π –ö–æ—Ä–µ–µ –ø–æ–∏—Å–∫–æ–≤—ã–º –ø–æ—Ä—Ç–∞–ª–æ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Naver –ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–∫–æ–ª–æ 70¬†% –∂–∏—Ç–µ–ª–µ–π[22] Yahoo! Japan –∏ Yahoo! Taiwan¬†‚Äî —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –Ø–ø–æ–Ω–∏–∏ –∏ –¢–∞–π–≤–∞–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ[23]. –ü–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π Google –ø–æ–ª—å–∑—É—é—Ç—Å—è 50,3¬†% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –†–æ—Å—Å–∏–∏, –Ø–Ω–¥–µ–∫—Å–æ–º¬†‚Äî 47,9¬†%[24]. –°–æ–≥–ª–∞—Å–Ω–æ –¥–∞–Ω–Ω—ã–º LiveInternet –≤ –¥–µ–∫–∞–±—Ä–µ 2017¬†–≥–æ–¥–∞ –æ–± –æ—Ö–≤–∞—Ç–µ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤[25]: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≤–Ω–µ—à–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∏—Å–∫–∞. –ß–∏—Å–ª–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫ —ç—Ç–∏–º —Å–∏—Å—Ç–µ–º–∞–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Ä–∞—Å—Ç—ë—Ç. –î–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ä–≤–µ—Ä–æ–≤. –°–µ—Ä–≤–µ—Ä–∞ –æ–±—ã—á–Ω–æ –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç –≤ —Å–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ü–µ–Ω—Ç—Ä—ã (–¥–∞—Ç–∞-—Ü–µ–Ω—Ç—Ä—ã). –£ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º —Å–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ü–µ–Ω—Ç—Ä—ã —Ä–∞–∑–±—Ä–æ—Å–∞–Ω—ã –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É. –í –æ–∫—Ç—è–±—Ä–µ 2012¬†–≥–æ–¥–∞ Google –∑–∞–ø—É—Å—Ç–∏–ª–∞ –ø—Ä–æ–µ–∫—Ç ¬´–ì–¥–µ –∂–∏–≤—ë—Ç –ò–Ω—Ç–µ—Ä–Ω–µ—Ç¬ª, –≥–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å —Ü–µ–Ω—Ç—Ä–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ–π –∫–æ–º–ø–∞–Ω–∏–∏[26]. –û —Ä–∞–±–æ—Ç–µ –¥–∞—Ç–∞-—Ü–µ–Ω—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ Google –∏–∑–≤–µ—Å—Ç–Ω–æ —Å–ª–µ–¥—É—é—â–µ–µ[27]: –†–∞–∑–º–µ—Ä –≤—Å–µ–º–∏—Ä–Ω–æ–π –ø–∞—É—Ç–∏–Ω—ã, –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π Google –Ω–∞ –¥–µ–∫–∞–±—Ä—å 2014¬†–≥–æ–¥–∞, —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 4,36 –º–∏–ª–ª–∏–∞—Ä–¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü[28]. –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É—Å—É–ª—å–º–∞–Ω—Å–∫–æ–º –º–∏—Ä–µ, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤ —Å—Ç—Ä–∞–Ω–∞—Ö –ë–ª–∏–∂–Ω–µ–≥–æ –í–æ—Å—Ç–æ–∫–∞ –∏ –ò–Ω–¥–∏–π—Å–∫–æ–≥–æ —Å—É–±–∫–æ–Ω—Ç–∏–Ω–µ–Ω—Ç–∞, —Å–ø–æ—Å–æ–±—Å—Ç–≤–æ–≤–∞–ª–æ —Ä–∞–∑–≤–∏—Ç–∏—é –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º, —É—á–∏—Ç—ã–≤–∞—é—â–∏—Ö –∏—Å–ª–∞–º—Å–∫–∏–µ —Ç—Ä–∞–¥–∏—Ü–∏–∏. –¢–∞–∫–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥–∞—é—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –Ω–µ –ø–æ–ø–∞–¥–∞—Ç—å –Ω–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–∞–π—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–∞–π—Ç—ã —Å –ø–æ—Ä–Ω–æ–≥—Ä–∞—Ñ–∏–µ–π, –∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ —Ç–µ–º–∏ —Å–∞–π—Ç–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç –∏—Å–ª–∞–º—Å–∫–æ–π –≤–µ—Ä–µ. –ù–µ–∑–∞–¥–æ–ª–≥–æ –¥–æ –º—É—Å—É–ª—å–º–∞–Ω—Å–∫–æ–≥–æ –º–µ—Å—è—Ü–∞ –†–∞–º–∞–¥–∞–Ω, –≤ –∏—é–ª–µ 2013¬†–≥–æ–¥–∞, –º–∏—Ä—É –±—ã–ª –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω Halalgoogling[–∞–Ω–≥–ª.]¬†‚Äî —Å–∏—Å—Ç–µ–º–∞, –≤—ã–¥–∞—é—â–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ç–æ–ª—å–∫–æ —Ö–∞–ª—è–ª—å–Ω—ã–µ ¬´–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ¬ª —Å—Å—ã–ª–∫–∏[29], —Ñ–∏–ª—å—Ç—Ä—É—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –æ—Ç –¥—Ä—É–≥–∏—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º, —Ç–∞–∫–∏—Ö –∫–∞–∫ Google –∏ Bing. –î–≤—É–º—è –≥–æ–¥–∞–º–∏ —Ä–∞–Ω–µ–µ, –≤ —Å–µ–Ω—Ç—è–±—Ä–µ 2011¬†–≥–æ–¥–∞, –±—ã–ª –∑–∞–ø—É—â–µ–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ I‚ÄômHalal, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–π –¥–ª—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ë–ª–∏–∂–Ω–µ–≥–æ –í–æ—Å—Ç–æ–∫–∞. –û–¥–Ω–∞–∫–æ —ç—Ç–æ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å –ø—Ä–∏—à–ª–æ—Å—å –≤—Å–∫–æ—Ä–µ –∑–∞–∫—Ä—ã—Ç—å, –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é –≤–ª–∞–¥–µ–ª—å—Ü–∞, –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è[30]. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –∏ –º–µ–¥–ª–µ–Ω–Ω—ã–π —Ç–µ–º–ø —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –º—É—Å—É–ª—å–º–∞–Ω—Å–∫–æ–º –º–∏—Ä–µ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å—É –∏ –º–µ—à–∞–ª–∏ —É—Å–ø–µ—Ö—É —Å–µ—Ä—å—ë–∑–Ω–æ–≥–æ –∏—Å–ª–∞–º—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞. –û—á–µ–≤–∏–¥–µ–Ω –ø—Ä–æ–≤–∞–ª –æ–≥—Ä–æ–º–Ω—ã—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ –≤–µ–±-–ø—Ä–æ–µ–∫—Ç—ã –º—É—Å—É–ª—å–º–∞–Ω—Å–∫–æ–≥–æ –æ–±—Ä–∞–∑–∞ –∂–∏–∑–Ω–∏, –æ–¥–Ω–∏–º –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª Muxlim[–∞–Ω–≥–ª.]. –û–Ω –ø–æ–ª—É—á–∏–ª –º–∏–ª–ª–∏–æ–Ω—ã –¥–æ–ª–ª–∞—Ä–æ–≤ –æ—Ç –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ Rite Internet Ventures, –∏ —Ç–µ–ø–µ—Ä—å¬†‚Äî –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ—Ç I‚ÄômHalal –ø–µ—Ä–µ–¥ –µ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏–µ–º¬†‚Äî –≤—ã—Å—Ç—É–ø–∞–µ—Ç —Å —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–¥–µ–µ–π –æ —Ç–æ–º, —á—Ç–æ ¬´—Å–ª–µ–¥—É—é—â–∏–π Facebook –∏–ª–∏ Google –º–æ–≥—É—Ç –ø–æ—è–≤–∏—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –≤ —Å—Ç—Ä–∞–Ω–∞—Ö –ë–ª–∏–∂–Ω–µ–≥–æ –í–æ—Å—Ç–æ–∫–∞, –µ—Å–ª–∏ –≤—ã –ø–æ–¥–¥–µ—Ä–∂–∏—Ç–µ –Ω–∞—à—É –±–ª–µ—Å—Ç—è—â—É—é –º–æ–ª–æ–¥—ë–∂—å¬ª[–∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω 1716 –¥–Ω–µ–π]. –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ –∏—Å–ª–∞–º—Å–∫–∏–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –≤ –æ–±–ª–∞—Å—Ç–∏ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –≤ —Ç–µ—á–µ–Ω–∏–µ –º–Ω–æ–≥–∏—Ö –ª–µ—Ç –∑–∞–Ω–∏–º–∞—é—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–æ–≥–æ, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞—Ä–∏–∞—Ç—É, –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é—Ç –≤–µ–±-—Å–∞–π—Ç—ã –∫–∞–∫ ¬´—Ö–∞–ª—è–ª—å¬ª –∏–ª–∏ ¬´—Ö–∞—Ä–∞–º¬ª. –í—Å–µ –±—ã–≤—à–∏–µ –∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏—Å–ª–∞–º—Å–∫–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –ø—Ä–æ—Å—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ª–∏–±–æ —ç—Ç–æ –≥–ª–∞–≤–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ Google, Yahoo –∏ Bing, —Å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–µ–π—Å—è –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ –º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Ö–∞—Ä–∞–º-—Å–∞–π—Ç–∞–º, —Ç–∞–∫–∏–º –∫–∞–∫ —Å–∞–π—Ç—ã –æ –Ω–∞–≥–æ—Ç–µ, –õ–ì–ë–¢, –∞–∑–∞—Ä—Ç–Ω—ã—Ö –∏–≥—Ä–∞—Ö –∏ –∫–∞–∫–∏–º-–ª–∏–±–æ –¥—Ä—É–≥–∏–º, —Ç–µ–º–∞—Ç–∏–∫–∞ –∫–æ—Ç–æ—Ä—ã—Ö —Å—á–∏—Ç–∞–µ—Ç—Å—è –∞–Ω—Ç–∏–∏—Å–ª–∞–º—Å–∫–æ–π[–∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω 1716 –¥–Ω–µ–π]. –°—Ä–µ–¥–∏ –¥—Ä—É–≥–∏—Ö —Ä–µ–ª–∏–≥–∏–æ–∑–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–º–∏ —è–≤–ª—è—é—Ç—Å—è Jewogle¬†‚Äî –µ–≤—Ä–µ–π—Å–∫–∞—è –≤–µ—Ä—Å–∏—è Google –∏ SeekFind.org¬†‚Äî —Ö—Ä–∏—Å—Ç–∏–∞–Ω—Å–∫–∏–π —Å–∞–π—Ç, –≤–∫–ª—é—á–∞—é—â–∏–π –≤ —Å–µ–±—è —Ñ–∏–ª—å—Ç—Ä—ã, –æ–±–µ—Ä–µ–≥–∞—é—â–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –ø–æ–¥–æ—Ä–≤–∞—Ç—å –∏–ª–∏ –æ—Å–ª–∞–±–∏—Ç—å –∏—Ö –≤–µ—Ä—É[31]. –ú–Ω–æ–≥–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ Google –∏ Bing, –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã –≤—ã–±–æ—Ä–æ—á–Ω–æ–≥–æ —É–≥–∞–¥—ã–≤–∞–Ω–∏—è —Ç–æ–≥–æ, –∫–∞–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—Ç–µ–ª –±—ã —É–≤–∏–¥–µ—Ç—å, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –µ–≥–æ –ø—Ä–æ—à–ª—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è—Ö –≤ —Å–∏—Å—Ç–µ–º–µ. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ, –≤–µ–±-—Å–∞–π—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ —Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å –ø—Ä–æ—à–ª—ã–º–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –≠—Ç–æ—Ç —ç—Ñ—Ñ–µ–∫—Ç –ø–æ–ª—É—á–∏–ª –Ω–∞–∑–≤–∞–Ω–∏–µ ¬´–ø—É–∑—ã—Ä—å —Ñ–∏–ª—å—Ç—Ä–æ–≤¬ª[32]. –í—Å—ë —ç—Ç–æ –≤–µ–¥—ë—Ç –∫ —Ç–æ–º—É, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø–æ–ª—É—á–∞—é—Ç –Ω–∞–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–µ–π —Å–≤–æ–µ–π —Ç–æ—á–∫–µ –∑—Ä–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤ —Å–≤–æ—ë–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º ¬´–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–º –ø—É–∑—ã—Ä–µ¬ª. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, ¬´—ç—Ñ—Ñ–µ–∫—Ç –ø—É–∑—ã—Ä—è¬ª –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –º–Ω–µ–Ω–∏—è[33]. –í –Ω–∞—á–∞–ª–µ 2024 –≥–æ–¥–∞ Google –≤–Ω–µ–¥—Ä–∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –≤ —Å–≤–æ—é –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É[34]. –ß–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤, –Ø–Ω–¥–µ–∫—Å –∑–∞–ø—É—Å—Ç–∏–ª–∏ –≤ —Å–≤–æ—ë–º —Å–µ—Ä–≤–∏—Å–µ \"–ü–æ–∏—Å–∫–∞\" —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª \"–ù–µ–π—Ä–æ\"[35], –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö —Ä–∞–±–æ—Ç—ã Yandex GPT –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –∑–∞–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω—ã, —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –≤–µ–±-—Å–∞–π—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∏—Ö –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏, –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ —Ç–æ, —á—Ç–æ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –æ–∫–∞–∑—ã–≤–∞—é—Ç –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ø–æ–∏—Å–∫–æ–≤—É—é –≤—ã–¥–∞—á—É[36][37]. –¢–∞–∫–∞—è –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä—è–º—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: –∫–æ–º–ø–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∫–ª–∞–º–∏—Ä—É—é—Ç—Å—è –≤ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ, –º–æ–≥—É—Ç —Å—Ç–∞—Ç—å –±–æ–ª–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –Ω–µ–π. –£–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Å—Ç–Ω—ã–º –∑–∞–∫–æ–Ω–∞–º, —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä–æ–º –≤–ª–∏—è–Ω–∏—è –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, Google –Ω–µ –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–Ω–∞—Ü–∏—Å—Ç—Å–∫–∏–µ –≤–µ–±-—Å–∞–π—Ç—ã –≤–æ –§—Ä–∞–Ω—Ü–∏–∏ –∏ –ì–µ—Ä–º–∞–Ω–∏–∏, –≥–¥–µ –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ –•–æ–ª–æ–∫–æ—Å—Ç–∞ –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ[38]. –ü—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å –º–æ–∂–µ—Ç —Ç–∞–∫–∂–µ –±—ã—Ç—å —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º —á–∞—Å—Ç–æ —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –Ω–µ—Ñ–æ—Ä–º–∞—Ç–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –≤ –ø–æ–ª—å–∑—É –±–æ–ª–µ–µ ¬´–ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö¬ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤[39]. –ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≥–ª–∞–≤–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º –æ—Ç–¥–∞—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–º —Å–∞–π—Ç–∞–º[37]. –ü–æ–∏—Å–∫–æ–≤–∞—è –±–æ–º–±–∞¬†‚Äî –æ–¥–∏–Ω –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ–ø—ã—Ç–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–º, —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º –∏–ª–∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø—Ä–∏—á–∏–Ω–∞–º."
  },
  {
    "url": "https://si.wikipedia.org/wiki/%E0%B7%80%E0%B7%99%E0%B6%B6%E0%B7%8A_%E0%B7%83%E0%B7%99%E0%B7%80%E0%B7%94%E0%B6%B8%E0%B7%8A_%E0%B6%BA%E0%B6%B1%E0%B7%8A%E0%B6%AD%E0%B7%8A%E2%80%8D%E0%B6%BB",
    "title": "‡∑Ä‡∑ô‡∂∂‡∑ä ‡∑É‡∑ô‡∑Ä‡∑î‡∂∏‡∑ä ‡∂∫‡∂±‡∑ä‡∂≠‡∑ä‚Äç‡∂ª - ‡∑Ä‡∑í‡∂ö‡∑í‡∂¥‡∑ì‡∂©‡∑í‡∂∫‡∑è",
    "content": "‡∑Ä‡∑ô‡∂∂‡∑ä ‡∑É‡∑ô‡∑Ä‡∑î‡∂∏‡∑ä ‡∂∫‡∂±‡∑ä‡∂≠‡∑ä‚Äç‡∂ª‡∂∫‡∂ö‡∑ä ‡∂∫‡∂±‡∑î  ‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä ‡∑Ä‡∑í‡∑É‡∑í‡∂ª ‡∑Ä‡∑í‡∂∫‡∂∏‡∂±‡∑ô‡∑Ñ‡∑í ‡∂≠‡∑ú‡∂ª‡∂≠‡∑î‡∂ª‡∑î ‡∂ú‡∑Ä‡∑ö‡∑Ç‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂±‡∑í‡∂¥‡∂Ø‡∑Ä‡∂± ‡∂Ω‡∂Ø ‡∂∏‡∑ò‡∂Ø‡∑î‡∂ö‡∑è‡∂Ç‡∂ú ‡∂¥‡∂Ø‡∑ä‡∂∞‡∂≠‡∑í‡∂∫‡∂ö‡∑í. ‡∂ú‡∑ñ‡∂ú‡∂Ω‡∑ä, ‡∂∫‡∑è‡∑Ñ‡∑ñ ‡∑É‡∑Ñ ‡∂∂‡∑í‡∂Ç, ‡∂ë‡∂∏‡∑ä.‡∂ë‡∑É‡∑ä.‡∂ë‡∂±‡∑ä(msn), ‡∂Ü‡∑É‡∑ä‡∂ö‡∑ä ‡∂¢‡∑ì‡∑Ä‡∑É‡∑ä(ask jeeves) ‡∂¢‡∂±‡∂¥‡∑ä‚Äç‡∂ª‡∑í‡∂∫ ‡∑Ä‡∑ô‡∂∂‡∑ä ‡∑É‡∑ô‡∑Ä‡∑î‡∂∏‡∑ä ‡∂∫‡∂±‡∑ä‡∂≠‡∑ä‚Äç‡∂ª‡∑Ä‡∂Ω‡∂ß ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ ‡∑Ä‡∑ô‡∂∫‡∑í. ‡∑É‡∑ô‡∑Ä‡∑î‡∂∏‡∑ä ‡∂∫‡∂±‡∑ä‡∂≠‡∑ä‚Äç‡∂ª‡∂∫‡∂ö‡∑ä ‡∂∏‡∂ú‡∑í‡∂±‡∑ä ‡∑Ä‡∑ô‡∂∂‡∑ä ‡∂¥‡∑í‡∂ß‡∑î‡∑Ä‡∂Ω‡∂ß ‡∂Ö‡∂∏‡∂≠‡∂ª‡∑Ä ‡∂¥‡∑í‡∂Ç‡∂≠‡∑ñ‡∂ª, ‡∑Ä‡∑ì‡∂©‡∑í‡∂∫‡∑ù ‡∑É‡∑Ñ ‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ‡∂ú‡∑ú‡∂±‡∑î ‡∑Ä‡∂ª‡∑ä‡∂ú ‡∂Ø ‡∑É‡∑ú‡∂∫‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∑ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫‡∑è‡∑Ä ‡∂á‡∂≠."
  },
  {
    "url": "https://simple.wikipedia.org/wiki/Search_engine",
    "title": "Search engine - Simple English Wikipedia, the free encyclopedia",
    "content": "A search engine is a website that allows users to look up information on the World Wide Web (WWW), part of the Internet. The search engine will achieve this by looking at many web pages to find matches to the user's search inputs. It will return results ranked by relevancy and popularity by the search engine. The most popular search-engines are Google Search and Bing. Older services include Webcrawler are,  Yahoo! Search, Ask.com, Lycos, and Alta Vista.[1] Examples of specialized engines are Ecosia (supports ecological goals) or Tenor (picture engine). To use a search engine you must enter at least one keyword into the search box. Usually, an on-screen button must be clicked on to submit the search. The search engine looks for matches between the keyword(s) entered and its database of websites and words. After the user inputs their search or query into the search bar, a list of results will appear on the screen known as the search engine results page (SERP). This list of webpages contains matches related to the user's query in a particular order determined by a ranking system. Most search engines will remove \"spam\" pages from the list of results to provide a better list of results. The user can then click on any of the links to go to that webpage. Search engines are some of the most advanced websites on the web. They use special computer code to sort the web pages on SERPs. The most popular or highest-quality web pages will be near the top of the list. When a user types words into the search engine, it looks for web pages with those words. There could be thousands, or even millions, of web pages with those words. So, the search engine helps users by putting the web pages it thinks the user wants first. Search engines are very useful to find information about anything quickly and easily. Using more keywords or different keywords improves the results of searches. A search service may also include a portal with news, games, and more information besides a search engine.  Yahoo! has a popular portal, while Google has a simple design on its front page.  Search services usually work without charging money for finding sites, and are often supported with text or banner advertisements. Search engines use robots to ‚Äòcrawl‚Äô online content. The process of crawling is the first measure that search engines take before indexing content in virtually any form‚Äìvideos, text, images, webpages, etc. The content may constitute newly uploaded content to the internet or content that features updates or changes to its material. These robots, also known as crawlers or bots, record the information along with its links. Once the material has been crawled, it can be stored in a massive URL database. It‚Äôs this database that generates internet search results. After the bots crawl content, it can be indexed in the database and arranged in terms of its relevance. If internet content has not been crawled or indexed, it is unlikely to appear in the search results when someone makes a query no matter how relevant that content may be. After the content has been crawled, each of its words is indexed. The search engines also pinpoint where words are located on the crawled pages. During the indexing process, the search engine compares the content to other content with similar ‚Äòwords‚Äô and decides how to organize it within its index. Ranking is a complex process that is dependent on search engine algorithms. When a searcher makes a query on Google looking for anything from 19th-century British landscape painters to New York City plumbers, the search engine will generate a list of good matches to that query. How these matches appear in the list relates to their rank. The search engine lists what it ‚Äòthinks‚Äô are the best answers to the query early in its search results.[2] Google and other search engines rely on algorithms to interpret the searcher‚Äôs query, identify the websites and pages in its index that are related to the request, and it then ranks them in terms of relevance in its presented search results list. What‚Äôs important to search engines is to provide searchers with the most relevant matches to their queries possible. Website operators, in turn, use search engine optimization to give their pages a higher rank."
  },
  {
    "url": "https://sd.wikipedia.org/wiki/%D9%88%D9%8A%D8%A8_%DA%B3%D9%88%D9%84%D8%A7_%D8%A7%D9%86%D8%AC%DA%BB",
    "title": "ŸàŸäÿ® ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª - Ÿà⁄™ŸäŸæŸä⁄äŸäÿß",
    "content": "ŸàŸäÿ® ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª¬†Ÿá⁄™ ÿ≥ÿßŸÅŸΩŸàŸäÿ¶ÿ± ÿ≥ÿ≥ŸΩŸÖ ÿ¢ŸáŸäÿå ÿ¨Ÿä⁄™Ÿà ÿπÿßŸÑŸÖ⁄ØŸäÿ± ŸàŸäÿ® ŸÖÿßŸÜ ⁄Ñÿß⁄ª ÿ¨Ÿä ⁄≥ŸàŸÑÿß ŸÑÿßÿ°Ÿê ÿ¨Ÿà⁄ôŸäŸà ŸàŸäŸà ÿ¢ŸáŸä. ⁄≥ŸàŸÑÿß ÿ¨ÿß ŸÜÿ™Ÿäÿ¨ÿß ÿπŸÖŸàŸÖŸä ÿ∑Ÿàÿ± ŸÇÿ∑ÿßÿ± €æ ⁄èŸä⁄©ÿßÿ±Ÿäÿß Ÿà⁄ÉŸÜ Ÿøÿßÿå ÿ¨ŸÜ ⁄©Ÿä ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª ŸÜÿ™Ÿäÿ¨ŸÜ Ÿàÿßÿ±Ÿà ÿµŸÅÿ≠ÿß ⁄ÜŸäŸà ŸàŸäŸÜÿØŸà ÿ¢ŸáŸä. ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª Ÿæÿßÿ±ÿßŸÜ ⁄≥ŸàŸÑŸäŸÑ ŸÜÿ™Ÿäÿ¨ŸÜ €æ ŸàŸäÿ® ÿµŸÅÿ≠ÿßÿå ÿ™ÿµŸàŸäÿ±ŸàŸÜ €Ω ŸªŸäŸÜ ŸÇÿ≥ŸÖŸÜ ÿ¨ÿß ŸÅÿßÿ¶ŸäŸÑ ÿ¥ÿßŸÖŸÑ ŸáŸàŸÜÿØÿß ÿ¢ŸáŸÜ. ⁄™ÿ¨ŸáŸá ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª ŸÖŸäÿ≥ÿ±¬†ÿ≥ÿ±ŸÜÿßŸÖŸÜ ÿ¨Ÿä ⁄™ÿ™ÿßÿ® ŸÖÿßŸÜ Ÿæ⁄ª ⁄Ñÿß⁄ª ⁄≥ŸàŸÑŸä ⁄èŸäŸÜÿØÿß ÿ¢ŸáŸÜ. ŸàŸäÿ®¬†ÿ≥ÿ±ŸÜÿßŸÖŸÜ ÿ¨Ÿà ⁄™ÿ™ÿßÿ® ÿ¨ŸÜŸáŸÜ €æ ⁄Ñÿß⁄ª ⁄©Ÿä ŸÖÿß⁄ªŸáŸà ÿ¥ÿßŸÖŸÑ ⁄™ŸÜÿØÿß ÿ¢ŸáŸÜÿå Ÿæÿ± ŸàŸäÿ® ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª ÿßŸÑÿÆŸàÿßÿ±ÿ≤ŸÖŸä (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: Algorithm) ÿ¨Ÿä ŸÖÿØÿØ ÿ≥ÿßŸÜ ÿπÿßŸÑŸÖ⁄ØŸäÿ± ŸàŸäÿ® ŸÖÿßŸÜ ⁄Ñÿß⁄ª ÿ™ŸÑÿßÿ¥ ⁄™ŸÜÿØÿß ÿ¢ŸáŸÜ. ÿßŸÜŸΩÿ±ŸÜŸäŸΩ €æ ÿßŸáÿß ⁄Ñÿß⁄ª ÿ¨ŸÜ ÿ™ÿßÿ¶ŸäŸÜ ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª ⁄©Ÿä ŸæŸá⁄Ü ÿ≠ÿßÿµŸÑ ŸÜŸá Ÿáÿ¨Ÿä ÿßŸÜ ⁄©Ÿä ÿßŸàŸÜŸáŸà ŸàŸäÿ® (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: Deep Web) ⁄ÜŸäŸà ŸàŸäŸÜÿØŸà ÿ¢ŸáŸä. ÿßŸÜŸΩÿ±ŸÜŸäŸΩ ÿßŸÜÿØÿ± ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª ÿ¨Ÿà ÿ®ŸÜŸäÿßÿØ 1990 ⁄åÿßÿ±Ÿä ŸæŸäŸà. ⁄™Ÿäÿ± ÿ¢ŸáŸä (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: Whois) €æ ŸàÿßŸæÿ±ÿßÿ¶ŸäŸÜÿØ⁄ô ÿ¨Ÿä ⁄≥ŸàŸÑÿß ÿ¨Ÿä ÿ¥ÿ±Ÿàÿπÿßÿ™ 1982ÿπ €æ ŸøŸä[1] €Ω ŸÜŸàŸÜÿ®ŸàŸΩ ÿßŸÜŸÅÿßÿ±ŸÖŸäÿ¥ŸÜ ÿ≥ÿ±Ÿàÿ≥ (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: Knowbot information Service) ÿ¨Ÿä ÿ¥ÿ±Ÿàÿπÿßÿ™ 1989ÿπ €æ ŸøŸä.[2] ŸæŸáÿ±ŸäŸàŸÜ ŸÇŸÑŸÖÿ®ŸÜÿØ ⁄™ŸäŸÑ ⁄≥ŸàŸÑÿß ÿßŸÜÿ¨⁄ª 10 ÿ≥ŸäŸæŸΩŸÖÿ®ÿ± 1990ÿπ €æ ÿ¥ÿ±Ÿàÿπ ŸøŸä ÿ¨ŸÜŸáŸÜ ÿ¨Ÿä ÿ≤ÿ±ŸäÿπŸä ŸÅÿßÿ¶ŸäŸÑ Ÿàÿ∫Ÿäÿ±Ÿá ⁄≥ŸàŸÑŸä ÿ≥⁄Ø⁄æÿ®ÿß Ÿáÿ¶ÿß.[3]\n1993ÿπ ⁄©ÿßŸÜ ÿß⁄≥ ÿ≥⁄ÑŸä ÿπÿßŸÑŸÖ⁄ØŸäÿ± ŸàŸäÿ® ÿ¨Ÿä ÿØŸäŸΩÿß ŸáŸøŸÜ ÿ≥ÿßŸÜ ŸÖÿ≠ŸÅŸàÿ∏ ⁄™ÿ¶Ÿä ŸàŸäŸÜÿØŸä Ÿáÿ¶Ÿä. ÿßŸÜ ŸàŸÇÿ™ ŸΩŸÖ ÿ®Ÿäÿ±ŸÜŸäÿ±ÿ≥ŸÑŸä ⁄™Ÿäÿ™ÿ±ÿßÿ¶Ÿä ŸàŸäÿ® ÿ≥ÿ±Ÿàÿ± ÿ¨Ÿà⁄ôŸäÿß ÿ¨Ÿä⁄™Ÿä ÿ≥ÿ±ŸÜ ÿ¨Ÿä ŸàŸäÿ® ÿ≥ÿ±Ÿàÿ± ŸÖŸäÿ≤ÿ®ÿßŸÜŸä €æ Ÿáÿ¶ÿß.[4] ŸæŸáÿ±ŸäŸàŸÜ ÿßŸàÿ≤ÿßÿ± ÿ¨Ÿä⁄™Ÿà ÿπÿßŸÑŸÖ⁄ØŸäÿ± ŸàŸäÿ® €æ ⁄Ñÿß⁄ª ⁄©Ÿä ŸÖÿß⁄ªŸáŸÜ ÿ¨Ÿä ŸÖÿØÿØ ⁄©ÿßŸÜ ÿ®ÿ∫Ÿäÿ± ⁄≥ŸàŸÑ⁄ª ŸÑÿßÿ°Ÿê ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄™ŸäŸà ŸàŸäŸà ÿßŸÜ ⁄©Ÿä ÿ¢ÿ±⁄™Ÿä (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: Archie) ⁄ÜŸäŸà ŸàŸäŸà.[5] ÿ¢ÿ±⁄™Ÿäÿå ÿ¢ÿ±⁄™ÿßÿ¶ŸäŸà  (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: Archive) ŸÖÿßŸÜ ŸÜ⁄™ÿ™ŸÑ ŸÑŸÅÿ∏ ÿ¢ŸáŸä Ÿæÿ± ÿßŸÜ ŸÖÿßŸÜ ŸàŸä (ÿßŸÜ⁄Øÿ±Ÿäÿ≤Ÿä: V) ⁄©Ÿä ÿÆÿ™ŸÖ ⁄™ŸäŸà ŸàŸäŸà."
  },
  {
    "url": "https://sk.wikipedia.org/wiki/Web_search_engine",
    "title": "Web search engine ‚Äì Wikip√©dia",
    "content": "Web search engine alebo WWW search engine (do slovenƒçiny prekladan√© ako webov√Ω/internetov√Ω prieskumov√Ω stroj, webov√Ω/internetov√Ω vyhƒæad√°vaƒç, webov√Ω/internetov√Ω vyhƒæad√°vac√≠ n√°stroj, webov√Ω/internetov√Ω vyhƒæad√°vac√≠ prostriedok, webov√Ω/internetov√Ω vyhƒæad√°vac√≠ stroj, webov√°/internetov√° vyhƒæad√°vacia slu≈æba, webov√Ω/internetov√Ω vyhƒæad√°vac√≠ program, v be≈ænom jazyku len webov√Ω/internetov√Ω vyhƒæad√°vaƒç) alebo skr√°tane search engine (slovensk√© n√°zvy pozri v ƒçl√°nku search engine) je search engine, ktor√Ω vyhƒæad√°va na WWW. V ≈°ir≈°om zmysle zah≈ï≈àa aj web metasearch engines. Najzn√°mej≈°√≠e web search engines s√∫ Google, Yahoo, AltaVista a Bing. Search engine je zlo≈æen√Ω z t√Ωchto z√°kladn√Ωch ƒçast√≠: V praxi funguje search engine tak, ≈æe pou≈æ√≠vateƒæ zad√° po≈æiadavku a vyhƒæad√°vac√≠ program mu vyp√≠≈°e relevantn√© str√°nky, ktor√© n√°jde z vlastnej datab√°zy internetov√Ωch zdrojov, vytvorenej na z√°klade ƒçinnosti robota prehƒæad√°vaj√∫ceho hypertextov√∫ ≈°trukt√∫ru v≈°etk√Ωch webov√Ωch str√°nok. Vlastn√∫ datab√°zu zdrojov tvor√≠ spider overovan√≠m frekvencie pou≈æ√≠vania, aktualiz√°cie a miery vhodnosti ktor√∫ vykon√°va, naberaj√∫ str√°nky v jeho datab√°ze na kredibilite, teda vyhƒæad√°vac√≠ program vyber√° u≈æ len z kvalitn√Ωch, hodnotn√Ωch zdrojov. V√Ωber je navy≈°e r√Ωchly, keƒè≈æe √∫pln√© skenovanie webu sa vykon√°va s√∫stavne a nielen keƒè pou≈æ√≠vateƒæ zad√° po≈æiadavku. Poƒças pou≈æ√≠vania prieskumov√Ωch strojov je veƒæmi d√¥le≈æit√© spr√°vne voli≈• kƒæ√∫ƒçov√© slov√°, s ktor√Ωmi pracuje tzn. na z√°klade ktor√Ωch je v koneƒçnom d√¥sledku aj spiderom prehƒæadan√Ω cel√Ω WWW. Mali by by≈• √∫zko prepojen√© s t√©mou, ktor√∫ sa pou≈æ√≠vateƒæ sna≈æ√≠ vyhƒæada≈• a vhodn√© je pou≈æ√≠va≈• i synonym√° a booleovsk√© oper√°tory (&, +, -,...). Spider prech√°dza po u≈æ zn√°mych str√°nkach a cez ne hyperlinkami na ƒèal≈°ie a ƒèal≈°ie str√°nky, v ƒçom prakticky spoƒç√≠va cel√Ω syst√©m,  ak√Ωm je WWW vytvoren√Ω ‚Äì ako obrovsk√° sie≈•, sp√°jaj√∫ca v≈°etko so v≈°etk√Ωm. Datab√°za search enginu je zase ako pomyseln√° kniha, z ktorej je pou≈æ√≠vateƒæovi umo≈ænen√© preƒç√≠ta≈• si urƒçit√Ω √∫sek, ktor√Ω ho zauj√≠ma ‚Äì spider vytvor√≠ zoznam str√°nok, ktor√© pravidelne aktualizuje a obnovuje, datab√°za ich zap√≠≈°e a vyhƒæad√°vac√≠ program ich cez po≈æiadavky rozhrania pou≈æ√≠vateƒæa zobraz√≠."
  },
  {
    "url": "https://sl.wikipedia.org/wiki/Spletni_iskalnik",
    "title": "Spletni iskalnik - Wikipedija, prosta enciklopedija",
    "content": "Spletni iskalnik (tudi internetni iskalnik) je namenjen iskanju informacij na  spletu in FTP stre≈æniku, katerih iskalni izidi so obiƒçajno prikazani v obliki seznama. Informacije so lahko sestavljene iz  spletne strani, slik in drugih podakovnih oblik. Nekateri iskalniki prika≈æejo informacije s pomoƒçjo  podatkovnega rudarjenja, ki so dostopne v  podatkovnih bazah ali  spletnih adresarjih. V nasprotju s spletnimi adresarji, ki jih vzdr≈æujejo ljudje, spletni iskalniki delujejo s pomoƒçjo  algoritmov oziroma kombinacijo algoritmov in ƒçlove≈°kega vnosa. Iskanje informacij po spletnem prostoru lahko delimo tudi po geografskih razse≈ænostih: iskanje po svetu (Google), iskanje po posamezni dr≈æavi (Najdi.si) ali pa lokalno iskanje (Raziskovalec.com). Pogosto so tudi spletni imeniki napaƒçno imenovani iskalniki; od njih se razlikujejo po tem, da i≈°ƒçejo po vnaprej pripravljenih straneh s kratkim opisom. Spletni iskalniki namesto tega uporabljajo sezname vsebine, ki jih samodejno generirajo algoritmi za branje spletnih vsebin (t. i. pajki). Rezultate iskanja oboji predstavljajo v obliki seznama zadetkov, ki vsebuje povezave do najdenih spletnih strani, veƒçpredstavnostnih datotek, lokacij na zemljevidu ipd. Skoraj vsi iskalniki in imeniki omogoƒçajo tudi napredno iskanje informacij. Tako iskalnik Najdi.si, kot iskalnik Google.com omogoƒçata izbiro naslednjih iskalnih parametrov: Januarja leta 1994 sta Jerry Yang in David Filo podiplomska ≈°tudenta   elektrotehnike na  Univerzi Stanford ustanovila spletno stran z imenom Davidov in Jerryev vodnik po svetovnem spletu. To je bil imenik drugih  spletnih strani, organiziranih v hierarhijo, v nasprotju z iskalniki, ki indeksirajo strani. Aprila 1994, je bil Davidov in Jerryev vodnik po svetovnem spletu preimenovan v Yahoo. Ime Yahoo je kratica za ¬ª≈†e en hierarhiƒçno naravnan ponudnik upravljanja podatkov¬´¬†(angle≈°ko Yet Another Hierarchical Officious Oracle). Domena Yahoo.com je bila ustanovljena 18. januarja leta 1995. Nato se marca leta 1995 vkljuƒçila v posel in sreƒçala z veƒç deset kapitalisti  Silicijeve doline. Na kar so se aprila leta 1995 dogovorili  za financiranje Yahooja  z zaƒçetno nalo≈æbo v vi≈°ini skoraj 2 milijona dolarjev.  Yahoo je bil tako zelo uspe≈°na mednarodna nevladna organizacija, katera je imela aprila leta 1996 skupno 49 zaposlenih. Danes je Yahoo ena izmed vodilnih globalnih internetnih komunikacij, trgovin ter hkrati medijsko podjetje, katero ponuja celovito mre≈æo storitev za veƒç kot 345 milijonov primerkov vsak mesec po vsem svetu. Kot prvi spletni navigacijski vodnik po spletu, je  www.yahoo.com  vodilni vodnik v smislu prometa, ogla≈°evanja, gospodinjstva, kateri dosega poslovne uporabnike. Yahoo je ≈°tevilka 1 blagovnih znamk na internetu  in hkrati dose≈æe najveƒçje obƒçinstvo po vsem svetu. Podjetje ponuja spletno poslovanje in podjetni≈°ke storitve, zasnovane za poveƒçanje  produktivnosti. Leta 2000 je Yahoo priƒçel uporabljati Google za rezultate iskanja. V naslednjih ≈°tirih letih so razvili svojo iskalno tehnologijo, katero so zaƒçeli uporabljati leta 2004. Yahoo je prav tako prenovil svoje po≈°tne storitve, s ƒçimer se je zaƒçelo  tekmovanje  z Google Gmail v letu 2007. Dru≈æba se je borila do 2008, z nekaterimi  velikimi odpu≈°ƒçanji. Istega leta meseca februarja so pri Microsoft Corporation naredili nenaroƒçeno ponudbo za prevzem Yahoo-ja za 44.6 billionov dolarjev. Ponudbo so s strani Yahooja  nato uradno zavrnili za kar so trdili, da jih znatno podcenjujejo ter, da ta poteza ni bila v interesu njihovih delniƒçarjev. Tri leta kasneje je imel Yahoo borzno kapitulacijo za 22.24 billionov. Januarja 2008 je soustanovitelja Jerrya Yanga nadomestil Carol Bartz.[1][2] Google je bil ustanovljen leta 1998, njegova ustanovitelja pa sta Larry Page in Sergey Brin, ki sta bila v tistem ƒçasu ≈°tudenta na  univerzi Stanford.\nPage in  Brin sta skupaj delala na iskalniku Back Rub od leta 1996, vendar pa sta dobila vzpodbudo od soustanovitelja  Yahooja David Fila  in se odloƒçila, da leta 1998 ustanovita podjetje, katerega zaƒçetki so se priƒçeli v prijateljevi gara≈æi. \nTakrat je bil Google ≈°e v  alfa fazi, ≈°tevilo indeksiranih strani je bilo samo 25 milijonov, dnevnih iskanj pa je bilo 10,000. Popularnost iskalnika se je vi≈°ala predvsem z ustnim izroƒçilom ter z vraƒçanjem obiskovalcev, saj so bili ti zadovoljni z rezultati iskanj. Google je napravil velik korak naprej leta 2000, ko je zamenjal Inktomi kot ponudnika dodatnega iskanja na  Yahooju. Za tem je ponudil iskanje ≈°e  AOLu,  Netscapu,  Freeserveu ter  BBCju. To je Googlu dalo izjemno pokritost iskanj. Poslediƒçno mu je narastel ugled in kmalu je postal eden najbolj zanesljivih in natanƒçnih iskalnikov.\nKljub prekinitvi sodelovanja z  Yahoojem leta 2004 je Google ≈°e poveƒçal svoj vpliv na  internetu. Globalno dominacijo so poveƒçali z razvojem lokalnih verzij iskalnika. Aktivno je razvijal tudi razliƒçna iskanja kot so iskanje novic, slik, izdelkov  (Froogle) in lokalna iskanja. Usmeril se je v to, da postane glavni ponudnik raƒçunalni≈°kih storitev in iz prestola vr≈æe Microsoft. V ta namen so razvili produkte kot so e-po≈°tno storitev gmail, Google earth, Google talk (VoIP storitev), Google base in Google book search.\nGoogle je vsekakor postal sinonim za iskanje, poleg tega pa ima tudi mesto v slovarju za glagol ¬ªto google¬´. ≈†irjenje in integracija razliƒçnih Googlovih storitev ga je naredila dominantnega v  spletnem trgu. Za mnoge strani pa je Google glavni vir obiskovalcev in je tako glavna tarƒça za rangiranje, saj ob dobri poziciji na iskalniku dobi≈° obƒçutno veƒç obiska na spletno stran.[3] Bing (predhodno poimenovan ¬ªLive Search, Windows Live Search, MSN Search¬´) je trenutni Microsoft-ov spletni iskalnik (ogla≈°evan kot motor odloƒçitve). Predstavil ga je Mikrosoftov glavni izvr≈°ni direktor 28. maja leta 2009, na konferenci Vse digitalne stvari v San Diegu. V celoti se je na spletu pojavil 3. junija leta 2009, predhodno verzijo so pa predstavili 1. junija leta 2009, na kar je v prvih tednih Bing uspe≈°no pridobival tr≈æni dele≈æ. Pomembne spremembe vkljuƒçujejo zapisovanje iskalnih poizvedb v realnem ƒçasu, tako kot so vnesene in tako je bila dodana lista sorodnih iskanj, ki bazira na semantiƒçni oziroma pomenski  tehnologiji iz  Powerseta, ki ga je Microsoft kupil leta 2008. Leta 2009, natanƒçneje 29. julija sta Microsoft in Yahoo oznanila dogovor, s katerim bo Bing poganjal Yahoojev iskalnik. MSN iskalnik je bil prviƒç lansiran jeseni leta 1998 in je uporabljal iskalne zadetke iz  Inktomija. V zaƒçetku leta 1999 je MSN iskalnik lansiral razliƒçico, ki je prikazovala oglase iz Looksmarta, kateri so bili pome≈°ani skupaj z zadetki iz  Inkomija, razen kratkega obdobja leta 1999, ko so namesto teh uporabljali zadetke iz  AltaViste. Od takrat je Microsoft nadgradil MSN iskalnik in s tem omogoƒçil lasten vgrajen iskalnik rezultatov in indeks, ki se posodablja tedensko ali celo dnevno. Nadgradnja se je zaƒçela kot beta program novembra leta 2004 (na podlagi veƒç letnih raziskav) in pri≈°la iz bete februarja leta 2005. Prvi javni beta Windows Live Search je bil predstavljen  8. marca leta 2006, z dokonƒçno sprostitvijo 11. septembra leta 2006 ter s tem nadomestil MSN iskalnik.  Kot prizadevanje za  ustvariti novo identiteto iskanja Microsoft-ovih storitev, je bil Live Search uradno nadome≈°ƒçen z Bing-om 3. junij leta 2009. Tako sta se Microsoft in Yahoo dogovorila za 10- letno sodelovanje, v katerem bo Yahoo iskalnik nadome≈°ƒçen z Bingom.[4][5] Spletni iskalniki so dokaj kompleksni programi. ƒåe na kratko povzamemo, so sestavljeni iz treh delov: Spletni roboti oz. pajki so neke vrste izvidniki za spletne iskalnike, z namenom iskanja in odkrivanja spletnih strani na  internetu. Ko  spletno stran najdejo, se vklopijo indekserji oz. kazalniki, ki indeksirajo najdeno  spletno mesto. Tehniƒçno  spletni roboti delujejo tako, da po≈°ljejo spletnim  stre≈ænikom ukaz oz. ≈æeljo za spletno stran, ki jo dotiƒçni stre≈ænik gosti, jo posnamejo in po≈°ljejo kazalniku v nadaljnjo obravnavo. Pajki tako tudi i≈°ƒçejo razliƒçne spletne povezave ( HTMLjeva nadbesedila in tako sprotno pridobivajo nove  spletne naslove za obdelavo.   Administratorji se teh neza≈æelenih robotov lahko ubranijo s posebnimi  programi oz. ukazi (kot so robots.txt), v katerem je HTML koda, ki robotu prepove oz. mu prepreƒçi pridobitev povratne informacije o  spletnem mestu. Drugaƒçe pa lahko vsak administrator prijavi svojo spletno stran preko iskalnika, kjer nato iskalnikov robot pregleda listo dodanih spletnih strani in jih tako indeksira. Indekserji oz. kazalniki od  spletnih robotov prejmejo celotne spletne strani v obdelavo, kjer indeksirajo oz. shranijo vsako besedo, ki se pojavi na obdelanem  spletnem mestu. Besede se shranijo v obratnem vrstnem redu abecedno. Vsak indeks ima eno besedo, seznam dokumentov  kjer se dotiƒçna beseda pojavi in v nekaterih primerih tudi lokacijo v tekstu, kjer se ta beseda nahaja. Za bolj≈°e, natanƒçnej≈°e in hitrej≈°e iskanje, spletni iskalniki eliminirajo besede kot so ¬ªin¬´, ¬ªza¬´, ¬ªpri¬´, ¬ªje¬´, katere poimenujejo ¬ªodveƒçne besede¬´¬†oziroma angle≈°ko: stop words. Te besede so nepomembne pri iskanju, zato jih lahko varno prezrejo v primeru iskanja. Iskalni procesor je najbolj sofisticiran sistem znotraj spletnega iskalnika. Tehniƒçno vsebuje nekaj nivojev, kot so uporabni≈°ki vmesnik za iskanje (polje za vpis iskane besede), nadaljnje podprogram, ki oceni vpisano iskalno besedo in jo primerja z bazo kazalnika in relevantnimi dokumenti in jo nato prika≈æe v vmesniku, ki uporabniku izpi≈°e predlagane  spletne strani. Polje za vpis iskalne besede in uporabni≈°ki vmesnik za prikaz najdenih rezultatov se od enega spletnega iskalnika do drugega razlikujejo predvsem v toƒçnosti in dodatnih funkcijah (angle≈°ko advanced search options), ki s pomoƒçjo drugih nivojev ≈°e dodatno filtrirajo iskane spletne besede in tako lahko ponudijo ≈°e bolj toƒçne rezultate. Najveƒçja razlika med naƒçini iskanja v razliƒçnih spletnih iskalnikih se ka≈æe v postopkih raƒçunanja relevantnosti iskane besede. Veƒçina jih raƒçuna na podlagi  statistiƒçne obdelave besed, drugi jih filtrirajo na podlagi drugih spletnih povezav, ki ka≈æejo na iskano besedo in tako na iskano spletno stran. Ti postopki so zapisani v  algoritmih. Administratorji spletnih iskalnikov vseskozi nadgrajujejo in spreminjajo algoritme, ki izvajajo preraƒçunavanje relevantnosti besed in tako jim omogoƒçajo ≈°e veƒçjo natanƒçnost.[6] Ta ƒçlanek o internetu je ≈°krbina. Pomagajte Wikipediji in ga  raz≈°irite."
  },
  {
    "url": "https://ckb.wikipedia.org/wiki/%D8%A8%D8%B2%D9%88%DB%8E%D9%86%DB%95%D8%B1%DB%8C_%DA%AF%DB%95%DA%95%D8%A7%D9%86%DB%8C_%D9%88%DB%8E%D8%A8",
    "title": "ÿ®ÿ≤Ÿà€éŸÜ€ïÿ±€å ⁄Ø€ï⁄ïÿßŸÜ€å Ÿà€éÿ® - Ÿà€å⁄©€åŸæ€åÿØ€åÿßÿå ÿ¶€åŸÜÿ≥ÿß€å⁄©⁄µ€ÜŸæ€åÿØ€åÿß€å ÿ¶ÿßÿ≤ÿßÿØ",
    "content": "ÿ®ÿ≤Ÿà€éŸÜ€ïÿ±€å ⁄Ø€ï⁄ïÿßŸÜ€å Ÿà€éÿ® ÿ¨€Üÿ±€é⁄©€ï ŸÑ€ï ÿ®ÿ≤Ÿà€éŸÜ€ïÿ±€å ⁄Ø€ï⁄ïÿßŸÜ (ÿ®€ï ÿ¶€åŸÜ⁄ØŸÑ€åÿ≤€å: Search engine) ÿ¶ÿßŸÖÿ±ÿßÿ≤€é⁄©€ï ⁄Ø€ï⁄µÿß⁄µ€ïÿØÿßÿ±€é⁄ò€å ⁄©ÿ±ÿßŸà€ï ÿ®€Ü ⁄Ø€ï⁄ïÿßŸÜ ÿ®€ï ÿØŸàÿß€å ÿ≤ÿßŸÜ€åÿßÿ±€åÿØÿß ŸÑ€ïÿ≥€ïÿ± ÿ™€ïŸàŸÜ€å ÿ®€ïÿ±ÿ®⁄µÿßŸà€å ÿ¨€å⁄æÿßŸÜ€å (World Wide Web). ÿ¶ÿß⁄©ÿßŸÖ€å ⁄Ø€ï⁄ïÿßŸÜ€ï⁄©ÿßŸÜ ÿ≤€Üÿ±ÿ™ÿ± ÿ®€ï ÿ¥€éŸà€ï€å ŸÑ€åÿ≥ÿ™€ï€å€ï⁄© Ÿæ€åÿ¥ÿßŸÜ ÿØ€ïÿØÿ±€éÿ™ Ÿà ÿØ€ïÿ™ŸàÿßŸÜ€éÿ™ Ÿæ€ï⁄ï€ï€å Ÿà€éÿ®ÿå Ÿà€éŸÜ€ï €åÿßŸÜ ⁄æ€ïÿ± ⁄Ü€ïÿ¥ŸÜ€ï Ÿæ€ï⁄ï⁄Ø€ï€å€ï⁄©€å ÿ™ÿ±€å ŸÑ€ï ÿÆ€Ü ⁄Øÿ±ÿ™ÿ®€éÿ™. ⁄òŸÖÿßÿ±€ï€å€ï⁄© ŸÑ€ï ÿ®€ïŸÜÿßŸàÿ®ÿßŸÜ⁄Øÿ™ÿ±€åŸÜ ⁄Ø€ï⁄ïÿßŸÜ⁄Ü€å€å⁄©ÿßŸÜ€å Ÿà€éÿ® ÿ¶€ïŸÖÿßŸÜ€ïŸÜ:\n⁄ØŸàŸà⁄Ø⁄µÿå €åÿß⁄æŸàŸàÿå MSNÿå ÿ¶ÿß⁄µÿ™ÿß⁄§€åÿ≥ÿ™ÿßÿå Ÿà ÿØ€ï⁄© ÿØ€ï⁄© ⁄Ø€Ü. ÿ¶€ïŸÖ€ï€å ÿØŸàÿß€å€åÿå ÿØ€ï⁄© ÿØ€ï⁄© ⁄Ø€Üÿå ÿ®ÿßŸÜ⁄Ø€ïÿ¥€ï€å ÿ¶€ïŸà€ï ÿØ€ï⁄©€ïŸÜ ⁄©€ï ÿ¶€ïŸàÿßŸÜ ÿ≤ÿßŸÜ€åÿßÿ±€å€å ⁄©€ïÿ≥€ï⁄©ÿßŸÜ ŸÜÿßŸÅÿ±€Üÿ¥ŸÜ Ÿà ⁄ï€é⁄Øÿß ŸÜÿßÿØ€ïŸÜ ⁄©€ÜŸÖŸæÿßŸÜ€åÿß⁄©ÿßŸÜ ⁄ï€é⁄©ŸÑÿßŸÖ ÿ®ÿÆ€ïŸÜ€ï ŸÜÿßŸà ÿ¶€ïŸÜÿ¨ÿßŸÖ€ï⁄©ÿßŸÜ€å ⁄Ø€ï⁄ïÿßŸÜ€ïŸà€ï.[Ÿ°]"
  },
  {
    "url": "https://sr.wikipedia.org/wiki/%D0%92%D0%B5%D0%B1-%D0%BF%D1%80%D0%B5%D1%82%D1%80%D0%B0%D0%B6%D0%B8%D0%B2%D0%B0%D1%87",
    "title": "–í–µ–±-–ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á ‚Äî –í–∏–∫–∏–ø–µ–¥–∏—ò–∞",
    "content": "–ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –≤–µ–±–∞ (–µ–Ω–≥–ª. web search engine) –ø—Ä–µ–¥—Å—Ç–∞–≤—ô–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–µ—Ä–≤–∏—Å, —á–∏—ò–∞ —ò–µ —Å–≤—Ä—Ö–∞ —Ç—Ä–∞–∂–µ—ö–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ –Ω–∞ –≤–µ–±—É, –∏ —Ç–æ —É–≥–ª–∞–≤–Ω–æ–º –∑–∞–¥–∞–≤–∞—ö–µ–º –∫—ô—É—á–Ω–∏—Ö —Ä–∏—ò–µ—á–∏, –∞ –º–Ω–æ–≥–æ —Ä—ò–µ—í–µ –æ–¥–∞–±–∏—Ä–æ–º –ø–æ–Ω—É—í–µ–Ω–∏—Ö —Å—Ç–∞–≤–∫–∏. –ò—Å—Ö–æ–¥ –ø—Ä–µ—Ç—Ä–∞–≥–µ —Å–µ –Ω–∞—ò—á–µ—à—õ–µ –ø—Ä–∏–∫–∞–∑—É—ò–µ –∫–∞–æ —Å–ø–∏—Å–∞–∫ –≤–µ–±-—Å–∞—ò—Ç–æ–≤–∞ –∫–æ—ò–∏ —Å–∞–¥—Ä–∂–µ —Ç—Ä–∞–∂–µ–Ω—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò—É, —É–∑ –º–æ–≥—É—õ–Ω–æ—Å—Ç –¥–∞ —Å–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ —Å—É –æ–¥–≥–æ–≤–æ—Ä –Ω–∞ —É–ø–∏—Ç –ø–æ—Å—ò–µ—Ç–µ —Å–∞ —Å—Ç—Ä–∞–Ω–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞. –í–µ–± —ò–µ —Ä–∞–∑–≤–∏–æ –¢–∏–º –ë–µ—Ä–Ω–µ—Ä—Å-–õ–∏ –∏ —ö–µ–≥–æ–≤–µ –∫–æ–ª–µ–≥–µ, 1990. –≥–æ–¥–∏–Ω–µ. –ó–∞ –Ω–µ—à—Ç–æ –≤–∏—à–µ –æ–¥ –¥–≤–∏—ò–µ –¥–µ—Ü–µ–Ω–∏—ò–µ, –ø–æ—Å—Ç–∞–æ —ò–µ –Ω–∞—ò–≤–µ—õ–∏ –∏–∑–≤–æ—Ä –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ —É –∏—Å—Ç–æ—Ä–∏—ò–∏ —á–æ–≤—ò–µ—á–∞–Ω—Å—Ç–≤–∞. –ü—Ä–æ—Ü—ò–µ—ö—É—ò–µ —Å–µ –¥–∞ —ò–µ —É–∫—É–ø–∞–Ω –±—Ä–æ—ò –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ –∏ –∑–∞–ø–∏—Å–∞ —É –±–∞–∑–∞–º–∞ –ø–æ–¥–∞—Ç–∞–∫–∞, —Å—Ç–æ—Ç–∏–Ω–µ –º–∏–ª–∏—ò–∞—Ä–¥–∏.[1] –î–æ –∫—Ä–∞—ò–∞ 2005. –≥–æ–¥–∏–Ω–µ, –≤–µ—õ —ò–µ –±–∏–ª–æ –ø—Ä–µ–∫–æ –º–∏–ª–∏—ò–∞—Ä–¥—É –∫–æ—Ä–∏—Å–Ω–∏–∫–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ —à–∏—Ä–æ–º —Å–≤–∏—ò–µ—Ç–∞. –ü—Ä–æ–Ω–∞–ª–∞–∂–µ—ö–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ –Ω–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É —ò–µ –ø–æ—Å—Ç–∞–ª–æ –±–∏—Ç–∞–Ω –¥–∏–æ —Å–≤–∞–∫–æ–¥–Ω–µ–≤–Ω–∏—Ö –∂–∏–≤–æ—Ç–Ω–∏—Ö –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –£ —Å—Ç–≤–∞—Ä–∏, –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—ö–µ —ò–µ –¥—Ä—É–≥–∞ –Ω–∞—ò–ø–æ–ø—É–ª–∞—Ä–Ω–∏—ò–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç –Ω–∞ –≤–µ–±—É, –∏–∑–∞ –µ-–ø–æ—à—Ç–µ, —Å–∞ –ø—Ä–µ–∫–æ 550 –º–∏–ª–∏–æ–Ω–∞ –ø—Ä–µ—Ç—Ä–∞–≥–∞ —Å–≤–∞–∫–∏ –¥–∞–Ω. –í–µ–± —Å–µ —Å–∞—Å—Ç–æ—ò–∏ –æ–¥ –ø–æ–≤—Ä—à–∏–Ω—Å–∫–æ–≥ –∏ –¥—É–±–∏–Ω—Å–∫–æ–≥ (—Ç–∞–∫–æ—í–µ —Å–∫—Ä–∏–≤–µ–Ω–∏ –∏–ª–∏ –Ω–µ–≤–∏–¥—ô–∏–≤–∏ –≤–µ–±). –°–≤–∞–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞ –ø–æ–≤—Ä—à–∏–Ω—Å–∫–æ–º –≤–µ–±—É –∏–º–∞ –ª–æ–≥–∏—á–Ω—É –∞–¥—Ä–µ—Å—É –∫–æ—ò–∞ —Å–µ –Ω–∞–∑–∏–≤–∞ –≤–µ–±-–∞–¥—Ä–µ—Å–∞ (–µ–Ω–≥–ª. Uniforme Resource Locator - URL). –í–µ–±-–∞–¥—Ä–µ—Å–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ–º–æ–≥—É—õ–∞–≤–∞ —ö–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–Ω–æ —É—á–∏—Ç–∞–≤–∞—ö–µ. –°—É–ø—Ä–æ—Ç–Ω–æ —Ç–æ–º–µ, –¥—É–±–∏–Ω—Å–∫–∏ –≤–µ–± —Å–∞–¥—Ä–∂–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ –Ω–∏—ò–µ –º–æ–≥—É—õ–µ –¥–∏—Ä–µ–∫—Ç–Ω–æ —É—á–∏—Ç–∞—Ç–∏ –∫–∞–æ –∏ –∑–∞–ø–∏—Å–µ —É –±–∞–∑–∞–º–∞ –ø–æ–¥–∞—Ç–∞–∫–∞ –∫–æ—ò–∏ —Å—É —Å–∫–ª–∞–¥–∏—à—Ç–µ–Ω–∏ —É —Å–∏—Å—Ç–µ–º–∏–º–∞ –±–∞–∑–∞ –ø–æ–¥–∞—Ç–∞–∫–∞. –°–º–∞—Ç—Ä–∞ —Å–µ –¥–∞ —ò–µ –¥—É–±–∏–Ω—Å–∫–∏ –≤–µ–± 100 –ø—É—Ç–∞ –≤–µ—õ–∏ –æ–¥ –ø–æ–≤—Ä—à–∏–Ω—Å–∫–æ–≥.[1] –ê–ª–∞—Ç–∫–µ –∫–æ—ò–µ —Å–µ –∫–æ—Ä–∏—Å—Ç–µ –∑–∞ –ø—Ä–æ–Ω–∞–ª–∞–∂–µ—ö–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ –Ω–∞ –≤–µ–±—É –∑–æ–≤—É —Å–µ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏. –í—ò–µ—Ä—É—ò–µ —Å–µ –¥–∞ —ò–µ –≤–∏—à–µ –æ–¥ –º–∏–ª–∏–æ–Ω –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ –Ω–∞ –≤–µ–±—É. –ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–µ —ò–µ –º–æ–≥—É—õ–µ –∫–ª–∞—Å–∏—Ñ–∏–∫–æ–≤–∞—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤—É —Ç–∏–ø–∞ –ø–æ–¥–∞—Ç–∞–∫–∞ –∫–æ—ò–µ –ø—Ä–µ—Ç—Ä–∞–∂—É—ò—É. –ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –∫–æ—ò–∏ –ø—Ä–µ—Ç—Ä–∞–∂—É—ò—É —Ç–µ–∫—Å—Ç—É–∞–ª–Ω–µ –¥–æ–∫—É–º–µ–Ω—Ç–µ –∑–æ–≤–µ–º–æ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞, –¥–æ–∫ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–µ –∫–æ—ò–∏ –ø—Ä–µ—Ç—Ä–∞–∂—É—ò—É —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Å–∞–Ω–µ –ø–æ–¥–∞—Ç–∫–µ –∫–æ—ò–∏ —Å–µ —á—É–≤–∞—ò—É —É –±–∞–∑–∞–º–∞ –ø–æ–¥–∞—Ç–∞–∫–∞ –∑–æ–≤–µ–º–æ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –±–∞–∑–∞ –ø–æ–¥–∞—Ç–∞–∫–∞. –ú–Ω–æ–≥–∏ –ø–æ–ø—É–ª–∞—Ä–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –∫–∞–æ —à—Ç–æ —Å—É Google –∏ Yahoo —Å—É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞, –¥–æ–∫ —Å–µ –º–Ω–æ–≥–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –µ-—Ç—Ä–≥–æ–≤–∏–Ω–∞ –∫–∞–æ —à—Ç–æ —ò–µ Amazon.com, —Å–º–∞—Ç—Ä–∞—ò—É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏–º–∞ –±–∞–∑–∞ –ø–æ–¥–∞—Ç–∞–∫–∞. –ò–Ω—Ç–µ–≥—Ä–∏—Å–∞–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –í–∏–∫–∏–ø–µ–¥–∏—ò–µ —ò–µ —Ç–∞–∫–æ—í–µ –ø—Ä–∏–º—ò–µ—Ä –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –±–∞–∑–µ –ø–æ–¥–∞—Ç–∞–∫–∞. –ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ –æ–±–∏—á–Ω–æ –∏–º–∞—ò—É –ø—Ä–æ—Å—Ç–∏—ò–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å —Å–∞ —Ç–µ–∫—Å—Ç—É–∞–ª–Ω–∏–º –ø–æ—ô–µ–º –≥–¥—ò–µ –∫–æ—Ä–∏—Å–Ω–∏—Ü–∏ —É–Ω–æ—Å–µ —Å–≤–æ—ò —É–ø–∏—Ç –∫–æ—ò–∏ –æ–±–∏—á–Ω–æ —á–∏–Ω–µ –∫—ô—É—á–Ω–µ —Ä–∏—ò–µ—á–∏ –∫–æ—ò–µ –æ–¥—Ä–∞–∂–∞–≤–∞—ò—É –ø–æ—Ç—Ä–µ–±–µ –∫–æ—Ä–∏—Å–Ω–∏–∫–∞ –∑–∞ –æ–¥—Ä–µ—í–µ–Ω–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞–º–∞. –° –¥—Ä—É–≥–µ —Å—Ç—Ä–∞–Ω–µ, –º–Ω–æ–≥–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –±–∞–∑–∞ –ø–æ–¥–∞—Ç–∞–∫–∞ –æ–º–æ–≥—É—õ–∞–≤–∞—ò—É –∫–æ—Ä–∏—Å–Ω–∏—Ü–∏–º–∞ –¥–∞ –≤—Ä—à–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–µ –∏ —Å–ª–æ–∂–µ–Ω–∏—ò–µ —É–ø–∏—Ç–µ. –ü–æ—Å—Ç–æ—ò–µ –∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –∫–æ—ò–∏ —Å—É —Å–ø–µ—Ü–∏—ò–∞–ª–∏–∑–æ–≤–∞–Ω–∏ –∑–∞ –ø—Ä–µ—Ç—Ä–∞–≥—É –º—É–ª—Ç–∏–º–µ–¥–∏—ò–∞–ª–Ω–∏—Ö –¥–∞—Ç–æ—Ç–µ–∫–∞ (–∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ –∑–∞–ø–∏—Å–∞ –∏ —Å–ª–∏–∫–∞). –í–µ—õ–∏–Ω–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –ø–æ–∫—Ä–∏–≤–∞—ò—É —Å–∞–º–æ –º–∞–ª–∏ –¥–∏–æ –≤–µ–±–∞. –î–∞ –±–∏ —Å–µ –ø–æ–≤–µ—õ–∞–ª–∞ –ø–æ–∫—Ä–∏–≤–µ–Ω–æ—Å—Ç —ò–µ–¥–Ω–æ–≥ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ, –º–æ–≥—É—õ–µ —ò–µ –∫–æ–º–±–∏–Ω–æ–≤–∞—Ç–∏ –≤–∏—à–µ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –æ–¥—ò–µ–¥–Ω–æ–º. –°–∏—Å—Ç–µ–º–∏ –∑–∞ –ø—Ä–µ—Ç—Ä–∞–≥—É –∫–æ—ò–∏ –∫–æ—Ä–∏—Å—Ç–µ –¥—Ä—É–≥–µ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–µ –∑–∞ –æ–±–∞–≤—ô–∞—ö–µ –ø—Ä–µ—Ç—Ä–∞–≥–µ –∏ –∫–æ–º–±–∏–Ω—É—ò—É –∏—Ö —Å–∞ —Å–≤–æ—ò–∏–º —Ä–µ–∑—É–ª—Ç–∞—Ç–∏–º–∞, –Ω–∞–∑–∏–≤–∞—ò—É —Å–µ –º–µ—Ç–∞–ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–∞–∑–ª–∏—á–∏—Ç–∏—Ö –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –≤–µ–±–∞ –º–æ–∂–µ –∑–Ω–∞—Ç–Ω–æ –≤–∞—Ä–∏—Ä–∞—Ç–∏, –º–µ—í—É—Ç–∏–º —Ç–∏–ø–∏—á–∞–Ω –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ —Å–µ –æ–±–∏—á–Ω–æ —Å–∞—Å—Ç–æ—ò–∏ –æ–¥ —Å–ª–∏—ò–µ–¥–µ—õ–µ —á–µ—Ç–∏—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ: –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –ª–æ–∫–∞—Ü–∏—ò–µ –≤–µ–±–∞ (web crawler), –∏–Ω–¥–µ–∫—Å–µ—Ä–∞ (indexer), –∏–Ω–¥–µ–∫—Å–∞ –±–∞–∑–µ –ø–æ–¥–∞—Ç–∞–∫–∞ –∏ –º–∞—à–∏–Ω–µ –∑–∞ —É–ø–∏—Ç–µ (query engine). –ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –ª–æ–∫–∞—Ü–∏—ò–µ –≤–µ–±–∞, —Ç–∞–∫–æ—í–µ –ø–æ–∑–Ω–∞—Ç –∫–∞–æ –ø—Ä–æ–≥—Ä–∞–º —Ç—Ä–∞–≥–∞—á (web spider) –∏–ª–∏ –≤–µ–±-—Ä–æ–±–æ—Ç, –ø—Ä–æ–ª–∞–∑–∏ –∫—Ä–æ–∑ –≤–µ–± —É –ø–æ—Ç—Ä–∞–∑–∏ –∑–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∞ —Å–ª–∏—ò–µ–¥–µ—õ–∏ —ö–∏—Ö–æ–≤–µ URL –∞–¥—Ä–µ—Å–µ. –ò–Ω–¥–µ–∫—Å–µ—Ä —ò–µ –∑–∞–¥—É–∂–µ–Ω –∑–∞ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–∫—Å—Ç–∞ —Å–≤–∞–∫–µ –ø—Ä–æ–Ω–∞—í–µ–Ω–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –≤–∞—í–µ—ö–µ –∫—ô—É—á–Ω–∏—Ö —Ä–∏—ò–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤—É –∫–æ—ò–∏—Ö —Å–µ –æ–Ω–¥–∞ –ø—Ä–∞–≤–∏ –∏–Ω–¥–µ–∫—Å–Ω–∞ –±–∞–∑–∞ –ø–æ–¥–∞—Ç–∞–∫–∞ —Å–≤–∏—Ö –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞. –ö–∞–¥–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫ —É—Ä–∞–¥–∏ —É–ø–∏—Ç, –º–∞—à–∏–Ω–∞ –∑–∞ —É–ø–∏—Ç–µ –ø—Ä–µ—Ç—Ä–∞–∂—É—ò–µ –∏–Ω–¥–µ–∫—Å–Ω—É –±–∞–∑—É –ø–æ–¥–∞—Ç–∞–∫–∞ —É –ø–æ—Ç—Ä–∞–∑–∏ –∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∞ –∫–æ—ò–µ –æ–¥–≥–æ–≤–∞—Ä–∞—ò—É –∫—ô—É—á–Ω–∏–º —Ä–∏—ò–µ—á–∏–º–∞ –∫–æ—ò–µ —Å—É –ø—Ä–µ–¥–º–µ—Ç –∫–æ—Ä–∏—Å–Ω–∏–∫–æ–≤–æ–≥ —É–ø–∏—Ç–∞. –ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –≤–µ–±-—Å–∞—ò—Ç–æ–≤–∞ (web crawler) —ò–µ —Ä–∞—á—É–Ω–∞—Ä—Å–∫–∏ –ø—Ä–æ–≥—Ä–∞–º –∫–æ—ò–∏ –ø—Ä–µ—É–∑–∏–º–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ —Å–∞ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞. URL —Å–≤–∞–∫–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫—É—ò–µ —ö–µ–Ω—É –ª–æ–∫–∞—Ü–∏—ò—É –Ω–∞ –≤–µ–±—É. –û–±–∑–∏—Ä–æ–º –Ω–∞ –ø–æ—Å—Ç–æ—ò–∞—ö–µ URL –∞–¥—Ä–µ—Å–µ, —Å–≤–∞–∫–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–µ –º–æ–∂–µ –ø—Ä–µ—É–∑–µ—Ç–∏ —Å–∞ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ —É–ø–æ—Ç—Ä–µ–±–æ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∑–∞ –ø—Ä–µ–Ω–æ—Å —Ö–∏–ø–µ—Ä—Ç–µ–∫—Å—Ç–∞ (HTTP). –ü–æ–ª–∞–∑–µ—õ–∏ –æ–¥ —ò–µ–¥–Ω–µ –ø–æ—á–µ—Ç–Ω–µ URL –∞–¥—Ä–µ—Å–µ, –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ –Ω–µ–ø—Ä–µ—Å—Ç–∞–Ω–æ –ø—Ä–µ—É–∑–∏–º–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –±–∞–∑–∏—Ä–∞—ò—É—õ–∏ —Å–µ –Ω–∞ —ö–∏—Ö–æ–≤–∏–º URL –∞–¥—Ä–µ—Å–∞–º–∞ –∏ –≤–∞–¥–∏ URL –∞–¥—Ä–µ—Å–µ –∏–∑ –æ–Ω–∏—Ö –≤–µ—õ –ø—Ä–µ—É–∑–µ—Ç–∏—Ö, —Ç–∞–∫–æ –¥–∞ —ò–µ –º–æ–≥—É—õ–µ –ø—Ä–µ—É–∑–µ—Ç–∏ –Ω–æ–≤–µ. –û–≤–∞—ò –ø—Ä–æ—Ü–µ—Å —Å–µ –∑–∞–≤—Ä—à–∞–≤–∞ –∫–∞–¥–∞ —ò–µ –Ω–µ–∫–∏ —É—Å–ª–æ–≤ –∑–∞ –∑–∞—É—Å—Ç–∞–≤—ô–∞—ö–µ –ø—Ä–æ–≥—Ä–∞–º–∞ –∏—Å–ø—É—ö–µ–Ω. –ù–µ–∫–∏ –æ–¥ –º–æ–≥—É—õ–∏—Ö —É—Å–ª–æ–≤–∞ –∑–∞ —ö–µ–≥–æ–≤–æ –∑–∞—É—Å—Ç–∞–≤—ô–∞—ö–µ —Å—É: (1) –Ω–µ–º–∞ –≤–∏—à–µ –Ω–æ–≤–∏—Ö URL –∞–¥—Ä–µ—Å–∞ –Ω–∞ –ª–æ–∫–∞—Ü–∏—ò–∏ –∏–ª–∏ (2) —É–Ω–∞–ø—Ä–∏—ò–µ–¥ –¥–µ—Ñ–∏–Ω–∏—Å–∞–Ω–∏ –±—Ä–æ—ò, –æ–¥–Ω–æ—Å–Ω–æ —Å–ø–∏—Å–∞–∫ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —ò–µ –≤–µ—õ –ø—Ä–µ—É–∑–µ—Ç. –ü–æ—à—Ç–æ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –≤–µ–±-–ª–æ–∫–∞—Ü–∏—ò–∞ –º–æ–∂–µ –±–∏—Ç–∏ —É –∏–Ω—Ç–µ—Ä–∞–∫—Ü–∏—ò–∏ —Å–∞ —Ä–∞–∑–Ω–æ–ª–∏–∫–∏–º —Å–∞–º–æ—Å—Ç–∞–ª–Ω–∏–º –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∏–º–∞, –±–∏—Ç–Ω–æ —ò–µ –¥–∞ –±—É–¥–µ –ø—Ä–æ—ò–µ–∫—Ç–æ–≤–∞–Ω —Ç–∞–∫–æ –¥–∞ –≥–∞ —ò–µ –ª–∞–∫–æ –ø—Ä–∏–ª–∞–≥–æ–¥–∏—Ç–∏ –Ω–æ–≤–∏–º –∑–∞—Ö—Ç—ò–µ–≤–∏–º–∞. –ö–∞–∫–æ –±–∏ —Å–µ —É–±—Ä–∑–∞–æ –ø—Ä–æ—Ü–µ—Å –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—ö–∞, –º–æ–≥—É—õ–µ —ò–µ —É–ø–æ—Ç—Ä–∏—ò–µ–±–∏—Ç–∏ –≤–∏—à–µ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞. –û–Ω–∏ –º–æ–≥—É –±–∏—Ç–∏ –¥–≤–∞ —Ä–∞–∑–ª–∏—á–∏—Ç–∞ —Ç–∏–ø–∞, —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–∏ –∏ –¥–∏—Å—Ç—Ä–∏–±—É–∏—Ä–∞–Ω–∏.[2] –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ —Å–µ –Ω–∞–ª–∞–∑–µ –Ω–∞ –∏—Å—Ç–æ—ò –ª–æ–∫–∞—Ü–∏—ò–∏ —Å–∞ –∫–æ—ò–µ —Å–µ –ø–æ–∫—Ä–µ—õ—É –ø–∞—Ä–∞–ª–µ–ª–Ω–æ –∏ —Å–∞ –≤–∏—à–µ –º–∞—à–∏–Ω–∞.[3] –î–∏—Å—Ç—Ä–∏–±—É–∏—Ä–∞–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ —Å–µ –Ω–∞–ª–∞–∑–µ –Ω–∞ –≤–∏—à–µ —Ä–∞–∑–ª–∏—á–∏—Ç–∏—Ö –ª–æ–∫–∞—Ü–∏—ò–∞ –Ω–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—à—É —Å–µ –ø—É—Ç–µ–º —ò–µ–¥–Ω–æ–≥ —Ü–µ–Ω—Ç—Ä–∞–ª–Ω–æ–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞, –¥—Ä—É–≥–∏–º —Ä–∏—ò–µ—á–∏–º–∞ —Å–≤–∞–∫–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ –ø—Ä–µ—É–∑–∏–º–∞ —Å–∞–º–æ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ —Å—É –º—É –≥–µ–æ–≥—Ä–∞—Ñ—Å–∫–∏ –±–ª–∏–∑—É. –ù–∞—ò–∑–Ω–∞—á–∞—ò–Ω–∏—ò–∞ –ø—Ä–µ–¥–Ω–æ—Å—Ç –¥–∏—Å—Ç—Ä–∏–±—É–∏—Ä–∞–Ω–∏—Ö –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ —Ç–∏—á–µ —Å–µ —Å–º–∞—ö–µ—ö–∞ —Ç—Ä–æ—à–∫–æ–≤–∞ –∫–æ–º—É–Ω–∏–∫–∞—Ü–∏—ò–∞ –∫–æ—ò–∏ —Å—É —Ä–µ–∑—É–ª—Ç–∞—Ç —ö–∏—Ö–æ–≤–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –ú–µ—í—É—Ç–∏–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ —Å—É –ª–∞–∫—à–∏ –∑–∞ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—ò—É –∏ –∫–æ–Ω—Ç—Ä–æ–ª—É –Ω–µ–≥–æ –¥–∏—Å—Ç—Ä–∏–±—É–∏—Ä–∞–Ω–∏. –†–∞—Å—Ç –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω–µ –ø—Ä–æ–º—ò–µ–Ω–µ –Ω–∞ –≤–µ–±—É, —Å—Ç–≤–∞—Ä–∞—ò—É –ø–æ—Ç—Ä–µ–±—É –¥–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ —Ä–µ–≥—É–ª–∞—Ä–Ω–æ –≤—Ä—à–µ –Ω–æ–≤–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—ö–∞ –∫–∞–æ –∏ –¥–∞ –æ–¥—Ä–∂–∞–≤–∞—ò—É –∏–Ω–¥–µ–∫—Å–Ω—É –±–∞–∑—É –ø–æ–¥–∞—Ç–∞–∫–∞ –∞–∂—É—Ä–Ω–æ–º. –ú–µ—í—É—Ç–∏–º, —Å—É–≤–∏—à–µ —á–µ—Å—Ç–æ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—ö–µ –≤–µ–±–∞ –±–∏ –¥–æ–≤–µ–ª–æ –¥–æ –∑–Ω–∞—á–∞—ò–Ω–æ–≥ —Ç—Ä–æ—à–µ—ö–∞ —Ä–µ—Å—É—Ä—Å–∞, –∞–ª–∏ –∏ –ø–æ—Ç–µ—à–∫–æ—õ–µ —É —Ä–∞–¥—É –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –∫–æ—ò–∏–º–∞ —Å–µ —Ç—Ä–∞–∂–µ–Ω–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–∞–ª–∞–∑–µ. –°—Ç–æ–≥–∞ —ò–µ –ø–æ—Ç—Ä–µ–±–Ω–æ —É–ø–æ—Ç—Ä–∏—ò–µ–±–∏—Ç–∏ —ò–µ–¥–Ω—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—ò—É –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª–Ω–æ–≥ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—ö–∞. –à–µ–¥–Ω–∞ –æ–¥ —ö–∏—Ö —ò–µ –¥–∞ —Å–µ —Å–∞–º–æ –ø—Ä–µ—Ç—Ä–∞–∂—É—ò—É –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ —á–∏—ò–∏ —Å–µ —Å–∞–¥—Ä–∂–∞—ò –∏–ª–∏ URL –∞–¥—Ä–µ—Å–∞ –ø—Ä–æ–º–∏—ò–µ–Ω–∏–ª–∞ –æ–¥ –ø–æ—Å—ô–µ–¥—ö–µ –ø—Ä–µ—Ç—Ä–∞–≥–µ. –î—Ä—É–≥–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—ò–∞ —ò–µ –¥–∞ —Å–µ —É–ø–æ—Ç—Ä–∏—ò–µ–±–µ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ –∫–æ—ò–∏ –∏–º–∞—ò—É –ø—Ä–µ–¥–µ—Ñ–∏–Ω–∏—Å–∞–Ω—É –æ–±–ª–∞—Å—Ç –ø—Ä–µ—Ç—Ä–∞–≥–µ, –∏–ª–∏ –ø—Ä–µ–¥–µ—Ñ–∏–Ω–∏—Å–∞–Ω–∏ —Å–∫—É–ø —Ç–µ–º–∞ –∑–∞ –ø—Ä–µ—Ç—Ä–∞–≥—É. –û–≤–∏ –ø–æ—Å—ô–µ–¥—ö–∏ —Å–µ –º–æ–≥—É –∏—Å–∫–æ—Ä–∏—Å—Ç–∏—Ç–∏ –∑–∞ –∫—Ä–µ–∏—Ä–∞—ö–µ —Å–ø–µ—Ü–∏—ò–∞–ª–∏–∑–æ–≤–∞–Ω–∏—Ö –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ –∫–æ—ò–∏ —Å—É —ò–µ–¥–∏–Ω–æ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–∏ –∑–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ–¥—Ä–µ—í–µ–Ω–µ —Ç–µ–º–∞—Ç–∏–∫–µ. –ö–æ–Ω–≤–µ–Ω—Ü–∏–æ–Ω–∞–ª–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –≤–µ–±-–ª–æ–∫–∞—Ü–∏—ò–∞ —Å–µ –º–æ–≥—É —É–ø–æ—Ç—Ä–∏—ò–µ–±–∏—Ç–∏ —Å–∞–º–æ –∑–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—ö–µ –ø–æ–≤—Ä—à–∏–Ω—Å–∫–æ–≥ –≤–µ–±–∞. –ü–æ—Å–µ–±–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –ª–æ–∫–∞—Ü–∏—ò–∞ –≤–µ–±–∞ —Å–µ –ø—Ä–æ—ò–µ–∫—Ç—É—ò—É –∑–∞ –ø—Ä–µ—Ç—Ä–∞–≥—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ –∫–æ—ò–µ —Å–µ –Ω–∞–ª–∞–∑–µ —É –¥—É–±–∏–Ω—Å–∫–æ–º –≤–µ–±—É. –ü–æ—à—Ç–æ —Å—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–µ –∫–æ—ò–µ —Å–µ –Ω–∞–ª–∞–∑–µ —É –¥—É–±–∏–Ω—Å–∫–æ–º –≤–µ–±—É –æ–±–∏—á–Ω–æ —Å–∫—Ä–∏–≤–µ–Ω–µ –∏–∑–∞ —Ä–∞–∑–Ω–∏—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ, –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –ª–æ–∫–∞—Ü–∏—ò–∞ –¥—É–±–∏–Ω—Å–∫–æ–≥ –≤–µ–±–∞ —Å—É –ø—Ä–æ—ò–µ–∫—Ç–æ–≤–∞–Ω–∏ —Ç–∞–∫–æ –¥–∞ –ø—Ä–∏–∫—É–ø—ô–∞—ò—É –ø–æ–¥–∞—Ç–∫–µ –≤—Ä—à–µ—õ–∏ —É–ø–∏—Ç–µ —É –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å—É –ø—Ä–µ—Ç—Ä–∞–≥–µ –∏ –ø—Ä–µ—É–∑–º—É –ø–æ–≤—Ä–∞—Ç–Ω–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–µ. –ù–∞–∫–æ–Ω —à—Ç–æ —Å—É –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–µ—É–∑–µ—Ç–µ –Ω–∞ –º—ò–µ—Å—Ç–æ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞, –æ–Ω–µ —Å–µ –æ–±—Ä–∞—í—É—ò—É —É —Ñ–æ—Ä–º–∞—Ç—É –∫–æ—ò–∏ —ò–µ –ø–æ–¥–µ—Å–∞–Ω –∑–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—É –∏ –µ—Ñ–∏–∫–∞—Å–Ω—É —É–ø–æ—Ç—Ä–µ–±—É —Å–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏–º–∞. –°–∞–¥—Ä–∂–∞—ò–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –º–æ–≥—É –±–∏—Ç–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—ô–µ–Ω–∏ —Ä–∏—ò–µ—á–∏–º–∞ –∫–æ—ò–µ —Å–µ –Ω–∞ —ö–æ—ò –Ω–∞–ª–∞–∑–µ. –ù–µ—Å–∞–¥—Ä–∂–∞—ò–Ω–µ —Ä–∏—ò–µ—á–∏ –∫–∞–æ —à—Ç–æ —Å—É ‚Äû—ò–µ‚Äú –∏–ª–∏ ‚Äû–ª–∏‚Äú —Å–µ –æ–±–∏—á–Ω–æ –Ω–µ –∫–æ—Ä–∏—Å—Ç–µ –∑–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤—ô–∞—ö–µ —Å–∞–¥—Ä–∂–∞—ò–∞. –ù–µ—Ä–∏—ò–µ—Ç–∫–æ, —Ä–∏—ò–µ—á–∏ —Å–µ –∫–æ–Ω–≤–µ—Ä—Ç—É—ò—É —É —ö–∏—Ö–æ–≤ –∫–æ—Ä–∏—ò–µ–Ω —É–ø–æ—Ç—Ä–µ–±–æ–º –æ–¥–≥–æ–≤–∞—Ä–∞—ò—É—õ–µ–≥ –ø—Ä–æ–≥—Ä–∞–º–∞ –∫–∞–∫–æ –±–∏ —Å–µ –æ–ª–∞–∫—à–∞–ª–æ –ø–æ–≥–∞—í–∞—ö–µ —Ä–∞–∑–ª–∏—á–∏—Ç–∏—Ö –≤–∞—Ä–∏—ò–∞—Ü–∏—ò–∞ –∏—Å—Ç–µ —Ä–∏—ò–µ—á–∏. –ù–∞ –ø—Ä–∏–º—ò–µ—Ä, ‚Äû—Ä–∞—á—É–Ω‚Äú —ò–µ –∫–æ—Ä–∏—ò–µ–Ω —Ä–∏—ò–µ—á–∏ ‚Äû—Ä–∞—á—É–Ω–∞—Ç–∏‚Äú –∏ ‚Äû—Ä–∞—á—É–Ω–∞—Ä—Å—Ç–≤–æ‚Äú. –ù–∞–∫–æ–Ω —É–∫–ª–∞—ö–∞—ö–∞ –Ω–µ—Å–∞–¥—Ä–∂–∞—ò–Ω–∏—Ö —Ä–∏—ò–µ—á–∏ —Å–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –ø—Ä–æ—Ü–µ—Å–∞ –∏–∑–≤–ª–∞—á–µ—ö–∞ –∫–æ—Ä–∏—ò–µ–Ω–∞, –ø—Ä–µ–æ—Å—Ç–∞–ª–µ —Ä–∏—ò–µ—á–∏ (—Ç–∞–∫–æ–∑–≤–∞–Ω–∏ –∏–Ω–¥–µ–∫—Å–Ω–∏ –ø–æ—ò–º–æ–≤–∏) –∫–æ—Ä–∏—Å—Ç–µ —Å–µ –∑–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤—ô–∞—ö–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —É –ø—Ä–µ—Ç—Ä–∞–∑–∏. –†–µ—á–µ–Ω–∏—Ü–µ —Å–µ —Ç–∞–∫–æ—í–µ –º–æ–≥—É –ø—Ä–µ–ø–æ–∑–Ω–∞—Ç–∏ –∫–∞–æ –∑–∞—Å–µ–±–Ω–∏ –∏–Ω–¥–µ–∫—Å–Ω–∏ –ø–æ—ò–º–æ–≤–∏. –ù–∞–∫–æ–Ω —Ç–æ–≥–∞, –æ–¥–ª—É—á—É—ò–µ —Å–µ –æ –∑–Ω–∞—á–∞—ò—É —Å–≤–∞–∫–æ–≥ –ø–æ—ò–º–∞ —É –∑–∞—Å—Ç—É–ø–∞—ö—É —Å–∞–¥—Ä–∂–∞—ò–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–∏–ª–∏–∫–æ–º –¥–∞–≤–∞—ö–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ —É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É. –ó–Ω–∞—á–∞—ò –ø–æ—ò–º–∞ –ø –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∏ —Å —É –æ–∫–≤–∏—Ä—É –¥–∞—Ç–æ–≥ —Å–∫—É–ø–∞ –° —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –º–æ–∂–µ —Å–µ –æ–¥—Ä–µ–¥–∏—Ç–∏ –Ω–∞ –≤–∏—à–µ –Ω–∞—á–∏–Ω–∞. –ê–∫–æ —Ç—Ä–µ—Ç–∏—Ä–∞–º–æ —Å–≤–∞–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–æ —Ç–µ–∫—Å—Ç—É–∞–ª–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç, –æ–Ω–¥–∞ —Å–µ –∑–Ω–∞—á–∞—ò –ø –æ–±–∏—á–Ω–æ –∏–∑—Ä–∞—á—É–Ω–∞–≤–∞ –Ω–∞ –±–∞–∑–∏ –¥–≤–∏—ò–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ. –ü—Ä–≤–∞ —Å–µ –æ–¥–Ω–æ—Å–∏ –Ω–∞ —Ñ—Ä–µ–∫–≤–µ–Ω—Ç–Ω–æ—Å—Ç –ø–æ—ò–º–∞ (—Ñ–ø) —É —Å, –æ–¥–Ω–æ—Å–Ω–æ –±—Ä–æ—ò –ø—É—Ç–∞ –ø–æ—ò–∞–≤—ô–∏–≤–∞—ö–∞ –ø–æ—ò–º–∞ –ø —É —Å—Ç—Ä–∞–Ω–∏—Ü–∏ —Å, –∞ –¥—Ä—É–≥–∞ —Å–µ –æ–¥–Ω–æ—Å–∏ –Ω–∞ —Ñ—Ä–µ–∫–≤–µ–Ω—Ç–Ω–æ—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ñ–¥) —É —Å–∫—É–ø—É –°, –æ–¥–Ω–æ—Å–Ω–æ –±—Ä–æ—ò —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É —Å–∫—É–ø—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –° —É –∫–æ—ò–∏–º–∞ —Å–µ —Å—Ä–µ—õ–µ –ø–æ—ò–∞–º –ø. –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –≥–ª–µ–¥–∞–Ω–æ, —à—Ç–æ —Å–µ —É –≤–∏—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞–ª–∞–∑–∏ –ø–æ—ò–∞–º –ø, —Ç–æ —ò–µ –≤–∏—à–µ –±–∏—Ç–∞–Ω –∫–∞–æ –∑–∞—Å—Ç—É–ø–Ω–∏–∫ —Å–∞–¥—Ä–∂–∞—ò–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ. –ú–µ—í—É—Ç–∏–º, —à—Ç–æ —Å–µ —É –≤–∏—à–µ —Ä–∞–∑–ª–∏—á–∏—Ç–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ—ò–∞–≤—ô—É—ò–µ –ø–æ—ò–∞–º –ø, —É—Ç–æ–ª–∏–∫–æ —ò–µ –º–∞—ö–µ —É–ø–æ—Ç—Ä–µ–±—ô–∏–≤ –∑–∞ –¥–∏—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–∞—ö–µ —Ä–∞–∑–ª–∏—á–∏—Ç–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —ò–µ–¥–Ω–∏—Ö –æ–¥ –¥—Ä—É–≥–∏—Ö. –ö–∞–æ —Ä–µ–∑—É–ª—Ç–∞—Ç, –∑–Ω–∞—á–∞—ò –ø–æ—ò–º–∞ –±–∏ —Ç—Ä–µ–±–∞–ª–æ –¥–∞ –±—É–¥–µ –º–æ–Ω–æ–ª–∏—Ç–Ω–∞ –æ–ø–∞–¥–∞—ò—É—õ–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞ —ö–µ–≥–æ–≤–µ —Ñ—Ä–µ–∫–≤–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —É —Ä–∞–∑–ª–∏—á–∏—Ç–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∏–º–∞. –¢—Ä–µ–Ω—É—Ç–Ω–æ, –≤–µ—õ–∏–Ω–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —ò–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω–∞ —É —ò–µ–∑–∏–∫—É –∑–∞ –º–∞—Ä–∫–∏—Ä–∞—ö–µ —Ö–∏–ø–µ—Ä—Ç–µ–∫—Å—Ç–∞ (HTML), –∫–æ—ò–∏ –ø–æ—Å—ò–µ–¥—É—ò–µ —Å–∫—É–ø —Ç–∞–≥–æ–≤–∞ –∫–∞–æ —à—Ç–æ —Å—É title –∏ header. –¢–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–µ —Å–µ –º–æ–≥—É –∫–æ—Ä–∏—Å—Ç–∏—Ç–∏ –∑–∞ —É—Ç—ò–µ—Ü–∞—ö–µ –Ω–∞ –∑–Ω–∞—á–∞—ò –ø–æ—ò–º–æ–≤–∞ –∫–æ—ò–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—ô–∞—ò—É –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ. –ù–∞ –ø—Ä–∏–º—ò–µ—Ä, –ø–æ—ò–º–æ–≤–∏ –∫–æ—ò–∏ —Å–µ –Ω–∞–ª–∞–∑–µ —É –Ω–∞—Å–ª–æ–≤—É —ò–µ–¥–Ω–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ, –∏—Å—Ç–∞–∫–Ω—É—Ç–∏ –º–∞—Å–Ω–∏–º –∏–ª–∏ –∏—Å–∫–æ—à–µ–Ω–∏–º —Å–ª–æ–≤–∏–º–∞, –≤—Ä–ª–æ –≤—ò–µ—Ä–æ–≤–∞—Ç–Ω–æ —Å—É –∑–Ω–∞—á–∞—ò–Ω–∏—ò–∏ –∑–∞ –∑–∞—Å—Ç—É–ø–∞—ö–µ —ò–µ–¥–Ω–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–µ–≥–æ –æ–Ω–∏ –∫–æ—ò–∏ —Å–µ –ø–æ—ò–∞–≤—ô—É—ò—É —É —ö–µ–Ω–æ–º —Å–∞–¥—Ä–∂–∞—ò—É (body) –∏ –∫–æ—ò–∏ —Å—É –±–µ–∑ –ø–æ—Å–µ–±–Ω–æ–≥ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞—ö–∞. –£–æ–±–∏—á–∞—ò–µ–Ω–∏ —É–ø–∏—Ç –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É –≤–µ–±–∞ —Å–µ —Å–∞—Å—Ç–æ—ò–∏ –æ–¥ –Ω–µ–∫–∏—Ö –∫—ô—É—á–Ω–∏—Ö —Ä–∏—ò–µ—á–∏. –¢–∞–∫–∞–≤ —É–ø–∏—Ç —Å–µ —Ç–∞–∫–æ—í–µ –º–æ–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–∏ –∫–∞–æ —Å–∫—É–ø –ø–æ—ò–º–æ–≤–∞ —Å–∞ –æ–¥—Ä–µ—í–µ–Ω–∏–º –∑–Ω–∞—á–∞—ò–µ–º. –°—Ç–µ–ø–µ–Ω –ø–æ–∫–ª–∞–ø–∞—ö–∞ –∏–∑–º–µ—í—É —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ —É–ø–∏—Ç–∞, –æ–¥–Ω–æ—Å–Ω–æ —Ç–∞–∫–æ–∑–≤–∞–Ω–µ —Å–ª–∏—á–Ω–æ—Å—Ç–∏, –º–æ–∂–µ —Å–µ –º—ò–µ—Ä–∏—Ç–∏ –ø–æ—ò–º–æ–≤–∏–º–∞ –∫–æ—ò–µ –æ–Ω–∏ –º–µ—í—É—Å–æ–±–Ω–æ –¥–∏—ò–µ–ª–µ. –à–µ–¥–Ω–æ—Å—Ç–∞–≤–∞–Ω –ø—Ä–∏—Å—Ç—É–ø –æ–≤–æ–º –ø—Ä–æ–±–ª–µ–º—É —ò–µ –¥–∞ —Å–µ —Å–∞–±–∏—Ä–∞—ò—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏ –∑–Ω–∞—á–∞—ò–∞ –∫–æ—ò–∏ –æ–¥–≥–æ–≤–∞—Ä–∞—ò—É –ø–æ—ò–º–æ–≤–∏–º–∞ –∏–∑–º–µ—í—É —É–ø–∏—Ç–∞ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–µ. –û–≤–∞—ò –ø—Ä–∏—Å—Ç—É–ø –¥–∞—ò–µ –∫–∞–æ —Ä–µ–∑—É–ª—Ç–∞—Ç –≤–µ—õ–µ —Å–ª–∏—á–Ω–æ—Å—Ç–∏ –∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ –¥–∏—ò–µ–ª–µ –Ω–∞—ò–≤–∞–∂–Ω–∏—ò–µ –ø–æ—ò–º–æ–≤–µ —Å–∞ —Å–∞–º–∏–º —É–ø–∏—Ç–æ–º. –ú–µ—í—É—Ç–∏–º, –∏–º–∞ —Ç–µ–Ω–¥–µ–Ω—Ü–∏—ò—É –¥–∞ –¥–∞—ò–µ –ø—Ä–µ–¥–Ω–æ—Å—Ç –¥—É–∂–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∞ –Ω–∞–¥ –∫—Ä–∞—õ–∏–º. –û–≤–∞—ò –ø—Ä–æ–±–ª–µ–º —Å–µ –æ–±–∏—á–Ω–æ —Ä–∏—ò–µ—à–∞–≤–∞ —Ç–∞–∫–æ —à—Ç–æ —Å–µ –≥–æ—Ä—ö–∞ —Å–ª–∏—á–Ω–æ—Å—Ç –¥–∏—ò–µ–ª–∏ —Å–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–æ–º –∑–Ω–∞—á–∞—ò–∞ —É–ø–∏—Ç–∞ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–µ. –§—É–Ω–∫—Ü–∏—ò–∞ –∫–æ—ò–∞ –∏–∑—Ä–∞—á—É–Ω–∞–≤–∞ –æ–≤—É –≤—Ä—Å—Ç—É —Å–ª–∏—á–Ω–æ—Å—Ç–∏, –Ω–∞–∑–∏–≤–∞ —Å–µ –∫–æ—Å–∏–Ω—É—Å —Ñ—É–Ω–∫—Ü–∏—ò–∞. –î—É–∂–∏–Ω—É —Å–≤–∞–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —ò–µ –æ–≤–¥—ò–µ –º–æ–≥—É—õ–µ –∏–∑—Ä–∞—á—É–Ω–∞—Ç–∏ —É–Ω–∞–ø—Ä–∏—ò–µ–¥ –∏ —É—Å–∫–ª–∞–¥–∏—à—Ç–∏—Ç–∏ –Ω–∞ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É. –ü–æ—Å—Ç–æ—ò–µ –º–Ω–æ–≥–µ –º–µ—Ç–æ–¥–µ –∑–∞ —Ä–∞–Ω–≥–æ–≤–∞—ö–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞ –∫–æ—Ä–∏—Å–Ω–∏—á–∫–µ —É–ø–∏—Ç–µ, –∞ —Ä–∞–∑–ª–∏—á–∏—Ç–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –∏—Ö —Ä–∞–∑–ª–∏—á–∏—Ç–æ –∫–æ—Ä–∏—Å—Ç–µ. –ù–∞ –ø—Ä–∏–º—ò–µ—Ä, –Ω–µ–∫–µ –º–µ—Ç–æ–¥–µ —Ä–∞–Ω–≥–æ–≤–∞—ö–∞ –º–æ–≥—É —É–∑–µ—Ç–∏ —É –æ–±–∑–∏—Ä –±–ª–∏–∑–∏–Ω—É –ø–æ—ò–º–æ–≤–∞ –∫–æ—ò–∏ —Å—É –ø—Ä–µ–¥–º–µ—Ç —É–ø–∏—Ç–∞ —É –Ω–µ–∫–æ—ò —Å—Ç—Ä–∞–Ω–∏—Ü–∏. –ö–∞–æ –¥—Ä—É–≥–∏ –ø—Ä–∏–º—ò–µ—Ä, –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á –º–æ–∂–µ —Å–∞—á—É–≤–∞—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–µ –æ –±—Ä–æ—ò—É –ø—Ä–∏—Å—Ç—É–ø–∞ —Ä–∞–∑–ª–∏—á–∏—Ç–∏—Ö –∫–æ—Ä–∏—Å–Ω–∏–∫–∞ –æ–¥—Ä–µ—í–µ–Ω–æ—ò —Å—Ç—Ä–∞–Ω–∏—Ü–∏ –∏ –∏—Å–∫–æ—Ä–∏—Å—Ç–∏—Ç–∏ —Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–µ –∑–∞ —Ä–∞–Ω–≥–æ–≤–∞—ö–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–æ—ò–µ —õ–µ —Å–µ –ø—Ä–∏–∫–∞–∑–∞—Ç–∏ –ø–æ–≤–æ–¥–æ–º –±—É–¥—É—õ–∏—Ö —É–ø–∏—Ç–∞. –ù–∞ –≤–µ–±—É –ø–æ—Å—Ç–æ—ò–∏ –º–Ω–æ–≥–æ –ø–æ–ø—É–ª–∞—Ä–Ω–∏—Ö –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞, –∞–ª–∏ –ì—É–≥–ª —ò–µ —Å–º–∞—Ç—Ä–∞–Ω —ò–µ–¥–Ω–∏–º –æ–¥ –Ω–∞—ò–ø–æ–ø—É–ª–∞—Ä–Ω–∏—ò–∏—Ö. –ì–ª–∞–≤–Ω–∏ —Ä–∞–∑–ª–æ–≥ –∑–∞ —Ç–æ —ò–µ —ö–µ–≥–æ–≤–∞ –º–µ—Ç–æ–¥–∞ —Ä–∞–Ω–≥–æ–≤–∞—ö–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–æ—ò–∞ –∏–º–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç –¥–∞ —Ä–∞–∑–ª–∏–∫—É—ò–µ –Ω–∞—ò–≤–∞–∂–Ω–∏—ò–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ–¥ –º–∞—ö–µ –≤–∞–∂–Ω–∏—Ö —á–∞–∫ –∏ –∫–∞–¥–∞ —Å–µ —É —Å–≤–∏–º–∞ —ö–∏–º–∞ –∏—Å—Ç–∏ –±—Ä–æ—ò –ø—É—Ç–∞ –ø–æ—ò–∞–≤—ô—É—ò—É –ø–æ—ò–º–æ–≤–∏ –∫–æ—ò–∏ —Å—É –ø—Ä–µ–¥–º–µ—Ç —É–ø–∏—Ç–∞. –ó–∞ –æ–¥–ª—É—á–∏–≤–∞—ö–µ –æ –∑–Ω–∞—á–∞—ò—É —Å–≤–∞–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –ì—É–≥–ª –∫–æ—Ä–∏—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–µ –æ –ª–∏–Ω–∫–æ–≤–∞—ö—É –º–µ—í—É —ö–∏–º–∞, –æ–¥–Ω–æ—Å–Ω–æ –Ω–∞—á–∏–Ω –Ω–∞ –∫–æ—ò–∏ –ª–∏–Ω–∫—É—ò—É —ò–µ–¥–Ω–µ –Ω–∞ –¥—Ä—É–≥–µ. –¢–∞–∫–æ –ª–∏–Ω–∫ —Å–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ A –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ë –∞ –∫–æ—ò–∏ —ò–µ –ø–æ—Å—Ç–∞–≤–∏–æ –∞—É—Ç–æ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü–µ A, —Å–ª—É–∂–∏ –∫–∞–æ –∏–Ω–¥–∏–∫–∞—Ü–∏—ò–∞ –¥–∞ –∞—É—Ç–æ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü–µ A —Å–º–∞—Ç—Ä–∞ –¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ë –∏–º–∞ –Ω–µ–∫—É –≤—Ä–∏—ò–µ–¥–Ω–æ—Å—Ç. –ù–∞ —á–∏—Ç–∞–≤–æ–º –≤–µ–±—É, –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ë –º–æ–∂–µ –ª–∏–Ω–∫–æ–≤–∞—Ç–∏ –≤–µ—õ–∏ –±—Ä–æ—ò –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏ —Ç–∏ –ª–∏–Ω–∫–æ–≤–∏ –º–æ–≥—É –ø–æ—Å–ª—É–∂–∏—Ç–∏ –∑–∞ –æ–¥–ª—É—á–∏–≤–∞—ö–µ –æ —ö–µ–Ω–æ—ò —Å–≤–µ—É–∫—É–ø–Ω–æ—ò –≤—Ä–∏—ò–µ–¥–Ω–æ—Å—Ç–∏ –∏–ª–∏ –∑–Ω–∞—á–∞—ò—É. –ó–∞ –¥–∞—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—É, PageRank —ò–µ –º—ò–µ—Ä–∞ —ö–µ–Ω–æ–≥ —Ä–µ–ª–∞—Ç–∏–≤–Ω–æ–≥ –∑–Ω–∞—á–∞—ò–∞ –Ω–∞ –≤–µ–±—É, –∏ –æ–Ω —Å–µ –∏–∑—Ä–∞—á—É–Ω–∞–≤–∞ –Ω–∞ –±–∞–∑–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ –æ –ª–∏–Ω–∫–æ–≤–∞—ö—É.[4] –¢—Ä–∏ –≥–ª–∞–≤–Ω–µ –∏–¥–µ—ò–µ —Å—Ç–æ—ò–µ –∏–∑–∞ –¥–µ—Ñ–∏–Ω–∏—Å–∞—ö–∞ –∑–Ω–∞—á–∞—ò–∞ –∏ –∏–∑—Ä–∞—á—É–Ω–∞–≤–∞—ö–∞ PageRank-a: (1) –°—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ —Å—É –ª–∏–Ω–∫–æ–≤–∞–Ω–µ —Å–∞ –≤–∏—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å—É –Ω–∞—ò–≤—ò–µ—Ä–æ–≤–∞—Ç–Ω–∏—ò–µ –Ω–∞—ò–≤–∞–∂–Ω–∏—ò–µ. –î—Ä—É–≥–∏–º —Ä–∏—ò–µ—á–∏–º–∞, –∑–Ω–∞—á–∞—ò —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç—Ä–µ–±–∞ –¥–∞ —Å–µ —É—Å–ø–æ—Å—Ç–∞–≤–∏ –Ω–∞ –æ—Å–Ω–æ–≤—É —ö–µ–Ω–µ –ø–æ–ø—É–ª–∞—Ä–Ω–æ—Å—Ç–∏ –º–µ—í—É –∞—É—Ç–æ—Ä–∏–º–∞ —Å–≤–∏—Ö –¥—Ä—É–≥–∏—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞. (2) –°—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ —Å—É –ª–∏–Ω–∫–æ–≤–∞–Ω–µ —Å–∞ –Ω–∞—ò–∑–Ω–∞—á–∞—ò–Ω–∏—ò–∏—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞—ò–≤—ò–µ—Ä–æ–≤–∞—Ç–Ω–∏—ò–µ –∏ —Å–∞–º–µ –∏–º–∞—ò—É –ø–æ—Å–µ–±–∞–Ω –∑–Ω–∞—á–∞—ò. (3) –°—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–µ –∏–º–∞—ò—É –ª–∏–Ω–∫–æ–≤–µ –Ω–∞ –≤–∏—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏–º–∞—ò—É –º–∞—ö–µ —É—Ç–∏—Ü–∞—ò–∞ –Ω–∞ –∑–Ω–∞—á–∞—ò —Å–≤–∞–∫–µ –ª–∏–Ω–∫–æ–≤–∞–Ω–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ—ò–µ–¥–∏–Ω–∞—á–Ω–æ. –î—Ä—É–≥–∏–º —Ä–∏—ò–µ—á–∏–º–∞, –∞–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏–º–∞ –≤–∏—à–µ –ø–æ–¥—Å—Ç—Ä–∞–Ω–∏—Ü–∞, –æ–Ω–¥–∞ –æ–Ω–∞ —ò–µ–¥–∏–Ω–æ –º–æ–∂–µ –ø—Ä–µ–Ω–∏—ò–µ—Ç–∏ –º–∞—ö–∏ –¥–∏–æ —Å–≤–æ–≥ –∑–Ω–∞—á–∞—ò–∞ –Ω–∞ —Å–≤–∞–∫—É –æ–¥ —ö–∏—Ö. –ù–∞ –æ—Å–Ω–æ–≤—É –æ–≤–∏—Ö —Å—Ö–≤–∞—Ç–∞—ö–∞ –ì—É–≥–ª–æ–≤–∏ –æ—Å–Ω–∏–≤–∞—á–∏ —Å—É —Ä–∞–∑–≤–∏–ª–∏ –º–µ—Ç–æ–¥ –∑–∞ –∏–∑—Ä–∞—á—É–Ω–∞–≤–∞—ö–µ –∑–Ω–∞—á–∞—ò–∞ (PageRank) —Å–≤–∞–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–∞ –≤–µ–±—É.[4] PageRank –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–µ —Å–µ –º–æ–∂–µ –∫–æ–º–±–∏–Ω–æ–≤–∞—Ç–∏ —Å–∞ –¥—Ä—É–≥–∏–º –º—ò–µ—Ä–∞–º–∞ –Ω–∞ –±–∞–∑–∏ —Å–∞–¥—Ä–∂–∞—ò–∞ –∑–∞ –∏–Ω–¥–∏–∫–∞—Ü–∏—ò—É —ö–µ–Ω–æ–≥ —Å–≤–µ—É–∫—É–ø–Ω–æ–≥ –∑–Ω–∞—á–∞—ò–∞ —É –æ–¥–Ω–æ—Å—É –Ω–∞ –¥–∞—Ç–∏ —É–ø–∏—Ç. –ù–∞ –ø—Ä–∏–º—ò–µ—Ä, –∑–∞ –∑–∞–¥–∞—Ç–∏ —É–ø–∏—Ç x, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –º–æ–∂–µ –±–∏—Ç–∏ —Ä–∞–Ω–≥–æ–≤–∞–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤—É –ø–æ–Ω–¥–µ—Ä–∏—Å–∞–Ω–æ–≥ –∑–±–∏—Ä–∞ —ö–µ–Ω–∏—Ö —Å–ª–∏—á–Ω–æ—Å—Ç–∏ —Å–∞ —É–ø–∏—Ç–æ–º –∏ —ö–µ–Ω–æ–≥ PageRank-–∞. –ú–µ—í—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∞ —Å–∞ –≤–µ–ª–∏–∫–∏–º —Å–ª–∏—á–Ω–æ—Å—Ç–∏–º–∞, –æ–≤–∞—ò –º–µ—Ç–æ–¥ —õ–µ –¥–∞—Ç–∏ –ø—Ä–µ–¥–Ω–æ—Å—Ç –æ–Ω–∏–º–∞ –∫–æ—ò–µ –∏–º–∞—ò—É –≤–∏—à–∏ PageRank. –ó–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–µ –∫–∞–∂–µ –¥–∞ —ò–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞, —É–∫–æ–ª–∏–∫–æ –∫–æ—Ä–∏—Å–Ω–∏–∫ –∫–æ—ò–∏ —ò–µ –∏–∑–≤—Ä—à–∏–æ —É–ø–∏—Ç –Ω–∞–ª–∞–∑–∏ –¥–∞ —ò–µ –∫–æ—Ä–∏—Å–Ω–∞. –ó–∞ –∑–∞–¥–∞—Ç–∏ —É–ø–∏—Ç –∫–æ—Ä–∏—Å–Ω–∏–∫–∞ –Ω–∞ —Ñ–∏–∫—Å–Ω–∏ —Å–∫—É–ø —Å—Ç—Ä–∞–Ω–∏—Ü–∞, —Å–∫—É–ø –æ–Ω–∏—Ö –∫–æ—ò–µ —Å—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–µ —ò–µ —Ç–∞–∫–æ—í–µ —Ñ–∏–∫—Å–∞–Ω. –î–æ–±–∞—Ä —Å–∏—Å—Ç–µ–º –ø—Ä–µ—Ç—Ä–∞–≥–µ —Ç—Ä–µ–±–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫—É –¥–∞ –≤—Ä–∞—Ç–∏ –≤–∏—Å–æ–∫ —Å—Ç–µ–ø–µ–Ω —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–∞–æ –∏ –¥–∞ –∏—Ö —Ä–∞–Ω–≥—É—ò–µ –≤–∏—Å–æ–∫–æ —É –ø–æ–≤—Ä–∞—Ç–Ω–∏–º —Ä–µ–∑—É–ª—Ç–∞—Ç–∏–º–∞. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–∞–ª–Ω–æ, –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ —Å–µ –º—ò–µ—Ä–∏ –ø—Ä–µ–∫–æ –¥–≤–∞ –∫–æ–ª–∏—á–Ω–∏–∫–∞ –ø–æ–∑–Ω–∞—Ç–∞ –∫–∞–æ –æ–¥–∑–∏–≤ –∏ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç. –ö–æ–¥ —É–ø–∏—Ç–∞ —É —Å–∫—É–ø –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ x, –æ–¥–∑–∏–≤ —ò–µ –ø—Ä–æ—Ü–µ–Ω–∞—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ –∫–æ—ò–∏ —Å–µ –Ω–∞ —É–ø–∏—Ç –æ–¥–∑–∏–≤–∞—ò—É, –∞ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç —ò–µ –ø—Ä–æ—Ü–µ–Ω–∞—Ç –æ–¥–∑–≤–∞–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ –∫–æ—ò–∏ —Å—É –∑–∞ —É–ø–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏. –î–∞ –±–∏ —Å–µ –æ—Ü–∏—ò–µ–Ω–∏–ª–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç —ò–µ–¥–Ω–æ–≥ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ, –≤—Ä—à–µ —Å–µ –ø—Ä–æ–±–µ –Ω–∏–∑–æ–º —É–ø–∏—Ç–∞. –ó–∞ —Å–≤–∞–∫–∏ –ø–æ—Å–µ–±–∞–Ω —É–ø–∏—Ç, —Å–∫—É–ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ —Å–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫—É—ò–µ —É–Ω–∞–ø—Ä–∏—ò–µ–¥. –ö–æ–¥ —Å–≤–∞–∫–æ–≥ –ø—Ä–æ–±–Ω–æ–≥ —É–ø–∏—Ç–∞ —Ç—Ä–∞–∂–∏ —Å–µ –≤—Ä–∏—ò–µ–¥–Ω–æ—Å—Ç –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ –∑–∞ —Å–≤–∞–∫—É —Ç–∞—á–∫—É –æ–¥–∑–∏–≤–∞ –ø–æ–Ω–∞–æ—Å–æ–±. –ö–∞–¥–∞ —Å–µ –Ω–∞–ø—Ä–∞–≤–∏ —ò–µ–¥–Ω–∞ –ø—Ä–æ—Å—ò–µ—á–Ω–∞ –≤—Ä–∏—ò–µ–¥–Ω–æ—Å—Ç –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ –∑–∞ —Å–≤–∞–∫—É —Ç–∞—á–∫—É –æ–¥–∑–∏–≤–∞, –æ–Ω–¥–∞ —Å–µ –¥–æ–±–∏—ò–µ –∫—Ä–∏–≤–∞ —É–∫—É–ø–Ω–µ –ø—Ä–æ—Å—ò–µ—á–Ω–µ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ –∫–æ—ò–∞ —Å–ª—É–∂–∏ –∫–∞–æ –º—ò–µ—Ä–∞ —ö–µ–≥–æ–≤–µ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –à–µ–¥–∞–Ω —Å–∏—Å—Ç–µ–º –ø—Ä–µ—Ç—Ä–∞–≥–µ —Å–µ —Å–º–∞—Ç—Ä–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏—ò–∏–º –æ–¥ –¥—Ä—É–≥–æ–≥, —É–∫–æ–ª–∏–∫–æ —ò–µ —ö–µ–≥–æ–≤–∞ –∫—Ä–∏–≤–∞ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ –∏ –æ–¥–∑–∏–≤–∞ –∏–∑–Ω–∞–¥ –∫—Ä–∏–≤–µ –¥—Ä—É–≥–æ–≥. –ö–æ–¥ —Å–∞–≤—Ä—à–µ–Ω–æ–≥ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ –≤—Ä–∏—ò–µ–¥–Ω–æ—Å—Ç–∏ –æ–¥–∑–∏–≤–∞ –∏ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–±–∞ –¥–∞ –±—É–¥—É —ò–µ–¥–Ω–∞–∫–µ –±—Ä–æ—ò—É 1. –î—Ä—É–≥–∏–º —Ä–∏—ò–µ—á–∏–º–∞, —Ç–∞–∫–∞–≤ —Å–∏—Å—Ç–µ–º –ø—Ä–æ–Ω–∞–ª–∞–∑–∏ —Ç–∞—á–∞–Ω —Å–∫—É–ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ –∑–∞ —Å–≤–∞–∫–∏ —É–ø–∏—Ç. –£ –ø—Ä–∞–∫—Å–∏, —Å–∞–≤—Ä—à–µ–Ω —É—á–∏–Ω–∞–∫ –Ω–∏—ò–µ –æ—Å—Ç–≤–∞—Ä—ô–∏–≤ –∏–∑ –º–Ω–æ–≥–æ —Ä–∞–∑–ª–æ–≥–∞. –ù–∞ –ø—Ä–∏–º—ò–µ—Ä, –ø–æ—Ç—Ä–µ–±–µ –∫–æ—Ä–∏—Å–Ω–∏–∫–∞ –∑–∞ –æ–¥—Ä–µ—í–µ–Ω–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞–º–∞ –æ–±–∏—á–Ω–æ –Ω–µ –º–æ–≥—É –±–∏—Ç–∏ –ø—Ä–µ—Ü–∏–∑–Ω–æ –¥–µ—Ñ–∏–Ω–∏—Å–∞–Ω–µ –ø—Ä–æ–±–Ω–∏–º —É–ø–∏—Ç–æ–º, –∞–ª–∏ –Ω–∏ —Å–∞–º —Å–∞–¥—Ä–∂–∞—ò —É –¥–æ–∫—É–º–µ–Ω—Ç–∏–º–∞, –∫–∞–æ –Ω–∏ —É —É–ø–∏—Ç–∏–º–∞, —Å–µ –Ω–µ –º–æ–∂–µ —É –ø–æ—Ç–ø—É–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–∏ –ø–æ–Ω–¥–µ—Ä–∏—Å–∞–Ω–∏–º –ø–æ—ò–º–æ–≤–∏–º–∞. –£–ø–æ—Ç—Ä–µ–±–∞ –æ–¥–∑–∏–≤–∞ –∏ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ –∑–∞ –º—ò–µ—Ä–µ—ö–µ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–∞–ª–Ω–æ–≥ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ—Ç—Ä–∞–≥–µ —Ç–µ–∫—Å—Ç–∞, –∑–∞—Ö—Ç–∏—ò–µ–≤–∞ –¥–∞ —ò–µ —É–Ω–∞–ø—Ä–∏—ò–µ–¥ –ø–æ–∑–Ω–∞—Ç –±—Ä–æ—ò —Å–≤–∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω–∞—Ç–∞ –∑–∞ —Å–≤–∞–∫–∏ –ø—Ä–æ–±–Ω–∏ —É–ø–∏—Ç. –ú–µ—í—É—Ç–∏–º, –æ–≤–æ –Ω–∏—ò–µ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ –∑–∞ –æ—Ü—ò–µ—ö–∏–≤–∞—ö–µ –∏ –Ω–µ–∑–∞–≤–∏—Å–Ω–æ –≤—Ä–µ–¥–Ω–æ–≤–∞—ö–µ –≤–µ–ª–∏–∫–∏—Ö –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞, –±—É–¥—É—õ–∏ –¥–∞ —ò–µ –Ω–µ–º–æ–≥—É—õ–µ –∑–Ω–∞—Ç–∏ –±—Ä–æ—ò —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞ —Å–≤–∞–∫–∏ —É–ø–∏—Ç —É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É, —É–∫–æ–ª–∏–∫–æ —Å–µ —Å–≤–µ –æ–Ω–µ —Ä—É—á–Ω–æ –Ω–µ –ø—Ä–µ–≥–ª–µ–¥–∞—ò—É. –ë–µ–∑ –ø–æ–∑–Ω–∞–≤–∞—ö–∞ –±—Ä–æ—ò–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞ —Å–≤–∞–∫–∏ –ø—Ä–æ–±–Ω–∏ —É–ø–∏—Ç, –º—ò–µ—Ä–∞ –æ–¥–∑–∏–≤–∞ —Å–µ –Ω–µ –º–æ–∂–µ –∏–∑—Ä–∞—á—É–Ω–∞—Ç–∏. –ö–∞–æ —Ä–µ–∑—É–ª—Ç–∞—Ç –æ–≤–æ–≥ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–≥ –æ–≥—Ä–∞–Ω–∏—á–µ—ö–∞, –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ —Å–µ —á–µ—Å—Ç–æ –æ—Ü—ò–µ—ö—É—ò—É –Ω–∞ –æ—Å–Ω–æ–≤—É —Å—Ä–µ–¥—ö–µ –ø—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç–∏ –∫–æ—ò–∞ —Å–µ –∏–∑—Ä–∞—á—É–Ω–∞–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤—É –Ω–∞—ò—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—ò–∏—Ö –æ–¥–∑–≤–∞–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∫ –∑–∞ —Å–∫—É–ø –ø—Ä–æ–±–Ω–∏—Ö —É–ø–∏—Ç–∞ –∑–∞ –Ω–µ–∫–∏ –º–∞–ª–∏ —Ü–∏—ò–µ–ª–∏ –±—Ä–æ—ò ‚Äî—Ä–µ—Ü–∏–º–æ 20, –∏–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤—É –ø—Ä–æ—Å—ò–µ—á–Ω–µ –ø–æ–∑–∏—Ü–∏—ò–µ –ø—Ä–≤–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–æ—ò–∞ —ò–µ –ø–æ–≤—Ä–∞—Ç–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç —É —Å–≤–∞–∫–æ–º –ø–æ—ò–µ–¥–∏–Ω–∞—á–Ω–æ–º –ø—Ä–æ–±–Ω–æ–º —É–ø–∏—Ç—É.[5] –ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –≤–µ–±–∞ —Å—É, —É –æ—Å–Ω–æ–≤–∏, –µ–∫—Å–ø–µ—Ä—Ç—Å–∫–∏ —Å–∏—Å—Ç–µ–º–∏ –∫–æ—ò–∏ –∏–º–∞—ò—É –∑–∞ —Ü–∏—ô —Å—Ç–≤–∞—Ä–∞—ö–µ —à—Ç–æ –≤–∏—à–µ —Ö–µ—É—Ä–∏—Å—Ç–∏–∫–∞ —Å–ø–æ—Å–æ–±–Ω–∏—Ö –∑–∞ –ø–æ–º–æ—õ –µ–∫—Å–ø–µ—Ä—Ç—Å–∫–æ–º —Å–∏—Å—Ç–µ–º—É —É –ø—Ä–µ–¥–≤–∏—í–∞—ö—É —à—Ç–∞ —ò–µ —Ç–æ —à—Ç–æ –∫–æ—Ä–∏—Å–Ω–∏–∫ —Ç—Ä–∞–∂–∏. –°–ø–µ—Ü–∏—ò–∞–ª–∏–∑–æ–≤–∞–Ω–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∏ –≤–µ–±–∞ –∑–∞ —Å–≤—Ä—Ö—É –∏–º–∞—ò—É —Ç—Ä–∞–∂–µ—ö–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ —É –≤–µ–∑–∏ —Å–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–º –æ–±–ª–∞—à—õ—É."
  },
  {
    "url": "https://sh.wikipedia.org/wiki/Veb-pretra%C5%BEiva%C4%8D",
    "title": "Veb-pretra≈æivaƒç ‚Äì Wikipedija / –í–∏–∫–∏–ø–µ–¥–∏—ò–∞",
    "content": "Web search engine [w…õb s…úÀêtÕ° É Àà…õnd í…™n] (od engl. web: mre≈æa + search engine: stroj za pretra≈æivanje), softverski sistem dizajniran za pretra≈æivanje informacija na World Wide Webu. Katkad se za nj upotrebljavaju jo≈° nazivi web tra≈æilica i web pretra≈æivaƒç, posljednje ƒçesto istovremeno za web browser. Rezultati pretra≈æivanja opƒáenito su predstavljeni linijom rezultat√¢, odnosno stranicama tra≈æilice s rezultatima ili SERP-ovima (akr. od engl. search engine results page). Informacije mogu biti mje≈°avina web stranica, slika i drugih tipova datoteka. Neke tra≈æilice ƒçesto kopaju podatke dostupne u bazama podataka ili otvorenim direktorijima. Za razliku od web direktorij√¢, koje odr≈æavaju tek humani urednici, tra≈æilice takoƒëer odr≈æavaju informacije u realnom vremenu tako ≈°to pokreƒáu algoritam na web crawleru. Najpoznatiji dana≈°nji web search engine jest Google Search, a od drugih su poznati Yahoo! Search i Bing. Same internetske tra≈æilice postojale su prije debija weba u decembru 1990. Pretra≈æivanje korisnika WHOIS postoji od 1982.,[1] a mnogomre≈æno pretra≈æivanje korisnika Knowbot Information Service (KIS) prvi put je implementirano 1989.[2] Prva dobro dokumentirana tra≈æilica koja je pretra≈æivala sadr≈æajne datoteke, prije svega datoteke FTP-a, bio je Archie, koji je debitirao 10. septembra 1990."
  }
]